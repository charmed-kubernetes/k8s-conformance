  I0518 12:06:07.730560      19 e2e.go:117] Starting e2e run "27a801cb-a3ce-417b-86ca-2e2c2343835c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1716033967 - will randomize all specs

Will run 388 of 7408 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:77
  May 18 12:06:07.955: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:06:07.956: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  May 18 12:06:07.987: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  May 18 12:06:07.991: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  May 18 12:06:07.991: INFO: e2e test version: v1.29.5
  May 18 12:06:07.992: INFO: kube-apiserver version: v1.29.5
  May 18 12:06:07.992: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:06:07.997: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.042 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/18/24 12:06:08.234
  May 18 12:06:08.234: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 12:06:08.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:08.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:08.258
  STEP: Create a Replicaset @ 05/18/24 12:06:08.267
  STEP: Verify that the required pods have come up. @ 05/18/24 12:06:08.273
  May 18 12:06:08.276: INFO: Pod name sample-pod: Found 0 pods out of 1
  May 18 12:06:13.281: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 12:06:13.281
  STEP: Getting /status @ 05/18/24 12:06:13.281
  May 18 12:06:13.286: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/18/24 12:06:13.286
  May 18 12:06:13.295: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/18/24 12:06:13.295
  May 18 12:06:13.297: INFO: Observed &ReplicaSet event: ADDED
  May 18 12:06:13.297: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.297: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.297: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.297: INFO: Found replicaset test-rs in namespace replicaset-1952 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 18 12:06:13.297: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/18/24 12:06:13.297
  May 18 12:06:13.297: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 18 12:06:13.304: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/18/24 12:06:13.304
  May 18 12:06:13.305: INFO: Observed &ReplicaSet event: ADDED
  May 18 12:06:13.305: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.305: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.306: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.306: INFO: Observed replicaset test-rs in namespace replicaset-1952 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 12:06:13.306: INFO: Observed &ReplicaSet event: MODIFIED
  May 18 12:06:13.306: INFO: Found replicaset test-rs in namespace replicaset-1952 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  May 18 12:06:13.306: INFO: Replicaset test-rs has a patched status
  May 18 12:06:13.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1952" for this suite. @ 05/18/24 12:06:13.309
• [5.082 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 05/18/24 12:06:13.316
  May 18 12:06:13.316: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/18/24 12:06:13.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:13.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:13.339
  STEP: create the container to handle the HTTPGet hook request. @ 05/18/24 12:06:13.345
  STEP: create the pod with lifecycle hook @ 05/18/24 12:06:17.374
  STEP: delete the pod with lifecycle hook @ 05/18/24 12:06:25.406
  STEP: check prestop hook @ 05/18/24 12:06:27.422
  May 18 12:06:27.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9996" for this suite. @ 05/18/24 12:06:27.448
• [14.139 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 05/18/24 12:06:27.455
  May 18 12:06:27.455: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 12:06:27.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:27.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:27.477
  STEP: Creating service test in namespace statefulset-5665 @ 05/18/24 12:06:27.479
  May 18 12:06:27.495: INFO: Found 0 stateful pods, waiting for 1
  May 18 12:06:37.495: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/18/24 12:06:37.501
  W0518 12:06:37.511665      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  May 18 12:06:37.521: INFO: Found 1 stateful pods, waiting for 2
  May 18 12:06:47.521: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:06:47.521: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/18/24 12:06:47.528
  STEP: Delete all of the StatefulSets @ 05/18/24 12:06:47.53
  STEP: Verify that StatefulSets have been deleted @ 05/18/24 12:06:47.537
  May 18 12:06:47.540: INFO: Deleting all statefulset in ns statefulset-5665
  May 18 12:06:47.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5665" for this suite. @ 05/18/24 12:06:47.559
• [20.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 05/18/24 12:06:47.566
  May 18 12:06:47.566: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:06:47.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:47.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:47.586
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:06:47.588
  STEP: Saw pod success @ 05/18/24 12:06:51.605
  May 18 12:06:51.608: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-abb697c5-f524-4152-87eb-330ba2955605 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:06:51.626
  May 18 12:06:51.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-268" for this suite. @ 05/18/24 12:06:51.645
• [4.086 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/18/24 12:06:51.652
  May 18 12:06:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:06:51.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:51.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:51.673
  STEP: Creating projection with secret that has name projected-secret-test-4e63c34d-4aae-4463-8d83-e0bde6420ff3 @ 05/18/24 12:06:51.675
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:06:51.68
  STEP: Saw pod success @ 05/18/24 12:06:55.703
  May 18 12:06:55.706: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-secrets-1ec53600-4c59-4c90-932e-51ca2693c5cb container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:06:55.714
  May 18 12:06:55.731: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2411" for this suite. @ 05/18/24 12:06:55.733
• [4.086 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 05/18/24 12:06:55.739
  May 18 12:06:55.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:06:55.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:55.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:55.761
  STEP: Creating configMap with name projected-configmap-test-volume-7154f1ae-b6ba-4eb8-9a28-ba47e8ee4867 @ 05/18/24 12:06:55.766
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:06:55.771
  STEP: Saw pod success @ 05/18/24 12:06:59.796
  May 18 12:06:59.799: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-configmaps-c98a8529-2935-479b-84cd-6c8f10714088 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:06:59.806
  May 18 12:06:59.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-832" for this suite. @ 05/18/24 12:06:59.831
• [4.098 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 05/18/24 12:06:59.837
  May 18 12:06:59.837: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubelet-test @ 05/18/24 12:06:59.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:06:59.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:06:59.86
  May 18 12:07:01.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5501" for this suite. @ 05/18/24 12:07:01.895
• [2.066 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 05/18/24 12:07:01.903
  May 18 12:07:01.903: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename containers @ 05/18/24 12:07:01.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:01.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:01.974
  STEP: Creating a pod to test override arguments @ 05/18/24 12:07:01.977
  STEP: Saw pod success @ 05/18/24 12:07:03.992
  May 18 12:07:03.996: INFO: Trying to get logs from node ip-172-31-33-93 pod client-containers-2cc43921-ab7f-4e40-a80e-30bd3be2905a container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:07:04.003
  May 18 12:07:04.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9069" for this suite. @ 05/18/24 12:07:04.021
• [2.127 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 05/18/24 12:07:04.03
  May 18 12:07:04.030: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:07:04.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:04.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:04.051
  STEP: Setting up server cert @ 05/18/24 12:07:04.075
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:07:04.273
  STEP: Deploying the webhook pod @ 05/18/24 12:07:04.282
  STEP: Wait for the deployment to be ready @ 05/18/24 12:07:04.293
  May 18 12:07:04.300: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/18/24 12:07:06.312
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:07:06.322
  May 18 12:07:07.323: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/18/24 12:07:07.396
  STEP: Creating a configMap that should be mutated @ 05/18/24 12:07:07.408
  STEP: Deleting the collection of validation webhooks @ 05/18/24 12:07:07.44
  STEP: Creating a configMap that should not be mutated @ 05/18/24 12:07:07.484
  May 18 12:07:07.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4145" for this suite. @ 05/18/24 12:07:07.535
  STEP: Destroying namespace "webhook-markers-798" for this suite. @ 05/18/24 12:07:07.542
• [3.524 seconds]
------------------------------
S
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 05/18/24 12:07:07.554
  May 18 12:07:07.554: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:07:07.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:07.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:07.575
  STEP: creating service in namespace services-7369 @ 05/18/24 12:07:07.577
  STEP: creating service affinity-nodeport in namespace services-7369 @ 05/18/24 12:07:07.577
  STEP: creating replication controller affinity-nodeport in namespace services-7369 @ 05/18/24 12:07:07.593
  I0518 12:07:07.603493      19 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-7369, replica count: 3
  I0518 12:07:10.654375      19 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 12:07:10.666: INFO: Creating new exec pod
  May 18 12:07:13.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-7369 exec execpod-affinity8kf8b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  May 18 12:07:13.789: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  May 18 12:07:13.789: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:07:13.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-7369 exec execpod-affinity8kf8b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.152 80'
  May 18 12:07:13.883: INFO: stderr: "+ nc -v -t -w 2 10.152.183.152 80\nConnection to 10.152.183.152 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  May 18 12:07:13.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:07:13.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-7369 exec execpod-affinity8kf8b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.33.93 30340'
  May 18 12:07:13.975: INFO: stderr: "+ nc -v -t -w 2 172.31.33.93 30340\nConnection to 172.31.33.93 30340 port [tcp/*] succeeded!\n+ echo hostName\n"
  May 18 12:07:13.975: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:07:13.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-7369 exec execpod-affinity8kf8b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.70.23 30340'
  May 18 12:07:14.066: INFO: stderr: "+ nc -v -t -w 2 172.31.70.23 30340\n+ echo hostName\nConnection to 172.31.70.23 30340 port [tcp/*] succeeded!\n"
  May 18 12:07:14.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:07:14.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-7369 exec execpod-affinity8kf8b -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.33.93:30340/ ; done'
  May 18 12:07:14.200: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30340/\n"
  May 18 12:07:14.200: INFO: stdout: "\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l\naffinity-nodeport-nbx4l"
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Received response from host: affinity-nodeport-nbx4l
  May 18 12:07:14.200: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-7369, will wait for the garbage collector to delete the pods @ 05/18/24 12:07:14.218
  May 18 12:07:14.279: INFO: Deleting ReplicationController affinity-nodeport took: 7.564354ms
  May 18 12:07:14.380: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.938901ms
  May 18 12:07:17.605: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7369" for this suite. @ 05/18/24 12:07:17.609
• [10.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 05/18/24 12:07:17.618
  May 18 12:07:17.618: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:07:17.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:17.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:17.638
  STEP: starting the proxy server @ 05/18/24 12:07:17.641
  May 18 12:07:17.641: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-2142 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/18/24 12:07:17.669
  May 18 12:07:17.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2142" for this suite. @ 05/18/24 12:07:17.678
• [0.066 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/18/24 12:07:17.684
  May 18 12:07:17.684: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename apf @ 05/18/24 12:07:17.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:17.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:17.703
  STEP: getting /apis @ 05/18/24 12:07:17.706
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/18/24 12:07:17.708
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/18/24 12:07:17.709
  STEP: creating @ 05/18/24 12:07:17.71
  STEP: getting @ 05/18/24 12:07:17.727
  STEP: listing @ 05/18/24 12:07:17.73
  STEP: watching @ 05/18/24 12:07:17.732
  May 18 12:07:17.732: INFO: starting watch
  STEP: patching @ 05/18/24 12:07:17.733
  STEP: updating @ 05/18/24 12:07:17.738
  May 18 12:07:17.744: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 05/18/24 12:07:17.745
  STEP: patching /status @ 05/18/24 12:07:17.748
  STEP: updating /status @ 05/18/24 12:07:17.754
  STEP: deleting @ 05/18/24 12:07:17.763
  STEP: deleting a collection @ 05/18/24 12:07:17.775
  May 18 12:07:17.792: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-8108" for this suite. @ 05/18/24 12:07:17.795
• [0.117 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 05/18/24 12:07:17.802
  May 18 12:07:17.802: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:07:17.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:17.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:17.821
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:07:17.824
  STEP: Saw pod success @ 05/18/24 12:07:19.84
  May 18 12:07:19.843: INFO: Trying to get logs from node ip-172-31-70-23 pod downwardapi-volume-0d6d4bcc-acf6-4e5f-bee1-4529057c73fd container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:07:19.849
  May 18 12:07:19.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4221" for this suite. @ 05/18/24 12:07:19.868
• [2.075 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 05/18/24 12:07:19.877
  May 18 12:07:19.877: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 12:07:19.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:07:19.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:07:19.897
  May 18 12:08:19.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9252" for this suite. @ 05/18/24 12:08:19.918
• [60.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 05/18/24 12:08:19.927
  May 18 12:08:19.927: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 12:08:19.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:08:19.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:08:19.947
  STEP: create the rc1 @ 05/18/24 12:08:19.952
  STEP: create the rc2 @ 05/18/24 12:08:19.956
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/18/24 12:08:25.967
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/18/24 12:08:26.403
  STEP: wait for the rc to be deleted @ 05/18/24 12:08:26.413
  May 18 12:08:31.425: INFO: 68 pods remaining
  May 18 12:08:31.425: INFO: 68 pods has nil DeletionTimestamp
  May 18 12:08:31.425: INFO: 
  STEP: Gathering metrics @ 05/18/24 12:08:36.428
  W0518 12:08:36.432457      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 12:08:36.432: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 12:08:36.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-24nrv" in namespace "gc-845"
  May 18 12:08:36.449: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bqbk" in namespace "gc-845"
  May 18 12:08:36.461: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kd48" in namespace "gc-845"
  May 18 12:08:36.476: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tl6m" in namespace "gc-845"
  May 18 12:08:36.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-44cgg" in namespace "gc-845"
  May 18 12:08:36.506: INFO: Deleting pod "simpletest-rc-to-be-deleted-45lj5" in namespace "gc-845"
  May 18 12:08:36.517: INFO: Deleting pod "simpletest-rc-to-be-deleted-4czx6" in namespace "gc-845"
  May 18 12:08:36.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dqql" in namespace "gc-845"
  May 18 12:08:36.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-62bhs" in namespace "gc-845"
  May 18 12:08:36.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hwkh" in namespace "gc-845"
  May 18 12:08:36.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hx45" in namespace "gc-845"
  May 18 12:08:36.589: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rwxk" in namespace "gc-845"
  May 18 12:08:36.606: INFO: Deleting pod "simpletest-rc-to-be-deleted-6sjwf" in namespace "gc-845"
  May 18 12:08:36.618: INFO: Deleting pod "simpletest-rc-to-be-deleted-74sg4" in namespace "gc-845"
  May 18 12:08:36.641: INFO: Deleting pod "simpletest-rc-to-be-deleted-78zw8" in namespace "gc-845"
  May 18 12:08:36.653: INFO: Deleting pod "simpletest-rc-to-be-deleted-79qs7" in namespace "gc-845"
  May 18 12:08:36.666: INFO: Deleting pod "simpletest-rc-to-be-deleted-7v8gt" in namespace "gc-845"
  May 18 12:08:36.680: INFO: Deleting pod "simpletest-rc-to-be-deleted-7wdhj" in namespace "gc-845"
  May 18 12:08:36.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hcrg" in namespace "gc-845"
  May 18 12:08:36.716: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hrx8" in namespace "gc-845"
  May 18 12:08:36.729: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mhxp" in namespace "gc-845"
  May 18 12:08:36.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tht4" in namespace "gc-845"
  May 18 12:08:36.757: INFO: Deleting pod "simpletest-rc-to-be-deleted-8vc6m" in namespace "gc-845"
  May 18 12:08:36.771: INFO: Deleting pod "simpletest-rc-to-be-deleted-98b9h" in namespace "gc-845"
  May 18 12:08:36.785: INFO: Deleting pod "simpletest-rc-to-be-deleted-9b5f2" in namespace "gc-845"
  May 18 12:08:36.805: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rmqn" in namespace "gc-845"
  May 18 12:08:36.822: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4d6d" in namespace "gc-845"
  May 18 12:08:36.838: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8ct9" in namespace "gc-845"
  May 18 12:08:36.856: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjxr8" in namespace "gc-845"
  May 18 12:08:36.869: INFO: Deleting pod "simpletest-rc-to-be-deleted-bp8fc" in namespace "gc-845"
  May 18 12:08:36.887: INFO: Deleting pod "simpletest-rc-to-be-deleted-bvwhn" in namespace "gc-845"
  May 18 12:08:36.898: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbmqk" in namespace "gc-845"
  May 18 12:08:36.927: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbw6n" in namespace "gc-845"
  May 18 12:08:36.942: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7dsh" in namespace "gc-845"
  May 18 12:08:36.956: INFO: Deleting pod "simpletest-rc-to-be-deleted-djvps" in namespace "gc-845"
  May 18 12:08:36.970: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkdwf" in namespace "gc-845"
  May 18 12:08:36.993: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzlbq" in namespace "gc-845"
  May 18 12:08:37.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-f555t" in namespace "gc-845"
  May 18 12:08:37.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6878" in namespace "gc-845"
  May 18 12:08:37.047: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmlkw" in namespace "gc-845"
  May 18 12:08:37.063: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvbds" in namespace "gc-845"
  May 18 12:08:37.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzm77" in namespace "gc-845"
  May 18 12:08:37.103: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2vhg" in namespace "gc-845"
  May 18 12:08:37.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-gd6vt" in namespace "gc-845"
  May 18 12:08:37.133: INFO: Deleting pod "simpletest-rc-to-be-deleted-glmn7" in namespace "gc-845"
  May 18 12:08:37.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-gs29r" in namespace "gc-845"
  May 18 12:08:37.164: INFO: Deleting pod "simpletest-rc-to-be-deleted-gs9wn" in namespace "gc-845"
  May 18 12:08:37.175: INFO: Deleting pod "simpletest-rc-to-be-deleted-gvs4v" in namespace "gc-845"
  May 18 12:08:37.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2hf6" in namespace "gc-845"
  May 18 12:08:37.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9h4w" in namespace "gc-845"
  May 18 12:08:37.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-845" for this suite. @ 05/18/24 12:08:37.231
• [17.312 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 05/18/24 12:08:37.239
  May 18 12:08:37.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 12:08:37.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:08:37.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:08:37.263
  STEP: Creating a pod to test substitution in volume subpath @ 05/18/24 12:08:37.271
  STEP: Saw pod success @ 05/18/24 12:08:41.304
  May 18 12:08:41.307: INFO: Trying to get logs from node ip-172-31-33-93 pod var-expansion-aac785d4-0555-4656-bd46-71dafb282b38 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:08:41.319
  May 18 12:08:41.335: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2906" for this suite. @ 05/18/24 12:08:41.338
• [4.108 seconds]
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/18/24 12:08:41.348
  May 18 12:08:41.348: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename chunking @ 05/18/24 12:08:41.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:08:41.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:08:41.368
  STEP: creating a large number of resources @ 05/18/24 12:08:41.371
  STEP: retrieving the first page @ 05/18/24 12:08:59.056
  May 18 12:08:59.104: INFO: Retrieved 40/40 results with rv 8405 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0
  STEP: retrieving the second page until the token expires @ 05/18/24 12:08:59.105
  May 18 12:09:19.109: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:09:39.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:09:59.109: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:10:19.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:10:39.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:10:59.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:11:19.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:11:39.109: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:11:59.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:12:19.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:12:39.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:12:59.111: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:13:19.109: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:13:39.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:13:59.111: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:14:19.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:14:39.111: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:14:59.109: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:15:19.110: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODQwNSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  May 18 12:15:39.110: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  May 18 12:15:39.110: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/18/24 12:15:39.11
  STEP: retrieving all remaining pages @ 05/18/24 12:15:39.114
  May 18 12:15:39.118: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE5XHUwMDAwIn0
  May 18 12:15:39.122: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTU5XHUwMDAwIn0
  May 18 12:15:39.125: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTk5XHUwMDAwIn0
  May 18 12:15:39.129: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM5XHUwMDAwIn0
  May 18 12:15:39.132: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjc5XHUwMDAwIn0
  May 18 12:15:39.135: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzE5XHUwMDAwIn0
  May 18 12:15:39.139: INFO: Retrieved 40/40 results with rv 9165 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6OTE2NSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU5XHUwMDAwIn0
  May 18 12:15:39.143: INFO: Retrieved 40/40 results with rv 9165 and continue 
  May 18 12:15:39.143: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6446" for this suite. @ 05/18/24 12:15:39.147
• [417.805 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 05/18/24 12:15:39.153
  May 18 12:15:39.153: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:15:39.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:39.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:39.174
  STEP: Creating configMap with name configmap-test-volume-map-10f5efc0-8b28-41c3-8bb6-cc8fa7207d03 @ 05/18/24 12:15:39.177
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:15:39.182
  STEP: Saw pod success @ 05/18/24 12:15:43.204
  May 18 12:15:43.207: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-4bee27da-3f85-4fc9-bb74-f00b0cad6118 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:15:43.222
  May 18 12:15:43.237: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5574" for this suite. @ 05/18/24 12:15:43.241
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 05/18/24 12:15:43.247
  May 18 12:15:43.247: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:15:43.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:43.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:43.267
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:15:43.269
  STEP: Saw pod success @ 05/18/24 12:15:47.294
  May 18 12:15:47.297: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-8b3878fc-1263-484f-9af6-878109fba4a8 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:15:47.303
  May 18 12:15:47.316: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2898" for this suite. @ 05/18/24 12:15:47.32
• [4.079 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/18/24 12:15:47.326
  May 18 12:15:47.326: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename ingressclass @ 05/18/24 12:15:47.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:47.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:47.345
  STEP: getting /apis @ 05/18/24 12:15:47.347
  STEP: getting /apis/networking.k8s.io @ 05/18/24 12:15:47.35
  STEP: getting /apis/networking.k8s.iov1 @ 05/18/24 12:15:47.352
  STEP: creating @ 05/18/24 12:15:47.353
  STEP: getting @ 05/18/24 12:15:47.364
  STEP: listing @ 05/18/24 12:15:47.366
  STEP: watching @ 05/18/24 12:15:47.369
  May 18 12:15:47.369: INFO: starting watch
  STEP: patching @ 05/18/24 12:15:47.37
  STEP: updating @ 05/18/24 12:15:47.376
  May 18 12:15:47.379: INFO: waiting for watch events with expected annotations
  May 18 12:15:47.379: INFO: saw patched and updated annotations
  STEP: deleting @ 05/18/24 12:15:47.379
  STEP: deleting a collection @ 05/18/24 12:15:47.39
  May 18 12:15:47.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-8112" for this suite. @ 05/18/24 12:15:47.407
• [0.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 05/18/24 12:15:47.415
  May 18 12:15:47.415: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:15:47.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:47.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:47.433
  STEP: Setting up server cert @ 05/18/24 12:15:47.467
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:15:47.769
  STEP: Deploying the webhook pod @ 05/18/24 12:15:47.777
  STEP: Wait for the deployment to be ready @ 05/18/24 12:15:47.792
  May 18 12:15:47.799: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/18/24 12:15:49.811
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:15:49.821
  May 18 12:15:50.822: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 18 12:15:50.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/18/24 12:15:51.341
  STEP: Creating a custom resource that should be denied by the webhook @ 05/18/24 12:15:51.358
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/18/24 12:15:53.376
  STEP: Updating the custom resource with disallowed data should be denied @ 05/18/24 12:15:53.384
  STEP: Deleting the custom resource should be denied @ 05/18/24 12:15:53.393
  STEP: Remove the offending key and value from the custom resource data @ 05/18/24 12:15:53.4
  STEP: Deleting the updated custom resource should be successful @ 05/18/24 12:15:53.41
  May 18 12:15:53.976: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5922" for this suite. @ 05/18/24 12:15:53.98
  STEP: Destroying namespace "webhook-markers-6022" for this suite. @ 05/18/24 12:15:53.986
• [6.577 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/18/24 12:15:53.992
  May 18 12:15:53.992: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename endpointslice @ 05/18/24 12:15:53.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:54.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:54.013
  STEP: getting /apis @ 05/18/24 12:15:54.015
  STEP: getting /apis/discovery.k8s.io @ 05/18/24 12:15:54.019
  STEP: getting /apis/discovery.k8s.iov1 @ 05/18/24 12:15:54.02
  STEP: creating @ 05/18/24 12:15:54.021
  STEP: getting @ 05/18/24 12:15:54.034
  STEP: listing @ 05/18/24 12:15:54.036
  STEP: watching @ 05/18/24 12:15:54.039
  May 18 12:15:54.039: INFO: starting watch
  STEP: cluster-wide listing @ 05/18/24 12:15:54.04
  STEP: cluster-wide watching @ 05/18/24 12:15:54.043
  May 18 12:15:54.044: INFO: starting watch
  STEP: patching @ 05/18/24 12:15:54.045
  STEP: updating @ 05/18/24 12:15:54.048
  May 18 12:15:54.058: INFO: waiting for watch events with expected annotations
  May 18 12:15:54.058: INFO: saw patched and updated annotations
  STEP: deleting @ 05/18/24 12:15:54.058
  STEP: deleting a collection @ 05/18/24 12:15:54.074
  May 18 12:15:54.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8127" for this suite. @ 05/18/24 12:15:54.1
• [0.116 seconds]
------------------------------
SSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/18/24 12:15:54.108
  May 18 12:15:54.108: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename podtemplate @ 05/18/24 12:15:54.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:54.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:54.129
  STEP: Create set of pod templates @ 05/18/24 12:15:54.133
  May 18 12:15:54.139: INFO: created test-podtemplate-1
  May 18 12:15:54.145: INFO: created test-podtemplate-2
  May 18 12:15:54.148: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/18/24 12:15:54.148
  STEP: delete collection of pod templates @ 05/18/24 12:15:54.151
  May 18 12:15:54.151: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/18/24 12:15:54.167
  May 18 12:15:54.167: INFO: requesting list of pod templates to confirm quantity
  May 18 12:15:54.169: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5700" for this suite. @ 05/18/24 12:15:54.172
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/18/24 12:15:54.178
  May 18 12:15:54.178: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 12:15:54.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:54.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:54.198
  May 18 12:15:54.208: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  May 18 12:15:59.212: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 12:15:59.212
  May 18 12:15:59.212: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/18/24 12:15:59.225
  May 18 12:15:59.234: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7771",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "725e9a08-c64e-4e3e-adaa-559f9f840272",
      ResourceVersion: (string) (len=4) "9838",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631359,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 12:15:59.238: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  May 18 12:15:59.238: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  May 18 12:15:59.238: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7771",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f197e45a-9b7b-4703-a3e2-eb6558e6b02d",
      ResourceVersion: (string) (len=4) "9839",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "725e9a08-c64e-4e3e-adaa-559f9f840272",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 37 32 35 65 39 61 30  |"uid\":\"725e9a0|
              00000040  38 2d 63 36 34 65 2d 34  65 33 65 2d 61 64 61 61  |8-c64e-4e3e-adaa|
              00000050  2d 35 35 39 66 39 66 38  34 30 32 37 32 5c 22 7d  |-559f9f840272\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:15:59.245: INFO: Pod "test-cleanup-controller-qjtjk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-qjtjk",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-7771",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "35bcdeb2-2f57-44a0-bec4-6bed6073844d",
      ResourceVersion: (string) (len=4) "9810",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "f197e45a-9b7b-4703-a3e2-eb6558e6b02d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  66 31 39 37 65 34 35 61  |uid\":\"f197e45a|
              00000080  2d 39 62 37 62 2d 34 37  30 33 2d 61 33 65 32 2d  |-9b7b-4703-a3e2-|
              00000090  65 62 36 35 35 38 65 36  62 30 32 64 5c 22 7d 22  |eb6558e6b02d\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 34 34 5c 22 7d  |2.168.225.244\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qrpm4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qrpm4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.244",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.244"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631354,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5a84fb1a920830c38662b1f51f6ff6ea2e07486dc73a2b5a7cd026027f736fd3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:15:59.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7771" for this suite. @ 05/18/24 12:15:59.252
• [5.086 seconds]
------------------------------
S
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/18/24 12:15:59.264
  May 18 12:15:59.264: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename podtemplate @ 05/18/24 12:15:59.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:59.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:59.307
  May 18 12:15:59.338: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4444" for this suite. @ 05/18/24 12:15:59.342
• [0.086 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 05/18/24 12:15:59.349
  May 18 12:15:59.349: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 12:15:59.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:15:59.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:15:59.368
  STEP: Creating a test headless service @ 05/18/24 12:15:59.371
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5151.svc.cluster.local;sleep 1; done
   @ 05/18/24 12:15:59.375
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5151.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5151.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5151.svc.cluster.local;sleep 1; done
   @ 05/18/24 12:15:59.375
  STEP: creating a pod to probe DNS @ 05/18/24 12:15:59.375
  STEP: submitting the pod to kubernetes @ 05/18/24 12:15:59.375
  STEP: retrieving the pod @ 05/18/24 12:16:05.405
  STEP: looking for the results for each expected name from probers @ 05/18/24 12:16:05.418
  May 18 12:16:05.425: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.429: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.434: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.437: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.441: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.445: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.448: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.452: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5151.svc.cluster.local from pod dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb: the server could not find the requested resource (get pods dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb)
  May 18 12:16:05.452: INFO: Lookups using dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5151.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5151.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5151.svc.cluster.local jessie_udp@dns-test-service-2.dns-5151.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5151.svc.cluster.local]

  May 18 12:16:05.459: INFO: Pod client logs for webserver: 
  May 18 12:16:05.464: INFO: Pod client logs for querier: 
  May 18 12:16:05.487: INFO: Pod client logs for jessie-querier: 
  May 18 12:16:10.455: INFO: DNS probes using dns-5151/dns-test-7b180561-cdc7-4d19-bf62-f7d1cd22dfbb succeeded

  STEP: deleting the pod @ 05/18/24 12:16:10.455
  STEP: deleting the test headless service @ 05/18/24 12:16:10.471
  May 18 12:16:10.483: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5151" for this suite. @ 05/18/24 12:16:10.486
• [11.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 05/18/24 12:16:10.495
  May 18 12:16:10.495: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 12:16:10.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:16:10.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:16:10.516
  STEP: Creating service test in namespace statefulset-9503 @ 05/18/24 12:16:10.519
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/18/24 12:16:10.525
  STEP: Creating stateful set ss in namespace statefulset-9503 @ 05/18/24 12:16:10.528
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9503 @ 05/18/24 12:16:10.534
  May 18 12:16:10.536: INFO: Found 0 stateful pods, waiting for 1
  May 18 12:16:20.540: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/18/24 12:16:20.54
  May 18 12:16:20.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:16:20.648: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:16:20.648: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:16:20.648: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 12:16:20.653: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  May 18 12:16:30.655: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 18 12:16:30.655: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 18 12:16:30.671: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999813s
  May 18 12:16:31.677: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995938425s
  May 18 12:16:32.680: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990605237s
  May 18 12:16:33.686: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9875969s
  May 18 12:16:34.691: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981368142s
  May 18 12:16:35.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975879144s
  May 18 12:16:36.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971960603s
  May 18 12:16:37.705: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.965947703s
  May 18 12:16:38.711: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.961166577s
  May 18 12:16:39.716: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.948516ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9503 @ 05/18/24 12:16:40.717
  May 18 12:16:40.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 12:16:40.807: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:16:40.807: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:16:40.807: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 12:16:40.811: INFO: Found 1 stateful pods, waiting for 3
  May 18 12:16:50.812: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:16:50.812: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:16:50.812: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/18/24 12:16:50.812
  STEP: Scale down will halt with unhealthy stateful pod @ 05/18/24 12:16:50.812
  May 18 12:16:50.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:16:50.914: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:16:50.914: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:16:50.914: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 12:16:50.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:16:51.011: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:16:51.011: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:16:51.011: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 12:16:51.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:16:51.113: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:16:51.113: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:16:51.113: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 12:16:51.113: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 18 12:16:51.116: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  May 18 12:17:01.122: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 18 12:17:01.122: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May 18 12:17:01.122: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May 18 12:17:01.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999731s
  May 18 12:17:02.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996160199s
  May 18 12:17:03.146: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990193835s
  May 18 12:17:04.151: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985572307s
  May 18 12:17:05.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980182048s
  May 18 12:17:06.161: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974831551s
  May 18 12:17:07.166: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970650527s
  May 18 12:17:08.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965668621s
  May 18 12:17:09.175: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96084606s
  May 18 12:17:10.181: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.180547ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9503 @ 05/18/24 12:17:11.181
  May 18 12:17:11.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 12:17:11.278: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:17:11.278: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:17:11.278: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 12:17:11.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 12:17:11.389: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:17:11.389: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:17:11.389: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 12:17:11.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-9503 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 12:17:11.486: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:17:11.486: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:17:11.486: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 12:17:11.486: INFO: Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/18/24 12:17:21.504
  May 18 12:17:21.504: INFO: Deleting all statefulset in ns statefulset-9503
  May 18 12:17:21.508: INFO: Scaling statefulset ss to 0
  May 18 12:17:21.519: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 12:17:21.522: INFO: Deleting statefulset ss
  May 18 12:17:21.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9503" for this suite. @ 05/18/24 12:17:21.539
• [71.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/18/24 12:17:21.546
  May 18 12:17:21.546: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-runtime @ 05/18/24 12:17:21.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:21.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:21.566
  STEP: create the container @ 05/18/24 12:17:21.569
  W0518 12:17:21.577622      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 05/18/24 12:17:21.577
  STEP: get the container status @ 05/18/24 12:17:24.599
  STEP: the container should be terminated @ 05/18/24 12:17:24.603
  STEP: the termination message should be set @ 05/18/24 12:17:24.603
  May 18 12:17:24.603: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/18/24 12:17:24.603
  May 18 12:17:24.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7364" for this suite. @ 05/18/24 12:17:24.622
• [3.083 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 05/18/24 12:17:24.63
  May 18 12:17:24.630: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:17:24.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:24.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:24.65
  STEP: Creating configMap with name configmap-test-volume-map-78f7303f-f71b-4df8-8b66-9b2654bb14ab @ 05/18/24 12:17:24.653
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:17:24.658
  STEP: Saw pod success @ 05/18/24 12:17:28.68
  May 18 12:17:28.684: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-fcb568c7-7946-4618-9ddd-6e4001fdb946 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:17:28.692
  May 18 12:17:28.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6114" for this suite. @ 05/18/24 12:17:28.711
• [4.090 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 05/18/24 12:17:28.719
  May 18 12:17:28.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 12:17:28.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:28.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:28.741
  STEP: Creating a test headless service @ 05/18/24 12:17:28.744
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2763.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2763.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 05/18/24 12:17:28.749
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2763.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2763.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/18/24 12:17:28.749
  STEP: creating a pod to probe DNS @ 05/18/24 12:17:28.749
  STEP: submitting the pod to kubernetes @ 05/18/24 12:17:28.749
  STEP: retrieving the pod @ 05/18/24 12:17:30.767
  STEP: looking for the results for each expected name from probers @ 05/18/24 12:17:30.77
  May 18 12:17:30.788: INFO: DNS probes using dns-2763/dns-test-9c184fd3-fe16-47e6-a039-7aee1edc1ce9 succeeded

  STEP: deleting the pod @ 05/18/24 12:17:30.788
  STEP: deleting the test headless service @ 05/18/24 12:17:30.798
  May 18 12:17:30.813: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2763" for this suite. @ 05/18/24 12:17:30.816
• [2.102 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/18/24 12:17:30.822
  May 18 12:17:30.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename podtemplate @ 05/18/24 12:17:30.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:30.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:30.842
  STEP: Create a pod template @ 05/18/24 12:17:30.844
  STEP: Replace a pod template @ 05/18/24 12:17:30.849
  May 18 12:17:30.857: INFO: Found updated podtemplate annotation: "true"

  May 18 12:17:30.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4169" for this suite. @ 05/18/24 12:17:30.861
• [0.046 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 05/18/24 12:17:30.867
  May 18 12:17:30.867: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:17:30.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:30.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:30.887
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/18/24 12:17:30.889
  STEP: Saw pod success @ 05/18/24 12:17:34.912
  May 18 12:17:34.915: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-0b180de5-2a26-4714-a7ed-b0e83c5a7790 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:17:34.921
  May 18 12:17:34.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8066" for this suite. @ 05/18/24 12:17:34.939
• [4.078 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 05/18/24 12:17:34.945
  May 18 12:17:34.945: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubelet-test @ 05/18/24 12:17:34.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:34.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:34.966
  May 18 12:17:38.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6028" for this suite. @ 05/18/24 12:17:38.987
• [4.047 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 05/18/24 12:17:38.992
  May 18 12:17:38.992: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:17:38.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:39.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:39.013
  STEP: Creating configMap with name configmap-test-volume-811f352b-5042-48c3-8c09-314e8e909079 @ 05/18/24 12:17:39.015
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:17:39.019
  STEP: Saw pod success @ 05/18/24 12:17:43.042
  May 18 12:17:43.044: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-a7c2eb51-9e74-4e06-b961-4d5f6b3507c9 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:17:43.051
  May 18 12:17:43.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5216" for this suite. @ 05/18/24 12:17:43.072
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 05/18/24 12:17:43.08
  May 18 12:17:43.080: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 12:17:43.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:43.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:43.102
  STEP: creating a ReplicationController @ 05/18/24 12:17:43.107
  STEP: waiting for RC to be added @ 05/18/24 12:17:43.112
  STEP: waiting for available Replicas @ 05/18/24 12:17:43.112
  STEP: patching ReplicationController @ 05/18/24 12:17:43.962
  STEP: waiting for RC to be modified @ 05/18/24 12:17:43.971
  STEP: patching ReplicationController status @ 05/18/24 12:17:43.971
  STEP: waiting for RC to be modified @ 05/18/24 12:17:43.977
  STEP: waiting for available Replicas @ 05/18/24 12:17:43.977
  STEP: fetching ReplicationController status @ 05/18/24 12:17:43.982
  STEP: patching ReplicationController scale @ 05/18/24 12:17:43.986
  STEP: waiting for RC to be modified @ 05/18/24 12:17:43.994
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/18/24 12:17:43.994
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/18/24 12:17:45.402
  STEP: updating ReplicationController status @ 05/18/24 12:17:45.405
  STEP: waiting for RC to be modified @ 05/18/24 12:17:45.412
  STEP: listing all ReplicationControllers @ 05/18/24 12:17:45.413
  STEP: checking that ReplicationController has expected values @ 05/18/24 12:17:45.419
  STEP: deleting ReplicationControllers by collection @ 05/18/24 12:17:45.419
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/18/24 12:17:45.43
  May 18 12:17:45.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0518 12:17:45.484560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-7582" for this suite. @ 05/18/24 12:17:45.488
• [2.415 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 05/18/24 12:17:45.494
  May 18 12:17:45.494: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:17:45.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:45.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:45.52
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:17:45.524
  E0518 12:17:46.484722      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:47.485629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:48.485750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:49.485806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:17:49.549
  May 18 12:17:49.553: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-60d9dafe-ba3e-4702-95f7-68aca3bcfa34 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:17:49.56
  May 18 12:17:49.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6586" for this suite. @ 05/18/24 12:17:49.587
• [4.099 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 05/18/24 12:17:49.594
  May 18 12:17:49.594: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 12:17:49.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:49.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:49.613
  STEP: Creating simple DaemonSet "daemon-set" @ 05/18/24 12:17:49.634
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 12:17:49.639
  May 18 12:17:49.642: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:49.642: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:49.647: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:17:49.647: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:17:50.485916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:17:50.644: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:50.644: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:50.648: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 12:17:50.648: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:17:51.486292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:17:51.645: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:51.645: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:17:51.649: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 12:17:51.649: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 05/18/24 12:17:51.652
  May 18 12:17:51.656: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/18/24 12:17:51.656
  May 18 12:17:51.666: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/18/24 12:17:51.666
  May 18 12:17:51.668: INFO: Observed &DaemonSet event: ADDED
  May 18 12:17:51.668: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.668: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.668: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.668: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.668: INFO: Found daemon set daemon-set in namespace daemonsets-7097 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 18 12:17:51.668: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/18/24 12:17:51.668
  STEP: watching for the daemon set status to be patched @ 05/18/24 12:17:51.676
  May 18 12:17:51.677: INFO: Observed &DaemonSet event: ADDED
  May 18 12:17:51.677: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.677: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.678: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.678: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.678: INFO: Observed daemon set daemon-set in namespace daemonsets-7097 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 18 12:17:51.678: INFO: Observed &DaemonSet event: MODIFIED
  May 18 12:17:51.678: INFO: Found daemon set daemon-set in namespace daemonsets-7097 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  May 18 12:17:51.678: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 12:17:51.681
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7097, will wait for the garbage collector to delete the pods @ 05/18/24 12:17:51.682
  May 18 12:17:51.743: INFO: Deleting DaemonSet.extensions daemon-set took: 7.595749ms
  May 18 12:17:51.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.574893ms
  E0518 12:17:52.486354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:17:53.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:17:53.048: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 12:17:53.051: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10859"},"items":null}

  May 18 12:17:53.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10859"},"items":null}

  May 18 12:17:53.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7097" for this suite. @ 05/18/24 12:17:53.068
• [3.481 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 05/18/24 12:17:53.075
  May 18 12:17:53.075: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:17:53.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:53.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:53.096
  STEP: creating a collection of services @ 05/18/24 12:17:53.098
  May 18 12:17:53.098: INFO: Creating e2e-svc-a-zxm26
  May 18 12:17:53.106: INFO: Creating e2e-svc-b-j665t
  May 18 12:17:53.118: INFO: Creating e2e-svc-c-5vksm
  STEP: deleting service collection @ 05/18/24 12:17:53.132
  May 18 12:17:53.157: INFO: Collection of services has been deleted
  May 18 12:17:53.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6601" for this suite. @ 05/18/24 12:17:53.161
• [0.094 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 05/18/24 12:17:53.17
  May 18 12:17:53.170: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 12:17:53.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:53.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:53.19
  May 18 12:17:53.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  W0518 12:17:53.193699      19 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc000df9e10 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0518 12:17:53.487151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:54.487633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:55.487709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0518 12:17:55.730813      19 warnings.go:70] unknown field "alpha"
  W0518 12:17:55.730832      19 warnings.go:70] unknown field "beta"
  W0518 12:17:55.730834      19 warnings.go:70] unknown field "delta"
  W0518 12:17:55.730837      19 warnings.go:70] unknown field "epsilon"
  W0518 12:17:55.730839      19 warnings.go:70] unknown field "gamma"
  May 18 12:17:56.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5289" for this suite. @ 05/18/24 12:17:56.275
• [3.113 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 05/18/24 12:17:56.282
  May 18 12:17:56.282: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 12:17:56.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:56.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:56.303
  STEP: Creating a job @ 05/18/24 12:17:56.306
  STEP: Ensuring active pods == parallelism @ 05/18/24 12:17:56.312
  E0518 12:17:56.487917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:17:57.488055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/18/24 12:17:58.315
  STEP: deleting Job.batch foo in namespace job-3898, will wait for the garbage collector to delete the pods @ 05/18/24 12:17:58.315
  May 18 12:17:58.375: INFO: Deleting Job.batch foo took: 5.819052ms
  May 18 12:17:58.475: INFO: Terminating Job.batch foo pods took: 100.275597ms
  E0518 12:17:58.488686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/18/24 12:17:59.475
  May 18 12:17:59.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3898" for this suite. @ 05/18/24 12:17:59.485
  E0518 12:17:59.488754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
• [3.211 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/18/24 12:17:59.493
  May 18 12:17:59.493: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/18/24 12:17:59.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:17:59.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:17:59.521
  May 18 12:17:59.524: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:18:00.489586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:01.490318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:02.491030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:03.491181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:04.491205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:05.491439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:05.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7209" for this suite. @ 05/18/24 12:18:05.732
• [6.246 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 05/18/24 12:18:05.74
  May 18 12:18:05.740: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 12:18:05.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:05.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:05.761
  STEP: create the rc @ 05/18/24 12:18:05.767
  W0518 12:18:05.773804      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0518 12:18:06.495243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:07.496549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:08.501665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:09.504714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/18/24 12:18:09.786
  STEP: wait for the rc to be deleted @ 05/18/24 12:18:09.798
  E0518 12:18:10.528051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:11.528129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:12.528955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:13.529075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:14.529829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/18/24 12:18:14.803
  E0518 12:18:15.530259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:16.530359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:17.531170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:18.531258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:19.531333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:20.532226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:21.532316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:22.532484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:23.532720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:24.532799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:25.533257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:26.533355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:27.533465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:28.533534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:29.533751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:30.533954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:31.534102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:32.534287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:33.534399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:34.534506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:35.534681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:36.534770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:37.535713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:38.535808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:39.536407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:40.537310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:41.537432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:42.537521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:43.537587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:44.538552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/18/24 12:18:44.813
  W0518 12:18:44.817634      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 12:18:44.817: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 12:18:44.817: INFO: Deleting pod "simpletest.rc-2hv25" in namespace "gc-649"
  May 18 12:18:44.831: INFO: Deleting pod "simpletest.rc-2mnwl" in namespace "gc-649"
  May 18 12:18:44.845: INFO: Deleting pod "simpletest.rc-2vt5k" in namespace "gc-649"
  May 18 12:18:44.857: INFO: Deleting pod "simpletest.rc-4c7q4" in namespace "gc-649"
  May 18 12:18:44.872: INFO: Deleting pod "simpletest.rc-4w5wc" in namespace "gc-649"
  May 18 12:18:44.885: INFO: Deleting pod "simpletest.rc-4z7fx" in namespace "gc-649"
  May 18 12:18:44.899: INFO: Deleting pod "simpletest.rc-5brmj" in namespace "gc-649"
  May 18 12:18:44.910: INFO: Deleting pod "simpletest.rc-5dv4n" in namespace "gc-649"
  May 18 12:18:44.922: INFO: Deleting pod "simpletest.rc-5hhkd" in namespace "gc-649"
  May 18 12:18:44.937: INFO: Deleting pod "simpletest.rc-5tnlc" in namespace "gc-649"
  May 18 12:18:44.953: INFO: Deleting pod "simpletest.rc-5wb9g" in namespace "gc-649"
  May 18 12:18:44.963: INFO: Deleting pod "simpletest.rc-6b9s5" in namespace "gc-649"
  May 18 12:18:44.982: INFO: Deleting pod "simpletest.rc-6hbmk" in namespace "gc-649"
  May 18 12:18:45.007: INFO: Deleting pod "simpletest.rc-6jc5k" in namespace "gc-649"
  May 18 12:18:45.019: INFO: Deleting pod "simpletest.rc-6v747" in namespace "gc-649"
  May 18 12:18:45.036: INFO: Deleting pod "simpletest.rc-7xj4j" in namespace "gc-649"
  May 18 12:18:45.051: INFO: Deleting pod "simpletest.rc-84fqf" in namespace "gc-649"
  May 18 12:18:45.073: INFO: Deleting pod "simpletest.rc-85bkj" in namespace "gc-649"
  May 18 12:18:45.085: INFO: Deleting pod "simpletest.rc-8bwgr" in namespace "gc-649"
  May 18 12:18:45.099: INFO: Deleting pod "simpletest.rc-9542h" in namespace "gc-649"
  May 18 12:18:45.114: INFO: Deleting pod "simpletest.rc-9cg84" in namespace "gc-649"
  May 18 12:18:45.128: INFO: Deleting pod "simpletest.rc-9dfqp" in namespace "gc-649"
  May 18 12:18:45.148: INFO: Deleting pod "simpletest.rc-9vr7q" in namespace "gc-649"
  May 18 12:18:45.161: INFO: Deleting pod "simpletest.rc-b659l" in namespace "gc-649"
  May 18 12:18:45.175: INFO: Deleting pod "simpletest.rc-bfb9t" in namespace "gc-649"
  May 18 12:18:45.189: INFO: Deleting pod "simpletest.rc-bl9rm" in namespace "gc-649"
  May 18 12:18:45.203: INFO: Deleting pod "simpletest.rc-bmz5f" in namespace "gc-649"
  May 18 12:18:45.217: INFO: Deleting pod "simpletest.rc-bzrmp" in namespace "gc-649"
  May 18 12:18:45.230: INFO: Deleting pod "simpletest.rc-c646c" in namespace "gc-649"
  May 18 12:18:45.244: INFO: Deleting pod "simpletest.rc-c7cv7" in namespace "gc-649"
  May 18 12:18:45.259: INFO: Deleting pod "simpletest.rc-cdtqb" in namespace "gc-649"
  May 18 12:18:45.287: INFO: Deleting pod "simpletest.rc-chhnt" in namespace "gc-649"
  May 18 12:18:45.301: INFO: Deleting pod "simpletest.rc-d9h7s" in namespace "gc-649"
  May 18 12:18:45.322: INFO: Deleting pod "simpletest.rc-dbsvm" in namespace "gc-649"
  May 18 12:18:45.337: INFO: Deleting pod "simpletest.rc-dms5x" in namespace "gc-649"
  May 18 12:18:45.347: INFO: Deleting pod "simpletest.rc-dpm8g" in namespace "gc-649"
  May 18 12:18:45.360: INFO: Deleting pod "simpletest.rc-dwtpt" in namespace "gc-649"
  May 18 12:18:45.373: INFO: Deleting pod "simpletest.rc-dzmt2" in namespace "gc-649"
  May 18 12:18:45.385: INFO: Deleting pod "simpletest.rc-f242m" in namespace "gc-649"
  May 18 12:18:45.401: INFO: Deleting pod "simpletest.rc-fxs8p" in namespace "gc-649"
  May 18 12:18:45.415: INFO: Deleting pod "simpletest.rc-g84jc" in namespace "gc-649"
  May 18 12:18:45.433: INFO: Deleting pod "simpletest.rc-gvkt8" in namespace "gc-649"
  May 18 12:18:45.453: INFO: Deleting pod "simpletest.rc-gw5d9" in namespace "gc-649"
  May 18 12:18:45.468: INFO: Deleting pod "simpletest.rc-gwbhd" in namespace "gc-649"
  May 18 12:18:45.483: INFO: Deleting pod "simpletest.rc-h2bgt" in namespace "gc-649"
  May 18 12:18:45.497: INFO: Deleting pod "simpletest.rc-h7w54" in namespace "gc-649"
  May 18 12:18:45.508: INFO: Deleting pod "simpletest.rc-hjvxc" in namespace "gc-649"
  May 18 12:18:45.521: INFO: Deleting pod "simpletest.rc-hqs66" in namespace "gc-649"
  E0518 12:18:45.539494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:45.547: INFO: Deleting pod "simpletest.rc-hwjp4" in namespace "gc-649"
  May 18 12:18:45.561: INFO: Deleting pod "simpletest.rc-j69wm" in namespace "gc-649"
  May 18 12:18:45.577: INFO: Deleting pod "simpletest.rc-jrgpp" in namespace "gc-649"
  May 18 12:18:45.593: INFO: Deleting pod "simpletest.rc-jrr8v" in namespace "gc-649"
  May 18 12:18:45.609: INFO: Deleting pod "simpletest.rc-jv4wx" in namespace "gc-649"
  May 18 12:18:45.620: INFO: Deleting pod "simpletest.rc-jw6mj" in namespace "gc-649"
  May 18 12:18:45.637: INFO: Deleting pod "simpletest.rc-jwwnn" in namespace "gc-649"
  May 18 12:18:45.651: INFO: Deleting pod "simpletest.rc-jzrl2" in namespace "gc-649"
  May 18 12:18:45.667: INFO: Deleting pod "simpletest.rc-k4vzf" in namespace "gc-649"
  May 18 12:18:45.683: INFO: Deleting pod "simpletest.rc-kxvw9" in namespace "gc-649"
  May 18 12:18:45.698: INFO: Deleting pod "simpletest.rc-l66nl" in namespace "gc-649"
  May 18 12:18:45.710: INFO: Deleting pod "simpletest.rc-l82vc" in namespace "gc-649"
  May 18 12:18:45.724: INFO: Deleting pod "simpletest.rc-lkcd2" in namespace "gc-649"
  May 18 12:18:45.738: INFO: Deleting pod "simpletest.rc-lqtw2" in namespace "gc-649"
  May 18 12:18:45.748: INFO: Deleting pod "simpletest.rc-m5mct" in namespace "gc-649"
  May 18 12:18:45.765: INFO: Deleting pod "simpletest.rc-m5zgq" in namespace "gc-649"
  May 18 12:18:45.777: INFO: Deleting pod "simpletest.rc-mh84v" in namespace "gc-649"
  May 18 12:18:45.790: INFO: Deleting pod "simpletest.rc-njqsx" in namespace "gc-649"
  May 18 12:18:45.839: INFO: Deleting pod "simpletest.rc-nx595" in namespace "gc-649"
  May 18 12:18:45.855: INFO: Deleting pod "simpletest.rc-p22wn" in namespace "gc-649"
  May 18 12:18:45.870: INFO: Deleting pod "simpletest.rc-pcmp4" in namespace "gc-649"
  May 18 12:18:45.889: INFO: Deleting pod "simpletest.rc-pf9ff" in namespace "gc-649"
  May 18 12:18:45.919: INFO: Deleting pod "simpletest.rc-pjdrr" in namespace "gc-649"
  May 18 12:18:45.985: INFO: Deleting pod "simpletest.rc-pr6pn" in namespace "gc-649"
  May 18 12:18:46.060: INFO: Deleting pod "simpletest.rc-qk2sw" in namespace "gc-649"
  May 18 12:18:46.078: INFO: Deleting pod "simpletest.rc-qqq2t" in namespace "gc-649"
  May 18 12:18:46.117: INFO: Deleting pod "simpletest.rc-qv8kk" in namespace "gc-649"
  May 18 12:18:46.171: INFO: Deleting pod "simpletest.rc-qvvtg" in namespace "gc-649"
  May 18 12:18:46.219: INFO: Deleting pod "simpletest.rc-rlzdp" in namespace "gc-649"
  May 18 12:18:46.269: INFO: Deleting pod "simpletest.rc-rm8jw" in namespace "gc-649"
  May 18 12:18:46.323: INFO: Deleting pod "simpletest.rc-t2xcn" in namespace "gc-649"
  May 18 12:18:46.373: INFO: Deleting pod "simpletest.rc-tj585" in namespace "gc-649"
  May 18 12:18:46.415: INFO: Deleting pod "simpletest.rc-v8czt" in namespace "gc-649"
  May 18 12:18:46.469: INFO: Deleting pod "simpletest.rc-v8xlj" in namespace "gc-649"
  May 18 12:18:46.517: INFO: Deleting pod "simpletest.rc-vkpx9" in namespace "gc-649"
  E0518 12:18:46.540351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:46.570: INFO: Deleting pod "simpletest.rc-vng6s" in namespace "gc-649"
  May 18 12:18:46.633: INFO: Deleting pod "simpletest.rc-vwqfv" in namespace "gc-649"
  May 18 12:18:46.667: INFO: Deleting pod "simpletest.rc-vzclz" in namespace "gc-649"
  May 18 12:18:46.719: INFO: Deleting pod "simpletest.rc-w6hrn" in namespace "gc-649"
  May 18 12:18:46.776: INFO: Deleting pod "simpletest.rc-w7vmw" in namespace "gc-649"
  May 18 12:18:46.818: INFO: Deleting pod "simpletest.rc-w8mkk" in namespace "gc-649"
  May 18 12:18:46.870: INFO: Deleting pod "simpletest.rc-wfclb" in namespace "gc-649"
  May 18 12:18:46.924: INFO: Deleting pod "simpletest.rc-wg4qj" in namespace "gc-649"
  May 18 12:18:46.967: INFO: Deleting pod "simpletest.rc-wrzcj" in namespace "gc-649"
  May 18 12:18:47.019: INFO: Deleting pod "simpletest.rc-wt4fd" in namespace "gc-649"
  May 18 12:18:47.065: INFO: Deleting pod "simpletest.rc-wwlpm" in namespace "gc-649"
  May 18 12:18:47.118: INFO: Deleting pod "simpletest.rc-x62jv" in namespace "gc-649"
  May 18 12:18:47.165: INFO: Deleting pod "simpletest.rc-xrxr2" in namespace "gc-649"
  May 18 12:18:47.403: INFO: Deleting pod "simpletest.rc-xt85d" in namespace "gc-649"
  May 18 12:18:47.414: INFO: Deleting pod "simpletest.rc-zhgqf" in namespace "gc-649"
  May 18 12:18:47.441: INFO: Deleting pod "simpletest.rc-znb2r" in namespace "gc-649"
  May 18 12:18:47.462: INFO: Deleting pod "simpletest.rc-zrq6g" in namespace "gc-649"
  May 18 12:18:47.473: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-649" for this suite. @ 05/18/24 12:18:47.48
• [41.773 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/18/24 12:18:47.529
  May 18 12:18:47.529: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:18:47.529
  E0518 12:18:47.545321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:47.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:47.579
  STEP: Creating projection with secret that has name projected-secret-test-d25093cc-e8ca-4e1d-8285-e1068ae5f421 @ 05/18/24 12:18:47.59
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:18:47.594
  E0518 12:18:48.548857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:49.551557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:50.550333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:51.550519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:18:51.631
  May 18 12:18:51.633: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-secrets-4761666d-07e8-4ba5-b6a7-9ef7b3e776c5 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:18:51.64
  May 18 12:18:51.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3496" for this suite. @ 05/18/24 12:18:51.658
• [4.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/18/24 12:18:51.666
  May 18 12:18:51.666: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 12:18:51.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:51.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:51.692
  STEP: creating pod @ 05/18/24 12:18:51.695
  E0518 12:18:52.551142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:53.551213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:53.716: INFO: Pod pod-hostip-6def238f-6779-4653-a1e9-8764cb137a0f has hostIP: 172.31.33.93
  May 18 12:18:53.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9012" for this suite. @ 05/18/24 12:18:53.719
• [2.059 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/18/24 12:18:53.726
  May 18 12:18:53.726: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 12:18:53.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:53.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:53.749
  May 18 12:18:53.752: INFO: Creating deployment "webserver-deployment"
  May 18 12:18:53.757: INFO: Waiting for observed generation 1
  E0518 12:18:54.551516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:55.551518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:55.765: INFO: Waiting for all required pods to come up
  May 18 12:18:55.768: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/18/24 12:18:55.768
  May 18 12:18:55.769: INFO: Waiting for deployment "webserver-deployment" to complete
  May 18 12:18:55.775: INFO: Updating deployment "webserver-deployment" with a non-existent image
  May 18 12:18:55.787: INFO: Updating deployment webserver-deployment
  May 18 12:18:55.787: INFO: Waiting for observed generation 2
  E0518 12:18:56.551623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:57.551699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:18:57.794: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  May 18 12:18:57.797: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  May 18 12:18:57.800: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May 18 12:18:57.809: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  May 18 12:18:57.809: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  May 18 12:18:57.812: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  May 18 12:18:57.816: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  May 18 12:18:57.816: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  May 18 12:18:57.824: INFO: Updating deployment webserver-deployment
  May 18 12:18:57.824: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  May 18 12:18:57.831: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  May 18 12:18:57.834: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  May 18 12:18:57.845: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9e836222-d379-4bf1-8ba9-3aea65f9d09e",
      ResourceVersion: (string) (len=5) "13868",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 12:18:57.851: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
      ResourceVersion: (string) (len=5) "13871",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "9e836222-d379-4bf1-8ba9-3aea65f9d09e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 65 38 33 36 32  32 32 2d 64 33 37 39 2d  |\"9e836222-d379-|
              00000120  34 62 66 31 2d 38 62 61  39 2d 33 61 65 61 36 35  |4bf1-8ba9-3aea65|
              00000130  66 39 64 30 39 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f9d09e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:18:57.852: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  May 18 12:18:57.852: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
      ResourceVersion: (string) (len=5) "13869",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "9e836222-d379-4bf1-8ba9-3aea65f9d09e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 65 38 33 36 32  32 32 2d 64 33 37 39 2d  |\"9e836222-d379-|
              00000120  34 62 66 31 2d 38 62 61  39 2d 33 61 65 61 36 35  |4bf1-8ba9-3aea65|
              00000130  66 39 64 30 39 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f9d09e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:18:57.861: INFO: Pod "webserver-deployment-557759b7c7-2h4qp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-2h4qp",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2fdb6e05-adfa-4554-b0fb-1b3fac716655",
      ResourceVersion: (string) (len=5) "13640",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 39  38 2e 38 39 5c 22 7d 22  |2.168.198.89\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gjcg6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gjcg6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-90-158",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.90.158",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.90.158"
        }
      },
      PodIP: (string) (len=14) "192.168.198.89",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.198.89"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a72c0dd2b57a06f0bbfc47a63bae77e6cb27c1232ef6e25b24701156fd9ab6a7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.866: INFO: Pod "webserver-deployment-557759b7c7-2hnvs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-2hnvs",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7decf0f9-30c8-47bf-a3c7-f35d6a218eda",
      ResourceVersion: (string) (len=5) "13573",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 33 39 5c 22 7d  |2.168.225.239\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hl5r6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hl5r6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.239",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.239"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b0cd9e948c1e6908f4ea880a2b717c794369ffe4253a86f7214bd806da0917d4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.867: INFO: Pod "webserver-deployment-557759b7c7-6dfrn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6dfrn",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ccbba185-3a20-4af4-9983-527da1db344c",
      ResourceVersion: (string) (len=5) "13599",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 30  39 2e 37 31 5c 22 7d 22  |2.168.209.71\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qg4g2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qg4g2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) (len=14) "192.168.209.71",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.209.71"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ca7342c568780ee94d3047443c504617e71c8fcaf6a098a9e346397329a24c78",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.868: INFO: Pod "webserver-deployment-557759b7c7-7b4th" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7b4th",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fbb3cbec-f404-401e-8faf-813357729b71",
      ResourceVersion: (string) (len=5) "13578",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 31 36 5c 22 7d  |2.168.225.216\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7snsq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7snsq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.216",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.216"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c449a93a9286ba790ee26ed16b8852883d3b2e1271896bcbb3794baac7b6c95d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.870: INFO: Pod "webserver-deployment-557759b7c7-g5xw2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-g5xw2",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c3c92a7e-3583-4929-a0a0-c41bb02b21db",
      ResourceVersion: (string) (len=5) "13588",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 31 37 5c 22 7d  |2.168.225.217\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9cn24",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9cn24",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.217",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.217"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0bfe2b517b8f81e5d49ad6fbcd8dc949d585e3b91429080e59af224f76e99c89",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.871: INFO: Pod "webserver-deployment-557759b7c7-kvvch" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-kvvch",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e8512002-e143-4930-9927-0e94d6e732e0",
      ResourceVersion: (string) (len=5) "13644",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 39  38 2e 38 37 5c 22 7d 22  |2.168.198.87\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h2v4c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h2v4c",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-90-158",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.90.158",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.90.158"
        }
      },
      PodIP: (string) (len=14) "192.168.198.87",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.198.87"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0c35977fefe5d3652d69043ce5100599f55a64dabb0b1f329d1a7044197264f8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.875: INFO: Pod "webserver-deployment-557759b7c7-m422s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-m422s",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7397353f-fbb2-4b17-a834-87283055f35a",
      ResourceVersion: (string) (len=5) "13873",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631537,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m2sbb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m2sbb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.876: INFO: Pod "webserver-deployment-557759b7c7-mctxh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-mctxh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2d23f184-c680-4438-bf91-d3a879234e78",
      ResourceVersion: (string) (len=5) "13881",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631537,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mj4xq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mj4xq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.877: INFO: Pod "webserver-deployment-557759b7c7-spmbg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-spmbg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c5aed6f0-4352-448c-b0e6-156fec9ecd02",
      ResourceVersion: (string) (len=5) "13874",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631537,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xndds",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xndds",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.878: INFO: Pod "webserver-deployment-557759b7c7-xmbr6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xmbr6",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6807ab9b-06bb-499b-b923-855b618f9f9d",
      ResourceVersion: (string) (len=5) "13604",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 30  39 2e 37 34 5c 22 7d 22  |2.168.209.74\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2nzg4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2nzg4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) (len=14) "192.168.209.74",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.209.74"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://46c923e8f4c23f85e11f1add4a8e939854488b5925ede561a03ab1137b9a936a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.881: INFO: Pod "webserver-deployment-557759b7c7-zz7pq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-zz7pq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "97ae620f-7bf2-4f2c-a4de-541eb108a6e3",
      ResourceVersion: (string) (len=5) "13649",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "799c9234-f106-42cb-8adf-6501a5878171",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 39  39 63 39 32 33 34 2d 66  |d\":\"799c9234-f|
              00000090  31 30 36 2d 34 32 63 62  2d 38 61 64 66 2d 36 35  |106-42cb-8adf-65|
              000000a0  30 31 61 35 38 37 38 31  37 31 5c 22 7d 22 3a 7b  |01a5878171\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 39  38 2e 38 34 5c 22 7d 22  |2.168.198.84\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q72dk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q72dk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-90-158",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.90.158",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.90.158"
        }
      },
      PodIP: (string) (len=14) "192.168.198.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.198.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851631534,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8f3105cee7da944eb9b9cf24d9df5ee060366b671ea385af8736e6c195be743d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.882: INFO: Pod "webserver-deployment-9b4f5bf69-bcbtw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bcbtw",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bc1f2ef8-4a1e-43e3-be9b-8a12fb9b9101",
      ResourceVersion: (string) (len=5) "13876",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631537,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-45gqm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-45gqm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.883: INFO: Pod "webserver-deployment-9b4f5bf69-hcpfj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-hcpfj",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4908b34-a109-44cd-b3c4-8fd1eecf825a",
      ResourceVersion: (string) (len=5) "13859",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 30 39 2e 37  33 5c 22 7d 22 3a 7b 22  |68.209.73\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qxgxt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qxgxt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) (len=14) "192.168.209.73",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.209.73"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.885: INFO: Pod "webserver-deployment-9b4f5bf69-hm42k" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-hm42k",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "39ae402f-0322-48ef-b38f-5f1d99159902",
      ResourceVersion: (string) (len=5) "13706",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mzpcl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mzpcl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.886: INFO: Pod "webserver-deployment-9b4f5bf69-phvff" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-phvff",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d8f2d923-aae9-4107-a593-b2bd5c7128cb",
      ResourceVersion: (string) (len=5) "13727",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j5z62",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j5z62",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.888: INFO: Pod "webserver-deployment-9b4f5bf69-q8cqz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-q8cqz",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4173ded-d212-45f9-9b2c-4b4eda29f919",
      ResourceVersion: (string) (len=5) "13833",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631536,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 39 38 2e 38  32 5c 22 7d 22 3a 7b 22  |68.198.82\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kdn67",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kdn67",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-90-158",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631536,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.90.158",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.90.158"
        }
      },
      PodIP: (string) (len=14) "192.168.198.82",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.198.82"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.889: INFO: Pod "webserver-deployment-9b4f5bf69-s2hvs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-s2hvs",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1418",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e9ef9c33-2993-4faa-a3e1-14ef26c7cdd4",
      ResourceVersion: (string) (len=5) "13862",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "1938c12d-ac20-4ab0-9297-a77028cefff1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  33 38 63 31 32 64 2d 61  |d\":\"1938c12d-a|
              00000090  63 32 30 2d 34 61 62 30  2d 39 32 39 37 2d 61 37  |c20-4ab0-9297-a7|
              000000a0  37 30 32 38 63 65 66 66  66 31 5c 22 7d 22 3a 7b  |7028cefff1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 30 39 2e 37  38 5c 22 7d 22 3a 7b 22  |68.209.78\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8mvrz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8mvrz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631537,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851631535,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) (len=14) "192.168.209.78",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.209.78"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851631535,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:18:57.890: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1418" for this suite. @ 05/18/24 12:18:57.9
• [4.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/18/24 12:18:57.922
  May 18 12:18:57.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/18/24 12:18:57.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:57.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:57.973
  STEP: fetching the /apis discovery document @ 05/18/24 12:18:57.976
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/18/24 12:18:57.979
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/18/24 12:18:57.979
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/18/24 12:18:57.979
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/18/24 12:18:57.98
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/18/24 12:18:57.981
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/18/24 12:18:57.982
  May 18 12:18:57.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3671" for this suite. @ 05/18/24 12:18:57.986
• [0.077 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 05/18/24 12:18:57.999
  May 18 12:18:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:18:58
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:58.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:58.025
  STEP: Creating a ResourceQuota @ 05/18/24 12:18:58.028
  STEP: Getting a ResourceQuota @ 05/18/24 12:18:58.033
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/18/24 12:18:58.036
  STEP: Patching the ResourceQuota @ 05/18/24 12:18:58.039
  STEP: Deleting a Collection of ResourceQuotas @ 05/18/24 12:18:58.046
  STEP: Verifying the deleted ResourceQuota @ 05/18/24 12:18:58.056
  May 18 12:18:58.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3538" for this suite. @ 05/18/24 12:18:58.062
• [0.068 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 05/18/24 12:18:58.067
  May 18 12:18:58.067: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 12:18:58.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:18:58.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:18:58.087
  STEP: Creating a job @ 05/18/24 12:18:58.09
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/18/24 12:18:58.096
  E0518 12:18:58.551804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:18:59.552198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/18/24 12:19:00.101
  STEP: updating /status @ 05/18/24 12:19:00.109
  STEP: get /status @ 05/18/24 12:19:00.116
  May 18 12:19:00.119: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6234" for this suite. @ 05/18/24 12:19:00.122
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/18/24 12:19:00.128
  May 18 12:19:00.128: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename cronjob @ 05/18/24 12:19:00.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:19:00.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:19:00.149
  STEP: Creating a cronjob @ 05/18/24 12:19:00.152
  STEP: Ensuring more than one job is running at a time @ 05/18/24 12:19:00.159
  E0518 12:19:00.554068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:01.554144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:02.554253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:03.554325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:04.554530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:05.554582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:06.554614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:07.554726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:08.554881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:09.555103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:10.555200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:11.556280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:12.557110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:13.557338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:14.557945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:15.558885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:16.559594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:17.559664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:18.560267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:19.560726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:20.560973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:21.561309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:22.561418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:23.561537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:24.561594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:25.561713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:26.561819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:27.562780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:28.562872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:29.562966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:30.563254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:31.563338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:32.564038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:33.564135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:34.564176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:35.564262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:36.564297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:37.565199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:38.566216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:39.566288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:40.566380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:41.566571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:42.567197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:43.568254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:44.569164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:45.569252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:46.569349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:47.570169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:48.570817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:49.571003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:50.571185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:51.571286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:52.571381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:53.571468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:54.572235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:55.572337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:56.572735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:57.573723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:58.574773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:19:59.574900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:00.575571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:01.575668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:02.575754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:03.575844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:04.575957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:05.580609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:06.581434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:07.582251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:08.583136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:09.583245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:10.584257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:11.584415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:12.584453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:13.584542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:14.585217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:15.585351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:16.586011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:17.586120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:18.586584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:19.586766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:20.587535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:21.587630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:22.588227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:23.588325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:24.589232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:25.589344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:26.590151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:27.590997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:28.591130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:29.591189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:30.592225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:31.592437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:32.592758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:33.593745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:34.593831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:35.594107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:36.594396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:37.595153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:38.595257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:39.595358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:40.596219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:41.596373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:42.597095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:43.597677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:44.598361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:45.598451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:46.598535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:47.598714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:48.599375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:49.599585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:50.600242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:51.600542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:52.600633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:53.600721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:54.601010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:55.601190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:56.601756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:57.602804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:58.603172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:20:59.604240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/18/24 12:21:00.164
  STEP: Removing cronjob @ 05/18/24 12:21:00.167
  May 18 12:21:00.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3320" for this suite. @ 05/18/24 12:21:00.181
• [120.062 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 05/18/24 12:21:00.19
  May 18 12:21:00.190: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:21:00.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:00.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:00.219
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:21:00.221
  E0518 12:21:00.604745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:01.604839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:02.604931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:03.605032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:21:04.247
  May 18 12:21:04.251: INFO: Trying to get logs from node ip-172-31-70-23 pod downwardapi-volume-ecae49b5-eec4-4a0a-a3bf-a775bdd42ac7 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:21:04.267
  May 18 12:21:04.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1157" for this suite. @ 05/18/24 12:21:04.285
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 05/18/24 12:21:04.29
  May 18 12:21:04.290: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 12:21:04.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:04.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:04.311
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/18/24 12:21:04.314
  E0518 12:21:04.606012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:05.606104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 05/18/24 12:21:06.334
  STEP: Then the orphan pod is adopted @ 05/18/24 12:21:06.339
  E0518 12:21:06.606734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:21:07.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5194" for this suite. @ 05/18/24 12:21:07.351
• [3.066 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/18/24 12:21:07.356
  May 18 12:21:07.356: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 12:21:07.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:07.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:07.377
  E0518 12:21:07.607112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:08.607219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:09.607691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:10.607714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:11.608523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:12.608802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:21:13.428
  May 18 12:21:13.431: INFO: Trying to get logs from node ip-172-31-70-23 pod client-envvars-1c781c3f-c10b-49b2-ada4-9c0d94236732 container env3cont: <nil>
  STEP: delete the pod @ 05/18/24 12:21:13.438
  May 18 12:21:13.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5595" for this suite. @ 05/18/24 12:21:13.458
• [6.109 seconds]
------------------------------
SSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/18/24 12:21:13.465
  May 18 12:21:13.465: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename events @ 05/18/24 12:21:13.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:13.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:13.485
  STEP: Create set of events @ 05/18/24 12:21:13.487
  May 18 12:21:13.493: INFO: created test-event-1
  May 18 12:21:13.497: INFO: created test-event-2
  May 18 12:21:13.501: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/18/24 12:21:13.501
  STEP: delete collection of events @ 05/18/24 12:21:13.505
  May 18 12:21:13.505: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/18/24 12:21:13.522
  May 18 12:21:13.522: INFO: requesting list of events to confirm quantity
  May 18 12:21:13.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7384" for this suite. @ 05/18/24 12:21:13.528
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 05/18/24 12:21:13.535
  May 18 12:21:13.535: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:21:13.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:13.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:13.554
  STEP: creating service nodeport-test with type=NodePort in namespace services-3636 @ 05/18/24 12:21:13.557
  STEP: creating replication controller nodeport-test in namespace services-3636 @ 05/18/24 12:21:13.572
  I0518 12:21:13.580728      19 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-3636, replica count: 2
  E0518 12:21:13.608788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:14.608923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:15.609420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:16.610411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 12:21:16.631608      19 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 12:21:16.631: INFO: Creating new exec pod
  E0518 12:21:17.611243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:18.611354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:19.611422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:21:19.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May 18 12:21:19.755: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May 18 12:21:19.755: INFO: stdout: ""
  E0518 12:21:20.611528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:21:20.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May 18 12:21:20.748: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May 18 12:21:20.748: INFO: stdout: ""
  E0518 12:21:21.611600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:21:21.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May 18 12:21:21.742: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May 18 12:21:21.742: INFO: stdout: ""
  E0518 12:21:22.611768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:21:22.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  May 18 12:21:22.746: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  May 18 12:21:22.746: INFO: stdout: "nodeport-test-s865l"
  May 18 12:21:22.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.180 80'
  May 18 12:21:22.839: INFO: stderr: "+ nc -v -t -w 2 10.152.183.180 80\n+ echo hostName\nConnection to 10.152.183.180 80 port [tcp/http] succeeded!\n"
  May 18 12:21:22.839: INFO: stdout: "nodeport-test-tsw97"
  May 18 12:21:22.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.70.23 32270'
  May 18 12:21:22.926: INFO: stderr: "+ nc -v -t -w 2 172.31.70.23 32270\n+ echo hostName\nConnection to 172.31.70.23 32270 port [tcp/*] succeeded!\n"
  May 18 12:21:22.926: INFO: stdout: "nodeport-test-tsw97"
  May 18 12:21:22.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-3636 exec execpodx9kjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.90.158 32270'
  May 18 12:21:23.025: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.90.158 32270\nConnection to 172.31.90.158 32270 port [tcp/*] succeeded!\n"
  May 18 12:21:23.025: INFO: stdout: "nodeport-test-tsw97"
  May 18 12:21:23.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3636" for this suite. @ 05/18/24 12:21:23.03
• [9.505 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:470
  STEP: Creating a kubernetes client @ 05/18/24 12:21:23.039
  May 18 12:21:23.039: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-pred @ 05/18/24 12:21:23.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:23.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:23.061
  May 18 12:21:23.063: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 18 12:21:23.069: INFO: Waiting for terminating namespaces to be deleted...
  May 18 12:21:23.072: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-33-93 before test
  May 18 12:21:23.077: INFO: concurrent-28600580-sh4n6 from cronjob-3320 started at 2024-05-18 12:20:00 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container c ready: true, restart count 0
  May 18 12:21:23.077: INFO: nginx-ingress-controller-kubernetes-worker-fr7mv from ingress-nginx-kubernetes-worker started at 2024-05-18 11:59:30 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:21:23.077: INFO: calico-node-jt76w from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:21:23.077: INFO: nodeport-test-tsw97 from services-3636 started at 2024-05-18 12:21:13 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container nodeport-test ready: true, restart count 0
  May 18 12:21:23.077: INFO: sonobuoy from sonobuoy started at 2024-05-18 12:05:55 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 18 12:21:23.077: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-qg8tv from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:21:23.077: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:21:23.077: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:21:23.077: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-70-23 before test
  May 18 12:21:23.082: INFO: nginx-ingress-controller-kubernetes-worker-cwhst from ingress-nginx-kubernetes-worker started at 2024-05-18 12:02:05 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:21:23.082: INFO: calico-node-8tp4g from kube-system started at 2024-05-18 12:01:55 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:21:23.082: INFO: execpodx9kjx from services-3636 started at 2024-05-18 12:21:16 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container agnhost-container ready: true, restart count 0
  May 18 12:21:23.082: INFO: nodeport-test-s865l from services-3636 started at 2024-05-18 12:21:13 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container nodeport-test ready: true, restart count 0
  May 18 12:21:23.082: INFO: sonobuoy-e2e-job-9640b063a5a74f87 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container e2e ready: true, restart count 0
  May 18 12:21:23.082: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:21:23.082: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-hmcm6 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:21:23.082: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:21:23.082: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:21:23.082: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-90-158 before test
  May 18 12:21:23.086: INFO: nginx-ingress-controller-kubernetes-worker-4cg9g from ingress-nginx-kubernetes-worker started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:21:23.086: INFO: calico-node-5dtrz from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:21:23.086: INFO: coredns-bddfd76d7-gv2bt from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container coredns ready: true, restart count 0
  May 18 12:21:23.086: INFO: kube-state-metrics-6f48cdd76-glkfx from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container kube-state-metrics ready: true, restart count 0
  May 18 12:21:23.086: INFO: metrics-server-v0.6.3-69d7fbfdf8-thw8r from kube-system started at 2024-05-18 11:56:31 +0000 UTC (2 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container metrics-server ready: true, restart count 0
  May 18 12:21:23.086: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  May 18 12:21:23.086: INFO: dashboard-metrics-scraper-5dd7cb5fc-ks9g5 from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  May 18 12:21:23.086: INFO: kubernetes-dashboard-7b899cb9d9-4z7gj from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  May 18 12:21:23.086: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-l9qkt from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:21:23.086: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:21:23.086: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/18/24 12:21:23.086
  E0518 12:21:23.611842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:24.612276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/18/24 12:21:25.104
  STEP: Trying to apply a random label on the found node. @ 05/18/24 12:21:25.118
  STEP: verifying the node has the label kubernetes.io/e2e-a4f46e2f-389f-4d26-9d29-4e998914cd7c 42 @ 05/18/24 12:21:25.126
  STEP: Trying to relaunch the pod, now with labels. @ 05/18/24 12:21:25.13
  E0518 12:21:25.612308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:26.612590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-a4f46e2f-389f-4d26-9d29-4e998914cd7c off the node ip-172-31-33-93 @ 05/18/24 12:21:27.147
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-a4f46e2f-389f-4d26-9d29-4e998914cd7c @ 05/18/24 12:21:27.158
  May 18 12:21:27.161: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-9691" for this suite. @ 05/18/24 12:21:27.166
• [4.133 seconds]
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 05/18/24 12:21:27.173
  May 18 12:21:27.173: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:21:27.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:27.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:27.193
  STEP: Creating secret with name secret-test-d315df89-12bc-4d9a-acd9-bc8cac8a58fc @ 05/18/24 12:21:27.196
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:21:27.2
  E0518 12:21:27.613113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:28.613294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:29.613395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:30.613484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:21:31.223
  May 18 12:21:31.226: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-secrets-a70a3d0e-77e8-41cf-898b-b4f079c1e803 container secret-env-test: <nil>
  STEP: delete the pod @ 05/18/24 12:21:31.232
  May 18 12:21:31.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9425" for this suite. @ 05/18/24 12:21:31.25
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/18/24 12:21:31.257
  May 18 12:21:31.257: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-watch @ 05/18/24 12:21:31.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:21:31.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:21:31.278
  May 18 12:21:31.281: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:21:31.613588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:32.613704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:33.614009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 05/18/24 12:21:33.816
  May 18 12:21:33.820: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:33Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:21:33Z]] name:name1 resourceVersion:15072 uid:939e9973-40c4-4c91-bdbd-fafc915d4c0c] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:21:34.614195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:35.615062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:36.615176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:37.616263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:38.616334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:39.616599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:40.616705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:41.616881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:42.616971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:43.617074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 05/18/24 12:21:43.821
  May 18 12:21:43.827: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:43Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:21:43Z]] name:name2 resourceVersion:15108 uid:993c62dd-d16d-4661-a33e-3b697f78ea82] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:21:44.617446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:45.617600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:46.617660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:47.618505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:48.618607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:49.618720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:50.618825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:51.618862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:52.619517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:53.619619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 05/18/24 12:21:53.827
  May 18 12:21:53.835: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:21:53Z]] name:name1 resourceVersion:15127 uid:939e9973-40c4-4c91-bdbd-fafc915d4c0c] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:21:54.619704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:55.620253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:56.620433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:57.620644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:58.620747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:21:59.620905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:00.621989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:01.622283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:02.622466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:03.622651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 05/18/24 12:22:03.837
  May 18 12:22:03.843: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:22:03Z]] name:name2 resourceVersion:15147 uid:993c62dd-d16d-4661-a33e-3b697f78ea82] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:22:04.623165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:05.623373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:06.623617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:07.624240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:08.624354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:09.624685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:10.624786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:11.625083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:12.625372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:13.625429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 05/18/24 12:22:13.843
  May 18 12:22:13.850: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:21:53Z]] name:name1 resourceVersion:15168 uid:939e9973-40c4-4c91-bdbd-fafc915d4c0c] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:22:14.626379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:15.626562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:16.627553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:17.627680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:18.627759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:19.628239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:20.628762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:21.629772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:22.630609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:23.630942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 05/18/24 12:22:23.851
  May 18 12:22:23.859: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-18T12:21:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-18T12:22:03Z]] name:name2 resourceVersion:15188 uid:993c62dd-d16d-4661-a33e-3b697f78ea82] num:map[num1:9223372036854775807 num2:1000000]]}
  E0518 12:22:24.631156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:25.631254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:26.631363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:27.632242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:28.632341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:29.632519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:30.632621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:31.632977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:32.633212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:33.633286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:22:34.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-694" for this suite. @ 05/18/24 12:22:34.379
• [63.130 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/18/24 12:22:34.387
  May 18 12:22:34.387: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename tables @ 05/18/24 12:22:34.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:22:34.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:22:34.412
  May 18 12:22:34.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-9951" for this suite. @ 05/18/24 12:22:34.422
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 05/18/24 12:22:34.43
  May 18 12:22:34.430: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 12:22:34.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:22:34.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:22:34.45
  STEP: Creating service test in namespace statefulset-342 @ 05/18/24 12:22:34.453
  STEP: Creating a new StatefulSet @ 05/18/24 12:22:34.458
  May 18 12:22:34.469: INFO: Found 0 stateful pods, waiting for 3
  E0518 12:22:34.633692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:35.633811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:36.633879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:37.634797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:38.634996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:39.635068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:40.635175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:41.636248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:42.636432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:43.636672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:22:44.470: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:22:44.470: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:22:44.470: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  May 18 12:22:44.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-342 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:22:44.583: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:22:44.583: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:22:44.583: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0518 12:22:44.636928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:45.637219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:46.637279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:47.638304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:48.638388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:49.638457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:50.638564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:51.638730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:52.638825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:53.639082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/18/24 12:22:54.592
  May 18 12:22:54.613: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/18/24 12:22:54.613
  E0518 12:22:54.639341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:55.639428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:56.640221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:57.640445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:58.640566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:22:59.640648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:00.641572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:01.641695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:02.641793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:03.642096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/18/24 12:23:04.621
  May 18 12:23:04.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-342 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0518 12:23:04.642142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:23:04.712: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:23:04.712: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:23:04.712: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0518 12:23:05.642258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:06.642341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:07.642395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:08.642649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:09.642838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:10.643187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:11.643320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:12.643419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:13.643510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:14.643584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:23:14.727: INFO: Waiting for StatefulSet statefulset-342/ss2 to complete update
  E0518 12:23:15.644224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:16.644327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:17.644546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:18.644657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:19.645096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:20.645193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:21.645293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:22.645366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:23.645420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:24.645525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/18/24 12:23:24.731
  May 18 12:23:24.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-342 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 12:23:24.818: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 12:23:24.818: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 12:23:24.818: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0518 12:23:25.646592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:26.646766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:27.647933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:28.647891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:29.648676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:30.648761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:31.648846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:32.649098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:33.649391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:34.649566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:23:34.847: INFO: Updating stateful set ss2
  E0518 12:23:35.649678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:36.649874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:37.650713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:38.650870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:39.651101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:40.651171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:41.652251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:42.652385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:43.652652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:44.653075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/18/24 12:23:44.855
  May 18 12:23:44.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-342 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 12:23:44.952: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 12:23:44.952: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 12:23:44.952: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0518 12:23:45.653170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:46.653344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:47.653794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:48.653900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:49.654097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:50.654201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:51.654305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:52.654655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:53.654765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:54.654946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:23:54.967: INFO: Deleting all statefulset in ns statefulset-342
  May 18 12:23:54.971: INFO: Scaling statefulset ss2 to 0
  E0518 12:23:55.655169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:56.655280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:57.656208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:58.656575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:23:59.657315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:00.657405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:01.658236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:02.659069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:03.659165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:04.660230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:04.985: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 12:24:04.989: INFO: Deleting statefulset ss2
  May 18 12:24:05.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-342" for this suite. @ 05/18/24 12:24:05.004
• [90.583 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/18/24 12:24:05.014
  May 18 12:24:05.014: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename watch @ 05/18/24 12:24:05.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:24:05.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:24:05.035
  STEP: creating a watch on configmaps @ 05/18/24 12:24:05.038
  STEP: creating a new configmap @ 05/18/24 12:24:05.039
  STEP: modifying the configmap once @ 05/18/24 12:24:05.043
  STEP: closing the watch once it receives two notifications @ 05/18/24 12:24:05.05
  May 18 12:24:05.050: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5777  65c02c85-837b-43f5-8357-e3c954c92d2f 15817 0 2024-05-18 12:24:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-18 12:24:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:24:05.050: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5777  65c02c85-837b-43f5-8357-e3c954c92d2f 15818 0 2024-05-18 12:24:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-18 12:24:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/18/24 12:24:05.051
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/18/24 12:24:05.057
  STEP: deleting the configmap @ 05/18/24 12:24:05.058
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/18/24 12:24:05.064
  May 18 12:24:05.064: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5777  65c02c85-837b-43f5-8357-e3c954c92d2f 15819 0 2024-05-18 12:24:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-18 12:24:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:24:05.064: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5777  65c02c85-837b-43f5-8357-e3c954c92d2f 15820 0 2024-05-18 12:24:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-18 12:24:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:24:05.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5777" for this suite. @ 05/18/24 12:24:05.068
• [0.061 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 05/18/24 12:24:05.075
  May 18 12:24:05.075: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:24:05.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:24:05.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:24:05.093
  STEP: Creating resourceQuota "e2e-rq-status-hnfpd" @ 05/18/24 12:24:05.099
  May 18 12:24:05.106: INFO: Resource quota "e2e-rq-status-hnfpd" reports spec: hard cpu limit of 500m
  May 18 12:24:05.106: INFO: Resource quota "e2e-rq-status-hnfpd" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-hnfpd" /status @ 05/18/24 12:24:05.106
  STEP: Confirm /status for "e2e-rq-status-hnfpd" resourceQuota via watch @ 05/18/24 12:24:05.113
  May 18 12:24:05.115: INFO: observed resourceQuota "e2e-rq-status-hnfpd" in namespace "resourcequota-3042" with hard status: v1.ResourceList(nil)
  May 18 12:24:05.115: INFO: Found resourceQuota "e2e-rq-status-hnfpd" in namespace "resourcequota-3042" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May 18 12:24:05.115: INFO: ResourceQuota "e2e-rq-status-hnfpd" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/18/24 12:24:05.117
  May 18 12:24:05.123: INFO: Resource quota "e2e-rq-status-hnfpd" reports spec: hard cpu limit of 1
  May 18 12:24:05.123: INFO: Resource quota "e2e-rq-status-hnfpd" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-hnfpd" /status @ 05/18/24 12:24:05.123
  STEP: Confirm /status for "e2e-rq-status-hnfpd" resourceQuota via watch @ 05/18/24 12:24:05.129
  May 18 12:24:05.131: INFO: observed resourceQuota "e2e-rq-status-hnfpd" in namespace "resourcequota-3042" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  May 18 12:24:05.131: INFO: Found resourceQuota "e2e-rq-status-hnfpd" in namespace "resourcequota-3042" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  May 18 12:24:05.131: INFO: ResourceQuota "e2e-rq-status-hnfpd" /status was patched
  STEP: Get "e2e-rq-status-hnfpd" /status @ 05/18/24 12:24:05.131
  May 18 12:24:05.133: INFO: Resourcequota "e2e-rq-status-hnfpd" reports status: hard cpu of 1
  May 18 12:24:05.133: INFO: Resourcequota "e2e-rq-status-hnfpd" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-hnfpd" /status before checking Spec is unchanged @ 05/18/24 12:24:05.136
  May 18 12:24:05.143: INFO: Resourcequota "e2e-rq-status-hnfpd" reports status: hard cpu of 2
  May 18 12:24:05.143: INFO: Resourcequota "e2e-rq-status-hnfpd" reports status: hard memory of 2Gi
  May 18 12:24:05.144: INFO: Found resourceQuota "e2e-rq-status-hnfpd" in namespace "resourcequota-3042" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  May 18 12:24:05.146: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b171e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17230), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17260), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:05.660861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:06.660937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:07.661300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:08.662402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:09.662630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:10.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16168), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b161f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16240), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:10.663409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:11.663516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:12.664247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:13.664393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:14.664570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:15.150: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e62b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e62e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6318), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:15.665252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:16.665345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:17.665594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:18.665689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:19.666579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:20.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6540), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6570), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e65a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:20.666686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:21.666780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:22.666926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:23.667169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:24.667263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:25.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6870), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e68a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e68d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:25.668133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:26.668218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:27.668872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:28.668976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:29.669061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:30.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16828), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16858), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b168a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:30.669149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:31.669385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:32.669693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:33.669973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:34.670892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:35.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16c18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16c48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16c90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:35.670938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:36.671157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:37.671162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:38.672223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:39.672396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:40.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6d68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6db0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e6df8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:40.672493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:41.672658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:42.672765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:43.672861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:44.673140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:45.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16f30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16f78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b16fa8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:45.673235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:46.673425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:47.673470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:48.673567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:49.673701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:50.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b172d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17308), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17350), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:50.674625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:51.674763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:52.674944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:53.675165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:54.675260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:24:55.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b175f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17638), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17668), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:24:55.675360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:56.675443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:57.676232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:58.676352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:24:59.676712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:00.150: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e73e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7410), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7440), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:00.676903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:01.677012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:02.678000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:03.678098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:04.678647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:05.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17b30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17b60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17b90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:05.679347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:06.680239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:07.680949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:08.681049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:09.682008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:10.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17ea8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17ed8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b17f20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:10.682578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:11.682680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:12.682848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:13.683168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:14.683266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:15.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7740), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e77a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e77e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:15.684230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:16.684409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:17.684494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:18.684612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:19.684794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:20.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e79e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7a10), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7a40), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:20.685424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:21.685606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:22.685791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:23.685901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:24.686182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:25.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8558), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8588), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a85d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:25.686668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:26.686987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:27.687178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:28.687391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:29.687482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:30.150: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a88e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8930), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8960), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:30.687590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:31.687700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:32.687977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:33.688073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:34.688150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:35.150: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7dd0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7e00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0061e7e30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:35.688243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:36.688340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:37.688558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:38.688652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:39.688944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:40.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8d68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8db0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a8de0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:40.689523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:41.689614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:42.689779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:43.689890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:44.690559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:45.149: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a91d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a9200), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a9248), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:45.691262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:46.691363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:47.692407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:48.692498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:49.692948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:50.148: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-hnfpd", GenerateName:"", Namespace:"resourcequota-3042", SelfLink:"", UID:"7250f876-562e-4390-847d-99384a072b3e", ResourceVersion:"15833", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-hnfpd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a94a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a94d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 12, 24, 5, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0059a9530), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0518 12:25:50.693046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:51.693207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:52.693302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:53.693610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:54.693709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:25:55.150: INFO: ResourceQuota "e2e-rq-status-hnfpd" Spec was unchanged and /status reset
  May 18 12:25:55.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3042" for this suite. @ 05/18/24 12:25:55.155
• [110.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/18/24 12:25:55.162
  May 18 12:25:55.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pod-network-test @ 05/18/24 12:25:55.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:25:55.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:25:55.182
  STEP: Performing setup for networking test in namespace pod-network-test-3726 @ 05/18/24 12:25:55.185
  STEP: creating a selector @ 05/18/24 12:25:55.185
  STEP: Creating the service pods in kubernetes @ 05/18/24 12:25:55.185
  May 18 12:25:55.185: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0518 12:25:55.694623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:56.695613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:57.696247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:58.696340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:25:59.696683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:00.696939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:01.697773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:02.698753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:03.698846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:04.699751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:05.700075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:06.700026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/18/24 12:26:07.261
  E0518 12:26:07.700022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:08.700107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:26:09.276: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  May 18 12:26:09.276: INFO: Breadth first check of 192.168.225.245 on host 172.31.33.93...
  May 18 12:26:09.280: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.246:9080/dial?request=hostname&protocol=http&host=192.168.225.245&port=8083&tries=1'] Namespace:pod-network-test-3726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:09.280: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:09.280: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:09.280: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.246%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.225.245%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:09.340: INFO: Waiting for responses: map[]
  May 18 12:26:09.340: INFO: reached 192.168.225.245 after 0/1 tries
  May 18 12:26:09.340: INFO: Breadth first check of 192.168.209.90 on host 172.31.70.23...
  May 18 12:26:09.344: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.246:9080/dial?request=hostname&protocol=http&host=192.168.209.90&port=8083&tries=1'] Namespace:pod-network-test-3726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:09.344: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:09.344: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:09.344: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.246%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.209.90%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:09.401: INFO: Waiting for responses: map[]
  May 18 12:26:09.401: INFO: reached 192.168.209.90 after 0/1 tries
  May 18 12:26:09.401: INFO: Breadth first check of 192.168.198.85 on host 172.31.90.158...
  May 18 12:26:09.405: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.246:9080/dial?request=hostname&protocol=http&host=192.168.198.85&port=8083&tries=1'] Namespace:pod-network-test-3726 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:09.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:09.405: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:09.405: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3726/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.246%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.198.85%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:09.457: INFO: Waiting for responses: map[]
  May 18 12:26:09.457: INFO: reached 192.168.198.85 after 0/1 tries
  May 18 12:26:09.457: INFO: Going to retry 0 out of 3 pods....
  May 18 12:26:09.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3726" for this suite. @ 05/18/24 12:26:09.462
• [14.306 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 05/18/24 12:26:09.468
  May 18 12:26:09.468: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:26:09.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:26:09.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:26:09.49
  STEP: Creating configMap with name cm-test-opt-del-56ce2fee-c957-4f01-bda2-643fcc3e180f @ 05/18/24 12:26:09.495
  STEP: Creating configMap with name cm-test-opt-upd-69cdeac2-6800-402c-8cd0-354179036fd0 @ 05/18/24 12:26:09.499
  STEP: Creating the pod @ 05/18/24 12:26:09.502
  E0518 12:26:09.700484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:10.700744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-56ce2fee-c957-4f01-bda2-643fcc3e180f @ 05/18/24 12:26:11.55
  STEP: Updating configmap cm-test-opt-upd-69cdeac2-6800-402c-8cd0-354179036fd0 @ 05/18/24 12:26:11.557
  STEP: Creating configMap with name cm-test-opt-create-5ffdffec-280e-4435-8cdb-cfea6352ada2 @ 05/18/24 12:26:11.561
  STEP: waiting to observe update in volume @ 05/18/24 12:26:11.565
  E0518 12:26:11.700803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:12.700906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:13.701821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:14.701931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:26:15.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5713" for this suite. @ 05/18/24 12:26:15.601
• [6.140 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/18/24 12:26:15.608
  May 18 12:26:15.608: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pod-network-test @ 05/18/24 12:26:15.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:26:15.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:26:15.627
  STEP: Performing setup for networking test in namespace pod-network-test-7209 @ 05/18/24 12:26:15.629
  STEP: creating a selector @ 05/18/24 12:26:15.629
  STEP: Creating the service pods in kubernetes @ 05/18/24 12:26:15.629
  May 18 12:26:15.629: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0518 12:26:15.702854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:16.703207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:17.703779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:18.703861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:19.704666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:20.705665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:21.706352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:22.706555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:23.707108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:24.707181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:25.707523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:26.708365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:27.709027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:28.709136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:29.709856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:30.710044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:31.710817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:32.711010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:33.711750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:34.712316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:35.713032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:36.713164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:37.713281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/18/24 12:26:37.734
  E0518 12:26:38.713993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:39.714395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:26:39.750: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  May 18 12:26:39.750: INFO: Breadth first check of 192.168.225.247 on host 172.31.33.93...
  May 18 12:26:39.754: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.248:9080/dial?request=hostname&protocol=udp&host=192.168.225.247&port=8081&tries=1'] Namespace:pod-network-test-7209 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:39.754: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:39.754: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:39.754: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7209/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.248%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.225.247%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:39.808: INFO: Waiting for responses: map[]
  May 18 12:26:39.808: INFO: reached 192.168.225.247 after 0/1 tries
  May 18 12:26:39.808: INFO: Breadth first check of 192.168.209.85 on host 172.31.70.23...
  May 18 12:26:39.813: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.248:9080/dial?request=hostname&protocol=udp&host=192.168.209.85&port=8081&tries=1'] Namespace:pod-network-test-7209 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:39.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:39.813: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:39.813: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7209/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.248%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.209.85%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:39.864: INFO: Waiting for responses: map[]
  May 18 12:26:39.864: INFO: reached 192.168.209.85 after 0/1 tries
  May 18 12:26:39.864: INFO: Breadth first check of 192.168.198.91 on host 172.31.90.158...
  May 18 12:26:39.867: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.225.248:9080/dial?request=hostname&protocol=udp&host=192.168.198.91&port=8081&tries=1'] Namespace:pod-network-test-7209 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:39.868: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:39.868: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7209/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.225.248%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.198.91%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  May 18 12:26:39.916: INFO: Waiting for responses: map[]
  May 18 12:26:39.916: INFO: reached 192.168.198.91 after 0/1 tries
  May 18 12:26:39.916: INFO: Going to retry 0 out of 3 pods....
  May 18 12:26:39.916: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7209" for this suite. @ 05/18/24 12:26:39.921
• [24.321 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/18/24 12:26:39.928
  May 18 12:26:39.928: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pod-network-test @ 05/18/24 12:26:39.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:26:39.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:26:39.95
  STEP: Performing setup for networking test in namespace pod-network-test-3777 @ 05/18/24 12:26:39.952
  STEP: creating a selector @ 05/18/24 12:26:39.953
  STEP: Creating the service pods in kubernetes @ 05/18/24 12:26:39.953
  May 18 12:26:39.953: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0518 12:26:40.714455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:41.714764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:42.714945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:43.715161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:44.716096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:45.716301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:46.716398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:47.716473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:48.717469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:49.717494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:50.717611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:51.718074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/18/24 12:26:52.029
  E0518 12:26:52.718156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:53.718244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:26:54.060: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  May 18 12:26:54.060: INFO: Going to poll 192.168.225.250 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  May 18 12:26:54.064: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.225.250:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3777 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:54.064: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:54.064: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:54.064: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3777/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.225.250%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 18 12:26:54.111: INFO: Found all 1 expected endpoints: [netserver-0]
  May 18 12:26:54.111: INFO: Going to poll 192.168.209.98 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  May 18 12:26:54.116: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.209.98:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3777 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:54.116: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:54.116: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:54.116: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3777/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.209.98%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 18 12:26:54.174: INFO: Found all 1 expected endpoints: [netserver-1]
  May 18 12:26:54.174: INFO: Going to poll 192.168.198.95 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  May 18 12:26:54.178: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.198.95:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3777 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:26:54.178: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:26:54.179: INFO: ExecWithOptions: Clientset creation
  May 18 12:26:54.179: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3777/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.198.95%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 18 12:26:54.226: INFO: Found all 1 expected endpoints: [netserver-2]
  May 18 12:26:54.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3777" for this suite. @ 05/18/24 12:26:54.231
• [14.309 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 05/18/24 12:26:54.237
  May 18 12:26:54.237: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 12:26:54.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:26:54.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:26:54.26
  STEP: Creating pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642 @ 05/18/24 12:26:54.263
  E0518 12:26:54.718358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:55.718756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 12:26:56.283
  May 18 12:26:56.286: INFO: Initial restart count of pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 is 0
  May 18 12:26:56.289: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:26:56.719390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:57.720248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:26:58.295: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:26:58.720575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:26:59.720662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:00.299: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:00.720753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:01.720837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:02.304: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:02.720922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:03.721039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:04.310: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:04.721221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:05.721408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:06.316: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:06.722021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:07.722278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:08.320: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:08.722394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:09.722602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:10.326: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:10.722694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:11.722910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:12.331: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:12.723941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:13.724162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:14.335: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:14.724953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:15.725136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:16.341: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:16.726227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:17.726992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:18.345: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:18.727154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:19.728226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:20.352: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:20.728320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:21.728803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:22.356: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:22.729671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:23.729914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:24.361: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:24.730178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:25.730383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:26.367: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:26.730475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:27.730592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:28.371: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:28.730924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:29.731124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:30.376: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:30.732004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:31.732109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:32.381: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:32.732406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:33.732499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:34.385: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:34.733289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:35.733519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:36.391: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:36.733616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:37.733983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:38.396: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:38.734241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:39.734408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:40.402: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:40.734993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:41.735157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:42.408: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:42.735640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:43.736229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:44.412: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:44.737189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:45.737353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:46.416: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:46.738133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:47.738478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:48.422: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:48.738793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:49.738900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:50.427: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:50.739137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:51.739186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:52.432: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:52.739421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:53.739519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:54.438: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:54.740577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:55.741558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:56.442: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:56.742024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:57.742514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:27:58.447: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  E0518 12:27:58.743275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:27:59.743402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:00.453: INFO: Get pod test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 in namespace container-probe-2642
  May 18 12:28:00.453: INFO: Restart count of pod container-probe-2642/test-grpc-9bb92e8a-22e2-4f0a-bf1d-726098eb83d2 is now 1 (1m4.167445884s elapsed)
  STEP: deleting the pod @ 05/18/24 12:28:00.453
  May 18 12:28:00.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2642" for this suite. @ 05/18/24 12:28:00.472
• [66.241 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/18/24 12:28:00.478
  May 18 12:28:00.478: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename events @ 05/18/24 12:28:00.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:00.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:00.499
  STEP: creating a test event @ 05/18/24 12:28:00.501
  STEP: listing events in all namespaces @ 05/18/24 12:28:00.508
  STEP: listing events in test namespace @ 05/18/24 12:28:00.521
  STEP: listing events with field selection filtering on source @ 05/18/24 12:28:00.523
  STEP: listing events with field selection filtering on reportingController @ 05/18/24 12:28:00.526
  STEP: getting the test event @ 05/18/24 12:28:00.529
  STEP: patching the test event @ 05/18/24 12:28:00.532
  STEP: getting the test event @ 05/18/24 12:28:00.545
  STEP: updating the test event @ 05/18/24 12:28:00.549
  STEP: getting the test event @ 05/18/24 12:28:00.557
  STEP: deleting the test event @ 05/18/24 12:28:00.561
  STEP: listing events in all namespaces @ 05/18/24 12:28:00.574
  STEP: listing events in test namespace @ 05/18/24 12:28:00.585
  May 18 12:28:00.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6472" for this suite. @ 05/18/24 12:28:00.593
• [0.121 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 05/18/24 12:28:00.6
  May 18 12:28:00.600: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption @ 05/18/24 12:28:00.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:00.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:00.622
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:28:00.628
  E0518 12:28:00.744287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:01.744382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/18/24 12:28:02.658
  May 18 12:28:02.664: INFO: running pods: 0 < 3
  E0518 12:28:02.744421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:03.744529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:04.666: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5306" for this suite. @ 05/18/24 12:28:04.67
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/18/24 12:28:04.678
  May 18 12:28:04.678: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename watch @ 05/18/24 12:28:04.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:04.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:04.7
  STEP: creating a watch on configmaps with label A @ 05/18/24 12:28:04.702
  STEP: creating a watch on configmaps with label B @ 05/18/24 12:28:04.703
  STEP: creating a watch on configmaps with label A or B @ 05/18/24 12:28:04.704
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/18/24 12:28:04.705
  May 18 12:28:04.709: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16852 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:04.709: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16852 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/18/24 12:28:04.709
  May 18 12:28:04.717: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16853 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:04.717: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16853 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/18/24 12:28:04.717
  May 18 12:28:04.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16854 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:04.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16854 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/18/24 12:28:04.723
  May 18 12:28:04.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16855 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:04.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4972  b4dfcefe-0025-4b61-b04f-52109f7e27dd 16855 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/18/24 12:28:04.728
  May 18 12:28:04.733: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4972  b6220a6f-9869-4282-998d-b02108e633c2 16856 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:04.733: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4972  b6220a6f-9869-4282-998d-b02108e633c2 16856 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0518 12:28:04.744723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:05.745151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:06.744947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:07.745314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:08.745500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:09.745775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:10.746573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:11.746755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:12.747323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:13.747427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/18/24 12:28:14.733
  May 18 12:28:14.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4972  b6220a6f-9869-4282-998d-b02108e633c2 16936 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:28:14.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4972  b6220a6f-9869-4282-998d-b02108e633c2 16936 0 2024-05-18 12:28:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-18 12:28:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0518 12:28:14.747988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:15.748054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:16.748140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:17.748533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:18.749214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:19.749320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:20.749447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:21.749588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:22.749982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:23.750829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:24.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4972" for this suite. @ 05/18/24 12:28:24.745
  E0518 12:28:24.750953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
• [20.076 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 05/18/24 12:28:24.754
  May 18 12:28:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:28:24.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:24.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:24.776
  STEP: Setting up server cert @ 05/18/24 12:28:24.804
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:28:24.968
  STEP: Deploying the webhook pod @ 05/18/24 12:28:24.976
  STEP: Wait for the deployment to be ready @ 05/18/24 12:28:24.987
  May 18 12:28:24.995: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:28:25.751196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:26.751404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:28:27.007
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:28:27.017
  E0518 12:28:27.751942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:28.018: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 18 12:28:28.026: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5534-crds.webhook.example.com via the AdmissionRegistration API @ 05/18/24 12:28:28.536
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/18/24 12:28:28.552
  E0518 12:28:28.752244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:29.752401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:30.752936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:31.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1356" for this suite. @ 05/18/24 12:28:31.178
  STEP: Destroying namespace "webhook-markers-1931" for this suite. @ 05/18/24 12:28:31.185
• [6.437 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 05/18/24 12:28:31.192
  May 18 12:28:31.192: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:28:31.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:31.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:31.213
  STEP: creating Agnhost RC @ 05/18/24 12:28:31.216
  May 18 12:28:31.216: INFO: namespace kubectl-5505
  May 18 12:28:31.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-5505 create -f -'
  May 18 12:28:31.304: INFO: stderr: ""
  May 18 12:28:31.304: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/18/24 12:28:31.304
  E0518 12:28:31.753043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:32.309: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:28:32.309: INFO: Found 0 / 1
  E0518 12:28:32.754052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:33.309: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:28:33.309: INFO: Found 1 / 1
  May 18 12:28:33.309: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May 18 12:28:33.313: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:28:33.313: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 18 12:28:33.313: INFO: wait on agnhost-primary startup in kubectl-5505 
  May 18 12:28:33.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-5505 logs agnhost-primary-dkxfr agnhost-primary'
  May 18 12:28:33.372: INFO: stderr: ""
  May 18 12:28:33.372: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 05/18/24 12:28:33.372
  May 18 12:28:33.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-5505 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  May 18 12:28:33.428: INFO: stderr: ""
  May 18 12:28:33.428: INFO: stdout: "service/rm2 exposed\n"
  May 18 12:28:33.434: INFO: Service rm2 in namespace kubectl-5505 found.
  E0518 12:28:33.754699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:34.754797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/18/24 12:28:35.442
  May 18 12:28:35.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-5505 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  May 18 12:28:35.496: INFO: stderr: ""
  May 18 12:28:35.496: INFO: stdout: "service/rm3 exposed\n"
  May 18 12:28:35.503: INFO: Service rm3 in namespace kubectl-5505 found.
  E0518 12:28:35.755835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:36.755936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:37.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5505" for this suite. @ 05/18/24 12:28:37.514
• [6.328 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 05/18/24 12:28:37.52
  May 18 12:28:37.520: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 12:28:37.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:37.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:37.542
  STEP: Creating service test in namespace statefulset-3993 @ 05/18/24 12:28:37.544
  STEP: Creating statefulset ss in namespace statefulset-3993 @ 05/18/24 12:28:37.548
  May 18 12:28:37.558: INFO: Found 0 stateful pods, waiting for 1
  E0518 12:28:37.756257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:38.756334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:39.756603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:40.756686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:41.756774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:42.756946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:43.757657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:44.757751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:45.757941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:46.758021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:47.561: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/18/24 12:28:47.566
  STEP: updating a scale subresource @ 05/18/24 12:28:47.569
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/18/24 12:28:47.576
  STEP: Patch a scale subresource @ 05/18/24 12:28:47.578
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/18/24 12:28:47.584
  May 18 12:28:47.587: INFO: Deleting all statefulset in ns statefulset-3993
  May 18 12:28:47.591: INFO: Scaling statefulset ss to 0
  E0518 12:28:47.758685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:48.758962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:49.759194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:50.760220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:51.760309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:52.761378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:53.761463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:54.761646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:55.761732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:56.761897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:28:57.604: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 12:28:57.606: INFO: Deleting statefulset ss
  May 18 12:28:57.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3993" for this suite. @ 05/18/24 12:28:57.623
• [20.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 05/18/24 12:28:57.63
  May 18 12:28:57.630: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 12:28:57.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:28:57.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:28:57.652
  May 18 12:28:57.655: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:28:57.762984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:28:58.763451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/18/24 12:28:59.12
  May 18 12:28:59.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4382 --namespace=crd-publish-openapi-4382 create -f -'
  May 18 12:28:59.181: INFO: stderr: ""
  May 18 12:28:59.181: INFO: stdout: "e2e-test-crd-publish-openapi-9131-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May 18 12:28:59.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4382 --namespace=crd-publish-openapi-4382 delete e2e-test-crd-publish-openapi-9131-crds test-cr'
  May 18 12:28:59.227: INFO: stderr: ""
  May 18 12:28:59.227: INFO: stdout: "e2e-test-crd-publish-openapi-9131-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  May 18 12:28:59.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4382 --namespace=crd-publish-openapi-4382 apply -f -'
  May 18 12:28:59.291: INFO: stderr: ""
  May 18 12:28:59.291: INFO: stdout: "e2e-test-crd-publish-openapi-9131-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  May 18 12:28:59.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4382 --namespace=crd-publish-openapi-4382 delete e2e-test-crd-publish-openapi-9131-crds test-cr'
  May 18 12:28:59.340: INFO: stderr: ""
  May 18 12:28:59.340: INFO: stdout: "e2e-test-crd-publish-openapi-9131-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/18/24 12:28:59.34
  May 18 12:28:59.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4382 explain e2e-test-crd-publish-openapi-9131-crds'
  May 18 12:28:59.379: INFO: stderr: ""
  May 18 12:28:59.379: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-9131-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0518 12:28:59.764297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:00.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4382" for this suite. @ 05/18/24 12:29:00.606
• [2.983 seconds]
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 05/18/24 12:29:00.614
  May 18 12:29:00.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename proxy @ 05/18/24 12:29:00.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:00.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:00.639
  May 18 12:29:00.643: INFO: Creating pod...
  E0518 12:29:00.765306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:01.765389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:02.664: INFO: Creating service...
  May 18 12:29:02.675: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/DELETE
  May 18 12:29:02.686: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 18 12:29:02.686: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/GET
  May 18 12:29:02.689: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May 18 12:29:02.689: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/HEAD
  May 18 12:29:02.694: INFO: http.Client request:HEAD | StatusCode:200
  May 18 12:29:02.694: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/OPTIONS
  May 18 12:29:02.697: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 18 12:29:02.697: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/PATCH
  May 18 12:29:02.701: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 18 12:29:02.701: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/POST
  May 18 12:29:02.705: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 18 12:29:02.705: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/pods/agnhost/proxy/some/path/with/PUT
  May 18 12:29:02.709: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 18 12:29:02.709: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/DELETE
  May 18 12:29:02.714: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 18 12:29:02.714: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/GET
  May 18 12:29:02.719: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  May 18 12:29:02.719: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/HEAD
  May 18 12:29:02.725: INFO: http.Client request:HEAD | StatusCode:200
  May 18 12:29:02.725: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/OPTIONS
  May 18 12:29:02.730: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 18 12:29:02.730: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/PATCH
  May 18 12:29:02.736: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 18 12:29:02.736: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/POST
  May 18 12:29:02.743: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 18 12:29:02.743: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-6493/services/test-service/proxy/some/path/with/PUT
  May 18 12:29:02.749: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 18 12:29:02.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6493" for this suite. @ 05/18/24 12:29:02.753
• [2.147 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 05/18/24 12:29:02.761
  May 18 12:29:02.761: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 12:29:02.762
  E0518 12:29:02.765814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:02.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:02.783
  STEP: Creating pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191 @ 05/18/24 12:29:02.791
  E0518 12:29:03.765982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:04.766085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 12:29:04.813
  May 18 12:29:04.818: INFO: Initial restart count of pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 is 0
  May 18 12:29:04.822: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:05.766253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:06.766348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:06.827: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:07.766910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:08.767186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:08.833: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:09.767292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:10.767391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:10.839: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:11.767481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:12.767668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:12.844: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:13.767758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:14.767804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:14.850: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:15.768699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:16.768795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:16.855: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:17.769838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:18.770037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:18.861: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:19.770342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:20.770458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:20.867: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:21.771441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:22.771972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:22.873: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  E0518 12:29:23.772135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:24.773097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:24.879: INFO: Get pod liveness-951d7c30-39de-463b-9aee-9ed0167a6331 in namespace container-probe-2191
  May 18 12:29:24.879: INFO: Restart count of pod container-probe-2191/liveness-951d7c30-39de-463b-9aee-9ed0167a6331 is now 1 (20.061371433s elapsed)
  STEP: deleting the pod @ 05/18/24 12:29:24.88
  May 18 12:29:24.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2191" for this suite. @ 05/18/24 12:29:24.899
• [22.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/18/24 12:29:24.907
  May 18 12:29:24.907: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 12:29:24.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:24.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:24.925
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/18/24 12:29:24.928
  May 18 12:29:24.936: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0518 12:29:25.773202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:26.773299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:27.773539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:28.773634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:29.774414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:29.941: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 12:29:29.941
  STEP: getting scale subresource @ 05/18/24 12:29:29.941
  STEP: updating a scale subresource @ 05/18/24 12:29:29.945
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/18/24 12:29:29.954
  STEP: Patch a scale subresource @ 05/18/24 12:29:29.959
  May 18 12:29:29.987: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5452" for this suite. @ 05/18/24 12:29:29.993
• [5.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/18/24 12:29:30.004
  May 18 12:29:30.004: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/18/24 12:29:30.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:30.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:30.034
  May 18 12:29:30.038: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:29:30.775482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:31.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5001" for this suite. @ 05/18/24 12:29:31.084
• [1.086 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/18/24 12:29:31.091
  May 18 12:29:31.091: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename watch @ 05/18/24 12:29:31.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:31.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:31.111
  STEP: creating a new configmap @ 05/18/24 12:29:31.114
  STEP: modifying the configmap once @ 05/18/24 12:29:31.12
  STEP: modifying the configmap a second time @ 05/18/24 12:29:31.131
  STEP: deleting the configmap @ 05/18/24 12:29:31.139
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/18/24 12:29:31.145
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/18/24 12:29:31.146
  May 18 12:29:31.147: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3100  fc2d6aae-c5ac-466d-94a4-ea0e16ecb62e 17491 0 2024-05-18 12:29:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-18 12:29:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:29:31.147: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3100  fc2d6aae-c5ac-466d-94a4-ea0e16ecb62e 17492 0 2024-05-18 12:29:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-18 12:29:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:29:31.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3100" for this suite. @ 05/18/24 12:29:31.151
• [0.067 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 05/18/24 12:29:31.158
  May 18 12:29:31.158: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-webhook @ 05/18/24 12:29:31.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:31.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:31.177
  STEP: Setting up server cert @ 05/18/24 12:29:31.181
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/18/24 12:29:31.588
  STEP: Deploying the custom resource conversion webhook pod @ 05/18/24 12:29:31.597
  STEP: Wait for the deployment to be ready @ 05/18/24 12:29:31.612
  May 18 12:29:31.628: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0518 12:29:31.775922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:32.776238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:29:33.642
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:29:33.653
  E0518 12:29:33.777297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:34.653: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May 18 12:29:34.663: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:29:34.778218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:35.778470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:36.779311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/18/24 12:29:37.22
  STEP: Create a v2 custom resource @ 05/18/24 12:29:37.237
  STEP: List CRs in v1 @ 05/18/24 12:29:37.268
  STEP: List CRs in v2 @ 05/18/24 12:29:37.272
  E0518 12:29:37.779860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:37.836: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7164" for this suite. @ 05/18/24 12:29:37.84
• [6.693 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/18/24 12:29:37.852
  May 18 12:29:37.852: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:29:37.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:37.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:37.871
  STEP: Creating secret with name projected-secret-test-e8783fe2-1016-428b-98ed-3a19697a2029 @ 05/18/24 12:29:37.874
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:29:37.878
  E0518 12:29:38.779965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:39.780044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:40.780152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:41.780251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:29:41.904
  May 18 12:29:41.908: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-secrets-04716062-590f-4b9e-b860-ee39c2225925 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:29:41.915
  May 18 12:29:41.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-400" for this suite. @ 05/18/24 12:29:41.939
• [4.094 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 05/18/24 12:29:41.946
  May 18 12:29:41.946: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename runtimeclass @ 05/18/24 12:29:41.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:41.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:41.964
  E0518 12:29:42.780800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:43.780879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:43.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9055" for this suite. @ 05/18/24 12:29:44.001
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/18/24 12:29:44.009
  May 18 12:29:44.009: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:29:44.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:44.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:44.027
  STEP: Creating configMap with name configmap-projected-all-test-volume-8a582a0d-b509-4f4f-8b3a-0e675c75d7e3 @ 05/18/24 12:29:44.03
  STEP: Creating secret with name secret-projected-all-test-volume-3ab02e98-01df-4239-985a-3fa041ec36ff @ 05/18/24 12:29:44.035
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/18/24 12:29:44.039
  E0518 12:29:44.781373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:45.781478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:46.781554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:47.781871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:29:48.065
  May 18 12:29:48.068: INFO: Trying to get logs from node ip-172-31-33-93 pod projected-volume-199e3fb8-c9c3-4668-9488-5f8d94cb6323 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:29:48.075
  May 18 12:29:48.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7380" for this suite. @ 05/18/24 12:29:48.097
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 05/18/24 12:29:48.104
  May 18 12:29:48.104: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:29:48.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:48.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:48.122
  STEP: creating Agnhost RC @ 05/18/24 12:29:48.125
  May 18 12:29:48.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-7666 create -f -'
  May 18 12:29:48.206: INFO: stderr: ""
  May 18 12:29:48.206: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/18/24 12:29:48.206
  E0518 12:29:48.781967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:49.211: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:29:49.211: INFO: Found 0 / 1
  E0518 12:29:49.782247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:50.211: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:29:50.211: INFO: Found 1 / 1
  May 18 12:29:50.211: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/18/24 12:29:50.211
  May 18 12:29:50.215: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:29:50.215: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 18 12:29:50.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-7666 patch pod agnhost-primary-2jp7g -p {"metadata":{"annotations":{"x":"y"}}}'
  May 18 12:29:50.263: INFO: stderr: ""
  May 18 12:29:50.263: INFO: stdout: "pod/agnhost-primary-2jp7g patched\n"
  STEP: checking annotations @ 05/18/24 12:29:50.263
  May 18 12:29:50.267: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 12:29:50.267: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 18 12:29:50.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7666" for this suite. @ 05/18/24 12:29:50.271
• [2.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/18/24 12:29:50.279
  May 18 12:29:50.279: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 12:29:50.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:50.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:50.296
  May 18 12:29:50.313: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0518 12:29:50.783299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:51.783414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:52.784319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:53.784441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:54.784553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:55.317: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 12:29:55.317
  STEP: Scaling up "test-rs" replicaset @ 05/18/24 12:29:55.317
  May 18 12:29:55.327: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/18/24 12:29:55.327
  May 18 12:29:55.338: INFO: observed ReplicaSet test-rs in namespace replicaset-992 with ReadyReplicas 1, AvailableReplicas 1
  May 18 12:29:55.351: INFO: observed ReplicaSet test-rs in namespace replicaset-992 with ReadyReplicas 1, AvailableReplicas 1
  May 18 12:29:55.371: INFO: observed ReplicaSet test-rs in namespace replicaset-992 with ReadyReplicas 1, AvailableReplicas 1
  May 18 12:29:55.380: INFO: observed ReplicaSet test-rs in namespace replicaset-992 with ReadyReplicas 1, AvailableReplicas 1
  E0518 12:29:55.785621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:56.452: INFO: observed ReplicaSet test-rs in namespace replicaset-992 with ReadyReplicas 2, AvailableReplicas 2
  E0518 12:29:56.786469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:29:56.860: INFO: observed Replicaset test-rs in namespace replicaset-992 with ReadyReplicas 3 found true
  May 18 12:29:56.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-992" for this suite. @ 05/18/24 12:29:56.866
• [6.593 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/18/24 12:29:56.872
  May 18 12:29:56.872: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:29:56.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:29:56.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:29:56.892
  STEP: Creating secret with name s-test-opt-del-299e9863-5945-45d5-86b3-d83e0b778f60 @ 05/18/24 12:29:56.9
  STEP: Creating secret with name s-test-opt-upd-9106d66b-87ef-4d38-8292-999feaa85bfd @ 05/18/24 12:29:56.907
  STEP: Creating the pod @ 05/18/24 12:29:56.912
  E0518 12:29:57.786922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:29:58.787186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-299e9863-5945-45d5-86b3-d83e0b778f60 @ 05/18/24 12:29:58.957
  STEP: Updating secret s-test-opt-upd-9106d66b-87ef-4d38-8292-999feaa85bfd @ 05/18/24 12:29:58.964
  STEP: Creating secret with name s-test-opt-create-aa7f20ce-b06f-45e0-9c8c-29a1303636b8 @ 05/18/24 12:29:58.969
  STEP: waiting to observe update in volume @ 05/18/24 12:29:58.974
  E0518 12:29:59.788185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:00.788279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:01.788368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:02.789345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:30:03.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9264" for this suite. @ 05/18/24 12:30:03.016
• [6.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 05/18/24 12:30:03.024
  May 18 12:30:03.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:30:03.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:30:03.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:30:03.045
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2534 @ 05/18/24 12:30:03.048
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/18/24 12:30:03.058
  STEP: creating service externalsvc in namespace services-2534 @ 05/18/24 12:30:03.059
  STEP: creating replication controller externalsvc in namespace services-2534 @ 05/18/24 12:30:03.073
  I0518 12:30:03.084677      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-2534, replica count: 2
  E0518 12:30:03.789435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:04.789887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:05.789987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 12:30:06.135488      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 05/18/24 12:30:06.141
  May 18 12:30:06.156: INFO: Creating new exec pod
  E0518 12:30:06.790136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:07.790540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:30:08.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2534 exec execpodxl4f4 -- /bin/sh -x -c nslookup clusterip-service.services-2534.svc.cluster.local'
  May 18 12:30:08.288: INFO: stderr: "+ nslookup clusterip-service.services-2534.svc.cluster.local\n"
  May 18 12:30:08.288: INFO: stdout: "Server:\t\t10.152.183.117\nAddress:\t10.152.183.117#53\n\nclusterip-service.services-2534.svc.cluster.local\tcanonical name = externalsvc.services-2534.svc.cluster.local.\nName:\texternalsvc.services-2534.svc.cluster.local\nAddress: 10.152.183.71\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2534, will wait for the garbage collector to delete the pods @ 05/18/24 12:30:08.288
  May 18 12:30:08.349: INFO: Deleting ReplicationController externalsvc took: 7.183072ms
  May 18 12:30:08.450: INFO: Terminating ReplicationController externalsvc pods took: 100.358022ms
  E0518 12:30:08.790909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:09.791228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:10.791642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:30:11.673: INFO: Cleaning up the ClusterIP to ExternalName test service
  May 18 12:30:11.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2534" for this suite. @ 05/18/24 12:30:11.691
• [8.673 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 05/18/24 12:30:11.697
  May 18 12:30:11.697: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context-test @ 05/18/24 12:30:11.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:30:11.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:30:11.716
  E0518 12:30:11.792550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:12.792855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:13.793332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:14.793422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:30:15.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7511" for this suite. @ 05/18/24 12:30:15.748
• [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/18/24 12:30:15.757
  May 18 12:30:15.757: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:30:15.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:30:15.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:30:15.778
  STEP: Creating secret with name secret-test-a06d68d4-b00a-499f-bcd8-73d6c54d8f42 @ 05/18/24 12:30:15.78
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:30:15.785
  E0518 12:30:15.793727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:16.793833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:17.793996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:30:17.804
  May 18 12:30:17.809: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-secrets-0bbe60b2-e2a2-467d-a565-daf39d179f25 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:30:17.816
  May 18 12:30:17.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8278" for this suite. @ 05/18/24 12:30:17.835
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 05/18/24 12:30:17.842
  May 18 12:30:17.842: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:30:17.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:30:17.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:30:17.859
  STEP: Creating configMap with name configmap-test-upd-a5954244-4fce-44ed-b9b3-63545af4f27f @ 05/18/24 12:30:17.868
  STEP: Creating the pod @ 05/18/24 12:30:17.874
  E0518 12:30:18.794204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:19.794556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-a5954244-4fce-44ed-b9b3-63545af4f27f @ 05/18/24 12:30:19.904
  STEP: waiting to observe update in volume @ 05/18/24 12:30:19.91
  E0518 12:30:20.794730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:21.794827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:22.794878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:23.794978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:24.795377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:25.795463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:26.795554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:27.795910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:28.796028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:29.796148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:30.796234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:31.796349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:32.797342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:33.797494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:34.797601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:35.797695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:36.797801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:37.797849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:38.798318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:39.798411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:40.798503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:41.798590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:42.798891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:43.799333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:44.799431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:45.800248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:46.801025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:47.802067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:48.802158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:49.802473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:50.802670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:51.802745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:52.803547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:53.804290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:54.805036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:55.805244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:56.806011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:57.806903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:58.807281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:30:59.807354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:00.807686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:01.807560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:02.807691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:03.807802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:04.808835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:05.808918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:06.809007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:07.809719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:08.810568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:09.811324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:10.811432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:11.812273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:12.812943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:13.813125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:14.813217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:15.814132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:16.814886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:17.815926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:18.816923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:19.817006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:20.817780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:21.817844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:22.818896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:23.819694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:24.820249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:25.820418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:26.821158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:27.821544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:28.822331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:29.822450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:30.823258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:31.824270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:32.824983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:33.825194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:34.825715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:35.825811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:36.826442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:37.826724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:38.827677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:39.827853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:40.827954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:41.828034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:42.828935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:43.829121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:31:44.305: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-205" for this suite. @ 05/18/24 12:31:44.31
• [86.476 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 05/18/24 12:31:44.318
  May 18 12:31:44.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:31:44.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:31:44.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:31:44.338
  STEP: Setting up server cert @ 05/18/24 12:31:44.362
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:31:44.527
  STEP: Deploying the webhook pod @ 05/18/24 12:31:44.536
  STEP: Wait for the deployment to be ready @ 05/18/24 12:31:44.549
  May 18 12:31:44.556: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:31:44.829828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:45.830099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:31:46.569
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:31:46.581
  E0518 12:31:46.830232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:31:47.582: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/18/24 12:31:47.59
  STEP: create a pod that should be denied by the webhook @ 05/18/24 12:31:47.604
  STEP: create a pod that causes the webhook to hang @ 05/18/24 12:31:47.611
  E0518 12:31:47.830920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:48.831081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:49.831181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:50.831283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:51.831462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:52.831724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:53.831800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:54.831903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:55.832256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:56.832448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 05/18/24 12:31:57.619
  STEP: create a configmap that should be admitted by the webhook @ 05/18/24 12:31:57.651
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/18/24 12:31:57.659
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/18/24 12:31:57.667
  STEP: create a namespace that bypass the webhook @ 05/18/24 12:31:57.673
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/18/24 12:31:57.69
  May 18 12:31:57.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6059" for this suite. @ 05/18/24 12:31:57.756
  STEP: Destroying namespace "webhook-markers-2160" for this suite. @ 05/18/24 12:31:57.765
  STEP: Destroying namespace "exempted-namespace-6196" for this suite. @ 05/18/24 12:31:57.772
• [13.461 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 05/18/24 12:31:57.78
  May 18 12:31:57.780: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:31:57.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:31:57.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:31:57.801
  STEP: Creating configMap with name configmap-test-volume-map-c3abe1c9-945b-4802-b24f-6f5b5efb964f @ 05/18/24 12:31:57.804
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:31:57.809
  E0518 12:31:57.832521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:58.832637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:31:59.833217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:00.833416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:01.833730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:32:01.834
  May 18 12:32:01.838: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-9b11d339-a70d-4894-a98a-f959858609e0 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:32:01.846
  May 18 12:32:01.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1168" for this suite. @ 05/18/24 12:32:01.869
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 05/18/24 12:32:01.876
  May 18 12:32:01.876: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:32:01.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:01.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:01.895
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/18/24 12:32:01.898
  E0518 12:32:02.834528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:03.834658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:04.835146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:05.835235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:32:05.92
  May 18 12:32:05.928: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-b6bc872e-e809-441e-bbe6-c8b07774608d container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:32:05.936
  May 18 12:32:05.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7461" for this suite. @ 05/18/24 12:32:05.957
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 05/18/24 12:32:05.966
  May 18 12:32:05.966: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 12:32:05.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:05.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:05.991
  STEP: Creating namespace "e2e-ns-xm74f" @ 05/18/24 12:32:05.994
  May 18 12:32:06.010: INFO: Namespace "e2e-ns-xm74f-8305" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-xm74f-8305" @ 05/18/24 12:32:06.01
  May 18 12:32:06.022: INFO: Namespace "e2e-ns-xm74f-8305" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-xm74f-8305" @ 05/18/24 12:32:06.022
  May 18 12:32:06.030: INFO: Namespace "e2e-ns-xm74f-8305" has []v1.FinalizerName{"kubernetes"}
  May 18 12:32:06.030: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1634" for this suite. @ 05/18/24 12:32:06.035
  STEP: Destroying namespace "e2e-ns-xm74f-8305" for this suite. @ 05/18/24 12:32:06.041
• [0.081 seconds]
------------------------------
S
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 05/18/24 12:32:06.048
  May 18 12:32:06.048: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:32:06.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:06.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:06.067
  May 18 12:32:06.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-492" for this suite. @ 05/18/24 12:32:06.077
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 05/18/24 12:32:06.084
  May 18 12:32:06.084: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:32:06.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:06.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:06.105
  STEP: creating all guestbook components @ 05/18/24 12:32:06.108
  May 18 12:32:06.108: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  May 18 12:32:06.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.191: INFO: stderr: ""
  May 18 12:32:06.191: INFO: stdout: "service/agnhost-replica created\n"
  May 18 12:32:06.191: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  May 18 12:32:06.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.278: INFO: stderr: ""
  May 18 12:32:06.278: INFO: stdout: "service/agnhost-primary created\n"
  May 18 12:32:06.279: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  May 18 12:32:06.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.362: INFO: stderr: ""
  May 18 12:32:06.362: INFO: stdout: "service/frontend created\n"
  May 18 12:32:06.362: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  May 18 12:32:06.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.430: INFO: stderr: ""
  May 18 12:32:06.430: INFO: stdout: "deployment.apps/frontend created\n"
  May 18 12:32:06.430: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May 18 12:32:06.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.499: INFO: stderr: ""
  May 18 12:32:06.499: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  May 18 12:32:06.499: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  May 18 12:32:06.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 create -f -'
  May 18 12:32:06.557: INFO: stderr: ""
  May 18 12:32:06.557: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/18/24 12:32:06.557
  May 18 12:32:06.557: INFO: Waiting for all frontend pods to be Running.
  E0518 12:32:06.836268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:07.836738      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:08.837040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:09.837216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:10.837366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:11.607: INFO: Waiting for frontend to serve content.
  May 18 12:32:11.619: INFO: Trying to add a new entry to the guestbook.
  May 18 12:32:11.633: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.644
  May 18 12:32:11.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  May 18 12:32:11.697: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.697: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.697
  May 18 12:32:11.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  May 18 12:32:11.755: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.755: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.755
  May 18 12:32:11.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  May 18 12:32:11.817: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.817: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.817
  May 18 12:32:11.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  E0518 12:32:11.837986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:11.861: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.861: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.861
  May 18 12:32:11.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  May 18 12:32:11.924: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.924: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/18/24 12:32:11.924
  May 18 12:32:11.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4963 delete --grace-period=0 --force -f -'
  May 18 12:32:11.990: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:32:11.991: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  May 18 12:32:11.991: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4963" for this suite. @ 05/18/24 12:32:11.995
• [5.919 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 05/18/24 12:32:12.003
  May 18 12:32:12.003: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:32:12.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:12.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:12.048
  STEP: Counting existing ResourceQuota @ 05/18/24 12:32:12.053
  E0518 12:32:12.838890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:13.839236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:14.839960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:15.840668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:16.841736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 12:32:17.057
  STEP: Ensuring resource quota status is calculated @ 05/18/24 12:32:17.063
  E0518 12:32:17.841860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:18.842049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:19.068: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9624" for this suite. @ 05/18/24 12:32:19.073
• [7.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/18/24 12:32:19.082
  May 18 12:32:19.082: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-runtime @ 05/18/24 12:32:19.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:19.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:19.102
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/18/24 12:32:19.113
  E0518 12:32:19.842797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:20.843680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:21.843798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:22.844018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:23.845010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:24.845102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:25.846049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:26.846156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:27.846961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:28.847789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:29.847890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:30.847926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:31.848298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/18/24 12:32:32.186
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/18/24 12:32:32.19
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/18/24 12:32:32.198
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/18/24 12:32:32.198
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/18/24 12:32:32.225
  E0518 12:32:32.848376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:33.848464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:34.848523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/18/24 12:32:35.245
  E0518 12:32:35.848610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/18/24 12:32:36.255
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/18/24 12:32:36.263
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/18/24 12:32:36.263
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/18/24 12:32:36.288
  E0518 12:32:36.848719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/18/24 12:32:37.298
  E0518 12:32:37.848927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:38.849180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/18/24 12:32:39.314
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/18/24 12:32:39.322
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/18/24 12:32:39.322
  May 18 12:32:39.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9426" for this suite. @ 05/18/24 12:32:39.355
• [20.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 05/18/24 12:32:39.363
  May 18 12:32:39.363: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:32:39.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:39.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:39.384
  STEP: creating service endpoint-test2 in namespace services-2664 @ 05/18/24 12:32:39.387
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2664 to expose endpoints map[] @ 05/18/24 12:32:39.396
  May 18 12:32:39.402: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0518 12:32:39.849231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:40.411: INFO: successfully validated that service endpoint-test2 in namespace services-2664 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2664 @ 05/18/24 12:32:40.411
  E0518 12:32:40.849313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:41.849585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2664 to expose endpoints map[pod1:[80]] @ 05/18/24 12:32:42.434
  May 18 12:32:42.447: INFO: successfully validated that service endpoint-test2 in namespace services-2664 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/18/24 12:32:42.447
  May 18 12:32:42.447: INFO: Creating new exec pod
  E0518 12:32:42.850324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:43.850451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:44.851184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:45.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 18 12:32:45.560: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 18 12:32:45.560: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:32:45.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.225 80'
  May 18 12:32:45.647: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.225 80\nConnection to 10.152.183.225 80 port [tcp/http] succeeded!\n"
  May 18 12:32:45.647: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-2664 @ 05/18/24 12:32:45.647
  E0518 12:32:45.852024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:46.852285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2664 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/18/24 12:32:47.67
  May 18 12:32:47.685: INFO: successfully validated that service endpoint-test2 in namespace services-2664 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/18/24 12:32:47.685
  E0518 12:32:47.852601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:48.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 18 12:32:48.774: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 18 12:32:48.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:32:48.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.225 80'
  E0518 12:32:48.853539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:48.865: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.225 80\nConnection to 10.152.183.225 80 port [tcp/http] succeeded!\n"
  May 18 12:32:48.865: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2664 @ 05/18/24 12:32:48.865
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2664 to expose endpoints map[pod2:[80]] @ 05/18/24 12:32:48.883
  May 18 12:32:48.898: INFO: successfully validated that service endpoint-test2 in namespace services-2664 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/18/24 12:32:48.898
  E0518 12:32:49.854479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:49.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  May 18 12:32:49.994: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  May 18 12:32:49.994: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 12:32:49.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2664 exec execpods985r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.225 80'
  May 18 12:32:50.088: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.225 80\nConnection to 10.152.183.225 80 port [tcp/http] succeeded!\n"
  May 18 12:32:50.089: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-2664 @ 05/18/24 12:32:50.089
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2664 to expose endpoints map[] @ 05/18/24 12:32:50.111
  E0518 12:32:50.854818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:51.132: INFO: successfully validated that service endpoint-test2 in namespace services-2664 exposes endpoints map[]
  May 18 12:32:51.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2664" for this suite. @ 05/18/24 12:32:51.155
• [11.799 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 05/18/24 12:32:51.162
  May 18 12:32:51.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename runtimeclass @ 05/18/24 12:32:51.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:51.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:51.181
  STEP: Deleting RuntimeClass runtimeclass-4412-delete-me @ 05/18/24 12:32:51.189
  STEP: Waiting for the RuntimeClass to disappear @ 05/18/24 12:32:51.197
  May 18 12:32:51.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4412" for this suite. @ 05/18/24 12:32:51.212
• [0.057 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/18/24 12:32:51.219
  May 18 12:32:51.219: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 12:32:51.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:51.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:51.238
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/18/24 12:32:51.241
  E0518 12:32:51.855194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:52.855292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 05/18/24 12:32:53.266
  STEP: Then the orphan pod is adopted @ 05/18/24 12:32:53.271
  E0518 12:32:53.856258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 05/18/24 12:32:54.28
  May 18 12:32:54.284: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/18/24 12:32:54.296
  E0518 12:32:54.856371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:32:55.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5472" for this suite. @ 05/18/24 12:32:55.31
• [4.099 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 05/18/24 12:32:55.318
  May 18 12:32:55.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:32:55.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:55.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:55.338
  STEP: Creating configMap with name projected-configmap-test-volume-c80f89fc-ea75-4ba3-b09d-e8eb84dba140 @ 05/18/24 12:32:55.341
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:32:55.346
  E0518 12:32:55.856442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:56.856551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:57.856716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:32:58.856820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:32:59.372
  May 18 12:32:59.376: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-configmaps-8cd2b561-4ce9-4b1d-abaa-b8253c7fb3a7 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:32:59.384
  May 18 12:32:59.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8394" for this suite. @ 05/18/24 12:32:59.406
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 05/18/24 12:32:59.414
  May 18 12:32:59.414: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 12:32:59.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:32:59.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:32:59.435
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/18/24 12:32:59.438
  May 18 12:32:59.438: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:32:59.857711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:33:00.680: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:33:00.858623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:01.859009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:02.859427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:03.859513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:04.859605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:33:05.755: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9060" for this suite. @ 05/18/24 12:33:05.761
• [6.354 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/18/24 12:33:05.768
  May 18 12:33:05.768: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 12:33:05.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:05.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:05.789
  STEP: creating the pod @ 05/18/24 12:33:05.794
  STEP: setting up watch @ 05/18/24 12:33:05.794
  E0518 12:33:05.860318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: submitting the pod to kubernetes @ 05/18/24 12:33:05.897
  STEP: verifying the pod is in kubernetes @ 05/18/24 12:33:05.907
  STEP: verifying pod creation was observed @ 05/18/24 12:33:05.912
  E0518 12:33:06.860435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:07.861016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/18/24 12:33:07.922
  STEP: verifying pod deletion was observed @ 05/18/24 12:33:07.93
  E0518 12:33:08.861323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:33:08.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2568" for this suite. @ 05/18/24 12:33:08.954
• [3.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 05/18/24 12:33:08.96
  May 18 12:33:08.960: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:33:08.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:08.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:08.979
  STEP: Creating a pod to test downward api env vars @ 05/18/24 12:33:08.982
  E0518 12:33:09.861506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:10.861757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:11.862739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:12.862975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:33:13.008
  May 18 12:33:13.011: INFO: Trying to get logs from node ip-172-31-33-93 pod downward-api-549f2d02-fe1d-493a-b692-590298a89182 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:33:13.022
  May 18 12:33:13.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9115" for this suite. @ 05/18/24 12:33:13.039
• [4.085 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 05/18/24 12:33:13.045
  May 18 12:33:13.045: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 12:33:13.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:13.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:13.066
  STEP: Creating a test namespace @ 05/18/24 12:33:13.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:13.087
  STEP: Creating a pod in the namespace @ 05/18/24 12:33:13.089
  STEP: Waiting for the pod to have running status @ 05/18/24 12:33:13.099
  E0518 12:33:13.863122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:14.863176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 05/18/24 12:33:15.105
  STEP: Waiting for the namespace to be removed. @ 05/18/24 12:33:15.111
  E0518 12:33:15.863308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:16.863406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:17.864046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:18.864155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:19.864258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:20.864840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:21.865748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:22.866114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:23.867173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:24.867525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:25.867605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/18/24 12:33:26.116
  STEP: Verifying there are no pods in the namespace @ 05/18/24 12:33:26.134
  May 18 12:33:26.140: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1460" for this suite. @ 05/18/24 12:33:26.143
  STEP: Destroying namespace "nsdeletetest-6109" for this suite. @ 05/18/24 12:33:26.155
  May 18 12:33:26.157: INFO: Namespace nsdeletetest-6109 was already deleted
  STEP: Destroying namespace "nsdeletetest-2018" for this suite. @ 05/18/24 12:33:26.157
• [13.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 05/18/24 12:33:26.165
  May 18 12:33:26.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:33:26.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:26.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:26.183
  STEP: Creating configMap with name configmap-test-volume-e8481c36-408b-41e1-8803-35d640969a3d @ 05/18/24 12:33:26.186
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:33:26.191
  E0518 12:33:26.868640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:27.868999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:33:28.209
  May 18 12:33:28.213: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-294f1ccb-a2f0-4f5c-a186-b0e82dc3ec81 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:33:28.219
  May 18 12:33:28.233: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3447" for this suite. @ 05/18/24 12:33:28.236
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/18/24 12:33:28.244
  May 18 12:33:28.244: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subpath @ 05/18/24 12:33:28.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:28.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:28.264
  STEP: Setting up data @ 05/18/24 12:33:28.267
  STEP: Creating pod pod-subpath-test-projected-4mgc @ 05/18/24 12:33:28.274
  STEP: Creating a pod to test atomic-volume-subpath @ 05/18/24 12:33:28.274
  E0518 12:33:28.869889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:29.869996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:30.870092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:31.870483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:32.871084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:33.871208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:34.872237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:35.872672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:36.873613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:37.874414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:38.874525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:39.874710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:40.875154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:41.875253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:42.875739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:43.875831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:44.876234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:45.877165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:46.878132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:47.878539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:48.878782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:49.878956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:33:50.341
  May 18 12:33:50.345: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-subpath-test-projected-4mgc container test-container-subpath-projected-4mgc: <nil>
  STEP: delete the pod @ 05/18/24 12:33:50.355
  STEP: Deleting pod pod-subpath-test-projected-4mgc @ 05/18/24 12:33:50.371
  May 18 12:33:50.371: INFO: Deleting pod "pod-subpath-test-projected-4mgc" in namespace "subpath-9986"
  May 18 12:33:50.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9986" for this suite. @ 05/18/24 12:33:50.379
• [22.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 05/18/24 12:33:50.384
  May 18 12:33:50.384: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:33:50.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:50.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:50.404
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/18/24 12:33:50.407
  E0518 12:33:50.879665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:51.880252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:52.880718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:53.880841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:33:54.427
  May 18 12:33:54.431: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-0470af11-72dd-48e6-a614-40bae921a29a container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:33:54.438
  May 18 12:33:54.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4728" for this suite. @ 05/18/24 12:33:54.456
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 05/18/24 12:33:54.461
  May 18 12:33:54.461: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:33:54.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:54.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:54.483
  STEP: Creating a pod to test downward api env vars @ 05/18/24 12:33:54.486
  E0518 12:33:54.880951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:55.881058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:56.881153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:57.881613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:33:58.509
  May 18 12:33:58.512: INFO: Trying to get logs from node ip-172-31-33-93 pod downward-api-f6c236f0-a1d3-4b1a-980d-0d33bafbfd5d container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:33:58.519
  May 18 12:33:58.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9875" for this suite. @ 05/18/24 12:33:58.54
• [4.087 seconds]
------------------------------
SSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 05/18/24 12:33:58.548
  May 18 12:33:58.548: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename cronjob @ 05/18/24 12:33:58.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:33:58.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:33:58.574
  STEP: Creating a ReplaceConcurrent cronjob @ 05/18/24 12:33:58.578
  STEP: Ensuring a job is scheduled @ 05/18/24 12:33:58.584
  E0518 12:33:58.882153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:33:59.882263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/18/24 12:34:00.588
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/18/24 12:34:00.591
  STEP: Ensuring the job is replaced with a new one @ 05/18/24 12:34:00.595
  E0518 12:34:00.882900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:01.882989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:02.883766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:03.884172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:04.885078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:05.885262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:06.886025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:07.887065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:08.887762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:09.887856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:10.888626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:11.888718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:12.888858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:13.888954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:14.889792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:15.889885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:16.890325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:17.890433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:18.891090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:19.891241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:20.891712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:21.891808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:22.891903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:23.891999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:24.892095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:25.892310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:26.892376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:27.892404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:28.892904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:29.893002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:30.893583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:31.893763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:32.894057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:33.894249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:34.894798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:35.894891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:36.895592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:37.896025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:38.896710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:39.896818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:40.896938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:41.897016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:42.897506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:43.897557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:44.898104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:45.898203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:46.898726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:47.899021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:48.899182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:49.899365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:50.900406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:51.900606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:52.901228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:53.901355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:54.901959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:55.902154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:56.903229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:57.903794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:58.903901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:34:59.904006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/18/24 12:35:00.598
  May 18 12:35:00.604: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7123" for this suite. @ 05/18/24 12:35:00.609
• [62.068 seconds]
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 05/18/24 12:35:00.616
  May 18 12:35:00.616: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption @ 05/18/24 12:35:00.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:00.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:00.641
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/18/24 12:35:00.645
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:35:00.65
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/18/24 12:35:00.66
  STEP: Waiting for all pods to be running @ 05/18/24 12:35:00.66
  May 18 12:35:00.664: INFO: pods: 0 < 3
  E0518 12:35:00.904125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:01.904433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/18/24 12:35:02.666
  STEP: Updating the pdb to allow a pod to be evicted @ 05/18/24 12:35:02.676
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:35:02.685
  E0518 12:35:02.905422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:03.905761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/18/24 12:35:04.69
  STEP: Waiting for all pods to be running @ 05/18/24 12:35:04.69
  STEP: Waiting for the pdb to observed all healthy pods @ 05/18/24 12:35:04.694
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/18/24 12:35:04.719
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:35:04.733
  E0518 12:35:04.906745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:05.906924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/18/24 12:35:06.739
  STEP: locating a running pod @ 05/18/24 12:35:06.744
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/18/24 12:35:06.757
  STEP: Waiting for the pdb to be deleted @ 05/18/24 12:35:06.763
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/18/24 12:35:06.767
  STEP: Waiting for all pods to be running @ 05/18/24 12:35:06.767
  May 18 12:35:06.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4116" for this suite. @ 05/18/24 12:35:06.796
• [6.189 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/18/24 12:35:06.805
  May 18 12:35:06.805: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:35:06.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:06.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:06.829
  STEP: Creating a pod to test downward api env vars @ 05/18/24 12:35:06.833
  E0518 12:35:06.907761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:07.908130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:08.908465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:09.908743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:35:10.862
  May 18 12:35:10.866: INFO: Trying to get logs from node ip-172-31-33-93 pod downward-api-421a1cf4-d51b-4015-a707-887ef6f8cdd3 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:35:10.874
  May 18 12:35:10.889: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3269" for this suite. @ 05/18/24 12:35:10.892
• [4.093 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 05/18/24 12:35:10.898
  May 18 12:35:10.898: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:35:10.898
  E0518 12:35:10.909565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:10.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:10.923
  STEP: create deployment with httpd image @ 05/18/24 12:35:10.926
  May 18 12:35:10.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-1314 create -f -'
  May 18 12:35:10.987: INFO: stderr: ""
  May 18 12:35:10.987: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/18/24 12:35:10.987
  May 18 12:35:10.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-1314 diff -f -'
  E0518 12:35:11.909733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:12.909773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:13.909877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:14.910133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:15.272: INFO: rc: 1
  May 18 12:35:15.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-1314 delete -f -'
  May 18 12:35:15.317: INFO: stderr: ""
  May 18 12:35:15.317: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  May 18 12:35:15.317: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1314" for this suite. @ 05/18/24 12:35:15.321
• [4.430 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/18/24 12:35:15.328
  May 18 12:35:15.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 12:35:15.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:15.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:15.351
  May 18 12:35:15.354: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: creating the pod @ 05/18/24 12:35:15.354
  STEP: submitting the pod to kubernetes @ 05/18/24 12:35:15.354
  E0518 12:35:15.910430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:16.910515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:17.425: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-254" for this suite. @ 05/18/24 12:35:17.429
• [2.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/18/24 12:35:17.436
  May 18 12:35:17.436: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 12:35:17.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:17.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:17.457
  STEP: Creating simple DaemonSet "daemon-set" @ 05/18/24 12:35:17.475
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 12:35:17.479
  May 18 12:35:17.482: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:17.482: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:17.486: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:35:17.486: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:35:17.911561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:18.484: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:18.484: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:18.488: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 18 12:35:18.488: INFO: Node ip-172-31-70-23 is running 0 daemon pod, expected 1
  E0518 12:35:18.911825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:19.485: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:19.485: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:19.489: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 12:35:19.489: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/18/24 12:35:19.493
  May 18 12:35:19.516: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:19.516: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:19.518: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 18 12:35:19.518: INFO: Node ip-172-31-90-158 is running 0 daemon pod, expected 1
  E0518 12:35:19.912212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:20.513: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:20.513: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:35:20.518: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 12:35:20.518: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 12:35:20.522
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3153, will wait for the garbage collector to delete the pods @ 05/18/24 12:35:20.522
  May 18 12:35:20.584: INFO: Deleting DaemonSet.extensions daemon-set took: 8.259033ms
  May 18 12:35:20.684: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.442333ms
  E0518 12:35:20.912556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:21.913539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:22.490: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:35:22.490: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 12:35:22.492: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20287"},"items":null}

  May 18 12:35:22.495: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20287"},"items":null}

  May 18 12:35:22.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3153" for this suite. @ 05/18/24 12:35:22.509
• [5.080 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 05/18/24 12:35:22.516
  May 18 12:35:22.516: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/18/24 12:35:22.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:22.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:22.538
  STEP: Setting up the test @ 05/18/24 12:35:22.541
  STEP: Creating hostNetwork=false pod @ 05/18/24 12:35:22.541
  E0518 12:35:22.914309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:23.914369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 05/18/24 12:35:24.563
  E0518 12:35:24.914569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:25.914697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 05/18/24 12:35:26.581
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/18/24 12:35:26.581
  May 18 12:35:26.581: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.581: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.582: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.582: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 18 12:35:26.641: INFO: Exec stderr: ""
  May 18 12:35:26.641: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.641: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.642: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.642: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 18 12:35:26.693: INFO: Exec stderr: ""
  May 18 12:35:26.693: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.693: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.693: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.693: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 18 12:35:26.742: INFO: Exec stderr: ""
  May 18 12:35:26.742: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.742: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.742: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.742: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 18 12:35:26.793: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/18/24 12:35:26.793
  May 18 12:35:26.793: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.793: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.793: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.793: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  May 18 12:35:26.841: INFO: Exec stderr: ""
  May 18 12:35:26.841: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.841: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.841: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.841: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  May 18 12:35:26.888: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/18/24 12:35:26.888
  May 18 12:35:26.888: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.888: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.889: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.889: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  E0518 12:35:26.914910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:35:26.947: INFO: Exec stderr: ""
  May 18 12:35:26.947: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.947: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.948: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.948: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  May 18 12:35:26.995: INFO: Exec stderr: ""
  May 18 12:35:26.995: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:26.995: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:26.995: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:26.995: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 18 12:35:27.030: INFO: Exec stderr: ""
  May 18 12:35:27.030: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5336 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:35:27.030: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:35:27.031: INFO: ExecWithOptions: Clientset creation
  May 18 12:35:27.031: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5336/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  May 18 12:35:27.075: INFO: Exec stderr: ""
  May 18 12:35:27.075: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-5336" for this suite. @ 05/18/24 12:35:27.079
• [4.571 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:708
  STEP: Creating a kubernetes client @ 05/18/24 12:35:27.087
  May 18 12:35:27.087: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-pred @ 05/18/24 12:35:27.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:35:27.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:35:27.114
  May 18 12:35:27.122: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 18 12:35:27.135: INFO: Waiting for terminating namespaces to be deleted...
  May 18 12:35:27.141: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-33-93 before test
  May 18 12:35:27.147: INFO: replace-28600594-jbwh4 from cronjob-7123 started at 2024-05-18 12:34:00 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container c ready: true, restart count 0
  May 18 12:35:27.147: INFO: test-pod from e2e-kubelet-etc-hosts-5336 started at 2024-05-18 12:35:22 +0000 UTC (3 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container busybox-1 ready: true, restart count 0
  May 18 12:35:27.147: INFO: 	Container busybox-2 ready: true, restart count 0
  May 18 12:35:27.147: INFO: 	Container busybox-3 ready: true, restart count 0
  May 18 12:35:27.147: INFO: nginx-ingress-controller-kubernetes-worker-fr7mv from ingress-nginx-kubernetes-worker started at 2024-05-18 11:59:30 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:35:27.147: INFO: calico-node-jt76w from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:35:27.147: INFO: sonobuoy from sonobuoy started at 2024-05-18 12:05:55 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 18 12:35:27.147: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-qg8tv from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.147: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:35:27.147: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:35:27.148: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-70-23 before test
  May 18 12:35:27.156: INFO: replace-28600595-5z4gn from cronjob-7123 started at 2024-05-18 12:35:00 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.156: INFO: 	Container c ready: true, restart count 0
  May 18 12:35:27.156: INFO: test-host-network-pod from e2e-kubelet-etc-hosts-5336 started at 2024-05-18 12:35:24 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.156: INFO: 	Container busybox-1 ready: true, restart count 0
  May 18 12:35:27.156: INFO: 	Container busybox-2 ready: true, restart count 0
  May 18 12:35:27.156: INFO: nginx-ingress-controller-kubernetes-worker-cwhst from ingress-nginx-kubernetes-worker started at 2024-05-18 12:02:05 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.157: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:35:27.157: INFO: calico-node-8tp4g from kube-system started at 2024-05-18 12:01:55 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.157: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:35:27.157: INFO: pod-exec-websocket-79e3fec7-1280-418f-a109-947967f78032 from pods-254 started at 2024-05-18 12:35:15 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.157: INFO: 	Container main ready: true, restart count 0
  May 18 12:35:27.157: INFO: sonobuoy-e2e-job-9640b063a5a74f87 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.157: INFO: 	Container e2e ready: true, restart count 0
  May 18 12:35:27.157: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:35:27.157: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-hmcm6 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.157: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:35:27.157: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:35:27.157: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-90-158 before test
  May 18 12:35:27.163: INFO: nginx-ingress-controller-kubernetes-worker-4cg9g from ingress-nginx-kubernetes-worker started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:35:27.163: INFO: calico-node-5dtrz from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:35:27.163: INFO: coredns-bddfd76d7-gv2bt from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container coredns ready: true, restart count 0
  May 18 12:35:27.163: INFO: kube-state-metrics-6f48cdd76-glkfx from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container kube-state-metrics ready: true, restart count 0
  May 18 12:35:27.163: INFO: metrics-server-v0.6.3-69d7fbfdf8-thw8r from kube-system started at 2024-05-18 11:56:31 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container metrics-server ready: true, restart count 0
  May 18 12:35:27.163: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  May 18 12:35:27.163: INFO: dashboard-metrics-scraper-5dd7cb5fc-ks9g5 from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  May 18 12:35:27.163: INFO: kubernetes-dashboard-7b899cb9d9-4z7gj from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  May 18 12:35:27.163: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-l9qkt from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:35:27.163: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:35:27.163: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/18/24 12:35:27.163
  E0518 12:35:27.915655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:28.916241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/18/24 12:35:29.185
  STEP: Trying to apply a random label on the found node. @ 05/18/24 12:35:29.204
  STEP: verifying the node has the label kubernetes.io/e2e-50582dcb-7c58-4783-a158-636a40a3457a 95 @ 05/18/24 12:35:29.211
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/18/24 12:35:29.216
  E0518 12:35:29.917019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:30.917097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.33.93 on the node which pod4 resides and expect not scheduled @ 05/18/24 12:35:31.231
  E0518 12:35:31.917275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:32.917443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:33.917619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:34.917718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:35.917812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:36.917873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:37.917987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:38.918065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:39.918165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:40.918227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:41.919302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:42.919410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:43.919989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:44.920094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:45.921067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:46.921668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:47.922053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:48.922157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:49.922767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:50.923194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:51.923855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:52.924718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:53.925109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:54.925599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:55.925701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:56.926687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:57.927705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:58.927789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:35:59.927984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:00.929007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:01.929500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:02.929940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:03.930993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:04.931167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:05.932248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:06.932421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:07.932956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:08.933151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:09.933330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:10.934240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:11.934869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:12.934976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:13.935884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:14.936249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:15.936784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:16.936966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:17.937954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:18.938049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:19.938738      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:20.939305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:21.940223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:22.940429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:23.940849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:24.941022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:25.941594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:26.941703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:27.942538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:28.942603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:29.942715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:30.942972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:31.943188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:32.944037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:33.944371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:34.945027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:35.945369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:36.945459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:37.945523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:38.946586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:39.946638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:40.947678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:41.948225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:42.948440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:43.948682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:44.948772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:45.949458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:46.949556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:47.949971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:48.950134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:49.950535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:50.950625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:51.950766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:52.951147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:53.952088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:54.952385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:55.952542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:56.952712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:57.953160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:58.953259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:36:59.953546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:00.954306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:01.955143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:02.955250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:03.955723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:04.955837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:05.956811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:06.956997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:07.957610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:08.958587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:09.958897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:10.959009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:11.959153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:12.960061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:13.960222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:14.960324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:15.961092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:16.961264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:17.961325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:18.961433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:19.962461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:20.962726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:21.963625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:22.964010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:23.964250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:24.964491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:25.965220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:26.965465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:27.966260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:28.966412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:29.966524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:30.966723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:31.967587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:32.967675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:33.968219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:34.968282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:35.968822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:36.969053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:37.970120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:38.970238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:39.971249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:40.972266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:41.973099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:42.973489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:43.974432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:44.974627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:45.975007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:46.975224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:47.975929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:48.976237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:49.977093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:50.984977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:51.985605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:52.986026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:53.986126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:54.986302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:55.986989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:56.987190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:57.988229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:58.988319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:37:59.989443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:00.989526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:01.989730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:02.990099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:03.991008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:04.991165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:05.991556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:06.992248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:07.992505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:08.992783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:09.993688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:10.994365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:11.994977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:12.995188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:13.996220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:14.996956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:15.997084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:16.997549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:17.997712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:18.998566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:19.999308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:21.000224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:22.001183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:23.001296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:24.001389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:25.001562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:26.002603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:27.002878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:28.003345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:29.004324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:30.004894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:31.005074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:32.005763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:33.006056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:34.006147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:35.006388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:36.007389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:37.007414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:38.007792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:39.008442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:40.009483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:41.009579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:42.010395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:43.010498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:44.011448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:45.011555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:46.011692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:47.011770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:48.012571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:49.012681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:50.012856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:51.013931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:52.014938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:53.015074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:54.015901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:55.015976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:56.016522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:57.016714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:58.017636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:38:59.017747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:00.018343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:01.018712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:02.019028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:03.019164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:04.020222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:05.020331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:06.020910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:07.021025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:08.021983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:09.022104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:10.022555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:11.022680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:12.022936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:13.023068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:14.023878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:15.024229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:16.024550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:17.024644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:18.025363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:19.025645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:20.026108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:21.027184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:22.028034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:23.028967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:24.029594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:25.029711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:26.030480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:27.030597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:28.030914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:29.031140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:30.031801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:31.032246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:32.033277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:33.033521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:34.034014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:35.034108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:36.034615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:37.034790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:38.035237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:39.035331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:40.036100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:41.036327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:42.037189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:43.038107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:44.038237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:45.039328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:46.040217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:47.040326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:48.041269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:49.041443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:50.042339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:51.042570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:52.042964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:53.043400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:54.043945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:55.044233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:56.045211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:57.045392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:58.046083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:39:59.046182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:00.047055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:01.047163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:02.048230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:03.049181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:04.049510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:05.050497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:06.051141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:07.051495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:08.052192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:09.052884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:10.053766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:11.053938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:12.054558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:13.054685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:14.055119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:15.055177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:16.055538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:17.055656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:18.056499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:19.056557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:20.057625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:21.057722      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:22.058582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:23.059359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:24.059466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:25.059775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:26.060237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:27.060334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:28.060524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:29.060712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:30.061196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:31.061297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-50582dcb-7c58-4783-a158-636a40a3457a off the node ip-172-31-33-93 @ 05/18/24 12:40:31.238
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-50582dcb-7c58-4783-a158-636a40a3457a @ 05/18/24 12:40:31.25
  May 18 12:40:31.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7356" for this suite. @ 05/18/24 12:40:31.259
• [304.178 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 05/18/24 12:40:31.265
  May 18 12:40:31.265: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 12:40:31.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:31.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:31.288
  STEP: Creating a pod to test substitution in container's args @ 05/18/24 12:40:31.291
  E0518 12:40:32.061364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:33.061574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:34.061658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:35.061745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:40:35.315
  May 18 12:40:35.318: INFO: Trying to get logs from node ip-172-31-70-23 pod var-expansion-96599b86-6fe1-431e-8898-976bda9d0452 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:40:35.337
  May 18 12:40:35.356: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6124" for this suite. @ 05/18/24 12:40:35.36
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/18/24 12:40:35.367
  May 18 12:40:35.367: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename watch @ 05/18/24 12:40:35.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:35.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:35.39
  STEP: getting a starting resourceVersion @ 05/18/24 12:40:35.393
  STEP: starting a background goroutine to produce watch events @ 05/18/24 12:40:35.396
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/18/24 12:40:35.396
  E0518 12:40:36.062200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:37.062462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:38.062554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:40:38.128: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6882" for this suite. @ 05/18/24 12:40:38.174
• [2.858 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 05/18/24 12:40:38.225
  May 18 12:40:38.225: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:40:38.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:38.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:38.249
  STEP: Setting up server cert @ 05/18/24 12:40:38.346
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:40:38.56
  STEP: Deploying the webhook pod @ 05/18/24 12:40:38.57
  STEP: Wait for the deployment to be ready @ 05/18/24 12:40:38.582
  May 18 12:40:38.591: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:40:39.063243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:40.064271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:40:40.604
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:40:40.615
  E0518 12:40:41.065045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:40:41.615: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/18/24 12:40:41.623
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/18/24 12:40:41.625
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/18/24 12:40:41.625
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/18/24 12:40:41.625
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/18/24 12:40:41.626
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/18/24 12:40:41.626
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/18/24 12:40:41.627
  May 18 12:40:41.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2627" for this suite. @ 05/18/24 12:40:41.664
  STEP: Destroying namespace "webhook-markers-3617" for this suite. @ 05/18/24 12:40:41.672
• [3.454 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 05/18/24 12:40:41.68
  May 18 12:40:41.680: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 12:40:41.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:41.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:41.7
  May 18 12:40:41.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:40:42.065776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:43.066110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/18/24 12:40:43.131
  May 18 12:40:43.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4750 --namespace=crd-publish-openapi-4750 create -f -'
  May 18 12:40:43.200: INFO: stderr: ""
  May 18 12:40:43.200: INFO: stdout: "e2e-test-crd-publish-openapi-1333-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May 18 12:40:43.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4750 --namespace=crd-publish-openapi-4750 delete e2e-test-crd-publish-openapi-1333-crds test-cr'
  May 18 12:40:43.245: INFO: stderr: ""
  May 18 12:40:43.245: INFO: stdout: "e2e-test-crd-publish-openapi-1333-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  May 18 12:40:43.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4750 --namespace=crd-publish-openapi-4750 apply -f -'
  May 18 12:40:43.298: INFO: stderr: ""
  May 18 12:40:43.298: INFO: stdout: "e2e-test-crd-publish-openapi-1333-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  May 18 12:40:43.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4750 --namespace=crd-publish-openapi-4750 delete e2e-test-crd-publish-openapi-1333-crds test-cr'
  May 18 12:40:43.360: INFO: stderr: ""
  May 18 12:40:43.360: INFO: stdout: "e2e-test-crd-publish-openapi-1333-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/18/24 12:40:43.36
  May 18 12:40:43.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4750 explain e2e-test-crd-publish-openapi-1333-crds'
  May 18 12:40:43.401: INFO: stderr: ""
  May 18 12:40:43.401: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-1333-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0518 12:40:44.066908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:40:44.711: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4750" for this suite. @ 05/18/24 12:40:44.72
• [3.047 seconds]
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 05/18/24 12:40:44.727
  May 18 12:40:44.727: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 12:40:44.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:44.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:44.747
  May 18 12:40:44.751: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:40:45.067006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:46.067494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:47.068522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:40:47.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3945" for this suite. @ 05/18/24 12:40:47.832
• [3.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 05/18/24 12:40:47.838
  May 18 12:40:47.838: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 12:40:47.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:47.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:47.86
  STEP: Creating a test headless service @ 05/18/24 12:40:47.862
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-907 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-907;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-907 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-907;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-907.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-907.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-907.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-907.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-907.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-907.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-907.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-907.svc;check="$$(dig +notcp +noall +answer +search 232.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.232_tcp@PTR;sleep 1; done
   @ 05/18/24 12:40:47.878
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-907 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-907;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-907 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-907;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-907.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-907.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-907.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-907.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-907.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-907.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-907.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-907.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-907.svc;check="$$(dig +notcp +noall +answer +search 232.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.232_tcp@PTR;sleep 1; done
   @ 05/18/24 12:40:47.878
  STEP: creating a pod to probe DNS @ 05/18/24 12:40:47.878
  STEP: submitting the pod to kubernetes @ 05/18/24 12:40:47.878
  E0518 12:40:48.069199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:49.069727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 12:40:49.901
  STEP: looking for the results for each expected name from probers @ 05/18/24 12:40:49.904
  May 18 12:40:49.910: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.913: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.920: INFO: Unable to read wheezy_udp@dns-test-service.dns-907 from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.925: INFO: Unable to read wheezy_tcp@dns-test-service.dns-907 from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.928: INFO: Unable to read wheezy_udp@dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.934: INFO: Unable to read wheezy_tcp@dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.938: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.941: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.962: INFO: Unable to read jessie_udp@dns-test-service from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.966: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.970: INFO: Unable to read jessie_udp@dns-test-service.dns-907 from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.975: INFO: Unable to read jessie_tcp@dns-test-service.dns-907 from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.978: INFO: Unable to read jessie_udp@dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.982: INFO: Unable to read jessie_tcp@dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.987: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:49.990: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-907.svc from pod dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b: the server could not find the requested resource (get pods dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b)
  May 18 12:40:50.007: INFO: Lookups using dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-907 wheezy_tcp@dns-test-service.dns-907 wheezy_udp@dns-test-service.dns-907.svc wheezy_tcp@dns-test-service.dns-907.svc wheezy_udp@_http._tcp.dns-test-service.dns-907.svc wheezy_tcp@_http._tcp.dns-test-service.dns-907.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-907 jessie_tcp@dns-test-service.dns-907 jessie_udp@dns-test-service.dns-907.svc jessie_tcp@dns-test-service.dns-907.svc jessie_udp@_http._tcp.dns-test-service.dns-907.svc jessie_tcp@_http._tcp.dns-test-service.dns-907.svc]

  May 18 12:40:50.025: INFO: Pod client logs for webserver: 
  May 18 12:40:50.031: INFO: Pod client logs for querier: 
  May 18 12:40:50.037: INFO: Pod client logs for jessie-querier: 
  E0518 12:40:50.070487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:51.070601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:52.070770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:53.071252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:54.071359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:40:55.013: INFO: DNS probes using dns-907/dns-test-10b7f72d-1466-4c4b-8d52-38ec51ee652b succeeded

  STEP: deleting the pod @ 05/18/24 12:40:55.013
  STEP: deleting the test service @ 05/18/24 12:40:55.027
  STEP: deleting the test headless service @ 05/18/24 12:40:55.045
  May 18 12:40:55.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-907" for this suite. @ 05/18/24 12:40:55.062
• [7.231 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/18/24 12:40:55.069
  May 18 12:40:55.069: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:40:55.069
  E0518 12:40:55.071903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:55.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:55.09
  STEP: Creating projection with secret that has name projected-secret-test-map-feec49cc-1c08-4c0e-a1d1-451a44cc09cf @ 05/18/24 12:40:55.093
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:40:55.097
  E0518 12:40:56.072048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:57.072252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:58.073096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:40:59.073185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:40:59.117
  May 18 12:40:59.121: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-secrets-9850c1b7-527d-4b92-bd60-9657f684fc7a container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:40:59.129
  May 18 12:40:59.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1425" for this suite. @ 05/18/24 12:40:59.15
• [4.087 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/18/24 12:40:59.156
  May 18 12:40:59.156: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename watch @ 05/18/24 12:40:59.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:40:59.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:40:59.173
  STEP: creating a watch on configmaps with a certain label @ 05/18/24 12:40:59.176
  STEP: creating a new configmap @ 05/18/24 12:40:59.177
  STEP: modifying the configmap once @ 05/18/24 12:40:59.182
  STEP: changing the label value of the configmap @ 05/18/24 12:40:59.189
  STEP: Expecting to observe a delete notification for the watched object @ 05/18/24 12:40:59.196
  May 18 12:40:59.196: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21497 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:40:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:40:59.196: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21498 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:40:59.196: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21499 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/18/24 12:40:59.196
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/18/24 12:40:59.204
  E0518 12:41:00.073361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:01.073449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:02.073545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:03.074040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:04.074128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:05.074233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:06.074457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:07.074669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:08.074908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:09.075350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 05/18/24 12:41:09.204
  STEP: modifying the configmap a third time @ 05/18/24 12:41:09.213
  STEP: deleting the configmap @ 05/18/24 12:41:09.222
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/18/24 12:41:09.227
  May 18 12:41:09.227: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21551 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:41:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:41:09.227: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21552 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:41:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:41:09.227: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3699  1dc66e34-d496-4e99-b083-e936e5766cea 21553 0 2024-05-18 12:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-18 12:41:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  May 18 12:41:09.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3699" for this suite. @ 05/18/24 12:41:09.23
• [10.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/18/24 12:41:09.236
  May 18 12:41:09.236: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:41:09.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:41:09.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:41:09.257
  STEP: Creating secret with name s-test-opt-del-6a213880-0751-439d-b45a-f714062d3b41 @ 05/18/24 12:41:09.263
  STEP: Creating secret with name s-test-opt-upd-eb0d6bff-4f59-484d-ba35-811165a4c788 @ 05/18/24 12:41:09.267
  STEP: Creating the pod @ 05/18/24 12:41:09.271
  E0518 12:41:10.076277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:11.076552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-6a213880-0751-439d-b45a-f714062d3b41 @ 05/18/24 12:41:11.312
  STEP: Updating secret s-test-opt-upd-eb0d6bff-4f59-484d-ba35-811165a4c788 @ 05/18/24 12:41:11.318
  STEP: Creating secret with name s-test-opt-create-9b80c188-b19b-4dc7-a7d8-0f42c5c92cfa @ 05/18/24 12:41:11.324
  STEP: waiting to observe update in volume @ 05/18/24 12:41:11.332
  E0518 12:41:12.076620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:13.076951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:14.077022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:15.077880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:16.077958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:17.078499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:18.078723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:19.078819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:20.079814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:21.079895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:22.080243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:23.080591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:24.081192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:25.081251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:26.081591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:27.082026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:28.082106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:29.082324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:30.082421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:31.082628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:32.082777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:33.082826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:34.083728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:35.083803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:36.084229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:37.084395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:38.085222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:39.085413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:40.086291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:41.086414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:42.087406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:43.087524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:44.087700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:45.087787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:46.087884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:47.088800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:48.089309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:49.089397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:50.090084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:51.090144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:52.091137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:53.091204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:54.091964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:55.092026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:56.092917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:57.093138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:58.094189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:41:59.094379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:00.094926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:01.095804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:02.096166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:03.096245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:04.096352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:05.096567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:06.096724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:07.096937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:08.097568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:09.097715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:10.097809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:11.097886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:12.098768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:13.099653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:14.099880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:15.099996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:16.100369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:17.100465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:18.101299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:19.101487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:20.101594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:21.101726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:22.101773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:23.101894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:24.101911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:25.102930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:26.102962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:27.103232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:28.103980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:29.104098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:29.704: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9281" for this suite. @ 05/18/24 12:42:29.707
• [80.478 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 05/18/24 12:42:29.716
  May 18 12:42:29.716: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubelet-test @ 05/18/24 12:42:29.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:29.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:29.736
  E0518 12:42:30.104755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:31.105002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:31.767: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2328" for this suite. @ 05/18/24 12:42:31.77
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 05/18/24 12:42:31.778
  May 18 12:42:31.778: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:42:31.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:31.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:31.798
  STEP: Setting up server cert @ 05/18/24 12:42:31.826
  E0518 12:42:32.105403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:42:32.374
  STEP: Deploying the webhook pod @ 05/18/24 12:42:32.381
  STEP: Wait for the deployment to be ready @ 05/18/24 12:42:32.394
  May 18 12:42:32.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:42:33.106025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:34.106219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:42:34.414
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:42:34.424
  E0518 12:42:35.107136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:35.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/18/24 12:42:35.433
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/18/24 12:42:35.472
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/18/24 12:42:35.478
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/18/24 12:42:35.488
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/18/24 12:42:35.499
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/18/24 12:42:35.506
  May 18 12:42:35.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9730" for this suite. @ 05/18/24 12:42:35.548
  STEP: Destroying namespace "webhook-markers-7017" for this suite. @ 05/18/24 12:42:35.554
• [3.783 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/18/24 12:42:35.561
  May 18 12:42:35.561: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context @ 05/18/24 12:42:35.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:35.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:35.582
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/18/24 12:42:35.585
  E0518 12:42:36.107877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:37.108931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:38.109807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:39.110056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:42:39.608
  May 18 12:42:39.612: INFO: Trying to get logs from node ip-172-31-33-93 pod security-context-16bf51d3-a3a1-4a35-9cf3-c58cbea1563c container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:42:39.62
  May 18 12:42:39.636: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8819" for this suite. @ 05/18/24 12:42:39.639
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 05/18/24 12:42:39.645
  May 18 12:42:39.645: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 12:42:39.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:39.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:39.666
  STEP: creating a Deployment @ 05/18/24 12:42:39.672
  May 18 12:42:39.672: INFO: Creating simple deployment test-deployment-4jfzq
  May 18 12:42:39.682: INFO: deployment "test-deployment-4jfzq" doesn't have the required revision set
  E0518 12:42:40.110158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:41.110236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 05/18/24 12:42:41.696
  May 18 12:42:41.700: INFO: Deployment test-deployment-4jfzq has Conditions: [{Available True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jfzq-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/18/24 12:42:41.7
  May 18 12:42:41.709: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 42, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 42, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 42, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 42, 39, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4jfzq-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/18/24 12:42:41.709
  May 18 12:42:41.711: INFO: Observed &Deployment event: ADDED
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jfzq-5d576bd769"}
  May 18 12:42:41.711: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jfzq-5d576bd769"}
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 18 12:42:41.711: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jfzq-5d576bd769" is progressing.}
  May 18 12:42:41.711: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.711: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 18 12:42:41.712: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jfzq-5d576bd769" has successfully progressed.}
  May 18 12:42:41.712: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.712: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 18 12:42:41.712: INFO: Observed Deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jfzq-5d576bd769" has successfully progressed.}
  May 18 12:42:41.712: INFO: Found Deployment test-deployment-4jfzq in namespace deployment-8426 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 12:42:41.712: INFO: Deployment test-deployment-4jfzq has an updated status
  STEP: patching the Statefulset Status @ 05/18/24 12:42:41.712
  May 18 12:42:41.712: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 18 12:42:41.720: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/18/24 12:42:41.72
  May 18 12:42:41.722: INFO: Observed &Deployment event: ADDED
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jfzq-5d576bd769"}
  May 18 12:42:41.722: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jfzq-5d576bd769"}
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 18 12:42:41.722: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:39 +0000 UTC 2024-05-18 12:42:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jfzq-5d576bd769" is progressing.}
  May 18 12:42:41.722: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jfzq-5d576bd769" has successfully progressed.}
  May 18 12:42:41.722: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-18 12:42:40 +0000 UTC 2024-05-18 12:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jfzq-5d576bd769" has successfully progressed.}
  May 18 12:42:41.722: INFO: Observed deployment test-deployment-4jfzq in namespace deployment-8426 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 12:42:41.722: INFO: Observed &Deployment event: MODIFIED
  May 18 12:42:41.722: INFO: Found deployment test-deployment-4jfzq in namespace deployment-8426 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  May 18 12:42:41.723: INFO: Deployment test-deployment-4jfzq has a patched status
  May 18 12:42:41.725: INFO: Deployment "test-deployment-4jfzq":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-4jfzq",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8426",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fef78e4d-9ee3-4f2f-876e-f49d65c8830a",
      ResourceVersion: (string) (len=5) "21950",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851632959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632961,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632961,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632961,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632961,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-4jfzq-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 12:42:41.730: INFO: New ReplicaSet "test-deployment-4jfzq-5d576bd769" of Deployment "test-deployment-4jfzq":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-4jfzq-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8426",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ed856861-f688-49d0-b649-d52220ddf11d",
      ResourceVersion: (string) (len=5) "21945",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851632959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-4jfzq",
          UID: (types.UID) (len=36) "fef78e4d-9ee3-4f2f-876e-f49d65c8830a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 66 65 66  |k:{\"uid\":\"fef|
              00000120  37 38 65 34 64 2d 39 65  65 33 2d 34 66 32 66 2d  |78e4d-9ee3-4f2f-|
              00000130  38 37 36 65 2d 66 34 39  64 36 35 63 38 38 33 30  |876e-f49d65c8830|
              00000140  61 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |a\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632960,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:42:41.737: INFO: Pod "test-deployment-4jfzq-5d576bd769-m9xwp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-4jfzq-5d576bd769-m9xwp",
      GenerateName: (string) (len=33) "test-deployment-4jfzq-5d576bd769-",
      Namespace: (string) (len=15) "deployment-8426",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2ca049e-c860-4f1b-97cc-5e5bd94e7b1d",
      ResourceVersion: (string) (len=5) "21944",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851632959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-4jfzq-5d576bd769",
          UID: (types.UID) (len=36) "ed856861-f688-49d0-b649-d52220ddf11d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 65 64 38 35 36 38 36  31 2d 66 36 38 38 2d 34  |"ed856861-f688-4|
              000000a0  39 64 30 2d 62 36 34 39  2d 64 35 32 32 32 30 64  |9d0-b649-d52220d|
              000000b0  64 66 31 31 64 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |df11d\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632960,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 34 31 5c 22 7d  |2.168.225.241\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-chwmf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-chwmf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632960,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632960,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632960,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851632959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.241",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.241"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851632959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851632960,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://430dca1dfd2b91cb8d488a845500e8bb18faed0cce1c2f188f79548e5cce44aa",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:42:41.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8426" for this suite. @ 05/18/24 12:42:41.742
• [2.104 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 05/18/24 12:42:41.749
  May 18 12:42:41.749: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 12:42:41.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:41.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:41.77
  May 18 12:42:41.775: INFO: Got root ca configmap in namespace "svcaccounts-9929"
  May 18 12:42:41.781: INFO: Deleted root ca configmap in namespace "svcaccounts-9929"
  E0518 12:42:42.111181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/18/24 12:42:42.282
  May 18 12:42:42.286: INFO: Recreated root ca configmap in namespace "svcaccounts-9929"
  May 18 12:42:42.292: INFO: Updated root ca configmap in namespace "svcaccounts-9929"
  STEP: waiting for the root ca configmap reconciled @ 05/18/24 12:42:42.792
  May 18 12:42:42.797: INFO: Reconciled root ca configmap in namespace "svcaccounts-9929"
  May 18 12:42:42.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9929" for this suite. @ 05/18/24 12:42:42.801
• [1.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 05/18/24 12:42:42.808
  May 18 12:42:42.808: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:42:42.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:42.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:42.831
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/18/24 12:42:42.835
  E0518 12:42:43.111587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:44.112272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:45.112971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:46.113127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:42:46.861
  May 18 12:42:46.865: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-403f6715-6082-4b78-b817-809f97dcb5b3 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:42:46.871
  May 18 12:42:46.889: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4394" for this suite. @ 05/18/24 12:42:46.892
• [4.091 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 05/18/24 12:42:46.899
  May 18 12:42:46.899: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:42:46.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:42:46.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:42:46.92
  STEP: creating a replication controller @ 05/18/24 12:42:46.923
  May 18 12:42:46.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 create -f -'
  May 18 12:42:47.002: INFO: stderr: ""
  May 18 12:42:47.002: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/18/24 12:42:47.002
  May 18 12:42:47.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:42:47.049: INFO: stderr: ""
  May 18 12:42:47.049: INFO: stdout: "update-demo-nautilus-lrvfz update-demo-nautilus-r8lnj "
  May 18 12:42:47.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-lrvfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:47.091: INFO: stderr: ""
  May 18 12:42:47.091: INFO: stdout: ""
  May 18 12:42:47.091: INFO: update-demo-nautilus-lrvfz is created but not running
  E0518 12:42:47.113821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:48.113915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:49.114008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:50.114086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:51.114195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:52.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0518 12:42:52.115174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:52.134: INFO: stderr: ""
  May 18 12:42:52.134: INFO: stdout: "update-demo-nautilus-lrvfz update-demo-nautilus-r8lnj "
  May 18 12:42:52.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-lrvfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:52.175: INFO: stderr: ""
  May 18 12:42:52.175: INFO: stdout: "true"
  May 18 12:42:52.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-lrvfz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:42:52.216: INFO: stderr: ""
  May 18 12:42:52.216: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:42:52.216: INFO: validating pod update-demo-nautilus-lrvfz
  May 18 12:42:52.222: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:42:52.223: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:42:52.223: INFO: update-demo-nautilus-lrvfz is verified up and running
  May 18 12:42:52.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:52.264: INFO: stderr: ""
  May 18 12:42:52.265: INFO: stdout: "true"
  May 18 12:42:52.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:42:52.306: INFO: stderr: ""
  May 18 12:42:52.306: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:42:52.306: INFO: validating pod update-demo-nautilus-r8lnj
  May 18 12:42:52.310: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:42:52.310: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:42:52.310: INFO: update-demo-nautilus-r8lnj is verified up and running
  STEP: scaling down the replication controller @ 05/18/24 12:42:52.31
  May 18 12:42:52.311: INFO: scanned /root for discovery docs: <nil>
  May 18 12:42:52.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0518 12:42:53.115753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:53.369: INFO: stderr: ""
  May 18 12:42:53.369: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/18/24 12:42:53.369
  May 18 12:42:53.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:42:53.414: INFO: stderr: ""
  May 18 12:42:53.414: INFO: stdout: "update-demo-nautilus-lrvfz update-demo-nautilus-r8lnj "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 05/18/24 12:42:53.414
  E0518 12:42:54.116199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:55.116286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:56.116376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:57.116487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:42:58.116603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:58.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:42:58.456: INFO: stderr: ""
  May 18 12:42:58.456: INFO: stdout: "update-demo-nautilus-r8lnj "
  May 18 12:42:58.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:58.496: INFO: stderr: ""
  May 18 12:42:58.496: INFO: stdout: "true"
  May 18 12:42:58.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:42:58.536: INFO: stderr: ""
  May 18 12:42:58.536: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:42:58.536: INFO: validating pod update-demo-nautilus-r8lnj
  May 18 12:42:58.540: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:42:58.540: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:42:58.540: INFO: update-demo-nautilus-r8lnj is verified up and running
  STEP: scaling up the replication controller @ 05/18/24 12:42:58.54
  May 18 12:42:58.540: INFO: scanned /root for discovery docs: <nil>
  May 18 12:42:58.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0518 12:42:59.116792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:42:59.595: INFO: stderr: ""
  May 18 12:42:59.595: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/18/24 12:42:59.595
  May 18 12:42:59.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:42:59.639: INFO: stderr: ""
  May 18 12:42:59.639: INFO: stdout: "update-demo-nautilus-r8lnj update-demo-nautilus-xs2zf "
  May 18 12:42:59.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:59.680: INFO: stderr: ""
  May 18 12:42:59.680: INFO: stdout: "true"
  May 18 12:42:59.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:42:59.719: INFO: stderr: ""
  May 18 12:42:59.719: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:42:59.719: INFO: validating pod update-demo-nautilus-r8lnj
  May 18 12:42:59.724: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:42:59.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:42:59.724: INFO: update-demo-nautilus-r8lnj is verified up and running
  May 18 12:42:59.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-xs2zf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:42:59.766: INFO: stderr: ""
  May 18 12:42:59.766: INFO: stdout: ""
  May 18 12:42:59.766: INFO: update-demo-nautilus-xs2zf is created but not running
  E0518 12:43:00.117650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:01.117675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:02.117868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:03.117986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:04.118075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:04.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:43:04.809: INFO: stderr: ""
  May 18 12:43:04.809: INFO: stdout: "update-demo-nautilus-r8lnj update-demo-nautilus-xs2zf "
  May 18 12:43:04.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:43:04.851: INFO: stderr: ""
  May 18 12:43:04.851: INFO: stdout: "true"
  May 18 12:43:04.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-r8lnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:43:04.889: INFO: stderr: ""
  May 18 12:43:04.889: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:43:04.889: INFO: validating pod update-demo-nautilus-r8lnj
  May 18 12:43:04.893: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:43:04.893: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:43:04.893: INFO: update-demo-nautilus-r8lnj is verified up and running
  May 18 12:43:04.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-xs2zf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:43:04.933: INFO: stderr: ""
  May 18 12:43:04.933: INFO: stdout: "true"
  May 18 12:43:04.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods update-demo-nautilus-xs2zf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:43:04.971: INFO: stderr: ""
  May 18 12:43:04.971: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:43:04.971: INFO: validating pod update-demo-nautilus-xs2zf
  May 18 12:43:04.977: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:43:04.977: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:43:04.977: INFO: update-demo-nautilus-xs2zf is verified up and running
  STEP: using delete to clean up resources @ 05/18/24 12:43:04.977
  May 18 12:43:04.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
  May 18 12:43:05.025: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:43:05.025: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May 18 12:43:05.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get rc,svc -l name=update-demo --no-headers'
  May 18 12:43:05.087: INFO: stderr: "No resources found in kubectl-6275 namespace.\n"
  May 18 12:43:05.087: INFO: stdout: ""
  May 18 12:43:05.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6275 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0518 12:43:05.118846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:05.130: INFO: stderr: ""
  May 18 12:43:05.131: INFO: stdout: ""
  May 18 12:43:05.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6275" for this suite. @ 05/18/24 12:43:05.134
• [18.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/18/24 12:43:05.141
  May 18 12:43:05.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 12:43:05.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:05.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:05.163
  May 18 12:43:05.189: INFO: Create a RollingUpdate DaemonSet
  May 18 12:43:05.194: INFO: Check that daemon pods launch on every node of the cluster
  May 18 12:43:05.197: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:05.197: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:05.199: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:43:05.199: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:43:06.119430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:06.199: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:06.199: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:06.203: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 12:43:06.203: INFO: Node ip-172-31-70-23 is running 0 daemon pod, expected 1
  E0518 12:43:07.120359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:07.198: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:07.198: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:07.202: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 12:43:07.202: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  May 18 12:43:07.202: INFO: Update the DaemonSet to trigger a rollout
  May 18 12:43:07.211: INFO: Updating DaemonSet daemon-set
  E0518 12:43:08.120452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:08.224: INFO: Roll back the DaemonSet before rollout is complete
  May 18 12:43:08.233: INFO: Updating DaemonSet daemon-set
  May 18 12:43:08.233: INFO: Make sure DaemonSet rollback is complete
  May 18 12:43:08.235: INFO: Wrong image for pod: daemon-set-cm5hj. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  May 18 12:43:08.236: INFO: Pod daemon-set-cm5hj is not available
  May 18 12:43:08.239: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:08.239: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0518 12:43:09.121498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:09.241: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:09.241: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0518 12:43:10.121894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:10.237: INFO: Pod daemon-set-hhdvh is not available
  May 18 12:43:10.241: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:43:10.241: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 12:43:10.248
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1502, will wait for the garbage collector to delete the pods @ 05/18/24 12:43:10.248
  May 18 12:43:10.308: INFO: Deleting DaemonSet.extensions daemon-set took: 5.721429ms
  May 18 12:43:10.408: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.121631ms
  E0518 12:43:11.122064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:12.113: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:43:12.113: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 12:43:12.117: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22341"},"items":null}

  May 18 12:43:12.121: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22341"},"items":null}

  E0518 12:43:12.122233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:12.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1502" for this suite. @ 05/18/24 12:43:12.136
• [7.001 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 05/18/24 12:43:12.142
  May 18 12:43:12.142: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:43:12.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:12.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:12.164
  STEP: Creating a pod to test downward api env vars @ 05/18/24 12:43:12.166
  E0518 12:43:13.122894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:14.123016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:43:14.185
  May 18 12:43:14.189: INFO: Trying to get logs from node ip-172-31-33-93 pod downward-api-f91fb87a-8be7-4fd7-a998-d72519b1585d container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:43:14.195
  May 18 12:43:14.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7058" for this suite. @ 05/18/24 12:43:14.212
• [2.077 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 05/18/24 12:43:14.22
  May 18 12:43:14.220: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:43:14.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:14.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:14.24
  STEP: Creating a ResourceQuota with best effort scope @ 05/18/24 12:43:14.242
  STEP: Ensuring ResourceQuota status is calculated @ 05/18/24 12:43:14.248
  E0518 12:43:15.123998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:16.124204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 05/18/24 12:43:16.256
  STEP: Ensuring ResourceQuota status is calculated @ 05/18/24 12:43:16.26
  E0518 12:43:17.124429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:18.124979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 05/18/24 12:43:18.266
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/18/24 12:43:18.28
  E0518 12:43:19.125183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:20.125957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/18/24 12:43:20.284
  E0518 12:43:21.126046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:22.126139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/18/24 12:43:22.288
  STEP: Ensuring resource quota status released the pod usage @ 05/18/24 12:43:22.304
  E0518 12:43:23.127177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:24.128223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 05/18/24 12:43:24.309
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/18/24 12:43:24.32
  E0518 12:43:25.128834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:26.129059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/18/24 12:43:26.326
  E0518 12:43:27.130007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:28.130111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/18/24 12:43:28.33
  STEP: Ensuring resource quota status released the pod usage @ 05/18/24 12:43:28.345
  E0518 12:43:29.130228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:30.130304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:30.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1898" for this suite. @ 05/18/24 12:43:30.352
• [16.140 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 05/18/24 12:43:30.36
  May 18 12:43:30.360: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 12:43:30.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:30.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:30.382
  STEP: set up a multi version CRD @ 05/18/24 12:43:30.386
  May 18 12:43:30.387: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:43:31.131326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:32.132270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:33.132949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 05/18/24 12:43:33.509
  STEP: check the new version name is served @ 05/18/24 12:43:33.526
  E0518 12:43:34.133505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 05/18/24 12:43:34.307
  STEP: check the other version is not changed @ 05/18/24 12:43:34.922
  E0518 12:43:35.133880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:36.134237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:37.134558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:43:37.359: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9420" for this suite. @ 05/18/24 12:43:37.366
• [7.014 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 05/18/24 12:43:37.374
  May 18 12:43:37.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:43:37.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:37.391
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:37.394
  STEP: creating secret secrets-4500/secret-test-88e60834-22c0-4546-ba88-a5c114a4aac4 @ 05/18/24 12:43:37.398
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:43:37.402
  E0518 12:43:38.134673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:39.134719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:40.135231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:41.136243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:43:41.434
  May 18 12:43:41.438: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-4ec3a687-c631-414a-94b4-7902f423d92f container env-test: <nil>
  STEP: delete the pod @ 05/18/24 12:43:41.449
  May 18 12:43:41.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4500" for this suite. @ 05/18/24 12:43:41.473
• [4.105 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/18/24 12:43:41.479
  May 18 12:43:41.479: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subpath @ 05/18/24 12:43:41.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:43:41.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:43:41.499
  STEP: Setting up data @ 05/18/24 12:43:41.502
  STEP: Creating pod pod-subpath-test-configmap-ggvj @ 05/18/24 12:43:41.513
  STEP: Creating a pod to test atomic-volume-subpath @ 05/18/24 12:43:41.513
  E0518 12:43:42.136353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:43.137257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:44.137362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:45.137438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:46.138274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:47.138592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:48.138704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:49.138788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:50.139415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:51.140269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:52.140519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:53.140827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:54.141543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:55.141631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:56.142387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:57.142470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:58.143114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:43:59.143227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:00.144224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:01.144317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:02.145052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:03.145161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:04.146017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:05.146934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:44:05.593
  May 18 12:44:05.597: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-subpath-test-configmap-ggvj container test-container-subpath-configmap-ggvj: <nil>
  STEP: delete the pod @ 05/18/24 12:44:05.605
  STEP: Deleting pod pod-subpath-test-configmap-ggvj @ 05/18/24 12:44:05.622
  May 18 12:44:05.622: INFO: Deleting pod "pod-subpath-test-configmap-ggvj" in namespace "subpath-3980"
  May 18 12:44:05.625: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3980" for this suite. @ 05/18/24 12:44:05.629
• [24.157 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/18/24 12:44:05.637
  May 18 12:44:05.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename discovery @ 05/18/24 12:44:05.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:05.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:05.655
  STEP: Setting up server cert @ 05/18/24 12:44:05.659
  STEP: Requesting APIResourceList from "/api/v1" @ 05/18/24 12:44:05.879
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/18/24 12:44:05.882
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/18/24 12:44:05.883
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/18/24 12:44:05.884
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/18/24 12:44:05.885
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/18/24 12:44:05.887
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/18/24 12:44:05.888
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/18/24 12:44:05.889
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/18/24 12:44:05.89
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/18/24 12:44:05.891
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/18/24 12:44:05.893
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/18/24 12:44:05.894
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/18/24 12:44:05.896
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/18/24 12:44:05.899
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/18/24 12:44:05.902
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/18/24 12:44:05.903
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/18/24 12:44:05.905
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/18/24 12:44:05.906
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/18/24 12:44:05.907
  May 18 12:44:05.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6547" for this suite. @ 05/18/24 12:44:05.913
• [0.286 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 05/18/24 12:44:05.923
  May 18 12:44:05.923: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 12:44:05.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:05.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:05.949
  E0518 12:44:06.147772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:07.148318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:07.970: INFO: Deleting pod "var-expansion-38b3982f-818a-4711-8ef3-ef478c0f678b" in namespace "var-expansion-8024"
  May 18 12:44:07.980: INFO: Wait up to 5m0s for pod "var-expansion-38b3982f-818a-4711-8ef3-ef478c0f678b" to be fully deleted
  E0518 12:44:08.149344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:09.149452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:09.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8024" for this suite. @ 05/18/24 12:44:09.993
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 05/18/24 12:44:10.001
  May 18 12:44:10.001: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:44:10.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:10.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:10.023
  STEP: creating a secret @ 05/18/24 12:44:10.027
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/18/24 12:44:10.032
  STEP: patching the secret @ 05/18/24 12:44:10.036
  STEP: deleting the secret using a LabelSelector @ 05/18/24 12:44:10.045
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/18/24 12:44:10.053
  May 18 12:44:10.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-546" for this suite. @ 05/18/24 12:44:10.061
• [0.068 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 05/18/24 12:44:10.069
  May 18 12:44:10.069: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:44:10.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:10.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:10.09
  STEP: creating a ConfigMap @ 05/18/24 12:44:10.093
  STEP: fetching the ConfigMap @ 05/18/24 12:44:10.098
  STEP: patching the ConfigMap @ 05/18/24 12:44:10.101
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/18/24 12:44:10.106
  STEP: deleting the ConfigMap by collection with a label selector @ 05/18/24 12:44:10.109
  STEP: listing all ConfigMaps in test namespace @ 05/18/24 12:44:10.118
  May 18 12:44:10.121: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4036" for this suite. @ 05/18/24 12:44:10.125
• [0.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/18/24 12:44:10.133
  May 18 12:44:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename discovery @ 05/18/24 12:44:10.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:10.148
  E0518 12:44:10.149596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:10.151
  STEP: Setting up server cert @ 05/18/24 12:44:10.155
  May 18 12:44:10.330: INFO: Checking APIGroup: apiregistration.k8s.io
  May 18 12:44:10.332: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  May 18 12:44:10.332: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  May 18 12:44:10.332: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  May 18 12:44:10.332: INFO: Checking APIGroup: apps
  May 18 12:44:10.333: INFO: PreferredVersion.GroupVersion: apps/v1
  May 18 12:44:10.333: INFO: Versions found [{apps/v1 v1}]
  May 18 12:44:10.333: INFO: apps/v1 matches apps/v1
  May 18 12:44:10.333: INFO: Checking APIGroup: events.k8s.io
  May 18 12:44:10.334: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  May 18 12:44:10.334: INFO: Versions found [{events.k8s.io/v1 v1}]
  May 18 12:44:10.334: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  May 18 12:44:10.334: INFO: Checking APIGroup: authentication.k8s.io
  May 18 12:44:10.335: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  May 18 12:44:10.335: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  May 18 12:44:10.335: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  May 18 12:44:10.335: INFO: Checking APIGroup: authorization.k8s.io
  May 18 12:44:10.336: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  May 18 12:44:10.337: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  May 18 12:44:10.337: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  May 18 12:44:10.337: INFO: Checking APIGroup: autoscaling
  May 18 12:44:10.338: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  May 18 12:44:10.338: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  May 18 12:44:10.338: INFO: autoscaling/v2 matches autoscaling/v2
  May 18 12:44:10.338: INFO: Checking APIGroup: batch
  May 18 12:44:10.339: INFO: PreferredVersion.GroupVersion: batch/v1
  May 18 12:44:10.339: INFO: Versions found [{batch/v1 v1}]
  May 18 12:44:10.339: INFO: batch/v1 matches batch/v1
  May 18 12:44:10.339: INFO: Checking APIGroup: certificates.k8s.io
  May 18 12:44:10.340: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  May 18 12:44:10.340: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  May 18 12:44:10.340: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  May 18 12:44:10.340: INFO: Checking APIGroup: networking.k8s.io
  May 18 12:44:10.341: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  May 18 12:44:10.341: INFO: Versions found [{networking.k8s.io/v1 v1}]
  May 18 12:44:10.341: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  May 18 12:44:10.341: INFO: Checking APIGroup: policy
  May 18 12:44:10.342: INFO: PreferredVersion.GroupVersion: policy/v1
  May 18 12:44:10.342: INFO: Versions found [{policy/v1 v1}]
  May 18 12:44:10.342: INFO: policy/v1 matches policy/v1
  May 18 12:44:10.342: INFO: Checking APIGroup: rbac.authorization.k8s.io
  May 18 12:44:10.344: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  May 18 12:44:10.344: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  May 18 12:44:10.344: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  May 18 12:44:10.344: INFO: Checking APIGroup: storage.k8s.io
  May 18 12:44:10.345: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  May 18 12:44:10.345: INFO: Versions found [{storage.k8s.io/v1 v1}]
  May 18 12:44:10.345: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  May 18 12:44:10.345: INFO: Checking APIGroup: admissionregistration.k8s.io
  May 18 12:44:10.346: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  May 18 12:44:10.346: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  May 18 12:44:10.346: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  May 18 12:44:10.346: INFO: Checking APIGroup: apiextensions.k8s.io
  May 18 12:44:10.347: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  May 18 12:44:10.347: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  May 18 12:44:10.347: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  May 18 12:44:10.347: INFO: Checking APIGroup: scheduling.k8s.io
  May 18 12:44:10.348: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  May 18 12:44:10.348: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  May 18 12:44:10.348: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  May 18 12:44:10.348: INFO: Checking APIGroup: coordination.k8s.io
  May 18 12:44:10.350: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  May 18 12:44:10.350: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  May 18 12:44:10.350: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  May 18 12:44:10.350: INFO: Checking APIGroup: node.k8s.io
  May 18 12:44:10.351: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  May 18 12:44:10.351: INFO: Versions found [{node.k8s.io/v1 v1}]
  May 18 12:44:10.351: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  May 18 12:44:10.351: INFO: Checking APIGroup: discovery.k8s.io
  May 18 12:44:10.352: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  May 18 12:44:10.352: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  May 18 12:44:10.352: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  May 18 12:44:10.352: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  May 18 12:44:10.353: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  May 18 12:44:10.353: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  May 18 12:44:10.353: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  May 18 12:44:10.353: INFO: Checking APIGroup: metrics.k8s.io
  May 18 12:44:10.355: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  May 18 12:44:10.355: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  May 18 12:44:10.355: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  May 18 12:44:10.355: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1619" for this suite. @ 05/18/24 12:44:10.359
• [0.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 05/18/24 12:44:10.367
  May 18 12:44:10.367: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:44:10.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:10.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:10.387
  STEP: Counting existing ResourceQuota @ 05/18/24 12:44:10.39
  E0518 12:44:11.150409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:12.150529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:13.150810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:14.151710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:15.152224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 12:44:15.395
  STEP: Ensuring resource quota status is calculated @ 05/18/24 12:44:15.401
  E0518 12:44:16.152752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:17.152844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 05/18/24 12:44:17.407
  STEP: Ensuring resource quota status captures replicaset creation @ 05/18/24 12:44:17.419
  E0518 12:44:18.153422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:19.153643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 05/18/24 12:44:19.424
  STEP: Ensuring resource quota status released usage @ 05/18/24 12:44:19.432
  E0518 12:44:20.154199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:21.154266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:21.437: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5222" for this suite. @ 05/18/24 12:44:21.442
• [11.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/18/24 12:44:21.452
  May 18 12:44:21.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/18/24 12:44:21.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:21.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:21.471
  STEP: creating a target pod @ 05/18/24 12:44:21.474
  E0518 12:44:22.154380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:23.154491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/18/24 12:44:23.501
  E0518 12:44:24.155142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:25.155178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/18/24 12:44:25.522
  May 18 12:44:25.522: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5666 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 12:44:25.522: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 12:44:25.523: INFO: ExecWithOptions: Clientset creation
  May 18 12:44:25.523: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-5666/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May 18 12:44:25.581: INFO: Exec stderr: ""
  May 18 12:44:25.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5666" for this suite. @ 05/18/24 12:44:25.593
• [4.150 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/18/24 12:44:25.602
  May 18 12:44:25.602: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename controllerrevisions @ 05/18/24 12:44:25.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:25.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:25.621
  STEP: Creating DaemonSet "e2e-b4xgg-daemon-set" @ 05/18/24 12:44:25.645
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 12:44:25.65
  May 18 12:44:25.654: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:25.654: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:25.659: INFO: Number of nodes with available pods controlled by daemonset e2e-b4xgg-daemon-set: 0
  May 18 12:44:25.659: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:44:26.155273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:26.654: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:26.654: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:26.659: INFO: Number of nodes with available pods controlled by daemonset e2e-b4xgg-daemon-set: 1
  May 18 12:44:26.659: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:44:27.155878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:27.655: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:27.655: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:44:27.660: INFO: Number of nodes with available pods controlled by daemonset e2e-b4xgg-daemon-set: 3
  May 18 12:44:27.660: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-b4xgg-daemon-set
  STEP: Confirm DaemonSet "e2e-b4xgg-daemon-set" successfully created with "daemonset-name=e2e-b4xgg-daemon-set" label @ 05/18/24 12:44:27.664
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-b4xgg-daemon-set" @ 05/18/24 12:44:27.672
  May 18 12:44:27.676: INFO: Located ControllerRevision: "e2e-b4xgg-daemon-set-7ffcb664dc"
  STEP: Patching ControllerRevision "e2e-b4xgg-daemon-set-7ffcb664dc" @ 05/18/24 12:44:27.68
  May 18 12:44:27.687: INFO: e2e-b4xgg-daemon-set-7ffcb664dc has been patched
  STEP: Create a new ControllerRevision @ 05/18/24 12:44:27.687
  May 18 12:44:27.694: INFO: Created ControllerRevision: e2e-b4xgg-daemon-set-594487995f
  STEP: Confirm that there are two ControllerRevisions @ 05/18/24 12:44:27.694
  May 18 12:44:27.694: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 18 12:44:27.697: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-b4xgg-daemon-set-7ffcb664dc" @ 05/18/24 12:44:27.697
  STEP: Confirm that there is only one ControllerRevision @ 05/18/24 12:44:27.704
  May 18 12:44:27.704: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 18 12:44:27.717: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-b4xgg-daemon-set-594487995f" @ 05/18/24 12:44:27.721
  May 18 12:44:27.731: INFO: e2e-b4xgg-daemon-set-594487995f has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/18/24 12:44:27.731
  W0518 12:44:27.738888      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 05/18/24 12:44:27.739
  May 18 12:44:27.739: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0518 12:44:28.156630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:28.739: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 18 12:44:28.744: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-b4xgg-daemon-set-594487995f=updated" @ 05/18/24 12:44:28.744
  STEP: Confirm that there is only one ControllerRevision @ 05/18/24 12:44:28.754
  May 18 12:44:28.754: INFO: Requesting list of ControllerRevisions to confirm quantity
  May 18 12:44:28.758: INFO: Found 1 ControllerRevisions
  May 18 12:44:28.762: INFO: ControllerRevision "e2e-b4xgg-daemon-set-69c9fd64cd" has revision 3
  STEP: Deleting DaemonSet "e2e-b4xgg-daemon-set" @ 05/18/24 12:44:28.765
  STEP: deleting DaemonSet.extensions e2e-b4xgg-daemon-set in namespace controllerrevisions-8070, will wait for the garbage collector to delete the pods @ 05/18/24 12:44:28.765
  May 18 12:44:28.830: INFO: Deleting DaemonSet.extensions e2e-b4xgg-daemon-set took: 10.132431ms
  May 18 12:44:28.930: INFO: Terminating DaemonSet.extensions e2e-b4xgg-daemon-set pods took: 100.251646ms
  E0518 12:44:29.157574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:30.158045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:30.537: INFO: Number of nodes with available pods controlled by daemonset e2e-b4xgg-daemon-set: 0
  May 18 12:44:30.537: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-b4xgg-daemon-set
  May 18 12:44:30.541: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22945"},"items":null}

  May 18 12:44:30.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22945"},"items":null}

  May 18 12:44:30.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8070" for this suite. @ 05/18/24 12:44:30.572
• [4.979 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/18/24 12:44:30.581
  May 18 12:44:30.581: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 12:44:30.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:30.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:30.61
  May 18 12:44:30.636: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0518 12:44:31.158426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:32.158501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:33.158656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:34.158751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:35.158949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:35.641: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 12:44:35.641
  May 18 12:44:35.642: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0518 12:44:36.159163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:37.159271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:37.647: INFO: Creating deployment "test-rollover-deployment"
  May 18 12:44:37.656: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0518 12:44:38.160063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:39.160151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:39.664: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  May 18 12:44:39.672: INFO: Ensure that both replica sets have 1 created replica
  May 18 12:44:39.680: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  May 18 12:44:39.691: INFO: Updating deployment test-rollover-deployment
  May 18 12:44:39.691: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0518 12:44:40.161130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:41.161228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:41.700: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  May 18 12:44:41.709: INFO: Make sure deployment "test-rollover-deployment" is complete
  May 18 12:44:41.716: INFO: all replica sets need to contain the pod-template-hash label
  May 18 12:44:41.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 12:44:42.161593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:43.161676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:43.726: INFO: all replica sets need to contain the pod-template-hash label
  May 18 12:44:43.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 12:44:44.161995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:45.162095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:45.726: INFO: all replica sets need to contain the pod-template-hash label
  May 18 12:44:45.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 12:44:46.162771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:47.162858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:47.726: INFO: all replica sets need to contain the pod-template-hash label
  May 18 12:44:47.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 12:44:48.163871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:49.163930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:49.725: INFO: all replica sets need to contain the pod-template-hash label
  May 18 12:44:49.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 12, 44, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 12, 44, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 12:44:50.164212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:51.164318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:51.725: INFO: 
  May 18 12:44:51.725: INFO: Ensure that both old replica sets have no replicas
  May 18 12:44:51.738: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ca54a2c9-e6df-4ca7-bae1-ed543283385a",
      ResourceVersion: (string) (len=5) "23119",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633077,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633091,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633091,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 12:44:51.744: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2df96ee0-1607-49e5-a71f-c18316cbb1be",
      ResourceVersion: (string) (len=5) "23109",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633079,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "ca54a2c9-e6df-4ca7-bae1-ed543283385a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 61 35 34 61 32  63 39 2d 65 36 64 66 2d  |\"ca54a2c9-e6df-|
              00000120  34 63 61 37 2d 62 61 65  31 2d 65 64 35 34 33 32  |4ca7-bae1-ed5432|
              00000130  38 33 33 38 35 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |83385a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633091,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:44:51.745: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  May 18 12:44:51.745: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "21dfda6f-db5b-4ad3-8cb4-48e1852c6049",
      ResourceVersion: (string) (len=5) "23118",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633070,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "ca54a2c9-e6df-4ca7-bae1-ed543283385a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633091,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  63 61 35 34 61 32 63 39  2d 65 36 64 66 2d 34 63  |ca54a2c9-e6df-4c|
              000000c0  61 37 2d 62 61 65 31 2d  65 64 35 34 33 32 38 33  |a7-bae1-ed543283|
              000000d0  33 38 35 61 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |385a\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633091,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:44:51.746: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "58880611-8092-4be0-bec8-d9fe17d70676",
      ResourceVersion: (string) (len=5) "23074",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633077,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "ca54a2c9-e6df-4ca7-bae1-ed543283385a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 61 35 34 61 32  63 39 2d 65 36 64 66 2d  |\"ca54a2c9-e6df-|
              00000120  34 63 61 37 2d 62 61 65  31 2d 65 64 35 34 33 32  |4ca7-bae1-ed5432|
              00000130  38 33 33 38 35 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |83385a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 12:44:51.750: INFO: Pod "test-rollover-deployment-68774655d5-bst6h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-bst6h",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e0f501c3-8c09-414a-bcd9-937aab72b7f0",
      ResourceVersion: (string) (len=5) "23087",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633079,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "2df96ee0-1607-49e5-a71f-c18316cbb1be",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 64  66 39 36 65 65 30 2d 31  |d\":\"2df96ee0-1|
              00000090  36 30 37 2d 34 39 65 35  2d 61 37 31 66 2d 63 31  |607-49e5-a71f-c1|
              000000a0  38 33 31 36 63 62 62 31  62 65 5c 22 7d 22 3a 7b  |8316cbb1be\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633081,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 35 35 5c 22 7d  |2.168.225.255\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n6x6p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n6x6p",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633081,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633081,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633081,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633079,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.255",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.255"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633079,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633080,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://45a441fc06d910ea8388a998acfb6c3fb50d546e92c49e820ca68a193873348a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 12:44:51.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1954" for this suite. @ 05/18/24 12:44:51.755
• [21.182 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 05/18/24 12:44:51.764
  May 18 12:44:51.764: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:44:51.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:51.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:51.783
  STEP: creating a replication controller @ 05/18/24 12:44:51.786
  May 18 12:44:51.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 create -f -'
  May 18 12:44:51.871: INFO: stderr: ""
  May 18 12:44:51.871: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/18/24 12:44:51.871
  May 18 12:44:51.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:44:51.921: INFO: stderr: ""
  May 18 12:44:51.921: INFO: stdout: "update-demo-nautilus-pkbts update-demo-nautilus-ssmxd "
  May 18 12:44:51.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods update-demo-nautilus-pkbts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:44:51.962: INFO: stderr: ""
  May 18 12:44:51.962: INFO: stdout: ""
  May 18 12:44:51.962: INFO: update-demo-nautilus-pkbts is created but not running
  E0518 12:44:52.164591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:53.164704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:54.164868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:55.165044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:56.165376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:56.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  May 18 12:44:57.005: INFO: stderr: ""
  May 18 12:44:57.005: INFO: stdout: "update-demo-nautilus-pkbts update-demo-nautilus-ssmxd "
  May 18 12:44:57.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods update-demo-nautilus-pkbts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:44:57.046: INFO: stderr: ""
  May 18 12:44:57.046: INFO: stdout: "true"
  May 18 12:44:57.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods update-demo-nautilus-pkbts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  May 18 12:44:57.097: INFO: stderr: ""
  May 18 12:44:57.097: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:44:57.097: INFO: validating pod update-demo-nautilus-pkbts
  May 18 12:44:57.104: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:44:57.104: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:44:57.104: INFO: update-demo-nautilus-pkbts is verified up and running
  May 18 12:44:57.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods update-demo-nautilus-ssmxd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  May 18 12:44:57.143: INFO: stderr: ""
  May 18 12:44:57.143: INFO: stdout: "true"
  May 18 12:44:57.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods update-demo-nautilus-ssmxd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0518 12:44:57.165983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:57.184: INFO: stderr: ""
  May 18 12:44:57.184: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  May 18 12:44:57.184: INFO: validating pod update-demo-nautilus-ssmxd
  May 18 12:44:57.190: INFO: got data: {
    "image": "nautilus.jpg"
  }

  May 18 12:44:57.190: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  May 18 12:44:57.190: INFO: update-demo-nautilus-ssmxd is verified up and running
  STEP: using delete to clean up resources @ 05/18/24 12:44:57.19
  May 18 12:44:57.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 delete --grace-period=0 --force -f -'
  May 18 12:44:57.234: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 12:44:57.234: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  May 18 12:44:57.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get rc,svc -l name=update-demo --no-headers'
  May 18 12:44:57.299: INFO: stderr: "No resources found in kubectl-8652 namespace.\n"
  May 18 12:44:57.299: INFO: stdout: ""
  May 18 12:44:57.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8652 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May 18 12:44:57.365: INFO: stderr: ""
  May 18 12:44:57.365: INFO: stdout: ""
  May 18 12:44:57.365: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8652" for this suite. @ 05/18/24 12:44:57.37
• [5.613 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 05/18/24 12:44:57.377
  May 18 12:44:57.377: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 12:44:57.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:57.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:57.403
  STEP: creating the pod @ 05/18/24 12:44:57.426
  STEP: submitting the pod to kubernetes @ 05/18/24 12:44:57.426
  STEP: verifying QOS class is set on the pod @ 05/18/24 12:44:57.439
  May 18 12:44:57.448: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6561" for this suite. @ 05/18/24 12:44:57.453
• [0.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 05/18/24 12:44:57.462
  May 18 12:44:57.462: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubelet-test @ 05/18/24 12:44:57.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:57.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:57.483
  STEP: Waiting for pod completion @ 05/18/24 12:44:57.5
  E0518 12:44:58.166118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:44:59.166465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:44:59.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8279" for this suite. @ 05/18/24 12:44:59.522
• [2.068 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 05/18/24 12:44:59.531
  May 18 12:44:59.531: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:44:59.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:44:59.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:44:59.55
  STEP: Creating configMap configmap-447/configmap-test-30542bf1-0b40-4aac-bacd-997a03e5b35f @ 05/18/24 12:44:59.553
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:44:59.558
  E0518 12:45:00.167438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:01.167525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:02.167977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:03.168065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:45:03.577
  May 18 12:45:03.581: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-fe3187bd-4179-40fc-8182-6119cd647d85 container env-test: <nil>
  STEP: delete the pod @ 05/18/24 12:45:03.589
  May 18 12:45:03.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-447" for this suite. @ 05/18/24 12:45:03.611
• [4.086 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 05/18/24 12:45:03.617
  May 18 12:45:03.617: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 12:45:03.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:03.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:03.639
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/18/24 12:45:03.642
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/18/24 12:45:03.642
  STEP: creating a pod to probe DNS @ 05/18/24 12:45:03.642
  STEP: submitting the pod to kubernetes @ 05/18/24 12:45:03.642
  E0518 12:45:04.168686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:05.168868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 12:45:05.666
  STEP: looking for the results for each expected name from probers @ 05/18/24 12:45:05.671
  May 18 12:45:05.689: INFO: DNS probes using dns-6817/dns-test-344c1c75-3ee4-4adc-a579-0c3245e31f69 succeeded

  STEP: deleting the pod @ 05/18/24 12:45:05.689
  May 18 12:45:05.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6817" for this suite. @ 05/18/24 12:45:05.707
• [2.097 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/18/24 12:45:05.715
  May 18 12:45:05.715: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename server-version @ 05/18/24 12:45:05.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:05.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:05.733
  STEP: Request ServerVersion @ 05/18/24 12:45:05.736
  STEP: Confirm major version @ 05/18/24 12:45:05.737
  May 18 12:45:05.737: INFO: Major version: 1
  STEP: Confirm minor version @ 05/18/24 12:45:05.737
  May 18 12:45:05.737: INFO: cleanMinorVersion: 29
  May 18 12:45:05.737: INFO: Minor version: 29
  May 18 12:45:05.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-9642" for this suite. @ 05/18/24 12:45:05.741
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/18/24 12:45:05.748
  May 18 12:45:05.748: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename lease-test @ 05/18/24 12:45:05.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:05.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:05.766
  May 18 12:45:05.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-2807" for this suite. @ 05/18/24 12:45:05.839
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/18/24 12:45:05.849
  May 18 12:45:05.849: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svc-latency @ 05/18/24 12:45:05.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:05.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:05.921
  May 18 12:45:05.925: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-3330 @ 05/18/24 12:45:05.925
  I0518 12:45:05.931881      19 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3330, replica count: 1
  E0518 12:45:06.169889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 12:45:06.982558      19 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0518 12:45:07.170923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 12:45:07.983400      19 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 12:45:08.096: INFO: Created: latency-svc-t9j9d
  May 18 12:45:08.106: INFO: Got endpoints: latency-svc-t9j9d [22.097277ms]
  May 18 12:45:08.120: INFO: Created: latency-svc-4tjmp
  May 18 12:45:08.123: INFO: Got endpoints: latency-svc-4tjmp [17.588093ms]
  May 18 12:45:08.125: INFO: Created: latency-svc-jz9jc
  May 18 12:45:08.134: INFO: Created: latency-svc-6rv2q
  May 18 12:45:08.135: INFO: Got endpoints: latency-svc-jz9jc [29.18202ms]
  May 18 12:45:08.143: INFO: Got endpoints: latency-svc-6rv2q [36.743598ms]
  May 18 12:45:08.147: INFO: Created: latency-svc-jp52q
  May 18 12:45:08.153: INFO: Got endpoints: latency-svc-jp52q [46.50144ms]
  May 18 12:45:08.156: INFO: Created: latency-svc-n5w9s
  May 18 12:45:08.162: INFO: Created: latency-svc-7gzfq
  May 18 12:45:08.165: INFO: Got endpoints: latency-svc-n5w9s [58.619565ms]
  May 18 12:45:08.169: INFO: Got endpoints: latency-svc-7gzfq [62.859205ms]
  E0518 12:45:08.171330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:08.173: INFO: Created: latency-svc-7f7k7
  May 18 12:45:08.179: INFO: Got endpoints: latency-svc-7f7k7 [72.252093ms]
  May 18 12:45:08.185: INFO: Created: latency-svc-hqz7d
  May 18 12:45:08.193: INFO: Got endpoints: latency-svc-hqz7d [86.1369ms]
  May 18 12:45:08.193: INFO: Created: latency-svc-mr2h7
  May 18 12:45:08.198: INFO: Got endpoints: latency-svc-mr2h7 [91.786936ms]
  May 18 12:45:08.204: INFO: Created: latency-svc-md8rk
  May 18 12:45:08.207: INFO: Got endpoints: latency-svc-md8rk [101.041337ms]
  May 18 12:45:08.208: INFO: Created: latency-svc-58rw5
  May 18 12:45:08.216: INFO: Got endpoints: latency-svc-58rw5 [109.552897ms]
  May 18 12:45:08.219: INFO: Created: latency-svc-bgp82
  May 18 12:45:08.228: INFO: Got endpoints: latency-svc-bgp82 [121.097343ms]
  May 18 12:45:08.231: INFO: Created: latency-svc-wjm29
  May 18 12:45:08.250: INFO: Got endpoints: latency-svc-wjm29 [143.554329ms]
  May 18 12:45:08.253: INFO: Created: latency-svc-rnbdr
  May 18 12:45:08.261: INFO: Created: latency-svc-75g5d
  May 18 12:45:08.264: INFO: Got endpoints: latency-svc-rnbdr [157.68934ms]
  May 18 12:45:08.267: INFO: Got endpoints: latency-svc-75g5d [160.514867ms]
  May 18 12:45:08.272: INFO: Created: latency-svc-26bpm
  May 18 12:45:08.278: INFO: Got endpoints: latency-svc-26bpm [154.584338ms]
  May 18 12:45:08.281: INFO: Created: latency-svc-sw5k6
  May 18 12:45:08.286: INFO: Created: latency-svc-95rp8
  May 18 12:45:08.286: INFO: Got endpoints: latency-svc-sw5k6 [151.199096ms]
  May 18 12:45:08.294: INFO: Got endpoints: latency-svc-95rp8 [151.315116ms]
  May 18 12:45:08.299: INFO: Created: latency-svc-7mxr6
  May 18 12:45:08.303: INFO: Got endpoints: latency-svc-7mxr6 [150.56611ms]
  May 18 12:45:08.307: INFO: Created: latency-svc-qsdp5
  May 18 12:45:08.314: INFO: Got endpoints: latency-svc-qsdp5 [148.970139ms]
  May 18 12:45:08.319: INFO: Created: latency-svc-7pxrx
  May 18 12:45:08.326: INFO: Created: latency-svc-kv48c
  May 18 12:45:08.328: INFO: Got endpoints: latency-svc-7pxrx [158.975008ms]
  May 18 12:45:08.333: INFO: Created: latency-svc-ddpsw
  May 18 12:45:08.335: INFO: Got endpoints: latency-svc-kv48c [155.982029ms]
  May 18 12:45:08.338: INFO: Got endpoints: latency-svc-ddpsw [145.007929ms]
  May 18 12:45:08.342: INFO: Created: latency-svc-n2vt6
  May 18 12:45:08.348: INFO: Got endpoints: latency-svc-n2vt6 [149.567845ms]
  May 18 12:45:08.352: INFO: Created: latency-svc-7dqd5
  May 18 12:45:08.356: INFO: Got endpoints: latency-svc-7dqd5 [148.744267ms]
  May 18 12:45:08.361: INFO: Created: latency-svc-pf4ng
  May 18 12:45:08.366: INFO: Got endpoints: latency-svc-pf4ng [150.368638ms]
  May 18 12:45:08.372: INFO: Created: latency-svc-xc92r
  May 18 12:45:08.377: INFO: Got endpoints: latency-svc-xc92r [149.535823ms]
  May 18 12:45:08.380: INFO: Created: latency-svc-cd8zt
  May 18 12:45:08.383: INFO: Got endpoints: latency-svc-cd8zt [132.645636ms]
  May 18 12:45:08.390: INFO: Created: latency-svc-jmbdk
  May 18 12:45:08.396: INFO: Created: latency-svc-lbvvc
  May 18 12:45:08.398: INFO: Got endpoints: latency-svc-jmbdk [134.282919ms]
  May 18 12:45:08.405: INFO: Got endpoints: latency-svc-lbvvc [137.795885ms]
  May 18 12:45:08.410: INFO: Created: latency-svc-7rrxp
  May 18 12:45:08.415: INFO: Got endpoints: latency-svc-7rrxp [136.584642ms]
  May 18 12:45:08.419: INFO: Created: latency-svc-t4gn2
  May 18 12:45:08.423: INFO: Got endpoints: latency-svc-t4gn2 [137.007572ms]
  May 18 12:45:08.424: INFO: Created: latency-svc-kt786
  May 18 12:45:08.430: INFO: Got endpoints: latency-svc-kt786 [135.80036ms]
  May 18 12:45:08.436: INFO: Created: latency-svc-vlcs4
  May 18 12:45:08.440: INFO: Got endpoints: latency-svc-vlcs4 [136.597424ms]
  May 18 12:45:08.441: INFO: Created: latency-svc-gwvxd
  May 18 12:45:08.450: INFO: Got endpoints: latency-svc-gwvxd [135.973483ms]
  May 18 12:45:08.454: INFO: Created: latency-svc-b2vjm
  May 18 12:45:08.460: INFO: Created: latency-svc-gk46t
  May 18 12:45:08.462: INFO: Got endpoints: latency-svc-b2vjm [133.985126ms]
  May 18 12:45:08.468: INFO: Created: latency-svc-pzdwh
  May 18 12:45:08.473: INFO: Created: latency-svc-6kxss
  May 18 12:45:08.482: INFO: Created: latency-svc-jhpfc
  May 18 12:45:08.488: INFO: Created: latency-svc-vfxcb
  May 18 12:45:08.494: INFO: Created: latency-svc-ttdvw
  May 18 12:45:08.501: INFO: Created: latency-svc-mgwhx
  May 18 12:45:08.502: INFO: Got endpoints: latency-svc-gk46t [167.388439ms]
  May 18 12:45:08.507: INFO: Created: latency-svc-rgkcm
  May 18 12:45:08.515: INFO: Created: latency-svc-8fszp
  May 18 12:45:08.521: INFO: Created: latency-svc-5gvcr
  May 18 12:45:08.528: INFO: Created: latency-svc-lg5qk
  May 18 12:45:08.534: INFO: Created: latency-svc-4v96b
  May 18 12:45:08.543: INFO: Created: latency-svc-5ftwl
  May 18 12:45:08.549: INFO: Created: latency-svc-gfglk
  May 18 12:45:08.553: INFO: Got endpoints: latency-svc-pzdwh [214.876204ms]
  May 18 12:45:08.555: INFO: Created: latency-svc-vnfcz
  May 18 12:45:08.567: INFO: Created: latency-svc-cnntt
  May 18 12:45:08.573: INFO: Created: latency-svc-hw4tg
  May 18 12:45:08.603: INFO: Got endpoints: latency-svc-6kxss [255.090414ms]
  May 18 12:45:08.614: INFO: Created: latency-svc-nr6pb
  May 18 12:45:08.652: INFO: Got endpoints: latency-svc-jhpfc [295.467748ms]
  May 18 12:45:08.663: INFO: Created: latency-svc-x6vdr
  May 18 12:45:08.703: INFO: Got endpoints: latency-svc-vfxcb [336.94514ms]
  May 18 12:45:08.717: INFO: Created: latency-svc-pdpqr
  May 18 12:45:08.751: INFO: Got endpoints: latency-svc-ttdvw [373.544892ms]
  May 18 12:45:08.764: INFO: Created: latency-svc-2rslr
  May 18 12:45:08.801: INFO: Got endpoints: latency-svc-mgwhx [418.619837ms]
  May 18 12:45:08.812: INFO: Created: latency-svc-d5gkq
  May 18 12:45:08.851: INFO: Got endpoints: latency-svc-rgkcm [452.358177ms]
  May 18 12:45:08.862: INFO: Created: latency-svc-htzd2
  May 18 12:45:08.904: INFO: Got endpoints: latency-svc-8fszp [498.620508ms]
  May 18 12:45:08.915: INFO: Created: latency-svc-96p2k
  May 18 12:45:08.954: INFO: Got endpoints: latency-svc-5gvcr [539.21656ms]
  May 18 12:45:08.966: INFO: Created: latency-svc-v4thp
  May 18 12:45:09.003: INFO: Got endpoints: latency-svc-lg5qk [579.641282ms]
  May 18 12:45:09.015: INFO: Created: latency-svc-w7h68
  May 18 12:45:09.053: INFO: Got endpoints: latency-svc-4v96b [622.446857ms]
  May 18 12:45:09.064: INFO: Created: latency-svc-8k2xc
  May 18 12:45:09.103: INFO: Got endpoints: latency-svc-5ftwl [662.441621ms]
  May 18 12:45:09.117: INFO: Created: latency-svc-rgc75
  May 18 12:45:09.154: INFO: Got endpoints: latency-svc-gfglk [703.997707ms]
  May 18 12:45:09.166: INFO: Created: latency-svc-t9ckr
  E0518 12:45:09.171605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:09.203: INFO: Got endpoints: latency-svc-vnfcz [740.16431ms]
  May 18 12:45:09.214: INFO: Created: latency-svc-ll48c
  May 18 12:45:09.253: INFO: Got endpoints: latency-svc-cnntt [750.505825ms]
  May 18 12:45:09.263: INFO: Created: latency-svc-c74qd
  May 18 12:45:09.304: INFO: Got endpoints: latency-svc-hw4tg [750.792574ms]
  May 18 12:45:09.315: INFO: Created: latency-svc-68jcz
  May 18 12:45:09.353: INFO: Got endpoints: latency-svc-nr6pb [750.232818ms]
  May 18 12:45:09.366: INFO: Created: latency-svc-bxcfw
  May 18 12:45:09.404: INFO: Got endpoints: latency-svc-x6vdr [752.20702ms]
  May 18 12:45:09.414: INFO: Created: latency-svc-prb67
  May 18 12:45:09.452: INFO: Got endpoints: latency-svc-pdpqr [748.240323ms]
  May 18 12:45:09.467: INFO: Created: latency-svc-nhkhl
  May 18 12:45:09.503: INFO: Got endpoints: latency-svc-2rslr [752.053392ms]
  May 18 12:45:09.516: INFO: Created: latency-svc-tnxnd
  May 18 12:45:09.551: INFO: Got endpoints: latency-svc-d5gkq [749.750385ms]
  May 18 12:45:09.562: INFO: Created: latency-svc-xjcmr
  May 18 12:45:09.604: INFO: Got endpoints: latency-svc-htzd2 [753.114963ms]
  May 18 12:45:09.616: INFO: Created: latency-svc-v4kwd
  May 18 12:45:09.653: INFO: Got endpoints: latency-svc-96p2k [749.703148ms]
  May 18 12:45:09.665: INFO: Created: latency-svc-kjhff
  May 18 12:45:09.702: INFO: Got endpoints: latency-svc-v4thp [748.072325ms]
  May 18 12:45:09.714: INFO: Created: latency-svc-lvjn5
  May 18 12:45:09.753: INFO: Got endpoints: latency-svc-w7h68 [749.791019ms]
  May 18 12:45:09.765: INFO: Created: latency-svc-czcms
  May 18 12:45:09.805: INFO: Got endpoints: latency-svc-8k2xc [752.239752ms]
  May 18 12:45:09.817: INFO: Created: latency-svc-bzkmr
  May 18 12:45:09.854: INFO: Got endpoints: latency-svc-rgc75 [750.868306ms]
  May 18 12:45:09.865: INFO: Created: latency-svc-qtxgm
  May 18 12:45:09.903: INFO: Got endpoints: latency-svc-t9ckr [749.434598ms]
  May 18 12:45:09.922: INFO: Created: latency-svc-jmhk9
  May 18 12:45:09.955: INFO: Got endpoints: latency-svc-ll48c [752.18821ms]
  May 18 12:45:09.967: INFO: Created: latency-svc-29qpq
  May 18 12:45:10.003: INFO: Got endpoints: latency-svc-c74qd [749.84506ms]
  May 18 12:45:10.014: INFO: Created: latency-svc-lk8bf
  May 18 12:45:10.055: INFO: Got endpoints: latency-svc-68jcz [751.389166ms]
  May 18 12:45:10.066: INFO: Created: latency-svc-h7lnc
  May 18 12:45:10.104: INFO: Got endpoints: latency-svc-bxcfw [750.487541ms]
  May 18 12:45:10.116: INFO: Created: latency-svc-xvvzq
  May 18 12:45:10.153: INFO: Got endpoints: latency-svc-prb67 [749.132949ms]
  May 18 12:45:10.171: INFO: Created: latency-svc-gp6zb
  E0518 12:45:10.171993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:10.202: INFO: Got endpoints: latency-svc-nhkhl [750.179455ms]
  May 18 12:45:10.215: INFO: Created: latency-svc-dnqq7
  May 18 12:45:10.252: INFO: Got endpoints: latency-svc-tnxnd [748.973426ms]
  May 18 12:45:10.265: INFO: Created: latency-svc-8gwkn
  May 18 12:45:10.303: INFO: Got endpoints: latency-svc-xjcmr [752.145216ms]
  May 18 12:45:10.314: INFO: Created: latency-svc-xvnm4
  May 18 12:45:10.355: INFO: Got endpoints: latency-svc-v4kwd [751.019005ms]
  May 18 12:45:10.367: INFO: Created: latency-svc-ln8k2
  May 18 12:45:10.401: INFO: Got endpoints: latency-svc-kjhff [747.25966ms]
  May 18 12:45:10.413: INFO: Created: latency-svc-jrfbm
  May 18 12:45:10.455: INFO: Got endpoints: latency-svc-lvjn5 [751.750437ms]
  May 18 12:45:10.465: INFO: Created: latency-svc-lvnjc
  May 18 12:45:10.505: INFO: Got endpoints: latency-svc-czcms [751.427516ms]
  May 18 12:45:10.516: INFO: Created: latency-svc-czqgb
  May 18 12:45:10.555: INFO: Got endpoints: latency-svc-bzkmr [749.381758ms]
  May 18 12:45:10.566: INFO: Created: latency-svc-n2vgh
  May 18 12:45:10.604: INFO: Got endpoints: latency-svc-qtxgm [749.78782ms]
  May 18 12:45:10.615: INFO: Created: latency-svc-svldh
  May 18 12:45:10.655: INFO: Got endpoints: latency-svc-jmhk9 [751.729406ms]
  May 18 12:45:10.669: INFO: Created: latency-svc-tn68r
  May 18 12:45:10.703: INFO: Got endpoints: latency-svc-29qpq [747.949694ms]
  May 18 12:45:10.718: INFO: Created: latency-svc-zkx99
  May 18 12:45:10.754: INFO: Got endpoints: latency-svc-lk8bf [751.175622ms]
  May 18 12:45:10.770: INFO: Created: latency-svc-nks86
  May 18 12:45:10.801: INFO: Got endpoints: latency-svc-h7lnc [745.986241ms]
  May 18 12:45:10.814: INFO: Created: latency-svc-4h7fg
  May 18 12:45:10.853: INFO: Got endpoints: latency-svc-xvvzq [749.188555ms]
  May 18 12:45:10.863: INFO: Created: latency-svc-snmc2
  May 18 12:45:10.905: INFO: Got endpoints: latency-svc-gp6zb [751.323114ms]
  May 18 12:45:10.917: INFO: Created: latency-svc-xjbkj
  May 18 12:45:10.953: INFO: Got endpoints: latency-svc-dnqq7 [750.230678ms]
  May 18 12:45:10.967: INFO: Created: latency-svc-j92px
  May 18 12:45:11.002: INFO: Got endpoints: latency-svc-8gwkn [749.686044ms]
  May 18 12:45:11.016: INFO: Created: latency-svc-qps28
  May 18 12:45:11.051: INFO: Got endpoints: latency-svc-xvnm4 [747.812367ms]
  May 18 12:45:11.063: INFO: Created: latency-svc-pffdf
  May 18 12:45:11.102: INFO: Got endpoints: latency-svc-ln8k2 [746.312173ms]
  May 18 12:45:11.119: INFO: Created: latency-svc-bnvt7
  May 18 12:45:11.153: INFO: Got endpoints: latency-svc-jrfbm [752.149429ms]
  May 18 12:45:11.165: INFO: Created: latency-svc-qxllg
  E0518 12:45:11.172716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:11.205: INFO: Got endpoints: latency-svc-lvnjc [750.14984ms]
  May 18 12:45:11.217: INFO: Created: latency-svc-jfrhp
  May 18 12:45:11.251: INFO: Got endpoints: latency-svc-czqgb [746.749227ms]
  May 18 12:45:11.271: INFO: Created: latency-svc-qjqks
  May 18 12:45:11.303: INFO: Got endpoints: latency-svc-n2vgh [748.71343ms]
  May 18 12:45:11.317: INFO: Created: latency-svc-gcgnj
  May 18 12:45:11.352: INFO: Got endpoints: latency-svc-svldh [748.147997ms]
  May 18 12:45:11.364: INFO: Created: latency-svc-f7mc8
  May 18 12:45:11.402: INFO: Got endpoints: latency-svc-tn68r [746.240064ms]
  May 18 12:45:11.415: INFO: Created: latency-svc-95zqt
  May 18 12:45:11.453: INFO: Got endpoints: latency-svc-zkx99 [750.228956ms]
  May 18 12:45:11.465: INFO: Created: latency-svc-wdld5
  May 18 12:45:11.504: INFO: Got endpoints: latency-svc-nks86 [750.348271ms]
  May 18 12:45:11.517: INFO: Created: latency-svc-fvvcr
  May 18 12:45:11.553: INFO: Got endpoints: latency-svc-4h7fg [751.683316ms]
  May 18 12:45:11.569: INFO: Created: latency-svc-d52rp
  May 18 12:45:11.602: INFO: Got endpoints: latency-svc-snmc2 [749.34082ms]
  May 18 12:45:11.616: INFO: Created: latency-svc-wh8sx
  May 18 12:45:11.653: INFO: Got endpoints: latency-svc-xjbkj [747.461517ms]
  May 18 12:45:11.663: INFO: Created: latency-svc-hmd6r
  May 18 12:45:11.705: INFO: Got endpoints: latency-svc-j92px [751.910023ms]
  May 18 12:45:11.717: INFO: Created: latency-svc-wmntm
  May 18 12:45:11.754: INFO: Got endpoints: latency-svc-qps28 [751.047702ms]
  May 18 12:45:11.766: INFO: Created: latency-svc-cghrf
  May 18 12:45:11.804: INFO: Got endpoints: latency-svc-pffdf [752.385533ms]
  May 18 12:45:11.815: INFO: Created: latency-svc-gnhlc
  May 18 12:45:11.853: INFO: Got endpoints: latency-svc-bnvt7 [750.702941ms]
  May 18 12:45:11.863: INFO: Created: latency-svc-pljc7
  May 18 12:45:11.906: INFO: Got endpoints: latency-svc-qxllg [752.455557ms]
  May 18 12:45:11.916: INFO: Created: latency-svc-szkbp
  May 18 12:45:11.954: INFO: Got endpoints: latency-svc-jfrhp [748.792545ms]
  May 18 12:45:11.965: INFO: Created: latency-svc-9z8cl
  May 18 12:45:12.003: INFO: Got endpoints: latency-svc-qjqks [751.643013ms]
  May 18 12:45:12.015: INFO: Created: latency-svc-zzxvb
  May 18 12:45:12.053: INFO: Got endpoints: latency-svc-gcgnj [749.83148ms]
  May 18 12:45:12.065: INFO: Created: latency-svc-4x9nl
  May 18 12:45:12.104: INFO: Got endpoints: latency-svc-f7mc8 [751.047219ms]
  May 18 12:45:12.116: INFO: Created: latency-svc-7xnzs
  May 18 12:45:12.154: INFO: Got endpoints: latency-svc-95zqt [751.884859ms]
  May 18 12:45:12.167: INFO: Created: latency-svc-65r7z
  E0518 12:45:12.173059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:12.204: INFO: Got endpoints: latency-svc-wdld5 [750.351715ms]
  May 18 12:45:12.216: INFO: Created: latency-svc-mwqd5
  May 18 12:45:12.253: INFO: Got endpoints: latency-svc-fvvcr [749.026832ms]
  May 18 12:45:12.265: INFO: Created: latency-svc-td4w4
  May 18 12:45:12.302: INFO: Got endpoints: latency-svc-d52rp [748.980221ms]
  May 18 12:45:12.313: INFO: Created: latency-svc-knjgd
  May 18 12:45:12.353: INFO: Got endpoints: latency-svc-wh8sx [750.291591ms]
  May 18 12:45:12.364: INFO: Created: latency-svc-cmrl5
  May 18 12:45:12.404: INFO: Got endpoints: latency-svc-hmd6r [751.185131ms]
  May 18 12:45:12.415: INFO: Created: latency-svc-ds8ck
  May 18 12:45:12.452: INFO: Got endpoints: latency-svc-wmntm [747.574922ms]
  May 18 12:45:12.468: INFO: Created: latency-svc-dgpf8
  May 18 12:45:12.503: INFO: Got endpoints: latency-svc-cghrf [749.013851ms]
  May 18 12:45:12.515: INFO: Created: latency-svc-hnmk7
  May 18 12:45:12.554: INFO: Got endpoints: latency-svc-gnhlc [750.241632ms]
  May 18 12:45:12.565: INFO: Created: latency-svc-p2nxp
  May 18 12:45:12.603: INFO: Got endpoints: latency-svc-pljc7 [750.812557ms]
  May 18 12:45:12.615: INFO: Created: latency-svc-rs5q8
  May 18 12:45:12.654: INFO: Got endpoints: latency-svc-szkbp [748.353172ms]
  May 18 12:45:12.669: INFO: Created: latency-svc-ht95j
  May 18 12:45:12.704: INFO: Got endpoints: latency-svc-9z8cl [749.607204ms]
  May 18 12:45:12.716: INFO: Created: latency-svc-npk8b
  May 18 12:45:12.753: INFO: Got endpoints: latency-svc-zzxvb [750.104186ms]
  May 18 12:45:12.764: INFO: Created: latency-svc-6l7kz
  May 18 12:45:12.807: INFO: Got endpoints: latency-svc-4x9nl [754.074131ms]
  May 18 12:45:12.821: INFO: Created: latency-svc-g4xwj
  May 18 12:45:12.854: INFO: Got endpoints: latency-svc-7xnzs [750.393581ms]
  May 18 12:45:12.864: INFO: Created: latency-svc-m6gmd
  May 18 12:45:12.905: INFO: Got endpoints: latency-svc-65r7z [751.382099ms]
  May 18 12:45:12.922: INFO: Created: latency-svc-7qxj9
  May 18 12:45:12.959: INFO: Got endpoints: latency-svc-mwqd5 [754.865707ms]
  May 18 12:45:12.979: INFO: Created: latency-svc-7mhrv
  May 18 12:45:13.003: INFO: Got endpoints: latency-svc-td4w4 [749.956748ms]
  May 18 12:45:13.013: INFO: Created: latency-svc-tp6wq
  May 18 12:45:13.053: INFO: Got endpoints: latency-svc-knjgd [750.847611ms]
  May 18 12:45:13.066: INFO: Created: latency-svc-pjg6s
  May 18 12:45:13.105: INFO: Got endpoints: latency-svc-cmrl5 [751.856068ms]
  May 18 12:45:13.120: INFO: Created: latency-svc-d59gh
  May 18 12:45:13.156: INFO: Got endpoints: latency-svc-ds8ck [752.278772ms]
  May 18 12:45:13.167: INFO: Created: latency-svc-gwwlc
  E0518 12:45:13.173491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:13.204: INFO: Got endpoints: latency-svc-dgpf8 [751.220986ms]
  May 18 12:45:13.216: INFO: Created: latency-svc-6tpcn
  May 18 12:45:13.253: INFO: Got endpoints: latency-svc-hnmk7 [749.994041ms]
  May 18 12:45:13.266: INFO: Created: latency-svc-g9v4n
  May 18 12:45:13.302: INFO: Got endpoints: latency-svc-p2nxp [747.91023ms]
  May 18 12:45:13.312: INFO: Created: latency-svc-n7c49
  May 18 12:45:13.353: INFO: Got endpoints: latency-svc-rs5q8 [749.171364ms]
  May 18 12:45:13.366: INFO: Created: latency-svc-mk8v6
  May 18 12:45:13.404: INFO: Got endpoints: latency-svc-ht95j [749.511323ms]
  May 18 12:45:13.415: INFO: Created: latency-svc-zmtnf
  May 18 12:45:13.454: INFO: Got endpoints: latency-svc-npk8b [750.082946ms]
  May 18 12:45:13.466: INFO: Created: latency-svc-wf5zf
  May 18 12:45:13.502: INFO: Got endpoints: latency-svc-6l7kz [748.826531ms]
  May 18 12:45:13.512: INFO: Created: latency-svc-f4brs
  May 18 12:45:13.553: INFO: Got endpoints: latency-svc-g4xwj [745.020301ms]
  May 18 12:45:13.566: INFO: Created: latency-svc-gdwfv
  May 18 12:45:13.603: INFO: Got endpoints: latency-svc-m6gmd [748.247843ms]
  May 18 12:45:13.613: INFO: Created: latency-svc-lhfbl
  May 18 12:45:13.654: INFO: Got endpoints: latency-svc-7qxj9 [749.12047ms]
  May 18 12:45:13.666: INFO: Created: latency-svc-b2c88
  May 18 12:45:13.703: INFO: Got endpoints: latency-svc-7mhrv [743.380025ms]
  May 18 12:45:13.717: INFO: Created: latency-svc-kltft
  May 18 12:45:13.753: INFO: Got endpoints: latency-svc-tp6wq [749.186131ms]
  May 18 12:45:13.765: INFO: Created: latency-svc-l56sp
  May 18 12:45:13.802: INFO: Got endpoints: latency-svc-pjg6s [748.774107ms]
  May 18 12:45:13.815: INFO: Created: latency-svc-646m9
  May 18 12:45:13.853: INFO: Got endpoints: latency-svc-d59gh [748.249783ms]
  May 18 12:45:13.867: INFO: Created: latency-svc-mgwj4
  May 18 12:45:13.904: INFO: Got endpoints: latency-svc-gwwlc [747.56377ms]
  May 18 12:45:13.915: INFO: Created: latency-svc-fg99w
  May 18 12:45:13.955: INFO: Got endpoints: latency-svc-6tpcn [751.094668ms]
  May 18 12:45:13.965: INFO: Created: latency-svc-p2rph
  May 18 12:45:14.002: INFO: Got endpoints: latency-svc-g9v4n [749.158515ms]
  May 18 12:45:14.013: INFO: Created: latency-svc-t8xnm
  May 18 12:45:14.052: INFO: Got endpoints: latency-svc-n7c49 [749.336585ms]
  May 18 12:45:14.062: INFO: Created: latency-svc-lgw2b
  May 18 12:45:14.105: INFO: Got endpoints: latency-svc-mk8v6 [752.321738ms]
  May 18 12:45:14.126: INFO: Created: latency-svc-wkh7t
  May 18 12:45:14.154: INFO: Got endpoints: latency-svc-zmtnf [749.370535ms]
  May 18 12:45:14.166: INFO: Created: latency-svc-z4m9z
  E0518 12:45:14.174098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:14.205: INFO: Got endpoints: latency-svc-wf5zf [750.71208ms]
  May 18 12:45:14.219: INFO: Created: latency-svc-ddcvx
  May 18 12:45:14.252: INFO: Got endpoints: latency-svc-f4brs [749.590619ms]
  May 18 12:45:14.266: INFO: Created: latency-svc-wvwl6
  May 18 12:45:14.304: INFO: Got endpoints: latency-svc-gdwfv [751.046421ms]
  May 18 12:45:14.315: INFO: Created: latency-svc-n6r2g
  May 18 12:45:14.353: INFO: Got endpoints: latency-svc-lhfbl [750.393203ms]
  May 18 12:45:14.364: INFO: Created: latency-svc-rm7kr
  May 18 12:45:14.404: INFO: Got endpoints: latency-svc-b2c88 [749.729144ms]
  May 18 12:45:14.416: INFO: Created: latency-svc-h5wk6
  May 18 12:45:14.453: INFO: Got endpoints: latency-svc-kltft [749.998526ms]
  May 18 12:45:14.465: INFO: Created: latency-svc-96c6s
  May 18 12:45:14.503: INFO: Got endpoints: latency-svc-l56sp [750.428906ms]
  May 18 12:45:14.513: INFO: Created: latency-svc-pqq8s
  May 18 12:45:14.553: INFO: Got endpoints: latency-svc-646m9 [751.42389ms]
  May 18 12:45:14.566: INFO: Created: latency-svc-m4wcc
  May 18 12:45:14.604: INFO: Got endpoints: latency-svc-mgwj4 [750.592928ms]
  May 18 12:45:14.614: INFO: Created: latency-svc-vb64h
  May 18 12:45:14.655: INFO: Got endpoints: latency-svc-fg99w [750.701613ms]
  May 18 12:45:14.665: INFO: Created: latency-svc-kqvp7
  May 18 12:45:14.704: INFO: Got endpoints: latency-svc-p2rph [748.82513ms]
  May 18 12:45:14.715: INFO: Created: latency-svc-275gv
  May 18 12:45:14.753: INFO: Got endpoints: latency-svc-t8xnm [750.677092ms]
  May 18 12:45:14.805: INFO: Got endpoints: latency-svc-lgw2b [753.519683ms]
  May 18 12:45:14.823: INFO: Created: latency-svc-cczln
  May 18 12:45:14.828: INFO: Created: latency-svc-v79jv
  May 18 12:45:14.853: INFO: Got endpoints: latency-svc-wkh7t [744.634055ms]
  May 18 12:45:14.864: INFO: Created: latency-svc-gwqdl
  May 18 12:45:14.903: INFO: Got endpoints: latency-svc-z4m9z [749.052663ms]
  May 18 12:45:14.915: INFO: Created: latency-svc-hmwt5
  May 18 12:45:14.954: INFO: Got endpoints: latency-svc-ddcvx [749.026429ms]
  May 18 12:45:14.964: INFO: Created: latency-svc-rg5xv
  May 18 12:45:15.002: INFO: Got endpoints: latency-svc-wvwl6 [750.41754ms]
  May 18 12:45:15.017: INFO: Created: latency-svc-tqdfq
  May 18 12:45:15.052: INFO: Got endpoints: latency-svc-n6r2g [748.394556ms]
  May 18 12:45:15.065: INFO: Created: latency-svc-wwlrf
  May 18 12:45:15.103: INFO: Got endpoints: latency-svc-rm7kr [749.96388ms]
  May 18 12:45:15.115: INFO: Created: latency-svc-fhgxj
  May 18 12:45:15.153: INFO: Got endpoints: latency-svc-h5wk6 [749.223221ms]
  May 18 12:45:15.167: INFO: Created: latency-svc-9nc58
  E0518 12:45:15.175131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:15.203: INFO: Got endpoints: latency-svc-96c6s [750.443488ms]
  May 18 12:45:15.214: INFO: Created: latency-svc-l6xsk
  May 18 12:45:15.252: INFO: Got endpoints: latency-svc-pqq8s [748.52336ms]
  May 18 12:45:15.263: INFO: Created: latency-svc-c52kq
  May 18 12:45:15.304: INFO: Got endpoints: latency-svc-m4wcc [750.434854ms]
  May 18 12:45:15.316: INFO: Created: latency-svc-n29bm
  May 18 12:45:15.353: INFO: Got endpoints: latency-svc-vb64h [749.006468ms]
  May 18 12:45:15.365: INFO: Created: latency-svc-mxzwk
  May 18 12:45:15.403: INFO: Got endpoints: latency-svc-kqvp7 [748.111699ms]
  May 18 12:45:15.413: INFO: Created: latency-svc-czvcw
  May 18 12:45:15.453: INFO: Got endpoints: latency-svc-275gv [749.372854ms]
  May 18 12:45:15.465: INFO: Created: latency-svc-glb9p
  May 18 12:45:15.503: INFO: Got endpoints: latency-svc-cczln [750.598956ms]
  May 18 12:45:15.516: INFO: Created: latency-svc-926rj
  May 18 12:45:15.554: INFO: Got endpoints: latency-svc-v79jv [748.809259ms]
  May 18 12:45:15.566: INFO: Created: latency-svc-bxsjn
  May 18 12:45:15.604: INFO: Got endpoints: latency-svc-gwqdl [750.4433ms]
  May 18 12:45:15.617: INFO: Created: latency-svc-plkms
  May 18 12:45:15.653: INFO: Got endpoints: latency-svc-hmwt5 [749.374311ms]
  May 18 12:45:15.666: INFO: Created: latency-svc-fv8r5
  May 18 12:45:15.703: INFO: Got endpoints: latency-svc-rg5xv [748.96544ms]
  May 18 12:45:15.714: INFO: Created: latency-svc-xpgct
  May 18 12:45:15.753: INFO: Got endpoints: latency-svc-tqdfq [750.342372ms]
  May 18 12:45:15.765: INFO: Created: latency-svc-r7zgd
  May 18 12:45:15.802: INFO: Got endpoints: latency-svc-wwlrf [750.04146ms]
  May 18 12:45:15.816: INFO: Created: latency-svc-4jt8q
  May 18 12:45:15.853: INFO: Got endpoints: latency-svc-fhgxj [749.082205ms]
  May 18 12:45:15.862: INFO: Created: latency-svc-tvhsl
  May 18 12:45:15.902: INFO: Got endpoints: latency-svc-9nc58 [748.564373ms]
  May 18 12:45:15.914: INFO: Created: latency-svc-dwqv2
  May 18 12:45:15.953: INFO: Got endpoints: latency-svc-l6xsk [749.675721ms]
  May 18 12:45:16.004: INFO: Got endpoints: latency-svc-c52kq [751.64041ms]
  May 18 12:45:16.055: INFO: Got endpoints: latency-svc-n29bm [750.904483ms]
  May 18 12:45:16.103: INFO: Got endpoints: latency-svc-mxzwk [749.857147ms]
  May 18 12:45:16.166: INFO: Got endpoints: latency-svc-czvcw [762.642715ms]
  E0518 12:45:16.175188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:16.205: INFO: Got endpoints: latency-svc-glb9p [751.473128ms]
  May 18 12:45:16.254: INFO: Got endpoints: latency-svc-926rj [750.066277ms]
  May 18 12:45:16.302: INFO: Got endpoints: latency-svc-bxsjn [747.905596ms]
  May 18 12:45:16.354: INFO: Got endpoints: latency-svc-plkms [750.337073ms]
  May 18 12:45:16.402: INFO: Got endpoints: latency-svc-fv8r5 [749.671741ms]
  May 18 12:45:16.452: INFO: Got endpoints: latency-svc-xpgct [748.985056ms]
  May 18 12:45:16.502: INFO: Got endpoints: latency-svc-r7zgd [749.553018ms]
  May 18 12:45:16.554: INFO: Got endpoints: latency-svc-4jt8q [751.00817ms]
  May 18 12:45:16.603: INFO: Got endpoints: latency-svc-tvhsl [749.730458ms]
  May 18 12:45:16.653: INFO: Got endpoints: latency-svc-dwqv2 [750.982005ms]
  May 18 12:45:16.653: INFO: Latencies: [17.588093ms 29.18202ms 36.743598ms 46.50144ms 58.619565ms 62.859205ms 72.252093ms 86.1369ms 91.786936ms 101.041337ms 109.552897ms 121.097343ms 132.645636ms 133.985126ms 134.282919ms 135.80036ms 135.973483ms 136.584642ms 136.597424ms 137.007572ms 137.795885ms 143.554329ms 145.007929ms 148.744267ms 148.970139ms 149.535823ms 149.567845ms 150.368638ms 150.56611ms 151.199096ms 151.315116ms 154.584338ms 155.982029ms 157.68934ms 158.975008ms 160.514867ms 167.388439ms 214.876204ms 255.090414ms 295.467748ms 336.94514ms 373.544892ms 418.619837ms 452.358177ms 498.620508ms 539.21656ms 579.641282ms 622.446857ms 662.441621ms 703.997707ms 740.16431ms 743.380025ms 744.634055ms 745.020301ms 745.986241ms 746.240064ms 746.312173ms 746.749227ms 747.25966ms 747.461517ms 747.56377ms 747.574922ms 747.812367ms 747.905596ms 747.91023ms 747.949694ms 748.072325ms 748.111699ms 748.147997ms 748.240323ms 748.247843ms 748.249783ms 748.353172ms 748.394556ms 748.52336ms 748.564373ms 748.71343ms 748.774107ms 748.792545ms 748.809259ms 748.82513ms 748.826531ms 748.96544ms 748.973426ms 748.980221ms 748.985056ms 749.006468ms 749.013851ms 749.026429ms 749.026832ms 749.052663ms 749.082205ms 749.12047ms 749.132949ms 749.158515ms 749.171364ms 749.186131ms 749.188555ms 749.223221ms 749.336585ms 749.34082ms 749.370535ms 749.372854ms 749.374311ms 749.381758ms 749.434598ms 749.511323ms 749.553018ms 749.590619ms 749.607204ms 749.671741ms 749.675721ms 749.686044ms 749.703148ms 749.729144ms 749.730458ms 749.750385ms 749.78782ms 749.791019ms 749.83148ms 749.84506ms 749.857147ms 749.956748ms 749.96388ms 749.994041ms 749.998526ms 750.04146ms 750.066277ms 750.082946ms 750.104186ms 750.14984ms 750.179455ms 750.228956ms 750.230678ms 750.232818ms 750.241632ms 750.291591ms 750.337073ms 750.342372ms 750.348271ms 750.351715ms 750.393203ms 750.393581ms 750.41754ms 750.428906ms 750.434854ms 750.4433ms 750.443488ms 750.487541ms 750.505825ms 750.592928ms 750.598956ms 750.677092ms 750.701613ms 750.702941ms 750.71208ms 750.792574ms 750.812557ms 750.847611ms 750.868306ms 750.904483ms 750.982005ms 751.00817ms 751.019005ms 751.046421ms 751.047219ms 751.047702ms 751.094668ms 751.175622ms 751.185131ms 751.220986ms 751.323114ms 751.382099ms 751.389166ms 751.42389ms 751.427516ms 751.473128ms 751.64041ms 751.643013ms 751.683316ms 751.729406ms 751.750437ms 751.856068ms 751.884859ms 751.910023ms 752.053392ms 752.145216ms 752.149429ms 752.18821ms 752.20702ms 752.239752ms 752.278772ms 752.321738ms 752.385533ms 752.455557ms 753.114963ms 753.519683ms 754.074131ms 754.865707ms 762.642715ms]
  May 18 12:45:16.653: INFO: 50 %ile: 749.34082ms
  May 18 12:45:16.653: INFO: 90 %ile: 751.729406ms
  May 18 12:45:16.653: INFO: 99 %ile: 754.865707ms
  May 18 12:45:16.653: INFO: Total sample count: 200
  May 18 12:45:16.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-3330" for this suite. @ 05/18/24 12:45:16.659
• [10.818 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 05/18/24 12:45:16.668
  May 18 12:45:16.668: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:45:16.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:16.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:16.687
  May 18 12:45:16.732: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8536" for this suite. @ 05/18/24 12:45:16.735
• [0.075 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/18/24 12:45:16.742
  May 18 12:45:16.742: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/18/24 12:45:16.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:16.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:16.809
  May 18 12:45:16.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:45:17.175730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:17.354: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9333" for this suite. @ 05/18/24 12:45:17.36
• [0.627 seconds]
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 05/18/24 12:45:17.369
  May 18 12:45:17.369: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename proxy @ 05/18/24 12:45:17.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:17.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:17.387
  May 18 12:45:17.390: INFO: Creating pod...
  E0518 12:45:18.176789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:19.177811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:19.410: INFO: Creating service...
  May 18 12:45:19.426: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=DELETE
  May 18 12:45:19.434: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 18 12:45:19.434: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=OPTIONS
  May 18 12:45:19.440: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 18 12:45:19.440: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=PATCH
  May 18 12:45:19.445: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 18 12:45:19.445: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=POST
  May 18 12:45:19.450: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 18 12:45:19.450: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=PUT
  May 18 12:45:19.454: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 18 12:45:19.454: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=DELETE
  May 18 12:45:19.460: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  May 18 12:45:19.460: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=OPTIONS
  May 18 12:45:19.466: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  May 18 12:45:19.466: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=PATCH
  May 18 12:45:19.473: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  May 18 12:45:19.473: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=POST
  May 18 12:45:19.479: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  May 18 12:45:19.479: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=PUT
  May 18 12:45:19.487: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  May 18 12:45:19.487: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=GET
  May 18 12:45:19.490: INFO: http.Client request:GET StatusCode:301
  May 18 12:45:19.490: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=GET
  May 18 12:45:19.496: INFO: http.Client request:GET StatusCode:301
  May 18 12:45:19.496: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/pods/agnhost/proxy?method=HEAD
  May 18 12:45:19.499: INFO: http.Client request:HEAD StatusCode:301
  May 18 12:45:19.499: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5968/services/e2e-proxy-test-service/proxy?method=HEAD
  May 18 12:45:19.504: INFO: http.Client request:HEAD StatusCode:301
  May 18 12:45:19.504: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5968" for this suite. @ 05/18/24 12:45:19.508
• [2.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 05/18/24 12:45:19.516
  May 18 12:45:19.516: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:45:19.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:19.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:19.538
  May 18 12:45:19.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9172 version'
  May 18 12:45:19.578: INFO: stderr: ""
  May 18 12:45:19.578: INFO: stdout: "Client Version: v1.29.5\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.5\n"
  May 18 12:45:19.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9172" for this suite. @ 05/18/24 12:45:19.582
• [0.074 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 05/18/24 12:45:19.59
  May 18 12:45:19.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 12:45:19.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:45:19.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:45:19.608
  STEP: Creating pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955 @ 05/18/24 12:45:19.611
  E0518 12:45:20.178010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:21.178102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 12:45:21.631
  May 18 12:45:21.635: INFO: Initial restart count of pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is 0
  May 18 12:45:21.639: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:22.178733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:23.179180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:23.644: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:24.179873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:25.179956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:25.649: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:26.179977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:27.180265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:27.653: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:28.180463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:29.180567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:29.658: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:30.181074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:31.181246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:31.663: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:32.182233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:33.182270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:33.668: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:34.183007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:35.183192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:35.673: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:36.183407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:37.183540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:37.678: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:38.184242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:39.184331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:39.685: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:40.184548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:41.185600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:41.690: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  May 18 12:45:41.690: INFO: Restart count of pod container-probe-7955/liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is now 1 (20.05483629s elapsed)
  E0518 12:45:42.185711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:43.185970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:43.695: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:44.186744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:45.186824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:45.700: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:46.187632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:47.188010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:47.705: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:48.188249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:49.189151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:49.712: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:50.190119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:51.191162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:51.717: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:52.191302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:53.191658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:53.723: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:54.192233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:55.192354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:55.729: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:56.192495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:57.193333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:57.735: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:45:58.193784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:45:59.193903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:45:59.741: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:00.194727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:01.194829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:01.745: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  May 18 12:46:01.745: INFO: Restart count of pod container-probe-7955/liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is now 2 (40.110536213s elapsed)
  E0518 12:46:02.195427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:03.195503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:03.752: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:04.196251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:05.196345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:05.757: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:06.197092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:07.197387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:07.763: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:08.198076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:09.199174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:09.769: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:10.200240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:11.200341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:11.775: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:12.200431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:13.200814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:13.779: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:14.201389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:15.201901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:15.785: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:16.202859      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:17.203934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:17.790: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:18.204841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:19.204956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:19.795: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:20.205053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:21.205207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:21.802: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  May 18 12:46:21.802: INFO: Restart count of pod container-probe-7955/liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is now 3 (1m0.166897357s elapsed)
  E0518 12:46:22.205323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:23.205426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:23.808: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:24.205980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:25.206074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:25.814: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:26.206539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:27.207473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:27.818: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:28.208228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:29.208988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:29.825: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:30.209919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:31.210263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:31.830: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:32.211261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:33.212241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:33.837: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:34.212523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:35.212588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:35.842: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:36.212691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:37.213412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:37.848: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:38.214346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:39.214439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:39.854: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:40.214513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:41.214670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:41.859: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  May 18 12:46:41.859: INFO: Restart count of pod container-probe-7955/liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is now 4 (1m20.223993709s elapsed)
  E0518 12:46:42.214724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:43.214843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:43.864: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:44.215762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:45.216540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:45.869: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:46.217421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:47.217875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:47.875: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:48.218220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:49.218420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:49.881: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:50.218534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:51.218640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:51.886: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:52.219400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:53.220225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:53.891: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:54.221103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:55.221290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:55.897: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:56.221514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:57.222439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:57.902: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:46:58.222545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:46:59.223343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:46:59.909: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:00.223798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:01.223902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:01.914: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:02.224531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:03.224848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:03.920: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:04.225440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:05.225525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:05.925: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:06.226465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:07.227468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:07.931: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:08.228498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:09.228596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:09.937: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:10.229475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:11.229651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:11.942: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:12.229701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:13.229748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:13.948: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:14.230634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:15.231064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:15.954: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:16.231231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:17.231541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:17.959: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:18.232394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:19.232587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:19.965: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:20.232668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:21.232847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:21.970: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:22.233536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:23.233645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:23.975: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:24.234720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:25.234900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:25.980: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:26.235615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:27.236486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:27.985: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:28.237186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:29.237284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:29.991: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:30.237904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:31.238580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:31.997: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:32.239423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:33.240240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:34.003: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:34.240553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:35.240783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:36.008: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:36.241643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:37.241853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:38.014: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:38.242712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:39.242887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:40.019: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  E0518 12:47:40.243157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:41.244233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:42.024: INFO: Get pod liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b in namespace container-probe-7955
  May 18 12:47:42.024: INFO: Restart count of pod container-probe-7955/liveness-69f2663a-7058-4ba2-bff7-a68795f65c2b is now 5 (2m20.389376737s elapsed)
  STEP: deleting the pod @ 05/18/24 12:47:42.024
  May 18 12:47:42.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7955" for this suite. @ 05/18/24 12:47:42.044
• [142.461 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/18/24 12:47:42.051
  May 18 12:47:42.051: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename init-container @ 05/18/24 12:47:42.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:47:42.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:47:42.076
  STEP: creating the pod @ 05/18/24 12:47:42.078
  May 18 12:47:42.079: INFO: PodSpec: initContainers in spec.initContainers
  E0518 12:47:42.244351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:43.244457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:44.244621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:45.244773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:45.695: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7593" for this suite. @ 05/18/24 12:47:45.7
• [3.656 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/18/24 12:47:45.708
  May 18 12:47:45.708: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 12:47:45.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:47:45.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:47:45.725
  STEP: creating a Deployment @ 05/18/24 12:47:45.733
  STEP: waiting for Deployment to be created @ 05/18/24 12:47:45.74
  STEP: waiting for all Replicas to be Ready @ 05/18/24 12:47:45.742
  May 18 12:47:45.743: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.744: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.753: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.753: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.772: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.772: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.805: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  May 18 12:47:45.805: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0518 12:47:46.245391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:46.545: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May 18 12:47:46.545: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  May 18 12:47:47.059: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/18/24 12:47:47.059
  May 18 12:47:47.068: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/18/24 12:47:47.069
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.070: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 0
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.071: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.087: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.087: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.120: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.120: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:47.136: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:47.136: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:47.142: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:47.142: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  E0518 12:47:47.246139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:48.246287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:48.557: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:48.557: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:48.582: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  STEP: listing Deployments @ 05/18/24 12:47:48.582
  May 18 12:47:48.586: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/18/24 12:47:48.586
  May 18 12:47:48.597: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/18/24 12:47:48.597
  May 18 12:47:48.608: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:48.616: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:48.635: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:48.650: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:48.662: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0518 12:47:49.246735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:50.080: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:50.105: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:50.117: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  May 18 12:47:50.126: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0518 12:47:50.247426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:51.247548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:51.567: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/18/24 12:47:51.593
  STEP: fetching the DeploymentStatus @ 05/18/24 12:47:51.601
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 1
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 2
  May 18 12:47:51.610: INFO: observed Deployment test-deployment in namespace deployment-5407 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/18/24 12:47:51.61
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.622: INFO: observed event type MODIFIED
  May 18 12:47:51.626: INFO: Log out all the ReplicaSets if there is no deployment created
  May 18 12:47:51.630: INFO: ReplicaSet "test-deployment-64fd565c98":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-64fd565c98",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d44e87fd-d703-4f0d-85ca-1648b37db5f4",
      ResourceVersion: (string) (len=5) "25775",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633267,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "801d8872-ec5c-4c23-8454-dd2555b9e5e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 38 30 31 64  38 38 37 32 2d 65 63 35  |":\"801d8872-ec5|
              00000130  63 2d 34 63 32 33 2d 38  34 35 34 2d 64 64 32 35  |c-4c23-8454-dd25|
              00000140  35 35 62 39 65 35 65 30  5c 22 7d 22 3a 7b 7d 7d  |55b9e5e0\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  May 18 12:47:51.639: INFO: pod: "test-deployment-64fd565c98-cnrhd":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-64fd565c98-cnrhd",
      GenerateName: (string) (len=27) "test-deployment-64fd565c98-",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "96db71cf-da3a-4128-9c76-b0983e162a63",
      ResourceVersion: (string) (len=5) "25771",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633267,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633273,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-64fd565c98",
          UID: (types.UID) (len=36) "d44e87fd-d703-4f0d-85ca-1648b37db5f4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633267,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 34 34 65 38 37 66 64  |uid\":\"d44e87fd|
              000000a0  2d 64 37 30 33 2d 34 66  30 64 2d 38 35 63 61 2d  |-d703-4f0d-85ca-|
              000000b0  31 36 34 38 62 33 37 64  62 35 66 34 5c 22 7d 22  |1648b37db5f4\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 33 34 5c 22 7d  |2.168.225.234\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qpjdj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qpjdj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633267,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633267,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.234",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.234"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633267,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633267,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=77) "containerd://9b4e51a62fc3ba40cc2fc7c8e96503d190f2dfb21efe199e5805c18880a93ec5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  May 18 12:47:51.641: INFO: pod: "test-deployment-64fd565c98-v52rh":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-64fd565c98-v52rh",
      GenerateName: (string) (len=27) "test-deployment-64fd565c98-",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a222adb-c9e1-491d-95e8-1652e6388f71",
      ResourceVersion: (string) (len=5) "25764",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633272,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-64fd565c98",
          UID: (types.UID) (len=36) "d44e87fd-d703-4f0d-85ca-1648b37db5f4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 34 34 65 38 37 66 64  |uid\":\"d44e87fd|
              000000a0  2d 64 37 30 33 2d 34 66  30 64 2d 38 35 63 61 2d  |-d703-4f0d-85ca-|
              000000b0  31 36 34 38 62 33 37 64  62 35 66 34 5c 22 7d 22  |1648b37db5f4\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=621) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 72 65 61 73 6f 6e  |me":{},"f:reason|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000090  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000000a0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 49  |"k:{\"type\":\"I|
              000000b0  6e 69 74 69 61 6c 69 7a  65 64 5c 22 7d 22 3a 7b  |nitialized\"}":{|
              000000c0  22 2e 22 3a 7b 7d 2c 22  66 3a 6c 61 73 74 50 72  |".":{},"f:lastPr|
              000000d0  6f 62 65 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |obeTime":{},"f:l|
              000000e0  61 73 74 54 72 61 6e 73  69 74 69 6f 6e 54 69 6d  |astTransitionTim|
              000000f0  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000100  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000110  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              00000120  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 50 6f  |k:{\"type\":\"Po|
              00000130  64 52 65 61 64 79 54 6f  53 74 61 72 74 43 6f 6e  |dReadyToStartCon|
              00000140  74 61 69 6e 65 72 73 5c  22 7d 22 3a 7b 22 2e 22  |tainers\"}":{"."|
              00000150  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000160  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000170  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000180  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000190  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 2c 22 6b  |,"f:type":{}},"k|
              000001a0  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 52 65 61  |:{\"type\":\"Rea|
              000001b0  64 79 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |dy\"}":{".":{},"|
              000001c0  66 3a 6c 61 73 74 50 72  6f 62 65 54 69 6d 65 22  |f:lastProbeTime"|
              000001d0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 54 72 61 6e 73  |:{},"f:lastTrans|
              000001e0  69 74 69 6f 6e 54 69 6d  65 22 3a 7b 7d 2c 22 66  |itionTime":{},"f|
              000001f0  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000200  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000210  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000220  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000230  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000240  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000250  3a 70 68 61 73 65 22 3a  7b 7d 2c 22 66 3a 73 74  |:phase":{},"f:st|
              00000260  61 72 74 54 69 6d 65 22  3a 7b 7d 7d 7d           |artTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w4knk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w4knk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=9) "Succeeded",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)({
              ExitCode: (int32) 0,
              Signal: (int32) 0,
              Reason: (string) (len=9) "Completed",
              Message: (string) "",
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633269,
                  loc: (*time.Location)(<already shown>)
                }
              },
              FinishedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633271,
                  loc: (*time.Location)(<already shown>)
                }
              },
              ContainerID: (string) (len=77) "containerd://401bcb8df18099ec189e4364d3f6890004a7ddb5722bc42c3a78b8a91d398a46"
            })
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=77) "containerd://401bcb8df18099ec189e4364d3f6890004a7ddb5722bc42c3a78b8a91d398a46",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  May 18 12:47:51.642: INFO: ReplicaSet "test-deployment-79ff746c4":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-79ff746c4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dcd84977-25b5-4da9-99b6-c71b7728a996",
      ResourceVersion: (string) (len=5) "25767",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "801d8872-ec5c-4c23-8454-dd2555b9e5e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 38 30 31 64  38 38 37 32 2d 65 63 35  |":\"801d8872-ec5|
              00000130  63 2d 34 63 32 33 2d 38  34 35 34 2d 64 64 32 35  |c-4c23-8454-dd25|
              00000140  35 35 62 39 65 35 65 30  5c 22 7d 22 3a 7b 7d 7d  |55b9e5e0\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  May 18 12:47:51.646: INFO: pod: "test-deployment-79ff746c4-42zvr":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-42zvr",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9fd55c31-51d7-4ee1-87bb-97d0cb6e75b7",
      ResourceVersion: (string) (len=5) "25714",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "dcd84977-25b5-4da9-99b6-c71b7728a996",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 63 64 38 34 39 37 37  |uid\":\"dcd84977|
              000000a0  2d 32 35 62 35 2d 34 64  61 39 2d 39 39 62 36 2d  |-25b5-4da9-99b6-|
              000000b0  63 37 31 62 37 37 32 38  61 39 39 36 5c 22 7d 22  |c71b7728a996\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 30  39 2e 36 36 5c 22 7d 22  |2.168.209.66\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dp4k2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dp4k2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.70.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.70.23"
        }
      },
      PodIP: (string) (len=14) "192.168.209.66",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.209.66"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633268,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633269,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c95031e071df2c829f375d4a35f9d15f49951387b109ef7cd0dfcb0415ebc671",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  May 18 12:47:51.649: INFO: pod: "test-deployment-79ff746c4-jnhbb":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-jnhbb",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "61f3da72-3ab2-405c-808a-3f0f71f2d9e9",
      ResourceVersion: (string) (len=5) "25766",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633270,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "dcd84977-25b5-4da9-99b6-c71b7728a996",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 63 64 38 34 39 37 37  |uid\":\"dcd84977|
              000000a0  2d 32 35 62 35 2d 34 64  61 39 2d 39 39 62 36 2d  |-25b5-4da9-99b6-|
              000000b0  63 37 31 62 37 37 32 38  61 39 39 36 5c 22 7d 22  |c71b7728a996\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 32 33 5c 22 7d  |2.168.225.223\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g9n2h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g9n2h",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633271,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633270,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.223",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.223"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633270,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851633270,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b18dd584624e45a81b815ab9de857110b85d48e47d8abcfcd0cd675c21786279",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  May 18 12:47:51.650: INFO: ReplicaSet "test-deployment-7fcc79b8c7":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-7fcc79b8c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5407",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "23f456fd-bf6d-4336-9013-fc8718e69ab5",
      ResourceVersion: (string) (len=5) "25666",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851633265,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "801d8872-ec5c-4c23-8454-dd2555b9e5e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 38 30 31 64  38 38 37 32 2d 65 63 35  |":\"801d8872-ec5|
              00000130  63 2d 34 63 32 33 2d 38  34 35 34 2d 64 64 32 35  |c-4c23-8454-dd25|
              00000140  35 35 62 39 65 35 65 30  5c 22 7d 22 3a 7b 7d 7d  |55b9e5e0\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851633268,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=22) "test-deployment-static": (string) (len=4) "true",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  May 18 12:47:51.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5407" for this suite. @ 05/18/24 12:47:51.659
• [5.958 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 05/18/24 12:47:51.665
  May 18 12:47:51.665: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/18/24 12:47:51.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:47:51.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:47:51.683
  STEP: create the container to handle the HTTPGet hook request. @ 05/18/24 12:47:51.69
  E0518 12:47:52.248253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:53.248335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/18/24 12:47:53.715
  E0518 12:47:54.248450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:55.248519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/18/24 12:47:55.737
  STEP: delete the pod with lifecycle hook @ 05/18/24 12:47:55.751
  E0518 12:47:56.248829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:57.249492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:47:57.770: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5617" for this suite. @ 05/18/24 12:47:57.774
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/18/24 12:47:57.784
  May 18 12:47:57.784: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:47:57.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:47:57.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:47:57.804
  STEP: Creating secret with name secret-test-map-bb7f7841-8188-495f-a448-93be67662c83 @ 05/18/24 12:47:57.808
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:47:57.813
  E0518 12:47:58.249695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:47:59.249721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:00.250544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:01.250625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:48:01.839
  May 18 12:48:01.843: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-secrets-45ffb154-2d3b-4d90-9d52-9fce83b5b6d2 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:48:01.859
  May 18 12:48:01.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2442" for this suite. @ 05/18/24 12:48:01.883
• [4.108 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 05/18/24 12:48:01.892
  May 18 12:48:01.892: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 12:48:01.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:01.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:01.91
  STEP: creating a Namespace @ 05/18/24 12:48:01.913
  STEP: patching the Namespace @ 05/18/24 12:48:01.931
  STEP: get the Namespace and ensuring it has the label @ 05/18/24 12:48:01.936
  May 18 12:48:01.940: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-262" for this suite. @ 05/18/24 12:48:01.944
  STEP: Destroying namespace "nspatchtest-926090fe-b233-4245-8585-a91f078c0182-8260" for this suite. @ 05/18/24 12:48:01.951
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 05/18/24 12:48:01.961
  May 18 12:48:01.961: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:48:01.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:01.976
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:01.981
  STEP: Creating the pod @ 05/18/24 12:48:01.987
  E0518 12:48:02.251013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:03.251178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:04.251860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:04.531: INFO: Successfully updated pod "annotationupdate92119291-8a1f-4f72-821d-b4b12d87c6db"
  E0518 12:48:05.252710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:06.252832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:07.253861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:08.254283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:08.556: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3704" for this suite. @ 05/18/24 12:48:08.561
• [6.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 05/18/24 12:48:08.569
  May 18 12:48:08.569: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 12:48:08.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:08.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:08.592
  May 18 12:48:08.596: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:48:09.254450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/18/24 12:48:09.947
  May 18 12:48:09.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4115 --namespace=crd-publish-openapi-4115 create -f -'
  May 18 12:48:10.013: INFO: stderr: ""
  May 18 12:48:10.013: INFO: stdout: "e2e-test-crd-publish-openapi-5197-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May 18 12:48:10.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4115 --namespace=crd-publish-openapi-4115 delete e2e-test-crd-publish-openapi-5197-crds test-cr'
  May 18 12:48:10.071: INFO: stderr: ""
  May 18 12:48:10.071: INFO: stdout: "e2e-test-crd-publish-openapi-5197-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  May 18 12:48:10.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4115 --namespace=crd-publish-openapi-4115 apply -f -'
  May 18 12:48:10.125: INFO: stderr: ""
  May 18 12:48:10.125: INFO: stdout: "e2e-test-crd-publish-openapi-5197-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  May 18 12:48:10.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4115 --namespace=crd-publish-openapi-4115 delete e2e-test-crd-publish-openapi-5197-crds test-cr'
  May 18 12:48:10.175: INFO: stderr: ""
  May 18 12:48:10.175: INFO: stdout: "e2e-test-crd-publish-openapi-5197-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/18/24 12:48:10.175
  May 18 12:48:10.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-4115 explain e2e-test-crd-publish-openapi-5197-crds'
  May 18 12:48:10.213: INFO: stderr: ""
  May 18 12:48:10.213: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-5197-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0518 12:48:10.255212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:11.255411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:11.479: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4115" for this suite. @ 05/18/24 12:48:11.486
• [2.924 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 05/18/24 12:48:11.493
  May 18 12:48:11.493: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 12:48:11.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:11.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:11.514
  STEP: Creating a pod to test env composition @ 05/18/24 12:48:11.517
  E0518 12:48:12.255549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:13.255627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:14.256237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:15.256319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:48:15.54
  May 18 12:48:15.543: INFO: Trying to get logs from node ip-172-31-33-93 pod var-expansion-d69cd9f2-4217-4f48-8174-cfe79bd12822 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 12:48:15.556
  May 18 12:48:15.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8762" for this suite. @ 05/18/24 12:48:15.576
• [4.088 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 05/18/24 12:48:15.582
  May 18 12:48:15.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:48:15.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:15.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:15.601
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/18/24 12:48:15.604
  E0518 12:48:16.256427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:17.256875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:18.257529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:19.257714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:48:19.626
  May 18 12:48:19.630: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-613958b4-bb46-4506-8cb1-598edba23813 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:48:19.638
  May 18 12:48:19.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2063" for this suite. @ 05/18/24 12:48:19.659
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 05/18/24 12:48:19.665
  May 18 12:48:19.665: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:48:19.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:19.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:19.685
  STEP: Setting up server cert @ 05/18/24 12:48:19.708
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:48:19.953
  STEP: Deploying the webhook pod @ 05/18/24 12:48:19.961
  STEP: Wait for the deployment to be ready @ 05/18/24 12:48:19.972
  May 18 12:48:19.979: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0518 12:48:20.258672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:21.258764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:48:21.99
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:48:22.002
  E0518 12:48:22.259021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:23.002: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/18/24 12:48:23.01
  STEP: create a namespace for the webhook @ 05/18/24 12:48:23.024
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/18/24 12:48:23.04
  May 18 12:48:23.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-274" for this suite. @ 05/18/24 12:48:23.118
  STEP: Destroying namespace "webhook-markers-8063" for this suite. @ 05/18/24 12:48:23.124
  STEP: Destroying namespace "fail-closed-namespace-328" for this suite. @ 05/18/24 12:48:23.132
• [3.475 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 05/18/24 12:48:23.141
  May 18 12:48:23.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 12:48:23.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:23.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:23.161
  STEP: create the deployment @ 05/18/24 12:48:23.164
  W0518 12:48:23.170025      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/18/24 12:48:23.17
  E0518 12:48:23.259502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 05/18/24 12:48:23.676
  STEP: wait for all rs to be garbage collected @ 05/18/24 12:48:23.682
  STEP: expected 0 rs, got 1 rs @ 05/18/24 12:48:23.688
  STEP: expected 0 pods, got 2 pods @ 05/18/24 12:48:23.695
  STEP: Gathering metrics @ 05/18/24 12:48:24.194
  W0518 12:48:24.200986      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 12:48:24.201: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 12:48:24.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8063" for this suite. @ 05/18/24 12:48:24.205
• [1.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 05/18/24 12:48:24.214
  May 18 12:48:24.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 12:48:24.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:24.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:24.239
  STEP: Creating a ResourceQuota with terminating scope @ 05/18/24 12:48:24.242
  STEP: Ensuring ResourceQuota status is calculated @ 05/18/24 12:48:24.247
  E0518 12:48:24.264959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:25.265066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/18/24 12:48:26.251
  STEP: Ensuring ResourceQuota status is calculated @ 05/18/24 12:48:26.257
  E0518 12:48:26.265280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:27.266025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/18/24 12:48:28.262
  E0518 12:48:28.266639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/18/24 12:48:28.273
  E0518 12:48:29.267193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:30.267303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/18/24 12:48:30.278
  E0518 12:48:31.268284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:32.268348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/18/24 12:48:32.282
  STEP: Ensuring resource quota status released the pod usage @ 05/18/24 12:48:32.297
  E0518 12:48:33.269395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:34.269914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/18/24 12:48:34.301
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/18/24 12:48:34.316
  E0518 12:48:35.270242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:36.270362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/18/24 12:48:36.321
  E0518 12:48:37.271420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:38.271531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/18/24 12:48:38.326
  STEP: Ensuring resource quota status released the pod usage @ 05/18/24 12:48:38.341
  E0518 12:48:39.272261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:40.272800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:40.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-429" for this suite. @ 05/18/24 12:48:40.351
• [16.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 05/18/24 12:48:40.359
  May 18 12:48:40.359: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 12:48:40.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:40.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:40.379
  STEP: Creating configMap with name configmap-test-volume-56d87bfb-1dc6-41d0-9f9d-13d6adc4aa58 @ 05/18/24 12:48:40.382
  STEP: Creating a pod to test consume configMaps @ 05/18/24 12:48:40.387
  E0518 12:48:41.272914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:42.273006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:43.273092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:44.273336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:48:44.409
  May 18 12:48:44.413: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-c39e71e5-96c9-435e-9ef0-e359fd155c86 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:48:44.42
  May 18 12:48:44.436: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-836" for this suite. @ 05/18/24 12:48:44.44
• [4.089 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 05/18/24 12:48:44.449
  May 18 12:48:44.449: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:48:44.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:44.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:44.551
  STEP: Starting the proxy @ 05/18/24 12:48:44.554
  May 18 12:48:44.554: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6398 proxy --unix-socket=/tmp/kubectl-proxy-unix620993148/test'
  STEP: retrieving proxy /api/ output @ 05/18/24 12:48:44.582
  May 18 12:48:44.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6398" for this suite. @ 05/18/24 12:48:44.588
• [0.146 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 05/18/24 12:48:44.595
  May 18 12:48:44.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/18/24 12:48:44.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:44.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:44.616
  STEP: create the container to handle the HTTPGet hook request. @ 05/18/24 12:48:44.621
  E0518 12:48:45.273813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:46.274053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/18/24 12:48:46.642
  E0518 12:48:47.274864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:48.275007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/18/24 12:48:48.659
  E0518 12:48:49.276035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:50.276300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/18/24 12:48:50.674
  May 18 12:48:50.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1444" for this suite. @ 05/18/24 12:48:50.688
• [6.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 05/18/24 12:48:50.695
  May 18 12:48:50.695: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-webhook @ 05/18/24 12:48:50.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:50.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:50.713
  STEP: Setting up server cert @ 05/18/24 12:48:50.715
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/18/24 12:48:50.916
  STEP: Deploying the custom resource conversion webhook pod @ 05/18/24 12:48:50.924
  STEP: Wait for the deployment to be ready @ 05/18/24 12:48:50.936
  May 18 12:48:50.943: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0518 12:48:51.276759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:52.276868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:48:52.953
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:48:52.963
  E0518 12:48:53.276951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:53.965: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  May 18 12:48:53.972: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 12:48:54.277151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:55.278146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:56.278987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/18/24 12:48:56.534
  STEP: v2 custom resource should be converted @ 05/18/24 12:48:56.54
  May 18 12:48:57.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-8201" for this suite. @ 05/18/24 12:48:57.101
• [6.413 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 05/18/24 12:48:57.109
  May 18 12:48:57.109: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 12:48:57.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:48:57.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:48:57.128
  STEP: Creating the pod @ 05/18/24 12:48:57.131
  E0518 12:48:57.279906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:58.280003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:48:59.280974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:48:59.670: INFO: Successfully updated pod "annotationupdate0cd2834e-fa10-44c4-a423-852486fc1974"
  E0518 12:49:00.281943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:01.282059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:02.282141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:03.282417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:03.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9527" for this suite. @ 05/18/24 12:49:03.697
• [6.596 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/18/24 12:49:03.705
  May 18 12:49:03.705: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 12:49:03.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:03.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:03.724
  STEP: Creating secret with name secret-test-4a719a17-d2df-4cd2-9a22-231e26e8a869 @ 05/18/24 12:49:03.727
  STEP: Creating a pod to test consume secrets @ 05/18/24 12:49:03.734
  E0518 12:49:04.282477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:05.282554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:06.283318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:07.284173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:49:07.755
  May 18 12:49:07.759: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-secrets-0db7a243-8f61-4a34-b410-2e48d2fe839d container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 12:49:07.764
  May 18 12:49:07.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-714" for this suite. @ 05/18/24 12:49:07.782
• [4.084 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 05/18/24 12:49:07.788
  May 18 12:49:07.788: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl-logs @ 05/18/24 12:49:07.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:07.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:07.809
  STEP: creating an pod @ 05/18/24 12:49:07.813
  May 18 12:49:07.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  May 18 12:49:07.862: INFO: stderr: ""
  May 18 12:49:07.862: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/18/24 12:49:07.862
  May 18 12:49:07.862: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0518 12:49:08.284495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:09.285372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:09.870: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/18/24 12:49:09.87
  May 18 12:49:09.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator'
  May 18 12:49:09.917: INFO: stderr: ""
  May 18 12:49:09.917: INFO: stdout: "I0518 12:49:08.418731       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/rs84 461\nI0518 12:49:08.618814       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/xpk8 215\nI0518 12:49:08.819396       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/cdxp 257\nI0518 12:49:09.019684       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/v7v 332\nI0518 12:49:09.218910       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/l9pc 216\nI0518 12:49:09.419207       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/pgd5 394\nI0518 12:49:09.619498       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/qrns 243\nI0518 12:49:09.819787       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/vw2f 579\n"
  STEP: limiting log lines @ 05/18/24 12:49:09.917
  May 18 12:49:09.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator --tail=1'
  May 18 12:49:09.966: INFO: stderr: ""
  May 18 12:49:09.966: INFO: stdout: "I0518 12:49:09.819787       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/vw2f 579\n"
  May 18 12:49:09.966: INFO: got output "I0518 12:49:09.819787       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/vw2f 579\n"
  STEP: limiting log bytes @ 05/18/24 12:49:09.966
  May 18 12:49:09.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator --limit-bytes=1'
  May 18 12:49:10.012: INFO: stderr: ""
  May 18 12:49:10.012: INFO: stdout: "I"
  May 18 12:49:10.012: INFO: got output "I"
  STEP: exposing timestamps @ 05/18/24 12:49:10.012
  May 18 12:49:10.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator --tail=1 --timestamps'
  May 18 12:49:10.059: INFO: stderr: ""
  May 18 12:49:10.059: INFO: stdout: "2024-05-18T12:49:10.018967001Z I0518 12:49:10.018897       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/sfq 422\n"
  May 18 12:49:10.059: INFO: got output "2024-05-18T12:49:10.018967001Z I0518 12:49:10.018897       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/sfq 422\n"
  STEP: restricting to a time range @ 05/18/24 12:49:10.059
  E0518 12:49:10.286052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:11.286157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:12.286260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:12.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator --since=1s'
  May 18 12:49:12.609: INFO: stderr: ""
  May 18 12:49:12.609: INFO: stdout: "I0518 12:49:11.619106       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/nlxq 411\nI0518 12:49:11.819379       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/4zq 459\nI0518 12:49:12.019497       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/n44 278\nI0518 12:49:12.219787       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/h7q 218\nI0518 12:49:12.419105       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/sbd2 381\n"
  May 18 12:49:12.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 logs logs-generator logs-generator --since=24h'
  May 18 12:49:12.658: INFO: stderr: ""
  May 18 12:49:12.658: INFO: stdout: "I0518 12:49:08.418731       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/rs84 461\nI0518 12:49:08.618814       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/xpk8 215\nI0518 12:49:08.819396       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/cdxp 257\nI0518 12:49:09.019684       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/v7v 332\nI0518 12:49:09.218910       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/l9pc 216\nI0518 12:49:09.419207       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/pgd5 394\nI0518 12:49:09.619498       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/qrns 243\nI0518 12:49:09.819787       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/vw2f 579\nI0518 12:49:10.018897       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/sfq 422\nI0518 12:49:10.219088       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/sdlt 587\nI0518 12:49:10.419415       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/dg6 463\nI0518 12:49:10.619703       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/r2zv 386\nI0518 12:49:10.818930       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/j2v 282\nI0518 12:49:11.019220       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/j95 583\nI0518 12:49:11.219491       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/dj5s 392\nI0518 12:49:11.419779       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/jdwf 479\nI0518 12:49:11.619106       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/nlxq 411\nI0518 12:49:11.819379       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/4zq 459\nI0518 12:49:12.019497       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/n44 278\nI0518 12:49:12.219787       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/h7q 218\nI0518 12:49:12.419105       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/sbd2 381\nI0518 12:49:12.619224       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/p7h 225\n"
  May 18 12:49:12.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-logs-9410 delete pod logs-generator'
  May 18 12:49:13.244: INFO: stderr: ""
  May 18 12:49:13.244: INFO: stdout: "pod \"logs-generator\" deleted\n"
  May 18 12:49:13.244: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-9410" for this suite. @ 05/18/24 12:49:13.247
• [5.465 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 05/18/24 12:49:13.254
  May 18 12:49:13.254: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:49:13.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:13.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:13.275
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/18/24 12:49:13.277
  E0518 12:49:13.286982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:14.287324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:15.288319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:16.288444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:17.288678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:49:17.3
  May 18 12:49:17.302: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-fcb1e9d6-b0da-499c-8963-b4859c2f7dd9 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:49:17.31
  May 18 12:49:17.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7139" for this suite. @ 05/18/24 12:49:17.332
• [4.085 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 05/18/24 12:49:17.339
  May 18 12:49:17.339: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 12:49:17.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:17.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:17.358
  STEP: Creating a test headless service @ 05/18/24 12:49:17.361
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_udp@PTR;check="$$(dig +tcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_tcp@PTR;sleep 1; done
   @ 05/18/24 12:49:17.378
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8433.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_udp@PTR;check="$$(dig +tcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_tcp@PTR;sleep 1; done
   @ 05/18/24 12:49:17.378
  STEP: creating a pod to probe DNS @ 05/18/24 12:49:17.378
  STEP: submitting the pod to kubernetes @ 05/18/24 12:49:17.378
  E0518 12:49:18.288880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:19.288957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 12:49:19.4
  STEP: looking for the results for each expected name from probers @ 05/18/24 12:49:19.404
  May 18 12:49:19.411: INFO: Unable to read wheezy_udp@dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.415: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.419: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.424: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.444: INFO: Unable to read jessie_udp@dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.449: INFO: Unable to read jessie_tcp@dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.452: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.456: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local from pod dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618: the server could not find the requested resource (get pods dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618)
  May 18 12:49:19.472: INFO: Lookups using dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618 failed for: [wheezy_udp@dns-test-service.dns-8433.svc.cluster.local wheezy_tcp@dns-test-service.dns-8433.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local jessie_udp@dns-test-service.dns-8433.svc.cluster.local jessie_tcp@dns-test-service.dns-8433.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8433.svc.cluster.local]

  May 18 12:49:19.477: INFO: Pod client logs for webserver: 
  May 18 12:49:19.485: INFO: Pod client logs for querier: 
  May 18 12:49:19.492: INFO: Pod client logs for jessie-querier: 
  E0518 12:49:20.289066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:21.289186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:22.289511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:23.289608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:24.289729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:24.470: INFO: DNS probes using dns-8433/dns-test-0d8fa1ae-562c-421f-b22f-0f465560e618 succeeded

  STEP: deleting the pod @ 05/18/24 12:49:24.47
  STEP: deleting the test service @ 05/18/24 12:49:24.483
  STEP: deleting the test headless service @ 05/18/24 12:49:24.507
  May 18 12:49:24.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8433" for this suite. @ 05/18/24 12:49:24.53
• [7.198 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:447
  STEP: Creating a kubernetes client @ 05/18/24 12:49:24.536
  May 18 12:49:24.536: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-pred @ 05/18/24 12:49:24.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:24.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:24.557
  May 18 12:49:24.560: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 18 12:49:24.568: INFO: Waiting for terminating namespaces to be deleted...
  May 18 12:49:24.572: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-33-93 before test
  May 18 12:49:24.577: INFO: nginx-ingress-controller-kubernetes-worker-fr7mv from ingress-nginx-kubernetes-worker started at 2024-05-18 11:59:30 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.577: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:49:24.577: INFO: calico-node-jt76w from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.577: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:49:24.577: INFO: sonobuoy from sonobuoy started at 2024-05-18 12:05:55 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.577: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 18 12:49:24.577: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-qg8tv from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:49:24.577: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:49:24.577: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:49:24.577: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-70-23 before test
  May 18 12:49:24.582: INFO: nginx-ingress-controller-kubernetes-worker-cwhst from ingress-nginx-kubernetes-worker started at 2024-05-18 12:02:05 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.582: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:49:24.582: INFO: calico-node-8tp4g from kube-system started at 2024-05-18 12:01:55 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.582: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:49:24.582: INFO: sonobuoy-e2e-job-9640b063a5a74f87 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:49:24.582: INFO: 	Container e2e ready: true, restart count 0
  May 18 12:49:24.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:49:24.582: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-hmcm6 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:49:24.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:49:24.582: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 12:49:24.582: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-90-158 before test
  May 18 12:49:24.587: INFO: nginx-ingress-controller-kubernetes-worker-4cg9g from ingress-nginx-kubernetes-worker started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.587: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 12:49:24.587: INFO: calico-node-5dtrz from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.587: INFO: 	Container calico-node ready: true, restart count 0
  May 18 12:49:24.587: INFO: coredns-bddfd76d7-gv2bt from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.587: INFO: 	Container coredns ready: true, restart count 0
  May 18 12:49:24.587: INFO: kube-state-metrics-6f48cdd76-glkfx from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.587: INFO: 	Container kube-state-metrics ready: true, restart count 0
  May 18 12:49:24.587: INFO: metrics-server-v0.6.3-69d7fbfdf8-thw8r from kube-system started at 2024-05-18 11:56:31 +0000 UTC (2 container statuses recorded)
  May 18 12:49:24.587: INFO: 	Container metrics-server ready: true, restart count 0
  May 18 12:49:24.587: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  May 18 12:49:24.587: INFO: dashboard-metrics-scraper-5dd7cb5fc-ks9g5 from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.588: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  May 18 12:49:24.588: INFO: kubernetes-dashboard-7b899cb9d9-4z7gj from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 12:49:24.588: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  May 18 12:49:24.588: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-l9qkt from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 12:49:24.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 12:49:24.588: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/18/24 12:49:24.588
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17d09629dfe1ebdc], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 05/18/24 12:49:24.627
  E0518 12:49:25.289984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:25.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8301" for this suite. @ 05/18/24 12:49:25.634
• [1.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 05/18/24 12:49:25.643
  May 18 12:49:25.643: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:49:25.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:25.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:25.665
  STEP: creating an Endpoint @ 05/18/24 12:49:25.67
  STEP: waiting for available Endpoint @ 05/18/24 12:49:25.674
  STEP: listing all Endpoints @ 05/18/24 12:49:25.676
  STEP: updating the Endpoint @ 05/18/24 12:49:25.679
  STEP: fetching the Endpoint @ 05/18/24 12:49:25.684
  STEP: patching the Endpoint @ 05/18/24 12:49:25.687
  STEP: fetching the Endpoint @ 05/18/24 12:49:25.694
  STEP: deleting the Endpoint by Collection @ 05/18/24 12:49:25.696
  STEP: waiting for Endpoint deletion @ 05/18/24 12:49:25.703
  STEP: fetching the Endpoint @ 05/18/24 12:49:25.704
  May 18 12:49:25.707: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3045" for this suite. @ 05/18/24 12:49:25.71
• [0.075 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 05/18/24 12:49:25.718
  May 18 12:49:25.718: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption @ 05/18/24 12:49:25.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:25.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:25.737
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:49:25.745
  E0518 12:49:26.290856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:27.291912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/18/24 12:49:27.749
  STEP: Waiting for all pods to be running @ 05/18/24 12:49:27.756
  May 18 12:49:27.760: INFO: running pods: 0 < 1
  E0518 12:49:28.292883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:29.292984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/18/24 12:49:29.761
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:49:29.773
  STEP: Patching PodDisruptionBudget status @ 05/18/24 12:49:29.779
  STEP: Waiting for the pdb to be processed @ 05/18/24 12:49:29.787
  May 18 12:49:29.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7740" for this suite. @ 05/18/24 12:49:29.792
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 05/18/24 12:49:29.8
  May 18 12:49:29.800: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 12:49:29.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:29.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:29.82
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/18/24 12:49:29.823
  May 18 12:49:29.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6603 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May 18 12:49:29.869: INFO: stderr: ""
  May 18 12:49:29.869: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/18/24 12:49:29.869
  E0518 12:49:30.293650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:31.293993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:32.294068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:33.294178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:34.294265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/18/24 12:49:34.919
  May 18 12:49:34.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6603 get pod e2e-test-httpd-pod -o json'
  May 18 12:49:34.959: INFO: stderr: ""
  May 18 12:49:34.959: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-05-18T12:49:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6603\",\n        \"resourceVersion\": \"26967\",\n        \"uid\": \"ae9a0b3a-6615-4257-858d-a021a0949cdf\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-wczsh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-33-93\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-wczsh\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-18T12:49:30Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-18T12:49:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-18T12:49:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-18T12:49:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-18T12:49:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://96a9f8168e6e813dfe06b184c184ef09ef4fdf85652ab47cd47e56d01082f3ca\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-05-18T12:49:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.33.93\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.33.93\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.225.235\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.225.235\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-05-18T12:49:29Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/18/24 12:49:34.959
  May 18 12:49:34.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6603 replace -f -'
  May 18 12:49:35.038: INFO: stderr: ""
  May 18 12:49:35.038: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/18/24 12:49:35.038
  May 18 12:49:35.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6603 delete pods e2e-test-httpd-pod'
  E0518 12:49:35.294632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:36.294806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:36.807: INFO: stderr: ""
  May 18 12:49:36.807: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 18 12:49:36.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6603" for this suite. @ 05/18/24 12:49:36.811
• [7.021 seconds]
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 05/18/24 12:49:36.821
  May 18 12:49:36.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context-test @ 05/18/24 12:49:36.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:36.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:36.842
  E0518 12:49:37.295474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:38.296378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:39.296481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:40.296618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:40.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4854" for this suite. @ 05/18/24 12:49:40.876
• [4.064 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 05/18/24 12:49:40.884
  May 18 12:49:40.884: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 12:49:40.885
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:40.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:40.904
  STEP: Creating a pod to test service account token:  @ 05/18/24 12:49:40.907
  E0518 12:49:41.297696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:42.297876      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:43.297957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:44.298046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:49:44.929
  May 18 12:49:44.934: INFO: Trying to get logs from node ip-172-31-33-93 pod test-pod-c1df2d45-3549-44e0-b3ba-7babb961b5e6 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 12:49:44.939
  May 18 12:49:44.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9078" for this suite. @ 05/18/24 12:49:44.955
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 05/18/24 12:49:44.963
  May 18 12:49:44.963: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 12:49:44.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:44.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:44.983
  STEP: Creating ServiceAccount "e2e-sa-jzvms"  @ 05/18/24 12:49:44.986
  May 18 12:49:44.991: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-jzvms"  @ 05/18/24 12:49:44.991
  May 18 12:49:44.998: INFO: AutomountServiceAccountToken: true
  May 18 12:49:44.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2174" for this suite. @ 05/18/24 12:49:45.002
• [0.044 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 05/18/24 12:49:45.007
  May 18 12:49:45.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 12:49:45.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:49:45.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:49:45.028
  STEP: Creating pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960 @ 05/18/24 12:49:45.031
  E0518 12:49:45.298810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:46.298872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 12:49:47.045
  May 18 12:49:47.048: INFO: Initial restart count of pod busybox-bce93194-eb85-4c34-935c-905579fbef8f is 0
  May 18 12:49:47.051: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:47.299703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:48.299800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:49.056: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:49.300248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:50.300332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:51.062: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:51.301297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:52.301571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:53.067: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:53.301610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:54.302234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:55.071: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:55.302838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:56.302929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:57.076: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:57.303513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:49:58.303616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:49:59.080: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:49:59.304486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:00.304960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:01.085: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:01.305349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:02.306301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:03.089: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:03.307321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:04.307555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:05.095: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:05.308621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:06.308865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:07.100: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:07.309674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:08.309764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:09.104: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:09.310717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:10.310931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:11.109: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:11.311605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:12.311826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:13.114: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:13.312246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:14.312746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:15.118: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:15.312871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:16.312985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:17.123: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:17.313471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:18.313566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:19.127: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:19.313649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:20.314607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:21.132: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:21.314656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:22.314833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:23.137: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:23.315799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:24.316243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:25.142: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:25.316598      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:26.316794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:27.145: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:27.317151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:28.317331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:29.150: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:29.317976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:30.318749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:31.156: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:31.319382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:32.319494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:33.159: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:33.320502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:34.320666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:35.163: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:35.321710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:36.322003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:37.167: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:37.322529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:38.322620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:39.172: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:39.322728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:40.322970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:41.176: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:41.323204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:42.323258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:43.181: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:43.323428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:44.324237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:45.186: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:45.325086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:46.325256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:47.192: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:47.326270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:48.326370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:49.196: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:49.327370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:50.328231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:51.201: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:51.328564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:52.328684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:53.206: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:53.328861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:54.328958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:55.211: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:55.329406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:56.329660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:57.216: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:57.330290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:50:58.330506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:50:59.220: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:50:59.330653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:00.330837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:01.225: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:01.331813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:02.332815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:03.231: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:03.333776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:04.333870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:05.236: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:05.334299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:06.334446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:07.241: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:07.334775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:08.335128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:09.247: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:09.335870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:10.335972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:11.251: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:11.336596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:12.336685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:13.256: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:13.336760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:14.336964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:15.262: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:15.337627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:16.338589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:17.268: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:17.339293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:18.339388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:19.272: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:19.339967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:20.340104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:21.277: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:21.340301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:22.340347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:23.282: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:23.341032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:24.341115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:25.287: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:25.342167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:26.343165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:27.292: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:27.344030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:28.344138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:29.297: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:29.344656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:30.345350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:31.303: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:31.346350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:32.346516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:33.308: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:33.347001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:34.347177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:35.313: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:35.348160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:36.348358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:37.318: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:37.349248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:38.349430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:39.323: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:39.350189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:40.350460      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:41.327: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:41.351724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:42.351810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:43.332: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:43.352641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:44.352737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:45.336: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:45.353768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:46.353904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:47.340: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:47.354455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:48.355477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:49.345: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:49.355577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:50.355686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:51.349: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:51.356560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:52.356768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:53.354: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:53.356789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:54.356979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:55.357223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:55.360: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:56.357693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:57.357996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:57.363: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:51:58.358823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:51:59.359096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:51:59.369: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:00.359192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:01.359266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:01.372: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:02.360241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:03.360346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:03.377: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:04.361120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:05.361224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:05.382: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:06.362066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:07.363015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:07.386: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:08.363181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:09.363207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:09.391: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:10.364241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:11.364433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:11.395: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:12.364819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:13.365607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:13.399: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:14.365668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:15.365851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:15.405: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:16.366844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:17.367153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:17.410: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:18.367247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:19.367379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:19.416: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:20.367472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:21.367560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:21.420: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:22.367661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:23.367751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:23.424: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:24.368632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:25.368741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:25.431: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:26.369358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:27.369448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:27.435: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:28.370434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:29.370536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:29.440: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:30.370627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:31.370794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:31.444: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:32.371832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:33.371932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:33.449: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:34.372023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:35.372140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:35.455: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:36.372808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:37.372949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:37.460: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:38.373536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:39.373737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:39.465: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:40.373952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:41.374058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:41.469: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:42.374983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:43.375164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:43.472: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:44.375209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:45.376243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:45.478: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:46.376324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:47.376548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:47.483: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:48.377342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:49.377423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:49.488: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:50.377854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:51.377998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:51.492: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:52.378707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:53.378795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:53.497: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:54.379736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:55.380238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:55.502: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:56.381117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:57.382023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:57.508: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:52:58.382227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:52:59.382371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:52:59.513: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:00.382474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:01.382651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:01.518: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:02.383646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:03.383735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:03.523: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:04.383836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:05.383933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:05.527: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:06.384337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:07.384987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:07.532: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:08.385408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:09.385474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:09.536: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:10.385679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:11.385785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:11.540: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:12.385895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:13.386802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:13.545: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:14.387177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:15.387279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:15.550: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:16.388250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:17.388490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:17.555: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:18.389465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:19.389621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:19.560: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:20.390600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:21.390688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:21.565: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:22.390782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:23.390905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:23.570: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:24.391064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:25.391177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:25.575: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:26.392251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:27.392587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:27.579: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:28.392692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:29.392851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:29.584: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:30.393412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:31.393531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:31.589: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:32.393762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:33.393856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:33.593: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:34.394562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:35.394647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:35.598: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:36.394747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:37.394955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:37.602: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:38.395270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:39.395373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:39.607: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:40.395479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:41.395576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:41.612: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:42.396157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:43.396497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:43.616: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:44.397120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:45.398177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:45.620: INFO: Get pod busybox-bce93194-eb85-4c34-935c-905579fbef8f in namespace container-probe-1960
  E0518 12:53:46.398282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:47.398652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/18/24 12:53:47.621
  May 18 12:53:47.636: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1960" for this suite. @ 05/18/24 12:53:47.641
• [242.640 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 05/18/24 12:53:47.648
  May 18 12:53:47.648: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 12:53:47.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:53:47.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:53:47.666
  STEP: creating a Service @ 05/18/24 12:53:47.671
  STEP: watching for the Service to be added @ 05/18/24 12:53:47.684
  May 18 12:53:47.686: INFO: Found Service test-service-cmmbm in namespace services-9132 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30383}]
  May 18 12:53:47.686: INFO: Service test-service-cmmbm created
  STEP: Getting /status @ 05/18/24 12:53:47.687
  May 18 12:53:47.691: INFO: Service test-service-cmmbm has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/18/24 12:53:47.691
  STEP: watching for the Service to be patched @ 05/18/24 12:53:47.696
  May 18 12:53:47.697: INFO: observed Service test-service-cmmbm in namespace services-9132 with annotations: map[] & LoadBalancer: {[]}
  May 18 12:53:47.697: INFO: Found Service test-service-cmmbm in namespace services-9132 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  May 18 12:53:47.697: INFO: Service test-service-cmmbm has service status patched
  STEP: updating the ServiceStatus @ 05/18/24 12:53:47.697
  May 18 12:53:47.706: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/18/24 12:53:47.706
  May 18 12:53:47.708: INFO: Observed Service test-service-cmmbm in namespace services-9132 with annotations: map[] & Conditions: {[]}
  May 18 12:53:47.708: INFO: Observed event: &Service{ObjectMeta:{test-service-cmmbm  services-9132  01a575d1-348f-40fb-88cf-47b337d16c97 27644 0 2024-05-18 12:53:47 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-05-18 12:53:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-18 12:53:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30383,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.108,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.108],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  May 18 12:53:47.708: INFO: Found Service test-service-cmmbm in namespace services-9132 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  May 18 12:53:47.708: INFO: Service test-service-cmmbm has service status updated
  STEP: patching the service @ 05/18/24 12:53:47.708
  STEP: watching for the Service to be patched @ 05/18/24 12:53:47.72
  May 18 12:53:47.721: INFO: observed Service test-service-cmmbm in namespace services-9132 with labels: map[test-service-static:true]
  May 18 12:53:47.721: INFO: observed Service test-service-cmmbm in namespace services-9132 with labels: map[test-service-static:true]
  May 18 12:53:47.721: INFO: observed Service test-service-cmmbm in namespace services-9132 with labels: map[test-service-static:true]
  May 18 12:53:47.721: INFO: Found Service test-service-cmmbm in namespace services-9132 with labels: map[test-service:patched test-service-static:true]
  May 18 12:53:47.721: INFO: Service test-service-cmmbm patched
  STEP: deleting the service @ 05/18/24 12:53:47.721
  STEP: watching for the Service to be deleted @ 05/18/24 12:53:47.738
  May 18 12:53:47.740: INFO: Observed event: ADDED
  May 18 12:53:47.740: INFO: Observed event: MODIFIED
  May 18 12:53:47.740: INFO: Observed event: MODIFIED
  May 18 12:53:47.740: INFO: Observed event: MODIFIED
  May 18 12:53:47.740: INFO: Found Service test-service-cmmbm in namespace services-9132 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  May 18 12:53:47.740: INFO: Service test-service-cmmbm deleted
  May 18 12:53:47.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9132" for this suite. @ 05/18/24 12:53:47.744
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 05/18/24 12:53:47.751
  May 18 12:53:47.751: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:53:47.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:53:47.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:53:47.772
  STEP: Setting up server cert @ 05/18/24 12:53:47.805
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:53:48.082
  STEP: Deploying the webhook pod @ 05/18/24 12:53:48.09
  STEP: Wait for the deployment to be ready @ 05/18/24 12:53:48.103
  May 18 12:53:48.110: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:53:48.399328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:49.400245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:53:50.121
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:53:50.132
  E0518 12:53:50.401074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:53:51.133: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/18/24 12:53:51.141
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/18/24 12:53:51.159
  STEP: Creating a dummy validating-webhook-configuration object @ 05/18/24 12:53:51.175
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/18/24 12:53:51.185
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/18/24 12:53:51.191
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/18/24 12:53:51.198
  May 18 12:53:51.253: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4917" for this suite. @ 05/18/24 12:53:51.257
  STEP: Destroying namespace "webhook-markers-2813" for this suite. @ 05/18/24 12:53:51.265
• [3.519 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 05/18/24 12:53:51.27
  May 18 12:53:51.270: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 12:53:51.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:53:51.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:53:51.291
  STEP: creating the pod with failed condition @ 05/18/24 12:53:51.294
  E0518 12:53:51.401677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:52.401789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:53.402571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:54.402662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:55.403078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:56.403228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:57.403847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:58.403923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:53:59.404318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:00.404521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:01.405187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:02.405280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:03.405515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:04.405768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:05.406527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:06.406634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:07.406741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:08.407179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:09.407441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:10.407517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:11.407565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:12.407957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:13.408216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:14.408260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:15.408642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:16.409315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:17.410214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:18.410315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:19.411236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:20.411348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:21.411893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:22.412242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:23.412279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:24.413353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:25.414101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:26.414719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:27.415247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:28.416224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:29.416424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:30.416589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:31.416896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:32.417104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:33.417306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:34.417431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:35.417425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:36.418012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:37.418459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:38.418532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:39.418702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:40.419751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:41.419787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:42.419881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:43.420190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:44.420299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:45.420387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:46.420487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:47.420537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:48.420832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:49.420922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:50.421005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:51.421187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:52.421295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:53.421418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:54.421531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:55.421851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:56.421964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:57.422007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:58.422105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:54:59.422299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:00.422899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:01.423000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:02.423200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:03.423299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:04.423393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:05.423476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:06.423609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:07.424007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:08.424016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:09.424136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:10.424222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:11.424295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:12.424406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:13.424880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:14.425938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:15.426015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:16.426168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:17.426342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:18.426367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:19.426569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:20.426660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:21.426944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:22.427502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:23.427655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:24.428191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:25.428281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:26.428386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:27.428433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:28.428525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:29.428721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:30.428774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:31.428858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:32.429942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:33.430027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:34.430125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:35.430215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:36.430352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:37.431027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:38.431180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:39.431347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:40.431441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:41.432256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:42.432363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:43.432449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:44.432548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:45.432636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:46.432728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:47.433605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:48.433811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:49.433898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:50.434002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 05/18/24 12:55:51.307
  E0518 12:55:51.434882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:55:51.822: INFO: Successfully updated pod "var-expansion-2061b993-e555-46db-9c7a-a12b97403c87"
  STEP: waiting for pod running @ 05/18/24 12:55:51.822
  E0518 12:55:52.435451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:53.435546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/18/24 12:55:53.829
  May 18 12:55:53.830: INFO: Deleting pod "var-expansion-2061b993-e555-46db-9c7a-a12b97403c87" in namespace "var-expansion-90"
  May 18 12:55:53.851: INFO: Wait up to 5m0s for pod "var-expansion-2061b993-e555-46db-9c7a-a12b97403c87" to be fully deleted
  E0518 12:55:54.435634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:55.436265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:56.437068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:57.438028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:58.438729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:55:59.438902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:00.439875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:01.439950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:02.440297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:03.440591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:04.440681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:05.440778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:06.440865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:07.441485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:08.442303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:09.442498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:10.442621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:11.442715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:12.443151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:13.443184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:14.443182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:15.444232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:16.445235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:17.445824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:18.446841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:19.446942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:20.447654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:21.448215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:22.448696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:23.448792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:24.449404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:25.449517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:56:25.932: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-90" for this suite. @ 05/18/24 12:56:25.936
• [154.673 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 05/18/24 12:56:25.944
  May 18 12:56:25.944: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:56:25.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:25.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:25.964
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 12:56:25.967
  E0518 12:56:26.449645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:27.450684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:28.450789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:29.450872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:56:29.99
  May 18 12:56:29.993: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-a5d83420-1933-49a9-9c6e-0997491f62f0 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 12:56:30.013
  May 18 12:56:30.030: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5834" for this suite. @ 05/18/24 12:56:30.034
• [4.098 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/18/24 12:56:30.042
  May 18 12:56:30.042: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename conformance-tests @ 05/18/24 12:56:30.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:30.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:30.062
  STEP: Getting node addresses @ 05/18/24 12:56:30.065
  May 18 12:56:30.065: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  May 18 12:56:30.071: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4993" for this suite. @ 05/18/24 12:56:30.073
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/18/24 12:56:30.082
  May 18 12:56:30.082: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-runtime @ 05/18/24 12:56:30.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:30.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:30.103
  STEP: create the container @ 05/18/24 12:56:30.105
  W0518 12:56:30.115302      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/18/24 12:56:30.115
  E0518 12:56:30.451464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:31.452228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:32.452327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/18/24 12:56:33.133
  STEP: the container should be terminated @ 05/18/24 12:56:33.137
  STEP: the termination message should be set @ 05/18/24 12:56:33.137
  May 18 12:56:33.137: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/18/24 12:56:33.137
  May 18 12:56:33.153: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5738" for this suite. @ 05/18/24 12:56:33.157
• [3.083 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 05/18/24 12:56:33.165
  May 18 12:56:33.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:56:33.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:33.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:33.184
  STEP: Setting up server cert @ 05/18/24 12:56:33.21
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:56:33.35
  STEP: Deploying the webhook pod @ 05/18/24 12:56:33.359
  STEP: Wait for the deployment to be ready @ 05/18/24 12:56:33.37
  May 18 12:56:33.377: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0518 12:56:33.452779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:34.452879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:56:35.389
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:56:35.4
  E0518 12:56:35.453138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:56:36.400: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/18/24 12:56:36.408
  STEP: create a configmap that should be updated by the webhook @ 05/18/24 12:56:36.423
  E0518 12:56:36.453850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:56:36.477: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1645" for this suite. @ 05/18/24 12:56:36.482
  STEP: Destroying namespace "webhook-markers-1635" for this suite. @ 05/18/24 12:56:36.492
• [3.333 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 05/18/24 12:56:36.498
  May 18 12:56:36.498: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 12:56:36.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:36.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:36.521
  STEP: creating a ServiceAccount @ 05/18/24 12:56:36.524
  STEP: watching for the ServiceAccount to be added @ 05/18/24 12:56:36.532
  STEP: patching the ServiceAccount @ 05/18/24 12:56:36.533
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/18/24 12:56:36.54
  STEP: deleting the ServiceAccount @ 05/18/24 12:56:36.543
  May 18 12:56:36.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2909" for this suite. @ 05/18/24 12:56:36.561
• [0.070 seconds]
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 05/18/24 12:56:36.568
  May 18 12:56:36.568: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename taint-single-pod @ 05/18/24 12:56:36.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:56:36.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:56:36.588
  May 18 12:56:36.591: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 12:56:37.454012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:38.454110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:39.454204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:40.454331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:41.454459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:42.454633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:43.455725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:44.456241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:45.456326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:46.456413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:47.457106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:48.457309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:49.457459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:50.457556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:51.458231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:52.458770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:53.459182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:54.460239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:55.460329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:56.460423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:57.461108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:58.461340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:56:59.461459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:00.461541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:01.461650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:02.461783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:03.462553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:04.462756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:05.462849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:06.463135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:07.463523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:08.463615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:09.463691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:10.464243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:11.464293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:12.464444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:13.464533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:14.465440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:15.465558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:16.465836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:17.465944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:18.465968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:19.466552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:20.466675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:21.467159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:22.467196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:23.467280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:24.468231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:25.469006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:26.469185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:27.469376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:28.469437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:29.469542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:30.469647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:31.470457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:32.470566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:33.470661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:34.470950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:35.471358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:36.471427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:57:36.591: INFO: Waiting for terminating namespaces to be deleted...
  May 18 12:57:36.595: INFO: Starting informer...
  STEP: Starting pod... @ 05/18/24 12:57:36.595
  May 18 12:57:36.810: INFO: Pod is running on ip-172-31-33-93. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/18/24 12:57:36.81
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/18/24 12:57:36.82
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/18/24 12:57:36.823
  May 18 12:57:36.823: INFO: Pod wasn't evicted. Proceeding
  May 18 12:57:36.823: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/18/24 12:57:36.834
  STEP: Waiting some time to make sure that toleration time passed. @ 05/18/24 12:57:36.841
  E0518 12:57:37.471546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:38.471637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:39.471745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:40.471813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:41.471913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:42.472241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:43.472540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:44.472609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:45.472730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:46.472843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:47.472931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:48.473313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:49.473479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:50.474432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:51.474673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:52.474777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:53.475097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:54.475185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:55.476226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:56.476415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:57.476626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:58.476804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:57:59.477349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:00.477406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:01.477508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:02.478568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:03.478746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:04.479212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:05.479296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:06.480223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:07.480455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:08.480914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:09.481007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:10.481265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:11.481519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:12.481627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:13.481943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:14.482112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:15.482276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:16.482367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:17.482475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:18.482582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:19.482705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:20.482784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:21.483774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:22.483868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:23.483961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:24.484239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:25.484340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:26.484523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:27.484576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:28.484674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:29.484801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:30.484873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:31.485050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:32.485232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:33.485447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:34.485634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:35.485803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:36.485919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:37.486037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:38.486216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:39.487123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:40.487289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:41.488250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:42.488614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:43.488706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:44.488865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:45.489051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:46.489141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:47.489224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:48.489319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:49.489607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:50.490359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:51.490530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:58:51.842: INFO: Pod wasn't evicted. Test successful
  May 18 12:58:51.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-4238" for this suite. @ 05/18/24 12:58:51.846
• [135.287 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 05/18/24 12:58:51.855
  May 18 12:58:51.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 12:58:51.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:58:51.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:58:51.877
  STEP: Creating simple DaemonSet "daemon-set" @ 05/18/24 12:58:51.895
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 12:58:51.901
  May 18 12:58:51.904: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:51.904: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:51.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 12:58:51.906: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 12:58:52.490985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:58:52.905: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:52.905: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:52.909: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 12:58:52.909: INFO: Node ip-172-31-70-23 is running 0 daemon pod, expected 1
  E0518 12:58:53.491062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:58:53.907: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:53.907: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 12:58:53.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 12:58:53.911: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/18/24 12:58:53.915
  STEP: DeleteCollection of the DaemonSets @ 05/18/24 12:58:53.92
  STEP: Verify that ReplicaSets have been deleted @ 05/18/24 12:58:53.928
  May 18 12:58:53.937: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28698"},"items":null}

  May 18 12:58:53.943: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28698"},"items":[{"metadata":{"name":"daemon-set-dl9zh","generateName":"daemon-set-","namespace":"daemonsets-9734","uid":"628a88e2-a90b-48f6-af69-97040255c377","resourceVersion":"28690","creationTimestamp":"2024-05-18T12:58:51Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ea47d40e-1965-41e2-922b-b341e4cc312e","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea47d40e-1965-41e2-922b-b341e4cc312e\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.198.92\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cxcc5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cxcc5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-90-158","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-90-158"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"}],"hostIP":"172.31.90.158","hostIPs":[{"ip":"172.31.90.158"}],"podIP":"192.168.198.92","podIPs":[{"ip":"192.168.198.92"}],"startTime":"2024-05-18T12:58:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-18T12:58:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://2c4967d4e0bbd5ff479f5e0d08f75e816f4099c4011db71c4a782b62fbde5f86","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hc7d9","generateName":"daemon-set-","namespace":"daemonsets-9734","uid":"447e9466-bc1d-45dc-86c3-26134ed65d7f","resourceVersion":"28692","creationTimestamp":"2024-05-18T12:58:51Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ea47d40e-1965-41e2-922b-b341e4cc312e","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea47d40e-1965-41e2-922b-b341e4cc312e\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.209.126\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rg4tm","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rg4tm","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-70-23","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-70-23"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:53Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"}],"hostIP":"172.31.70.23","hostIPs":[{"ip":"172.31.70.23"}],"podIP":"192.168.209.126","podIPs":[{"ip":"192.168.209.126"}],"startTime":"2024-05-18T12:58:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-18T12:58:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://570b55ebbef4040a36973028639414c042d7a4d82be666ed4bf8a456e0f3643b","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-sqxss","generateName":"daemon-set-","namespace":"daemonsets-9734","uid":"649d4bd8-439d-4dfe-9688-650e92b9766f","resourceVersion":"28688","creationTimestamp":"2024-05-18T12:58:51Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ea47d40e-1965-41e2-922b-b341e4cc312e","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea47d40e-1965-41e2-922b-b341e4cc312e\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-18T12:58:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.225.209\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-fj27m","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-fj27m","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-33-93","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-33-93"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-18T12:58:51Z"}],"hostIP":"172.31.33.93","hostIPs":[{"ip":"172.31.33.93"}],"podIP":"192.168.225.209","podIPs":[{"ip":"192.168.225.209"}],"startTime":"2024-05-18T12:58:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-18T12:58:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://6725a20f6f26ec73182db71e9d8d461f500b6cf6ac23af641a7e82a6343b4cea","started":true}],"qosClass":"BestEffort"}}]}

  May 18 12:58:53.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9734" for this suite. @ 05/18/24 12:58:53.965
• [2.115 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 05/18/24 12:58:53.971
  May 18 12:58:53.971: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 12:58:53.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:58:53.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:58:53.989
  STEP: Setting up server cert @ 05/18/24 12:58:54.018
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 12:58:54.185
  STEP: Deploying the webhook pod @ 05/18/24 12:58:54.196
  STEP: Wait for the deployment to be ready @ 05/18/24 12:58:54.209
  May 18 12:58:54.219: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 12:58:54.491246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:58:55.491329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 12:58:56.229
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 12:58:56.24
  E0518 12:58:56.491435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:58:57.240: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/18/24 12:58:57.248
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/18/24 12:58:57.248
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/18/24 12:58:57.263
  E0518 12:58:57.491945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/18/24 12:58:58.274
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/18/24 12:58:58.274
  E0518 12:58:58.492668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/18/24 12:58:59.3
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/18/24 12:58:59.3
  E0518 12:58:59.493130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:00.493352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:01.493551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:02.493940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:03.494053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/18/24 12:59:04.334
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/18/24 12:59:04.334
  E0518 12:59:04.494512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:05.494789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:06.494973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:07.495103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:08.495201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:59:09.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4113" for this suite. @ 05/18/24 12:59:09.413
  STEP: Destroying namespace "webhook-markers-8454" for this suite. @ 05/18/24 12:59:09.422
• [15.456 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 05/18/24 12:59:09.428
  May 18 12:59:09.428: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 12:59:09.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:59:09.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:59:09.445
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/18/24 12:59:09.448
  E0518 12:59:09.495338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:10.496252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:11.496548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:12.496751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 12:59:13.468
  May 18 12:59:13.471: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-d1605edd-9d05-4f12-9c0d-127ed53cba12 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 12:59:13.484
  E0518 12:59:13.497187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 12:59:13.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4740" for this suite. @ 05/18/24 12:59:13.509
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 05/18/24 12:59:13.515
  May 18 12:59:13.515: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 12:59:13.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 12:59:13.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 12:59:13.535
  STEP: Creating configMap with name cm-test-opt-del-ecf7ab29-08c9-450f-b680-f186415cc682 @ 05/18/24 12:59:13.541
  STEP: Creating configMap with name cm-test-opt-upd-bf2ca556-5a85-4308-ba03-3e3831c8ea0a @ 05/18/24 12:59:13.545
  STEP: Creating the pod @ 05/18/24 12:59:13.551
  E0518 12:59:14.498145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:15.498796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-ecf7ab29-08c9-450f-b680-f186415cc682 @ 05/18/24 12:59:15.593
  STEP: Updating configmap cm-test-opt-upd-bf2ca556-5a85-4308-ba03-3e3831c8ea0a @ 05/18/24 12:59:15.598
  STEP: Creating configMap with name cm-test-opt-create-1148e249-089b-4f14-9244-675491459a80 @ 05/18/24 12:59:15.603
  STEP: waiting to observe update in volume @ 05/18/24 12:59:15.606
  E0518 12:59:16.498889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:17.498974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:18.499190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:19.499336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:20.499384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:21.499463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:22.500253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:23.500334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:24.500500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:25.500626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:26.500742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:27.501643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:28.501743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:29.501821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:30.502007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:31.502101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:32.503179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:33.503267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:34.503384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:35.503473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:36.503559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:37.503665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:38.503775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:39.504255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:40.504341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:41.504446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:42.504532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:43.504693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:44.504874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:45.504990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:46.505496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:47.505582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:48.506492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:49.506728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:50.507061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:51.507178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:52.507291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:53.507355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:54.507468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:55.508244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:56.508336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:57.509148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:58.509261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 12:59:59.509332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:00.509472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:01.509575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:02.509606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:03.509685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:04.509792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:05.509886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:06.509975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:07.510217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:08.510287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:09.510410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:10.510493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:11.510644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:12.511597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:13.511724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:14.512686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:15.512800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:16.512810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:17.513672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:18.514589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:19.514728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:20.514833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:21.514923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:22.515393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:23.516237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:24.517281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:25.517395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:26.518408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:27.518477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:28.518936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:29.519670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:30.520250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:31.520440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:32.521239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:33.521357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:34.521723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:35.521896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:36.522179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:37.523160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:38.523560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:39.524783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:40.525602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:41.525710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:42.526310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:43.526442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:00:44.030: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4666" for this suite. @ 05/18/24 13:00:44.033
• [90.527 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 05/18/24 13:00:44.042
  May 18 13:00:44.042: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename runtimeclass @ 05/18/24 13:00:44.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:00:44.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:00:44.062
  STEP: getting /apis @ 05/18/24 13:00:44.064
  STEP: getting /apis/node.k8s.io @ 05/18/24 13:00:44.067
  STEP: getting /apis/node.k8s.io/v1 @ 05/18/24 13:00:44.068
  STEP: creating @ 05/18/24 13:00:44.069
  STEP: watching @ 05/18/24 13:00:44.085
  May 18 13:00:44.085: INFO: starting watch
  STEP: getting @ 05/18/24 13:00:44.091
  STEP: listing @ 05/18/24 13:00:44.094
  STEP: patching @ 05/18/24 13:00:44.097
  STEP: updating @ 05/18/24 13:00:44.101
  May 18 13:00:44.106: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 05/18/24 13:00:44.106
  STEP: deleting a collection @ 05/18/24 13:00:44.117
  May 18 13:00:44.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4745" for this suite. @ 05/18/24 13:00:44.134
• [0.099 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/18/24 13:00:44.141
  May 18 13:00:44.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context @ 05/18/24 13:00:44.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:00:44.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:00:44.162
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/18/24 13:00:44.164
  E0518 13:00:44.526952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:45.527146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:46.527233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:47.528196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:00:48.187
  May 18 13:00:48.191: INFO: Trying to get logs from node ip-172-31-70-23 pod security-context-f8a57ea3-9b88-4136-8d5c-a71139bc1bb0 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:00:48.205
  May 18 13:00:48.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2460" for this suite. @ 05/18/24 13:00:48.222
• [4.087 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/18/24 13:00:48.228
  May 18 13:00:48.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:00:48.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:00:48.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:00:48.25
  May 18 13:00:48.253: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: creating the pod @ 05/18/24 13:00:48.253
  STEP: submitting the pod to kubernetes @ 05/18/24 13:00:48.253
  E0518 13:00:48.528713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:49.529082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:00:50.278: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3013" for this suite. @ 05/18/24 13:00:50.282
• [2.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/18/24 13:00:50.29
  May 18 13:00:50.290: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subpath @ 05/18/24 13:00:50.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:00:50.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:00:50.309
  STEP: Setting up data @ 05/18/24 13:00:50.312
  STEP: Creating pod pod-subpath-test-secret-mx7g @ 05/18/24 13:00:50.32
  STEP: Creating a pod to test atomic-volume-subpath @ 05/18/24 13:00:50.32
  E0518 13:00:50.529003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:51.529263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:52.529352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:53.529454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:54.530136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:55.530163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:56.530727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:57.531694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:58.531739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:00:59.532382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:00.532736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:01.532915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:02.533246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:03.533357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:04.534137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:05.534232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:06.534535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:07.534674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:08.535529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:09.536222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:10.537109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:11.537305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:12.537502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:13.537613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:01:14.389
  May 18 13:01:14.392: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-subpath-test-secret-mx7g container test-container-subpath-secret-mx7g: <nil>
  STEP: delete the pod @ 05/18/24 13:01:14.399
  STEP: Deleting pod pod-subpath-test-secret-mx7g @ 05/18/24 13:01:14.416
  May 18 13:01:14.416: INFO: Deleting pod "pod-subpath-test-secret-mx7g" in namespace "subpath-1289"
  May 18 13:01:14.420: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1289" for this suite. @ 05/18/24 13:01:14.424
• [24.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 05/18/24 13:01:14.432
  May 18 13:01:14.432: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 13:01:14.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:14.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:14.457
  STEP: Creating service test in namespace statefulset-8752 @ 05/18/24 13:01:14.459
  STEP: Looking for a node to schedule stateful set and pod @ 05/18/24 13:01:14.465
  STEP: Creating pod with conflicting port in namespace statefulset-8752 @ 05/18/24 13:01:14.472
  STEP: Waiting until pod test-pod will start running in namespace statefulset-8752 @ 05/18/24 13:01:14.479
  E0518 13:01:14.538617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:15.538771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-8752 @ 05/18/24 13:01:16.485
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8752 @ 05/18/24 13:01:16.49
  May 18 13:01:16.511: INFO: Observed stateful pod in namespace: statefulset-8752, name: ss-0, uid: 7dd32ec7-d168-41ce-8af4-b39d22c1429b, status phase: Pending. Waiting for statefulset controller to delete.
  May 18 13:01:16.527: INFO: Observed stateful pod in namespace: statefulset-8752, name: ss-0, uid: 7dd32ec7-d168-41ce-8af4-b39d22c1429b, status phase: Failed. Waiting for statefulset controller to delete.
  May 18 13:01:16.536: INFO: Observed stateful pod in namespace: statefulset-8752, name: ss-0, uid: 7dd32ec7-d168-41ce-8af4-b39d22c1429b, status phase: Failed. Waiting for statefulset controller to delete.
  May 18 13:01:16.539: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8752
  E0518 13:01:16.539450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing pod with conflicting port in namespace statefulset-8752 @ 05/18/24 13:01:16.539
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8752 and will be in running state @ 05/18/24 13:01:16.552
  E0518 13:01:17.539537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:18.539618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:18.559: INFO: Deleting all statefulset in ns statefulset-8752
  May 18 13:01:18.562: INFO: Scaling statefulset ss to 0
  E0518 13:01:19.539738      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:20.539834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:21.539910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:22.540014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:23.540105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:24.540206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:25.541410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:26.541756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:27.542700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:28.542809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:28.576: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 13:01:28.579: INFO: Deleting statefulset ss
  May 18 13:01:28.591: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8752" for this suite. @ 05/18/24 13:01:28.595
• [14.170 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 05/18/24 13:01:28.603
  May 18 13:01:28.603: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:01:28.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:28.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:28.625
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:01:28.628
  E0518 13:01:29.543431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:30.543705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:31.544246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:32.544339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:01:32.651
  May 18 13:01:32.655: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-a520b7d1-e75d-48cc-8996-c00e4285f7de container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:01:32.664
  May 18 13:01:32.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6517" for this suite. @ 05/18/24 13:01:32.685
• [4.088 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 05/18/24 13:01:32.691
  May 18 13:01:32.691: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename containers @ 05/18/24 13:01:32.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:32.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:32.712
  STEP: Creating a pod to test override command @ 05/18/24 13:01:32.715
  E0518 13:01:33.544415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:34.544612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:35.544710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:36.544810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:01:36.736
  May 18 13:01:36.739: INFO: Trying to get logs from node ip-172-31-33-93 pod client-containers-7a643442-27ce-4c29-ba33-02adf1e802da container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:01:36.746
  May 18 13:01:36.763: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1400" for this suite. @ 05/18/24 13:01:36.767
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 05/18/24 13:01:36.773
  May 18 13:01:36.773: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 13:01:36.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:36.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:36.794
  STEP: Creating replication controller my-hostname-basic-ea16c62d-c0cb-41c5-938d-16a2298cf862 @ 05/18/24 13:01:36.797
  May 18 13:01:36.805: INFO: Pod name my-hostname-basic-ea16c62d-c0cb-41c5-938d-16a2298cf862: Found 0 pods out of 1
  E0518 13:01:37.545289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:38.545430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:39.545501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:40.545599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:41.545684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:41.811: INFO: Pod name my-hostname-basic-ea16c62d-c0cb-41c5-938d-16a2298cf862: Found 1 pods out of 1
  May 18 13:01:41.811: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ea16c62d-c0cb-41c5-938d-16a2298cf862" are running
  May 18 13:01:41.814: INFO: Pod "my-hostname-basic-ea16c62d-c0cb-41c5-938d-16a2298cf862-d525c" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:01:37 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:01:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:01:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:01:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:01:36 +0000 UTC Reason: Message:}])
  May 18 13:01:41.814: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/18/24 13:01:41.814
  May 18 13:01:41.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8763" for this suite. @ 05/18/24 13:01:41.829
• [5.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/18/24 13:01:41.835
  May 18 13:01:41.835: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename endpointslice @ 05/18/24 13:01:41.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:41.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:41.862
  May 18 13:01:41.874: INFO: Endpoints addresses: [172.31.23.188 172.31.44.169] , ports: [6443]
  May 18 13:01:41.874: INFO: EndpointSlices addresses: [172.31.23.188 172.31.44.169] , ports: [6443]
  May 18 13:01:41.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2898" for this suite. @ 05/18/24 13:01:41.877
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/18/24 13:01:41.883
  May 18 13:01:41.883: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pod-network-test @ 05/18/24 13:01:41.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:41.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:41.903
  STEP: Performing setup for networking test in namespace pod-network-test-6129 @ 05/18/24 13:01:41.906
  STEP: creating a selector @ 05/18/24 13:01:41.906
  STEP: Creating the service pods in kubernetes @ 05/18/24 13:01:41.906
  May 18 13:01:41.906: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0518 13:01:42.546085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:43.546188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:44.546311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:45.546511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:46.547245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:47.548189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:48.548229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:49.548326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:50.548724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:51.548818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:52.548912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:53.549015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/18/24 13:01:53.978
  E0518 13:01:54.549993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:01:55.550926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:56.007: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  May 18 13:01:56.007: INFO: Going to poll 192.168.225.217 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  May 18 13:01:56.011: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.225.217 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6129 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:01:56.011: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:01:56.011: INFO: ExecWithOptions: Clientset creation
  May 18 13:01:56.011: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6129/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.225.217+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0518 13:01:56.551745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:57.075: INFO: Found all 1 expected endpoints: [netserver-0]
  May 18 13:01:57.075: INFO: Going to poll 192.168.209.109 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  May 18 13:01:57.080: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.209.109 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6129 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:01:57.080: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:01:57.080: INFO: ExecWithOptions: Clientset creation
  May 18 13:01:57.081: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6129/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.209.109+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0518 13:01:57.551842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:58.125: INFO: Found all 1 expected endpoints: [netserver-1]
  May 18 13:01:58.125: INFO: Going to poll 192.168.198.102 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  May 18 13:01:58.128: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.198.102 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6129 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:01:58.128: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:01:58.129: INFO: ExecWithOptions: Clientset creation
  May 18 13:01:58.129: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6129/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.198.102+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0518 13:01:58.552664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:59.181: INFO: Found all 1 expected endpoints: [netserver-2]
  May 18 13:01:59.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6129" for this suite. @ 05/18/24 13:01:59.185
• [17.309 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 05/18/24 13:01:59.191
  May 18 13:01:59.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/18/24 13:01:59.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:01:59.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:01:59.213
  STEP: Creating 50 configmaps @ 05/18/24 13:01:59.217
  STEP: Creating RC which spawns configmap-volume pods @ 05/18/24 13:01:59.446
  E0518 13:01:59.553334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:01:59.575: INFO: Pod name wrapped-volume-race-6a22c1fb-9ab5-4ac5-9f54-74b6e5bdbfb7: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/18/24 13:01:59.575
  E0518 13:02:00.553896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:01.554007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 05/18/24 13:02:01.626
  May 18 13:02:01.638: INFO: Pod name wrapped-volume-race-bddd7c9e-c93f-46af-927e-4246b659f61d: Found 0 pods out of 5
  E0518 13:02:02.554164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:03.554200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:04.554318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:05.554423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:06.554513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:02:06.645: INFO: Pod name wrapped-volume-race-bddd7c9e-c93f-46af-927e-4246b659f61d: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/18/24 13:02:06.645
  STEP: Creating RC which spawns configmap-volume pods @ 05/18/24 13:02:06.665
  May 18 13:02:06.677: INFO: Pod name wrapped-volume-race-07395cc9-4331-4389-b304-ad2c966e9142: Found 0 pods out of 5
  E0518 13:02:07.554601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:08.554950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:09.555031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:10.555163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:11.556239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:02:11.685: INFO: Pod name wrapped-volume-race-07395cc9-4331-4389-b304-ad2c966e9142: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/18/24 13:02:11.685
  STEP: deleting ReplicationController wrapped-volume-race-07395cc9-4331-4389-b304-ad2c966e9142 in namespace emptydir-wrapper-9630, will wait for the garbage collector to delete the pods @ 05/18/24 13:02:11.702
  May 18 13:02:11.762: INFO: Deleting ReplicationController wrapped-volume-race-07395cc9-4331-4389-b304-ad2c966e9142 took: 6.343276ms
  May 18 13:02:11.863: INFO: Terminating ReplicationController wrapped-volume-race-07395cc9-4331-4389-b304-ad2c966e9142 pods took: 100.735247ms
  E0518 13:02:12.556927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:13.557899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-bddd7c9e-c93f-46af-927e-4246b659f61d in namespace emptydir-wrapper-9630, will wait for the garbage collector to delete the pods @ 05/18/24 13:02:13.764
  May 18 13:02:13.828: INFO: Deleting ReplicationController wrapped-volume-race-bddd7c9e-c93f-46af-927e-4246b659f61d took: 8.9083ms
  May 18 13:02:13.929: INFO: Terminating ReplicationController wrapped-volume-race-bddd7c9e-c93f-46af-927e-4246b659f61d pods took: 100.641239ms
  E0518 13:02:14.558864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-6a22c1fb-9ab5-4ac5-9f54-74b6e5bdbfb7 in namespace emptydir-wrapper-9630, will wait for the garbage collector to delete the pods @ 05/18/24 13:02:15.53
  E0518 13:02:15.559120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:02:15.593: INFO: Deleting ReplicationController wrapped-volume-race-6a22c1fb-9ab5-4ac5-9f54-74b6e5bdbfb7 took: 8.328061ms
  May 18 13:02:15.694: INFO: Terminating ReplicationController wrapped-volume-race-6a22c1fb-9ab5-4ac5-9f54-74b6e5bdbfb7 pods took: 100.934157ms
  E0518 13:02:16.559368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 05/18/24 13:02:17.395
  E0518 13:02:17.560082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:02:17.671: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-9630" for this suite. @ 05/18/24 13:02:17.675
• [18.489 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 05/18/24 13:02:17.681
  May 18 13:02:17.681: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 13:02:17.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:02:17.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:02:17.701
  May 18 13:02:17.731: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e3b2b21a-6605-48fb-99a8-4904a40bfe47", Controller:(*bool)(0xc004249316), BlockOwnerDeletion:(*bool)(0xc004249317)}}
  May 18 13:02:17.740: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e70ea24b-701d-422d-8208-6068b0caf78a", Controller:(*bool)(0xc004772306), BlockOwnerDeletion:(*bool)(0xc004772307)}}
  May 18 13:02:17.745: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"cbd045f5-3ef1-4c5b-8f09-12c0bb20b1b8", Controller:(*bool)(0xc004249546), BlockOwnerDeletion:(*bool)(0xc004249547)}}
  E0518 13:02:18.560760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:19.560880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:20.561825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:21.561917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:22.562039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:02:22.755: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5402" for this suite. @ 05/18/24 13:02:22.758
• [5.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/18/24 13:02:22.765
  May 18 13:02:22.765: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename limitrange @ 05/18/24 13:02:22.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:02:22.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:02:22.787
  STEP: Creating LimitRange "e2e-limitrange-qhh4j" in namespace "limitrange-3718" @ 05/18/24 13:02:22.789
  STEP: Creating another limitRange in another namespace @ 05/18/24 13:02:22.796
  May 18 13:02:22.812: INFO: Namespace "e2e-limitrange-qhh4j-6459" created
  May 18 13:02:22.812: INFO: Creating LimitRange "e2e-limitrange-qhh4j" in namespace "e2e-limitrange-qhh4j-6459"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-qhh4j" @ 05/18/24 13:02:22.817
  May 18 13:02:22.821: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-qhh4j" in "limitrange-3718" namespace @ 05/18/24 13:02:22.821
  May 18 13:02:22.828: INFO: LimitRange "e2e-limitrange-qhh4j" has been patched
  STEP: Delete LimitRange "e2e-limitrange-qhh4j" by Collection with labelSelector: "e2e-limitrange-qhh4j=patched" @ 05/18/24 13:02:22.828
  STEP: Confirm that the limitRange "e2e-limitrange-qhh4j" has been deleted @ 05/18/24 13:02:22.836
  May 18 13:02:22.836: INFO: Requesting list of LimitRange to confirm quantity
  May 18 13:02:22.839: INFO: Found 0 LimitRange with label "e2e-limitrange-qhh4j=patched"
  May 18 13:02:22.839: INFO: LimitRange "e2e-limitrange-qhh4j" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-qhh4j" @ 05/18/24 13:02:22.839
  May 18 13:02:22.842: INFO: Found 1 limitRange
  May 18 13:02:22.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3718" for this suite. @ 05/18/24 13:02:22.846
  STEP: Destroying namespace "e2e-limitrange-qhh4j-6459" for this suite. @ 05/18/24 13:02:22.853
• [0.095 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/18/24 13:02:22.86
  May 18 13:02:22.860: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename cronjob @ 05/18/24 13:02:22.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:02:22.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:02:22.883
  STEP: Creating a ForbidConcurrent cronjob @ 05/18/24 13:02:22.886
  STEP: Ensuring a job is scheduled @ 05/18/24 13:02:22.894
  E0518 13:02:23.562200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:24.562267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:25.562399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:26.562861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:27.563199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:28.564251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:29.564332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:30.564439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:31.564549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:32.564627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:33.565211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:34.565275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:35.565434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:36.565506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:37.566239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:38.566346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:39.567128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:40.567229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:41.567293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:42.567420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:43.568248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:44.568318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:45.568409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:46.568545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:47.569194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:48.569311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:49.570112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:50.570227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:51.571169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:52.571204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:53.572288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:54.572578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:55.573051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:56.574032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:57.574765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:58.575163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:02:59.575258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:00.576240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/18/24 13:03:00.899
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/18/24 13:03:00.901
  STEP: Ensuring no more jobs are scheduled @ 05/18/24 13:03:00.904
  E0518 13:03:01.577069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:02.577882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:03.577960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:04.579012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:05.579145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:06.579256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:07.580131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:08.580212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:09.580315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:10.580820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:11.581497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:12.581746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:13.582187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:14.582322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:15.582482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:16.582573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:17.582737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:18.583160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:19.584134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:20.584200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:21.585207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:22.585305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:23.585378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:24.585469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:25.585763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:26.586025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:27.586639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:28.586729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:29.587239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:30.587329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:31.588230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:32.589322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:33.590212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:34.590303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:35.591238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:36.591321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:37.592260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:38.592442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:39.592531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:40.592623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:41.593620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:42.593881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:43.593964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:44.594131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:45.595151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:46.596230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:47.596528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:48.596605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:49.597437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:50.597547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:51.598375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:52.598517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:53.599546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:54.599634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:55.600229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:56.600413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:57.601073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:58.602042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:03:59.602152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:00.602238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:01.602879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:02.602973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:03.603487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:04.604228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:05.604481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:06.604557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:07.605606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:08.605711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:09.606678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:10.607434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:11.607515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:12.608505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:13.608653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:14.608961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:15.609988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:16.610180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:17.611247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:18.611357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:19.611981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:20.612531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:21.612722      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:22.612892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:23.613277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:24.613454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:25.613508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:26.614574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:27.615227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:28.615353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:29.616244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:30.616356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:31.617252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:32.617437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:33.618341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:34.618444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:35.619211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:36.619306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:37.620119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:38.620209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:39.620371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:40.620544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:41.621115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:42.621302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:43.621472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:44.621868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:45.622954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:46.623155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:47.623234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:48.623327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:49.623426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:50.624244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:51.624335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:52.624498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:53.624605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:54.624828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:55.624924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:56.625095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:57.625956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:58.626020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:04:59.626685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:00.626942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:01.627500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:02.628239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:03.628484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:04.628542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:05.629333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:06.629432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:07.629538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:08.629631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:09.630509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:10.630673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:11.631162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:12.631256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:13.631948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:14.632217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:15.632479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:16.632691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:17.633708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:18.633785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:19.634685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:20.635443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:21.635535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:22.636251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:23.636624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:24.636810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:25.637817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:26.638252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:27.639278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:28.640229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:29.640759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:30.640869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:31.640953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:32.640994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:33.641642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:34.641840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:35.642188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:36.642371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:37.643298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:38.644223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:39.644537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:40.644627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:41.645090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:42.645189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:43.646160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:44.646334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:45.647002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:46.647152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:47.647910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:48.648276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:49.648382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:50.648577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:51.649590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:52.649997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:53.650818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:54.650911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:55.650989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:56.651164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:57.651361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:58.652223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:05:59.652754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:00.652933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:01.653450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:02.653633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:03.654667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:04.654911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:05.655608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:06.655709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:07.656213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:08.656313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:09.657227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:10.657319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:11.657916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:12.658137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:13.658219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:14.658425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:15.658512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:16.658585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:17.658676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:18.658764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:19.659048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:20.659180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:21.659206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:22.660230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:23.660332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:24.660430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:25.661506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:26.661614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:27.662455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:28.663308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:29.663401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:30.663492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:31.664235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:32.664401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:33.664496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:34.664599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:35.664749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:36.665568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:37.666576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:38.666670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:39.667366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:40.667451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:41.667578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:42.668016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:43.668713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:44.669193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:45.669283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:46.669438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:47.670281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:48.670722      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:49.670862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:50.671470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:51.671558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:52.672227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:53.672333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:54.672533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:55.672622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:56.672708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:57.672793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:58.672884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:06:59.673820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:00.673912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:01.674331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:02.674504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:03.675083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:04.675248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:05.675341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:06.676124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:07.677095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:08.677264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:09.678342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:10.678429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:11.678632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:12.679164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:13.680227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:14.680403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:15.681353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:16.681519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:17.682217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:18.682321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:19.683256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:20.683340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:21.684237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:22.684471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:23.684757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:24.684847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:25.684910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:26.684995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:27.685573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:28.685862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:29.686811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:30.686964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:31.687419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:32.687496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:33.687544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:34.688227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:35.689109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:36.689836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:37.689997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:38.690095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:39.690513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:40.690801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:41.691167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:42.692248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:43.692687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:44.692871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:45.693917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:46.694018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:47.694931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:48.695158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:49.696126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:50.696417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:51.696963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:52.697819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:53.698115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:54.698936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:55.699979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:56.700175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:57.700863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:58.700961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:07:59.701034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:00.701922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/18/24 13:08:00.912
  May 18 13:08:00.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6714" for this suite. @ 05/18/24 13:08:00.922
• [338.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/18/24 13:08:00.928
  May 18 13:08:00.928: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:08:00.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:08:00.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:08:00.957
  STEP: Creating secret with name secret-test-5d3a148e-7d64-4874-8d9a-cf5c7edd6ea2 @ 05/18/24 13:08:00.979
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:08:00.983
  E0518 13:08:01.702059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:02.702153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:03.702278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:04.702383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:08:05.006
  May 18 13:08:05.010: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-secrets-06635cfa-1d18-4f23-a07a-032b8c501c10 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:08:05.024
  May 18 13:08:05.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1567" for this suite. @ 05/18/24 13:08:05.042
  STEP: Destroying namespace "secret-namespace-3663" for this suite. @ 05/18/24 13:08:05.048
• [4.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 05/18/24 13:08:05.055
  May 18 13:08:05.055: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 13:08:05.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:08:05.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:08:05.074
  STEP: Creating pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950 @ 05/18/24 13:08:05.077
  E0518 13:08:05.702780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:06.702870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 13:08:07.094
  May 18 13:08:07.097: INFO: Initial restart count of pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac is 0
  May 18 13:08:07.100: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:07.703111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:08.703190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:09.105: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:09.704071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:10.704176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:11.109: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:11.705173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:12.705265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:13.114: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:13.706029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:14.706425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:15.119: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:15.707174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:16.707192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:17.123: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:17.707895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:18.708042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:19.127: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:19.708391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:20.708483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:21.132: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:21.709157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:22.709254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:23.136: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:23.709777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:24.709971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:25.141: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:25.710154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:26.710247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:27.146: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:27.710338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:28.710394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:29.151: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:29.710560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:30.710658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:31.156: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:31.711158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:32.711192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:33.161: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:33.711300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:34.712239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:35.166: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:35.712815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:36.712997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:37.170: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:37.713179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:38.713283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:39.175: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:39.713418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:40.713515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:41.180: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:41.714008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:42.714097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:43.185: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:43.714493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:44.714572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:45.189: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:45.715424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:46.715516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:47.195: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:47.715826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:48.715887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:49.200: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:49.716259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:50.716512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:51.205: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:51.717148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:52.717343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:53.209: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:53.717746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:54.717944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:55.215: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:55.718697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:56.718785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:57.220: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:57.718862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:08:58.719162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:08:59.225: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:08:59.719970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:00.720211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:01.230: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:01.721055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:02.721143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:03.235: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:03.721537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:04.721763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:05.240: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:05.722727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:06.722951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:07.243: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:07.723917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:08.724027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:09.248: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:09.724727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:10.724826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:11.252: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:11.725592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:12.725763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:13.255: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:13.726588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:14.727517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:15.260: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:15.728258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:16.729119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:17.264: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:17.729732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:18.729824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:19.268: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:19.730456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:20.730733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:21.272: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:21.731444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:22.732227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:23.277: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:23.732968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:24.733055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:25.282: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:25.733852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:26.733950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:27.288: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:27.734833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:28.734916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:29.293: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:29.735561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:30.735659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:31.298: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:31.736243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:32.737297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:33.303: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:33.738289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:34.738885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:35.309: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:35.739497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:36.739584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:37.313: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:37.739831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:38.739948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:39.318: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:39.740834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:40.740988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:41.322: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:41.741083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:42.741312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:43.327: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:43.742355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:44.742475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:45.333: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:45.742752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:46.742989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:47.336: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:47.743568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:48.744219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:49.341: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:49.745185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:50.745418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:51.346: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:51.745520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:52.746063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:53.351: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:53.746363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:54.746469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:55.355: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:55.747336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:56.748334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:57.359: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:57.748507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:09:58.748681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:09:59.364: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:09:59.749115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:00.749292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:01.368: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:01.750202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:02.750544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:03.373: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:03.750961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:04.751152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:05.378: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:05.751943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:06.752295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:07.383: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:07.752584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:08.752678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:09.388: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:09.753641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:10.753833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:11.392: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:11.754422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:12.755329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:13.398: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:13.756152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:14.756383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:15.402: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:15.757189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:16.757638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:17.408: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:17.758691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:18.758777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:19.412: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:19.759482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:20.760225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:21.417: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:21.760321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:22.761350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:23.422: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:23.761836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:24.761989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:25.426: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:25.762091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:26.762166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:27.431: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:27.762996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:28.763178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:29.436: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:29.764144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:30.764546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:31.441: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:31.764834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:32.765215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:33.446: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:33.765428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:34.765515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:35.451: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:35.765725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:36.765909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:37.456: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:37.766734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:38.766829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:39.461: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:39.767172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:40.768233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:41.466: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:41.769042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:42.769328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:43.471: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:43.769867      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:44.770075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:45.476: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:45.770599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:46.770696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:47.480: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:47.770761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:48.770796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:49.485: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:49.771149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:50.771173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:51.490: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:51.771830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:52.772223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:53.494: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:53.772835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:54.773055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:55.499: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:55.773754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:56.773846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:57.504: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:57.774660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:10:58.774753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:10:59.508: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:10:59.775152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:00.775250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:01.513: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:01.776235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:02.776264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:03.518: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:03.776832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:04.776930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:05.522: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:05.777386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:06.777501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:07.526: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:07.778286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:08.778376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:09.531: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:09.778672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:10.778851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:11.534: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:11.779074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:12.779321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:13.539: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:13.779420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:14.779503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:15.544: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:15.780220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:16.780336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:17.548: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:17.780867      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:18.781055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:19.553: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:19.781590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:20.781853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:21.556: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:21.781962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:22.782878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:23.561: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:23.783550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:24.783642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:25.565: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:25.784219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:26.784620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:27.571: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:27.785597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:28.785732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:29.575: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:29.786133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:30.786304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:31.580: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:31.786568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:32.786869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:33.586: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:33.787621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:34.787721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:35.590: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:35.788447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:36.788548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:37.594: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:37.788618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:38.788708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:39.599: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:39.789002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:40.789096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:41.604: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:41.789821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:42.789923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:43.609: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:43.790985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:44.791165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:45.614: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:45.792238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:46.792322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:47.619: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:47.792592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:48.792898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:49.624: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:49.793774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:50.794017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:51.629: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:51.794517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:52.794853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:53.634: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:53.795713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:54.796222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:55.638: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:55.796967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:56.797161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:57.643: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:57.798197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:11:58.798301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:11:59.649: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:11:59.798591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:00.798796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:01.654: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:12:01.799753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:02.800329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:03.660: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:12:03.801381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:04.801469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:05.665: INFO: Get pod test-grpc-44594bf2-0973-41d8-a828-6ad92bb687ac in namespace container-probe-2950
  E0518 13:12:05.802804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:06.802858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/18/24 13:12:07.665
  May 18 13:12:07.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2950" for this suite. @ 05/18/24 13:12:07.684
• [242.635 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 05/18/24 13:12:07.689
  May 18 13:12:07.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubelet-test @ 05/18/24 13:12:07.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:07.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:07.709
  May 18 13:12:07.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7503" for this suite. @ 05/18/24 13:12:07.738
• [0.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 05/18/24 13:12:07.747
  May 18 13:12:07.747: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption @ 05/18/24 13:12:07.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:07.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:07.773
  STEP: Creating a kubernetes client @ 05/18/24 13:12:07.776
  May 18 13:12:07.776: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption-2 @ 05/18/24 13:12:07.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:07.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:07.795
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:12:07.802
  E0518 13:12:07.803016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:08.803180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:09.803221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:12:09.814
  E0518 13:12:10.804200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:11.804308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:12:11.823
  E0518 13:12:12.804915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:13.805089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 05/18/24 13:12:13.828
  STEP: listing a collection of PDBs in namespace disruption-4931 @ 05/18/24 13:12:13.832
  STEP: deleting a collection of PDBs @ 05/18/24 13:12:13.835
  STEP: Waiting for the PDB collection to be deleted @ 05/18/24 13:12:13.847
  May 18 13:12:13.850: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-3569" for this suite. @ 05/18/24 13:12:13.853
  May 18 13:12:13.861: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4931" for this suite. @ 05/18/24 13:12:13.864
• [6.125 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 05/18/24 13:12:13.872
  May 18 13:12:13.872: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 13:12:13.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:13.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:13.901
  STEP: Creating a job @ 05/18/24 13:12:13.904
  STEP: Ensuring active pods == parallelism @ 05/18/24 13:12:13.91
  E0518 13:12:14.805210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:15.805398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 05/18/24 13:12:15.916
  May 18 13:12:16.432: INFO: Successfully updated pod "adopt-release-fshfr"
  STEP: Checking that the Job readopts the Pod @ 05/18/24 13:12:16.432
  E0518 13:12:16.806049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:17.806558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 05/18/24 13:12:18.442
  E0518 13:12:18.806660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:18.953: INFO: Successfully updated pod "adopt-release-fshfr"
  STEP: Checking that the Job releases the Pod @ 05/18/24 13:12:18.953
  E0518 13:12:19.806947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:20.807065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:20.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4381" for this suite. @ 05/18/24 13:12:20.967
• [7.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 05/18/24 13:12:20.973
  May 18 13:12:20.973: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:12:20.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:20.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:20.992
  STEP: Creating configMap with name projected-configmap-test-volume-map-c0acf353-0d45-4846-bd12-8330576fb120 @ 05/18/24 13:12:20.995
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:12:21.002
  E0518 13:12:21.807140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:22.807381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:23.808258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:24.808843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:12:25.027
  May 18 13:12:25.031: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-projected-configmaps-a30d5e1b-cf73-4ce4-a852-0f13d56147b2 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:12:25.04
  May 18 13:12:25.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3836" for this suite. @ 05/18/24 13:12:25.061
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/18/24 13:12:25.069
  May 18 13:12:25.069: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:12:25.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:25.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:25.088
  STEP: creating the pod @ 05/18/24 13:12:25.091
  STEP: submitting the pod to kubernetes @ 05/18/24 13:12:25.091
  W0518 13:12:25.098361      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0518 13:12:25.809127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:26.809308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/18/24 13:12:27.108
  STEP: updating the pod @ 05/18/24 13:12:27.111
  May 18 13:12:27.624: INFO: Successfully updated pod "pod-update-activedeadlineseconds-188292b4-a784-4e48-9dbc-59655b0db856"
  E0518 13:12:27.809623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:28.809690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:29.809819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:30.809919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:12:31.636: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6138" for this suite. @ 05/18/24 13:12:31.639
• [6.577 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/18/24 13:12:31.646
  May 18 13:12:31.646: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename cronjob @ 05/18/24 13:12:31.647
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:12:31.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:12:31.667
  STEP: Creating a suspended cronjob @ 05/18/24 13:12:31.669
  STEP: Ensuring no jobs are scheduled @ 05/18/24 13:12:31.673
  E0518 13:12:31.810011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:32.810912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:33.811511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:34.812363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:35.813213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:36.813312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:37.813823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:38.813886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:39.814014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:40.814105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:41.814943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:42.815931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:43.816470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:44.816647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:45.817415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:46.817501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:47.817741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:48.817833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:49.818596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:50.818700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:51.818745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:52.818945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:53.819260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:54.819455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:55.819731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:56.819796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:57.820208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:58.820303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:12:59.820407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:00.820591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:01.821246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:02.821299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:03.821756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:04.821852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:05.822030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:06.822628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:07.822695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:08.822958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:09.823013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:10.823168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:11.823633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:12.823936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:13.823991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:14.824253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:15.825204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:16.825305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:17.826285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:18.826622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:19.827083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:20.827252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:21.828237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:22.828517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:23.829384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:24.829604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:25.830194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:26.830286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:27.830939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:28.831157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:29.831716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:30.831792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:31.832553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:32.832873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:33.832975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:34.833700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:35.834316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:36.834492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:37.835255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:38.836243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:39.836851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:40.836951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:41.837976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:42.838271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:43.839007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:44.839160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:45.839718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:46.839820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:47.840451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:48.840637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:49.841652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:50.842577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:51.843630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:52.843938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:53.844671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:54.844852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:55.845662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:56.845852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:57.846820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:58.846982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:13:59.847535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:00.847679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:01.848724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:02.848963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:03.849156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:04.849318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:05.849884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:06.850072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:07.850167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:08.850354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:09.850992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:10.851179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:11.851750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:12.852372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:13.853139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:14.853230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:15.854084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:16.854247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:17.855076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:18.855197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:19.855368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:20.856247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:21.857082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:22.857965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:23.858580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:24.858753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:25.859727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:26.859825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:27.860469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:28.860707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:29.861264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:30.861445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:31.862341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:32.863413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:33.864095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:34.864285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:35.864761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:36.864920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:37.865704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:38.865833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:39.865919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:40.866558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:41.866962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:42.866987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:43.867052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:44.867183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:45.868244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:46.868721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:47.868756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:48.868928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:49.869065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:50.869151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:51.869905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:52.870878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:53.871388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:54.871654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:55.871648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:56.871991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:57.872084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:58.872177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:14:59.872823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:00.873841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:01.874628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:02.875028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:03.875785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:04.875862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:05.876768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:06.876919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:07.877376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:08.877557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:09.877973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:10.878577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:11.879551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:12.880000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:13.880667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:14.880752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:15.880841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:16.881029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:17.881809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:18.881950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:19.882406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:20.882651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:21.883689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:22.884014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:23.884222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:24.884325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:25.884903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:26.885002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:27.885975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:28.886071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:29.886912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:30.887162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:31.887813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:32.888234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:33.889244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:34.889434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:35.889969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:36.890143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:37.890970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:38.891164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:39.891885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:40.892191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:41.892790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:42.893046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:43.893098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:44.893266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:45.894219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:46.894346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:47.894459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:48.894632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:49.894989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:50.895159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:51.895640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:52.895989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:53.896658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:54.896752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:55.897616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:56.897720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:57.898609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:58.899150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:15:59.899175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:00.900228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:01.901110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:02.901415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:03.902138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:04.902318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:05.902479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:06.902675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:07.902742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:08.903779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:09.904637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:10.904829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:11.904987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:12.905105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:13.905941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:14.906209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:15.906791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:16.907068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:17.907139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:18.907222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:19.907645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:20.907737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:21.908227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:22.908418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:23.908502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:24.908767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:25.908853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:26.909037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:27.909531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:28.909756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:29.910452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:30.910630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:31.911065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:32.912027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:33.912797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:34.913003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:35.913081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:36.913173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:37.913268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:38.913679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:39.914372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:40.914555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:41.915108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:42.916293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:43.916966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:44.917067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:45.917552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:46.917649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:47.917970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:48.918070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:49.918945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:50.919061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:51.919950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:52.920058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:53.920640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:54.920844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:55.920937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:56.921333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:57.921986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:58.922256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:16:59.922851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:00.922945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:01.923471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:02.923907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:03.924633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:04.924880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:05.925665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:06.925759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:07.926646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:08.926731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:09.926835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:10.927075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:11.927756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:12.928599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:13.929071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:14.929601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:15.930028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:16.930195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:17.930764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:18.930992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:19.931882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:20.932250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:21.933281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:22.933369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:23.934333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:24.934516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:25.935421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:26.935514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:27.935596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:28.936226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:29.936949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:30.937141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/18/24 13:17:31.68
  STEP: Removing cronjob @ 05/18/24 13:17:31.684
  May 18 13:17:31.690: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5661" for this suite. @ 05/18/24 13:17:31.693
• [300.053 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 05/18/24 13:17:31.699
  May 18 13:17:31.699: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:17:31.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:31.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:31.719
  STEP: Setting up server cert @ 05/18/24 13:17:31.75
  E0518 13:17:31.937965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:17:32.097
  STEP: Deploying the webhook pod @ 05/18/24 13:17:32.105
  STEP: Wait for the deployment to be ready @ 05/18/24 13:17:32.117
  May 18 13:17:32.125: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 13:17:32.939065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:33.939247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:17:34.136
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:17:34.147
  E0518 13:17:34.939577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:17:35.148: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 18 13:17:35.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7655-crds.webhook.example.com via the AdmissionRegistration API @ 05/18/24 13:17:35.665
  STEP: Creating a custom resource while v1 is storage version @ 05/18/24 13:17:35.68
  E0518 13:17:35.940235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:36.940406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/18/24 13:17:37.711
  STEP: Patching the custom resource while v2 is storage version @ 05/18/24 13:17:37.723
  E0518 13:17:37.940787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:17:38.310: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7937" for this suite. @ 05/18/24 13:17:38.315
  STEP: Destroying namespace "webhook-markers-6840" for this suite. @ 05/18/24 13:17:38.321
• [6.628 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:335
  STEP: Creating a kubernetes client @ 05/18/24 13:17:38.328
  May 18 13:17:38.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-pred @ 05/18/24 13:17:38.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:38.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:38.346
  May 18 13:17:38.349: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  May 18 13:17:38.355: INFO: Waiting for terminating namespaces to be deleted...
  May 18 13:17:38.358: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-33-93 before test
  May 18 13:17:38.361: INFO: nginx-ingress-controller-kubernetes-worker-9sx8w from ingress-nginx-kubernetes-worker started at 2024-05-18 12:57:48 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.361: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 13:17:38.361: INFO: calico-node-jt76w from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.361: INFO: 	Container calico-node ready: true, restart count 0
  May 18 13:17:38.361: INFO: sonobuoy from sonobuoy started at 2024-05-18 12:05:55 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.361: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  May 18 13:17:38.361: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-qg8tv from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 13:17:38.361: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 13:17:38.361: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 13:17:38.361: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-70-23 before test
  May 18 13:17:38.366: INFO: nginx-ingress-controller-kubernetes-worker-cwhst from ingress-nginx-kubernetes-worker started at 2024-05-18 12:02:05 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.366: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 13:17:38.366: INFO: calico-node-8tp4g from kube-system started at 2024-05-18 12:01:55 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.366: INFO: 	Container calico-node ready: true, restart count 0
  May 18 13:17:38.366: INFO: sonobuoy-e2e-job-9640b063a5a74f87 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 13:17:38.366: INFO: 	Container e2e ready: true, restart count 0
  May 18 13:17:38.366: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 13:17:38.366: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-hmcm6 from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 13:17:38.366: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 13:17:38.366: INFO: 	Container systemd-logs ready: true, restart count 0
  May 18 13:17:38.366: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-90-158 before test
  May 18 13:17:38.372: INFO: nginx-ingress-controller-kubernetes-worker-4cg9g from ingress-nginx-kubernetes-worker started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.372: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  May 18 13:17:38.372: INFO: calico-node-5dtrz from kube-system started at 2024-05-18 12:02:50 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.372: INFO: 	Container calico-node ready: true, restart count 0
  May 18 13:17:38.372: INFO: coredns-bddfd76d7-gv2bt from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.372: INFO: 	Container coredns ready: true, restart count 0
  May 18 13:17:38.372: INFO: kube-state-metrics-6f48cdd76-glkfx from kube-system started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.373: INFO: 	Container kube-state-metrics ready: true, restart count 0
  May 18 13:17:38.373: INFO: metrics-server-v0.6.3-69d7fbfdf8-thw8r from kube-system started at 2024-05-18 11:56:31 +0000 UTC (2 container statuses recorded)
  May 18 13:17:38.373: INFO: 	Container metrics-server ready: true, restart count 0
  May 18 13:17:38.373: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  May 18 13:17:38.373: INFO: dashboard-metrics-scraper-5dd7cb5fc-ks9g5 from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.373: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  May 18 13:17:38.373: INFO: kubernetes-dashboard-7b899cb9d9-4z7gj from kubernetes-dashboard started at 2024-05-18 11:56:31 +0000 UTC (1 container statuses recorded)
  May 18 13:17:38.373: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  May 18 13:17:38.373: INFO: sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-l9qkt from sonobuoy started at 2024-05-18 12:05:57 +0000 UTC (2 container statuses recorded)
  May 18 13:17:38.373: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  May 18 13:17:38.373: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-33-93 @ 05/18/24 13:17:38.388
  STEP: verifying the node has the label node ip-172-31-70-23 @ 05/18/24 13:17:38.401
  STEP: verifying the node has the label node ip-172-31-90-158 @ 05/18/24 13:17:38.412
  May 18 13:17:38.424: INFO: Pod nginx-ingress-controller-kubernetes-worker-4cg9g requesting resource cpu=0m on Node ip-172-31-90-158
  May 18 13:17:38.424: INFO: Pod nginx-ingress-controller-kubernetes-worker-9sx8w requesting resource cpu=0m on Node ip-172-31-33-93
  May 18 13:17:38.424: INFO: Pod nginx-ingress-controller-kubernetes-worker-cwhst requesting resource cpu=0m on Node ip-172-31-70-23
  May 18 13:17:38.424: INFO: Pod calico-node-5dtrz requesting resource cpu=250m on Node ip-172-31-90-158
  May 18 13:17:38.424: INFO: Pod calico-node-8tp4g requesting resource cpu=250m on Node ip-172-31-70-23
  May 18 13:17:38.424: INFO: Pod calico-node-jt76w requesting resource cpu=250m on Node ip-172-31-33-93
  May 18 13:17:38.424: INFO: Pod coredns-bddfd76d7-gv2bt requesting resource cpu=100m on Node ip-172-31-90-158
  May 18 13:17:38.424: INFO: Pod kube-state-metrics-6f48cdd76-glkfx requesting resource cpu=0m on Node ip-172-31-90-158
  May 18 13:17:38.424: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-thw8r requesting resource cpu=5m on Node ip-172-31-90-158
  May 18 13:17:38.424: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-ks9g5 requesting resource cpu=0m on Node ip-172-31-90-158
  May 18 13:17:38.425: INFO: Pod kubernetes-dashboard-7b899cb9d9-4z7gj requesting resource cpu=0m on Node ip-172-31-90-158
  May 18 13:17:38.425: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-33-93
  May 18 13:17:38.425: INFO: Pod sonobuoy-e2e-job-9640b063a5a74f87 requesting resource cpu=0m on Node ip-172-31-70-23
  May 18 13:17:38.425: INFO: Pod sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-hmcm6 requesting resource cpu=0m on Node ip-172-31-70-23
  May 18 13:17:38.425: INFO: Pod sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-l9qkt requesting resource cpu=0m on Node ip-172-31-90-158
  May 18 13:17:38.425: INFO: Pod sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-qg8tv requesting resource cpu=0m on Node ip-172-31-33-93
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/18/24 13:17:38.425
  May 18 13:17:38.425: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-33-93
  May 18 13:17:38.433: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-70-23
  May 18 13:17:38.440: INFO: Creating a pod which consumes cpu=1151m on Node ip-172-31-90-158
  E0518 13:17:38.940898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:39.941084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/18/24 13:17:40.467
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f.17d097b440277db6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7723/filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f to ip-172-31-90-158] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f.17d097b45fdb4107], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f.17d097b46109e120], Reason = [Created], Message = [Created container filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f.17d097b46407a5f7], Reason = [Started], Message = [Started container filler-pod-564360b5-c30c-43e2-902e-044aa0eea58f] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b.17d097b43fd5ce9b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7723/filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b to ip-172-31-70-23] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b.17d097b45cec77e4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b.17d097b45debc463], Reason = [Created], Message = [Created container filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b.17d097b460a153ab], Reason = [Started], Message = [Started container filler-pod-674c338f-3124-4803-8cc8-ddbb3166994b] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce.17d097b43f606115], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7723/filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce to ip-172-31-33-93] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce.17d097b45f444eb8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce.17d097b4603af5f2], Reason = [Created], Message = [Created container filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce.17d097b463694fe7], Reason = [Started], Message = [Started container filler-pod-c7041e08-d05f-4a83-885b-89fb30eb7fce] @ 05/18/24 13:17:40.47
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17d097b4b8cb90fa], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 05/18/24 13:17:40.485
  E0518 13:17:40.941310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-33-93 @ 05/18/24 13:17:41.483
  STEP: verifying the node doesn't have the label node @ 05/18/24 13:17:41.494
  STEP: removing the label node off the node ip-172-31-70-23 @ 05/18/24 13:17:41.499
  STEP: verifying the node doesn't have the label node @ 05/18/24 13:17:41.511
  STEP: removing the label node off the node ip-172-31-90-158 @ 05/18/24 13:17:41.517
  STEP: verifying the node doesn't have the label node @ 05/18/24 13:17:41.529
  May 18 13:17:41.533: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7723" for this suite. @ 05/18/24 13:17:41.537
• [3.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 05/18/24 13:17:41.546
  May 18 13:17:41.546: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename disruption @ 05/18/24 13:17:41.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:41.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:41.566
  STEP: creating the pdb @ 05/18/24 13:17:41.568
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:17:41.573
  E0518 13:17:41.941661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:42.942249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 05/18/24 13:17:43.578
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:17:43.587
  E0518 13:17:43.942713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:44.942817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 05/18/24 13:17:45.591
  STEP: Waiting for the pdb to be processed @ 05/18/24 13:17:45.6
  E0518 13:17:45.943277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:46.943420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 05/18/24 13:17:47.61
  May 18 13:17:47.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7752" for this suite. @ 05/18/24 13:17:47.619
• [6.079 seconds]
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 05/18/24 13:17:47.625
  May 18 13:17:47.625: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:17:47.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:47.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:47.649
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:17:47.692
  E0518 13:17:47.944005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:48.944088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:49.944490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:50.944553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:17:51.717
  May 18 13:17:51.720: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-ef1ed1a2-7011-4fad-a102-431b3c20244d container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:17:51.74
  May 18 13:17:51.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7394" for this suite. @ 05/18/24 13:17:51.761
• [4.142 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 05/18/24 13:17:51.767
  May 18 13:17:51.767: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 13:17:51.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:51.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:51.786
  STEP: Updating Namespace "namespaces-8577" @ 05/18/24 13:17:51.788
  May 18 13:17:51.796: INFO: Namespace "namespaces-8577" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"27a801cb-a3ce-417b-86ca-2e2c2343835c", "kubernetes.io/metadata.name":"namespaces-8577", "namespaces-8577":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  May 18 13:17:51.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8577" for this suite. @ 05/18/24 13:17:51.799
• [0.038 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 05/18/24 13:17:51.805
  May 18 13:17:51.805: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:17:51.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:51.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:51.824
  STEP: validating api versions @ 05/18/24 13:17:51.827
  May 18 13:17:51.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-8465 api-versions'
  May 18 13:17:51.866: INFO: stderr: ""
  May 18 13:17:51.866: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  May 18 13:17:51.866: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8465" for this suite. @ 05/18/24 13:17:51.869
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 05/18/24 13:17:51.877
  May 18 13:17:51.877: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 13:17:51.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:17:51.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:17:51.895
  STEP: Creating service test in namespace statefulset-1870 @ 05/18/24 13:17:51.898
  STEP: Creating a new StatefulSet @ 05/18/24 13:17:51.905
  May 18 13:17:51.914: INFO: Found 0 stateful pods, waiting for 3
  E0518 13:17:51.945438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:52.945783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:53.945880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:54.946732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:55.946844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:56.946908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:57.947096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:58.947204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:17:59.947396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:00.947491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:18:01.915: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:18:01.915: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:18:01.915: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/18/24 13:18:01.925
  May 18 13:18:01.945: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 05/18/24 13:18:01.945
  E0518 13:18:01.947537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:02.948065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:03.948145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:04.948213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:05.948352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:06.949224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:07.949666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:08.949725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:09.949808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:10.949878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:11.949995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/18/24 13:18:11.953
  STEP: Performing a canary update @ 05/18/24 13:18:11.954
  May 18 13:18:11.973: INFO: Updating stateful set ss2
  May 18 13:18:11.984: INFO: Waiting for Pod statefulset-1870/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0518 13:18:12.950383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:13.950567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:14.950660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:15.950749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:16.950821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:17.950957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:18.951094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:19.951182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:20.951299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:21.951403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/18/24 13:18:21.981
  May 18 13:18:22.017: INFO: Found 2 stateful pods, waiting for 3
  E0518 13:18:22.951444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:23.951548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:24.952281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:25.952547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:26.952750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:27.952876      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:28.952993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:29.953123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:30.953200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:31.953328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:18:32.018: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:18:32.018: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:18:32.018: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/18/24 13:18:32.025
  May 18 13:18:32.045: INFO: Updating stateful set ss2
  May 18 13:18:32.056: INFO: Waiting for Pod statefulset-1870/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0518 13:18:32.954162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:33.954351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:34.954443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:35.954562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:36.954776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:37.954881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:38.954973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:39.955181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:40.955300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:41.956236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:18:42.073: INFO: Updating stateful set ss2
  May 18 13:18:42.079: INFO: Waiting for StatefulSet statefulset-1870/ss2 to complete update
  May 18 13:18:42.079: INFO: Waiting for Pod statefulset-1870/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0518 13:18:42.956953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:43.957138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:44.957406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:45.957512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:46.957610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:47.957968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:48.958087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:49.958173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:50.958695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:51.958815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:18:52.080: INFO: Deleting all statefulset in ns statefulset-1870
  May 18 13:18:52.084: INFO: Scaling statefulset ss2 to 0
  E0518 13:18:52.958928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:53.959028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:54.959489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:55.959297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:56.959383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:57.959709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:58.960230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:18:59.960872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:00.960975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:01.961163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:02.100: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 13:19:02.104: INFO: Deleting statefulset ss2
  May 18 13:19:02.117: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1870" for this suite. @ 05/18/24 13:19:02.122
• [70.253 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/18/24 13:19:02.13
  May 18 13:19:02.130: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subjectreview @ 05/18/24 13:19:02.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:02.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:02.149
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-5459" @ 05/18/24 13:19:02.152
  May 18 13:19:02.156: INFO: saUsername: "system:serviceaccount:subjectreview-5459:e2e"
  May 18 13:19:02.156: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-5459"}
  May 18 13:19:02.156: INFO: saUID: "8b45818d-8300-4a6f-b4c6-bf09f35e608d"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-5459:e2e" @ 05/18/24 13:19:02.156
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-5459:e2e" @ 05/18/24 13:19:02.156
  May 18 13:19:02.158: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-5459:e2e" api 'list' configmaps in "subjectreview-5459" namespace @ 05/18/24 13:19:02.158
  May 18 13:19:02.159: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-5459:e2e" @ 05/18/24 13:19:02.159
  May 18 13:19:02.162: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  May 18 13:19:02.162: INFO: LocalSubjectAccessReview has been verified
  May 18 13:19:02.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-5459" for this suite. @ 05/18/24 13:19:02.165
• [0.043 seconds]
------------------------------
SSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/18/24 13:19:02.172
  May 18 13:19:02.172: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename prestop @ 05/18/24 13:19:02.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:02.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:02.193
  STEP: Creating server pod server in namespace prestop-9390 @ 05/18/24 13:19:02.196
  STEP: Waiting for pods to come up. @ 05/18/24 13:19:02.203
  E0518 13:19:02.962080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:03.962237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-9390 @ 05/18/24 13:19:04.214
  E0518 13:19:04.962758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:05.963066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 05/18/24 13:19:06.227
  E0518 13:19:06.963166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:07.963669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:08.963767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:09.963842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:10.963921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:11.244: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/18/24 13:19:11.244
  May 18 13:19:11.258: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-9390" for this suite. @ 05/18/24 13:19:11.262
• [9.097 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 05/18/24 13:19:11.269
  May 18 13:19:11.269: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 13:19:11.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:11.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:11.287
  E0518 13:19:11.964027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:12.964039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/18/24 13:19:13.314
  May 18 13:19:13.314: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3967 pod-service-account-2e4def11-0082-4a1d-8354-09b83087b21d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/18/24 13:19:13.418
  May 18 13:19:13.418: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3967 pod-service-account-2e4def11-0082-4a1d-8354-09b83087b21d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/18/24 13:19:13.506
  May 18 13:19:13.506: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3967 pod-service-account-2e4def11-0082-4a1d-8354-09b83087b21d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  May 18 13:19:13.603: INFO: Got root ca configmap in namespace "svcaccounts-3967"
  May 18 13:19:13.605: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3967" for this suite. @ 05/18/24 13:19:13.611
• [2.349 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 05/18/24 13:19:13.618
  May 18 13:19:13.618: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:19:13.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:13.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:13.64
  STEP: Creating configMap with name projected-configmap-test-volume-map-84ca7a6a-58ef-4827-b4df-b94fe0640a83 @ 05/18/24 13:19:13.643
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:19:13.647
  E0518 13:19:13.964076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:14.964154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:15.965144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:16.965357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:19:17.676
  May 18 13:19:17.679: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-configmaps-b9d8ab86-1027-42ce-af98-69739c8ac467 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:19:17.686
  May 18 13:19:17.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3063" for this suite. @ 05/18/24 13:19:17.797
• [4.185 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 05/18/24 13:19:17.803
  May 18 13:19:17.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/18/24 13:19:17.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:17.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:17.823
  E0518 13:19:17.966081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:18.966204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 05/18/24 13:19:19.858
  STEP: Cleaning up the configmap @ 05/18/24 13:19:19.864
  STEP: Cleaning up the pod @ 05/18/24 13:19:19.869
  May 18 13:19:19.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-8365" for this suite. @ 05/18/24 13:19:19.886
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 05/18/24 13:19:19.892
  May 18 13:19:19.892: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pv @ 05/18/24 13:19:19.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:19.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:19.912
  STEP: Creating initial PV and PVC @ 05/18/24 13:19:19.915
  May 18 13:19:19.915: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3126" @ 05/18/24 13:19:19.928
  STEP: Listing PVCs in namespace "pv-3126" @ 05/18/24 13:19:19.931
  STEP: Patching the PV "pv-3126-c6z6l" @ 05/18/24 13:19:19.935
  STEP: Patching the PVC "pvc-bz846" @ 05/18/24 13:19:19.946
  STEP: Getting PV "pv-3126-c6z6l" @ 05/18/24 13:19:19.953
  STEP: Getting PVC "pvc-bz846" @ 05/18/24 13:19:19.955
  STEP: Deleting PVC "pvc-bz846" @ 05/18/24 13:19:19.958
  E0518 13:19:19.966963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Confirm deletion of PVC "pvc-bz846" @ 05/18/24 13:19:19.967
  E0518 13:19:20.967373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:21.967552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-3126-c6z6l" @ 05/18/24 13:19:21.976
  STEP: Confirm deletion of PV "pv-3126-c6z6l" @ 05/18/24 13:19:21.983
  E0518 13:19:22.968518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:23.969255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/18/24 13:19:23.99
  May 18 13:19:23.990: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-3126-vbbhv" @ 05/18/24 13:19:24.001
  STEP: Updating the PVC "pvc-jvvh2" @ 05/18/24 13:19:24.009
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-jvvh2=updated" @ 05/18/24 13:19:24.017
  STEP: Deleting PVC "pvc-jvvh2" via DeleteCollection @ 05/18/24 13:19:24.02
  STEP: Confirm deletion of PVC "pvc-jvvh2" @ 05/18/24 13:19:24.029
  E0518 13:19:24.969351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:25.969692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-3126-vbbhv" via DeleteCollection @ 05/18/24 13:19:26.037
  STEP: Confirm deletion of PV "pv-3126-vbbhv" @ 05/18/24 13:19:26.046
  E0518 13:19:26.970011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:27.970065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:28.053: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May 18 13:19:28.053: INFO: Deleting PersistentVolumeClaim "pvc-jvvh2"
  May 18 13:19:28.056: INFO: Deleting PersistentVolume "pv-3126-vbbhv"
  May 18 13:19:28.059: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3126" for this suite. @ 05/18/24 13:19:28.064
• [8.179 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 05/18/24 13:19:28.071
  May 18 13:19:28.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:19:28.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:28.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:28.091
  STEP: Creating configMap with name projected-configmap-test-volume-7bbc96a4-1903-47af-80cc-d2c34795c0e5 @ 05/18/24 13:19:28.096
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:19:28.099
  E0518 13:19:28.970156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:29.970244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:19:30.116
  May 18 13:19:30.121: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-configmaps-95894adc-a374-4374-ab97-8fd27928a623 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:19:30.127
  May 18 13:19:30.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9418" for this suite. @ 05/18/24 13:19:30.15
• [2.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 05/18/24 13:19:30.157
  May 18 13:19:30.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pv @ 05/18/24 13:19:30.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:30.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:30.178
  STEP: Creating initial PV and PVC @ 05/18/24 13:19:30.181
  May 18 13:19:30.181: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6701" @ 05/18/24 13:19:30.196
  STEP: Listing PVCs in namespace "pv-6701" @ 05/18/24 13:19:30.199
  STEP: Reading "pvc-r95jl" Status @ 05/18/24 13:19:30.202
  STEP: Reading "pv-6701-jt7xh" Status @ 05/18/24 13:19:30.206
  STEP: Patching "pvc-r95jl" Status @ 05/18/24 13:19:30.211
  STEP: Patching "pv-6701-jt7xh" Status @ 05/18/24 13:19:30.226
  STEP: Updating "pvc-r95jl" Status @ 05/18/24 13:19:30.231
  STEP: Updating "pv-6701-jt7xh" Status @ 05/18/24 13:19:30.242
  May 18 13:19:30.250: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  May 18 13:19:30.250: INFO: Deleting PersistentVolumeClaim "pvc-r95jl"
  May 18 13:19:30.257: INFO: Deleting PersistentVolume "pv-6701-jt7xh"
  May 18 13:19:30.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6701" for this suite. @ 05/18/24 13:19:30.265
• [0.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 05/18/24 13:19:30.27
  May 18 13:19:30.270: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 13:19:30.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:30.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:30.29
  STEP: Creating configMap with name configmap-test-volume-4799753a-7a15-4186-994b-4bc93ddf5fb2 @ 05/18/24 13:19:30.293
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:19:30.298
  E0518 13:19:30.971015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:31.971180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:32.972065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:33.972167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:19:34.319
  May 18 13:19:34.321: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-c0e52795-a10e-4df7-84a7-76b21258246b container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:19:34.329
  May 18 13:19:34.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2539" for this suite. @ 05/18/24 13:19:34.348
• [4.084 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 05/18/24 13:19:34.355
  May 18 13:19:34.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:19:34.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:34.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:34.376
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:19:34.379
  E0518 13:19:34.972267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:35.972364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:36.972428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:37.972525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:19:38.403
  May 18 13:19:38.407: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-3c4616cc-e7ed-471b-9382-7eb61c4aba9e container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:19:38.414
  May 18 13:19:38.430: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3448" for this suite. @ 05/18/24 13:19:38.433
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/18/24 13:19:38.441
  May 18 13:19:38.441: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 13:19:38.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:38.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:38.464
  May 18 13:19:38.466: INFO: Creating deployment "test-recreate-deployment"
  May 18 13:19:38.470: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  May 18 13:19:38.477: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0518 13:19:38.973342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:39.973522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:40.485: INFO: Waiting deployment "test-recreate-deployment" to complete
  May 18 13:19:40.487: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  May 18 13:19:40.496: INFO: Updating deployment test-recreate-deployment
  May 18 13:19:40.497: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  May 18 13:19:40.604: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1070",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9b2943c4-5c97-4590-ab8c-95c96fc99a5f",
      ResourceVersion: (string) (len=5) "33878",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 13:19:40.609: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1070",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de028fea-3044-41f4-ab4f-435c4c74b222",
      ResourceVersion: (string) (len=5) "33876",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "9b2943c4-5c97-4590-ab8c-95c96fc99a5f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 62 32 39 34 33  63 34 2d 35 63 39 37 2d  |\"9b2943c4-5c97-|
              00000120  34 35 39 30 2d 61 62 38  63 2d 39 35 63 39 36 66  |4590-ab8c-95c96f|
              00000130  63 39 39 61 35 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c99a5f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 13:19:40.610: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  May 18 13:19:40.610: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1070",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7e3a2560-8c23-4186-8093-a4c7b5cf5d68",
      ResourceVersion: (string) (len=5) "33866",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "9b2943c4-5c97-4590-ab8c-95c96fc99a5f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 62 32 39 34 33  63 34 2d 35 63 39 37 2d  |\"9b2943c4-5c97-|
              00000120  34 35 39 30 2d 61 62 38  63 2d 39 35 63 39 36 66  |4590-ab8c-95c96f|
              00000130  63 39 39 61 35 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c99a5f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 13:19:40.615: INFO: Pod "test-recreate-deployment-76fb77d45-x5tvc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-x5tvc",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-1070",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "49080f2c-4fc4-40be-b82e-8fea72b4151d",
      ResourceVersion: (string) (len=5) "33877",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "de028fea-3044-41f4-ab4f-435c4c74b222",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 65  30 32 38 66 65 61 2d 33  |d\":\"de028fea-3|
              00000090  30 34 34 2d 34 31 66 34  2d 61 62 34 66 2d 34 33  |044-41f4-ab4f-43|
              000000a0  35 63 34 63 37 34 62 32  32 32 5c 22 7d 22 3a 7b  |5c4c74b222\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dmmhf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dmmhf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 13:19:40.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1070" for this suite. @ 05/18/24 13:19:40.621
• [2.188 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/18/24 13:19:40.63
  May 18 13:19:40.630: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 13:19:40.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:40.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:40.649
  May 18 13:19:40.669: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/18/24 13:19:40.674
  May 18 13:19:40.677: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:40.677: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/18/24 13:19:40.677
  May 18 13:19:40.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:40.695: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:19:40.974234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:41.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:41.696: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:19:41.974705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:42.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 13:19:42.696: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/18/24 13:19:42.699
  May 18 13:19:42.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 13:19:42.715: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0518 13:19:42.974828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:43.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:43.715: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/18/24 13:19:43.715
  May 18 13:19:43.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:43.727: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:19:43.975836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:44.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:44.727: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:19:44.976462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:45.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  May 18 13:19:45.727: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 13:19:45.733
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4672, will wait for the garbage collector to delete the pods @ 05/18/24 13:19:45.733
  May 18 13:19:45.794: INFO: Deleting DaemonSet.extensions daemon-set took: 7.454553ms
  May 18 13:19:45.895: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.010171ms
  E0518 13:19:45.976560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:46.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:19:46.899: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 13:19:46.902: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33995"},"items":null}

  May 18 13:19:46.905: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33995"},"items":null}

  May 18 13:19:46.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4672" for this suite. @ 05/18/24 13:19:46.931
• [6.308 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 05/18/24 13:19:46.938
  May 18 13:19:46.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 13:19:46.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:46.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:46.963
  STEP: Creating configMap configmap-2329/configmap-test-a899d32e-3860-45e0-b694-8a4c42dbc6bf @ 05/18/24 13:19:46.965
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:19:46.97
  E0518 13:19:46.977267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:47.978094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:48.978874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:49.978912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:50.979523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:19:50.991
  May 18 13:19:50.995: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-configmaps-e923c211-b941-4862-90d9-9026d021e37a container env-test: <nil>
  STEP: delete the pod @ 05/18/24 13:19:51.002
  May 18 13:19:51.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2329" for this suite. @ 05/18/24 13:19:51.021
• [4.089 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/18/24 13:19:51.027
  May 18 13:19:51.027: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename limitrange @ 05/18/24 13:19:51.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:51.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:51.049
  STEP: Creating a LimitRange @ 05/18/24 13:19:51.052
  STEP: Setting up watch @ 05/18/24 13:19:51.052
  STEP: Submitting a LimitRange @ 05/18/24 13:19:51.155
  STEP: Verifying LimitRange creation was observed @ 05/18/24 13:19:51.163
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/18/24 13:19:51.163
  May 18 13:19:51.165: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May 18 13:19:51.165: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/18/24 13:19:51.165
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/18/24 13:19:51.172
  May 18 13:19:51.175: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  May 18 13:19:51.175: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/18/24 13:19:51.175
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/18/24 13:19:51.181
  May 18 13:19:51.186: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  May 18 13:19:51.186: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/18/24 13:19:51.186
  STEP: Failing to create a Pod with more than max resources @ 05/18/24 13:19:51.187
  STEP: Updating a LimitRange @ 05/18/24 13:19:51.189
  STEP: Verifying LimitRange updating is effective @ 05/18/24 13:19:51.194
  E0518 13:19:51.980242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:52.980338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/18/24 13:19:53.2
  STEP: Failing to create a Pod with more than max resources @ 05/18/24 13:19:53.208
  STEP: Deleting a LimitRange @ 05/18/24 13:19:53.21
  STEP: Verifying the LimitRange was deleted @ 05/18/24 13:19:53.218
  E0518 13:19:53.980675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:54.981724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:55.981903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:56.982201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:57.982665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:19:58.224: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/18/24 13:19:58.224
  May 18 13:19:58.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2105" for this suite. @ 05/18/24 13:19:58.235
• [7.215 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 05/18/24 13:19:58.242
  May 18 13:19:58.242: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:19:58.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:19:58.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:19:58.263
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-dd6cc770-3030-473b-ba8e-2c04964fcfe1 @ 05/18/24 13:19:58.269
  STEP: Creating the pod @ 05/18/24 13:19:58.273
  E0518 13:19:58.983205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:19:59.983297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-dd6cc770-3030-473b-ba8e-2c04964fcfe1 @ 05/18/24 13:20:00.297
  STEP: waiting to observe update in volume @ 05/18/24 13:20:00.302
  E0518 13:20:00.983834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:01.983917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:02.984042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:03.984252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:04.323: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4120" for this suite. @ 05/18/24 13:20:04.326
• [6.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/18/24 13:20:04.334
  May 18 13:20:04.334: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/18/24 13:20:04.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:04.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:04.354
  May 18 13:20:04.357: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:20:04.984332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:05.984408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:06.985019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:07.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6625" for this suite. @ 05/18/24 13:20:07.447
• [3.120 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 05/18/24 13:20:07.454
  May 18 13:20:07.454: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 13:20:07.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:07.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:07.474
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3218.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3218.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 05/18/24 13:20:07.476
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3218.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3218.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/18/24 13:20:07.476
  STEP: creating a pod to probe /etc/hosts @ 05/18/24 13:20:07.476
  STEP: submitting the pod to kubernetes @ 05/18/24 13:20:07.476
  E0518 13:20:07.985114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:08.985225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:09.985385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:10.985471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:11.986175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:12.986532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 13:20:13.5
  STEP: looking for the results for each expected name from probers @ 05/18/24 13:20:13.503
  May 18 13:20:13.518: INFO: DNS probes using dns-3218/dns-test-6a461fa8-d119-44b7-b71d-18e84669b49f succeeded

  STEP: deleting the pod @ 05/18/24 13:20:13.518
  May 18 13:20:13.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3218" for this suite. @ 05/18/24 13:20:13.534
• [6.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 05/18/24 13:20:13.543
  May 18 13:20:13.543: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:20:13.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:13.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:13.563
  STEP: Create a pod @ 05/18/24 13:20:13.565
  E0518 13:20:13.986606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:14.987508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/18/24 13:20:15.579
  May 18 13:20:15.591: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  May 18 13:20:15.591: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-595" for this suite. @ 05/18/24 13:20:15.594
• [2.058 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 05/18/24 13:20:15.602
  May 18 13:20:15.602: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 13:20:15.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:15.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:15.624
  May 18 13:20:15.627: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:20:15.988359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:16.988851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:17.988973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0518 13:20:18.164747      19 warnings.go:70] unknown field "alpha"
  W0518 13:20:18.164763      19 warnings.go:70] unknown field "beta"
  W0518 13:20:18.164766      19 warnings.go:70] unknown field "delta"
  W0518 13:20:18.164769      19 warnings.go:70] unknown field "epsilon"
  W0518 13:20:18.164771      19 warnings.go:70] unknown field "gamma"
  May 18 13:20:18.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6704" for this suite. @ 05/18/24 13:20:18.714
• [3.117 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/18/24 13:20:18.719
  May 18 13:20:18.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 13:20:18.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:18.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:18.741
  May 18 13:20:18.744: INFO: Creating ReplicaSet my-hostname-basic-e2fe2556-3760-40cb-9512-3a9a43ee2a2d
  May 18 13:20:18.757: INFO: Pod name my-hostname-basic-e2fe2556-3760-40cb-9512-3a9a43ee2a2d: Found 0 pods out of 1
  E0518 13:20:18.990021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:19.990119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:20.990178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:21.990313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:22.990400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:23.763: INFO: Pod name my-hostname-basic-e2fe2556-3760-40cb-9512-3a9a43ee2a2d: Found 1 pods out of 1
  May 18 13:20:23.763: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e2fe2556-3760-40cb-9512-3a9a43ee2a2d" is running
  May 18 13:20:23.765: INFO: Pod "my-hostname-basic-e2fe2556-3760-40cb-9512-3a9a43ee2a2d-qksg4" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:20:19 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:20:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:20:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:20:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-18 13:20:18 +0000 UTC Reason: Message:}])
  May 18 13:20:23.765: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/18/24 13:20:23.765
  May 18 13:20:23.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9075" for this suite. @ 05/18/24 13:20:23.781
• [5.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/18/24 13:20:23.788
  May 18 13:20:23.788: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subpath @ 05/18/24 13:20:23.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:23.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:23.807
  STEP: Setting up data @ 05/18/24 13:20:23.81
  STEP: Creating pod pod-subpath-test-configmap-ws6x @ 05/18/24 13:20:23.818
  STEP: Creating a pod to test atomic-volume-subpath @ 05/18/24 13:20:23.818
  E0518 13:20:23.991405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:24.992231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:25.992282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:26.992369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:27.992687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:28.992928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:29.993035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:30.993107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:31.993562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:32.993638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:33.994113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:34.994203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:35.994286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:36.994393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:37.995449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:38.995531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:39.996072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:40.996161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:41.996712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:42.996754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:43.997552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:44.997643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:46.000547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:47.000635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:20:47.89
  May 18 13:20:47.893: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-subpath-test-configmap-ws6x container test-container-subpath-configmap-ws6x: <nil>
  STEP: delete the pod @ 05/18/24 13:20:47.909
  STEP: Deleting pod pod-subpath-test-configmap-ws6x @ 05/18/24 13:20:47.926
  May 18 13:20:47.926: INFO: Deleting pod "pod-subpath-test-configmap-ws6x" in namespace "subpath-7607"
  May 18 13:20:47.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7607" for this suite. @ 05/18/24 13:20:47.931
• [24.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 05/18/24 13:20:47.938
  May 18 13:20:47.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:20:47.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:47.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:47.959
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/18/24 13:20:47.962
  E0518 13:20:48.001063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:49.001254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:50.002304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:20:51.002592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:20:51.983
  May 18 13:20:51.986: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-339969e7-766e-4fb7-85a2-7f7b6cff4dc2 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:20:51.993
  E0518 13:20:52.002602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:52.009: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3698" for this suite. @ 05/18/24 13:20:52.012
• [4.080 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 05/18/24 13:20:52.018
  May 18 13:20:52.018: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 13:20:52.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:52.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:52.038
  STEP: create the deployment @ 05/18/24 13:20:52.04
  W0518 13:20:52.047301      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/18/24 13:20:52.047
  STEP: delete the deployment @ 05/18/24 13:20:52.554
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/18/24 13:20:52.559
  E0518 13:20:53.003704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/18/24 13:20:53.073
  W0518 13:20:53.078037      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 13:20:53.078: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 13:20:53.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2804" for this suite. @ 05/18/24 13:20:53.081
• [1.070 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/18/24 13:20:53.089
  May 18 13:20:53.089: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 13:20:53.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:20:53.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:20:53.121
  May 18 13:20:53.139: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 13:20:53.144
  May 18 13:20:53.147: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:53.147: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:53.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:20:53.151: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:20:54.003811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:54.150: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:54.150: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:54.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 18 13:20:54.154: INFO: Node ip-172-31-90-158 is running 0 daemon pod, expected 1
  E0518 13:20:55.004142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:55.149: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:55.149: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:55.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 13:20:55.153: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/18/24 13:20:55.167
  STEP: Check that daemon pods images are updated. @ 05/18/24 13:20:55.176
  May 18 13:20:55.179: INFO: Wrong image for pod: daemon-set-54xxv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 18 13:20:55.179: INFO: Wrong image for pod: daemon-set-hvxdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 18 13:20:55.179: INFO: Wrong image for pod: daemon-set-j4zzd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 18 13:20:55.181: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:55.181: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0518 13:20:56.004048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:56.182: INFO: Wrong image for pod: daemon-set-hvxdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 18 13:20:56.185: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:56.185: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0518 13:20:57.004068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:57.181: INFO: Wrong image for pod: daemon-set-hvxdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  May 18 13:20:57.181: INFO: Pod daemon-set-plr4q is not available
  May 18 13:20:57.184: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:57.184: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0518 13:20:58.004713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:58.181: INFO: Pod daemon-set-99ssc is not available
  May 18 13:20:58.184: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:58.184: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/18/24 13:20:58.184
  May 18 13:20:58.189: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:58.189: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:58.191: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  May 18 13:20:58.191: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:20:59.004973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:20:59.188: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:59.189: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:20:59.192: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 13:20:59.192: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 13:20:59.206
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-419, will wait for the garbage collector to delete the pods @ 05/18/24 13:20:59.206
  May 18 13:20:59.267: INFO: Deleting DaemonSet.extensions daemon-set took: 7.101625ms
  May 18 13:20:59.367: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.767828ms
  E0518 13:21:00.005131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:01.005309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:01.072: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:21:01.072: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 13:21:01.075: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34744"},"items":null}

  May 18 13:21:01.079: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34744"},"items":null}

  May 18 13:21:01.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-419" for this suite. @ 05/18/24 13:21:01.095
• [8.014 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 05/18/24 13:21:01.103
  May 18 13:21:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:21:01.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:01.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:01.139
  STEP: Creating a ResourceQuota @ 05/18/24 13:21:01.142
  STEP: Getting a ResourceQuota @ 05/18/24 13:21:01.147
  STEP: Updating a ResourceQuota @ 05/18/24 13:21:01.149
  STEP: Verifying a ResourceQuota was modified @ 05/18/24 13:21:01.161
  STEP: Deleting a ResourceQuota @ 05/18/24 13:21:01.165
  STEP: Verifying the deleted ResourceQuota @ 05/18/24 13:21:01.171
  May 18 13:21:01.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4891" for this suite. @ 05/18/24 13:21:01.176
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 05/18/24 13:21:01.183
  May 18 13:21:01.183: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:21:01.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:01.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:01.204
  STEP: Discovering how many secrets are in namespace by default @ 05/18/24 13:21:01.207
  E0518 13:21:02.006309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:03.007078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:04.007205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:05.007286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:06.007330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/18/24 13:21:06.213
  E0518 13:21:07.007445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:08.008188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:09.008356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:10.009226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:11.009290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 13:21:11.217
  STEP: Ensuring resource quota status is calculated @ 05/18/24 13:21:11.223
  E0518 13:21:12.009400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:13.009596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/18/24 13:21:13.228
  STEP: Ensuring resource quota status captures secret creation @ 05/18/24 13:21:13.24
  E0518 13:21:14.009971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:15.010145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/18/24 13:21:15.245
  STEP: Ensuring resource quota status released usage @ 05/18/24 13:21:15.252
  E0518 13:21:16.010840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:17.010936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:17.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7254" for this suite. @ 05/18/24 13:21:17.261
• [16.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 05/18/24 13:21:17.268
  May 18 13:21:17.268: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 13:21:17.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:17.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:17.289
  STEP: create the rc @ 05/18/24 13:21:17.291
  W0518 13:21:17.297161      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0518 13:21:18.011968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:19.012210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:20.012311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:21.012388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:22.013456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/18/24 13:21:22.301
  STEP: wait for all pods to be garbage collected @ 05/18/24 13:21:22.307
  E0518 13:21:23.014252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:24.014346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:25.014433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:26.014573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:27.014792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/18/24 13:21:27.315
  W0518 13:21:27.321196      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 13:21:27.321: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 13:21:27.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3707" for this suite. @ 05/18/24 13:21:27.325
• [10.063 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 05/18/24 13:21:27.331
  May 18 13:21:27.331: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:21:27.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:27.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:27.352
  STEP: Creating the pod @ 05/18/24 13:21:27.355
  E0518 13:21:28.015846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:29.016248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:29.899: INFO: Successfully updated pod "labelsupdatef3bd6139-9a95-4b5d-aef9-31a113755f89"
  E0518 13:21:30.017121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:31.017235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:32.017757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:33.017841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:33.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6922" for this suite. @ 05/18/24 13:21:33.93
• [6.605 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 05/18/24 13:21:33.936
  May 18 13:21:33.936: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 13:21:33.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:33.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:33.956
  STEP: Creating a job @ 05/18/24 13:21:33.958
  STEP: Ensuring job reaches completions @ 05/18/24 13:21:33.964
  E0518 13:21:34.018879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:35.018986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:36.019117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:37.019174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:38.019199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:39.019293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:40.019734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:41.019824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:42.020351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:43.020465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:43.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1606" for this suite. @ 05/18/24 13:21:43.974
• [10.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 05/18/24 13:21:43.984
  May 18 13:21:43.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 13:21:43.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:21:44.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:21:44.008
  STEP: Creating pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722 @ 05/18/24 13:21:44.01
  E0518 13:21:44.020641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:45.020764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:46.020836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 13:21:46.024
  May 18 13:21:46.028: INFO: Initial restart count of pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a is 0
  May 18 13:21:46.031: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:47.021391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:48.021792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:48.037: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:49.022386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:50.022577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:50.041: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:51.022661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:52.022948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:52.047: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:53.023417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:54.023537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:54.051: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:55.023935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:56.024264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:56.055: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:57.024352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:21:58.024786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:21:58.060: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:21:59.025132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:00.025397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:00.063: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:01.025489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:02.025595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:02.069: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:03.026515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:04.026721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:04.073: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:05.027487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:06.027580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:06.078: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:07.027744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:08.028289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:08.083: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:09.028834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:10.029049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:10.088: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:11.029794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:12.030840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:12.093: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:13.031845      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:14.032273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:14.099: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:15.033093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:16.033271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:16.104: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:17.033380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:18.033746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:18.109: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:19.033979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:20.034057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:20.115: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:21.034172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:22.034376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:22.120: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:23.034824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:24.035101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:24.125: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:25.035188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:26.035289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:26.131: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:27.036245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:28.036714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:28.135: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:29.037560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:30.037654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:30.140: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:31.037889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:32.037957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:32.146: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:33.038068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:34.038988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:34.150: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  E0518 13:22:35.039914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:36.040243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:36.155: INFO: Get pod busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a in namespace container-probe-7722
  May 18 13:22:36.155: INFO: Restart count of pod container-probe-7722/busybox-6a0d9e83-bab4-46c0-b719-a8dbe9566a8a is now 1 (50.127018039s elapsed)
  STEP: deleting the pod @ 05/18/24 13:22:36.155
  May 18 13:22:36.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7722" for this suite. @ 05/18/24 13:22:36.174
• [52.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 05/18/24 13:22:36.181
  May 18 13:22:36.181: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:22:36.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:22:36.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:22:36.201
  STEP: creating service multi-endpoint-test in namespace services-5368 @ 05/18/24 13:22:36.204
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5368 to expose endpoints map[] @ 05/18/24 13:22:36.215
  May 18 13:22:36.217: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E0518 13:22:37.040322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:37.227: INFO: successfully validated that service multi-endpoint-test in namespace services-5368 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5368 @ 05/18/24 13:22:37.227
  E0518 13:22:38.041057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:39.041244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5368 to expose endpoints map[pod1:[100]] @ 05/18/24 13:22:39.247
  May 18 13:22:39.257: INFO: successfully validated that service multi-endpoint-test in namespace services-5368 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-5368 @ 05/18/24 13:22:39.257
  E0518 13:22:40.042016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:41.042408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5368 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/18/24 13:22:41.275
  May 18 13:22:41.286: INFO: successfully validated that service multi-endpoint-test in namespace services-5368 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/18/24 13:22:41.286
  May 18 13:22:41.286: INFO: Creating new exec pod
  E0518 13:22:42.042593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:43.042705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:44.043193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:44.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-5368 exec execpodqg6fg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  May 18 13:22:44.396: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  May 18 13:22:44.396: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:22:44.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-5368 exec execpodqg6fg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.78 80'
  May 18 13:22:44.486: INFO: stderr: "+ nc -v -t -w 2 10.152.183.78 80\n+ echo hostName\nConnection to 10.152.183.78 80 port [tcp/http] succeeded!\n"
  May 18 13:22:44.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:22:44.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-5368 exec execpodqg6fg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  May 18 13:22:44.581: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  May 18 13:22:44.581: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:22:44.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-5368 exec execpodqg6fg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.78 81'
  May 18 13:22:44.676: INFO: stderr: "+ nc -v -t -w 2 10.152.183.78 81\n+ echo hostName\nConnection to 10.152.183.78 81 port [tcp/*] succeeded!\n"
  May 18 13:22:44.676: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5368 @ 05/18/24 13:22:44.676
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5368 to expose endpoints map[pod2:[101]] @ 05/18/24 13:22:44.695
  May 18 13:22:44.708: INFO: successfully validated that service multi-endpoint-test in namespace services-5368 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-5368 @ 05/18/24 13:22:44.708
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5368 to expose endpoints map[] @ 05/18/24 13:22:44.72
  E0518 13:22:45.043717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:45.738: INFO: successfully validated that service multi-endpoint-test in namespace services-5368 exposes endpoints map[]
  May 18 13:22:45.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5368" for this suite. @ 05/18/24 13:22:45.758
• [9.584 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 05/18/24 13:22:45.766
  May 18 13:22:45.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 13:22:45.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:22:45.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:22:45.79
  STEP: creating the pod @ 05/18/24 13:22:45.795
  STEP: waiting for pod running @ 05/18/24 13:22:45.804
  E0518 13:22:46.044257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:47.044358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 05/18/24 13:22:47.815
  May 18 13:22:47.818: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3768 PodName:var-expansion-71f0a019-a994-449c-8361-ad3909473e37 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:22:47.818: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:22:47.818: INFO: ExecWithOptions: Clientset creation
  May 18 13:22:47.818: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3768/pods/var-expansion-71f0a019-a994-449c-8361-ad3909473e37/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 05/18/24 13:22:47.867
  May 18 13:22:47.871: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3768 PodName:var-expansion-71f0a019-a994-449c-8361-ad3909473e37 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:22:47.871: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:22:47.872: INFO: ExecWithOptions: Clientset creation
  May 18 13:22:47.872: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3768/pods/var-expansion-71f0a019-a994-449c-8361-ad3909473e37/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 05/18/24 13:22:47.914
  E0518 13:22:48.045251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:22:48.428: INFO: Successfully updated pod "var-expansion-71f0a019-a994-449c-8361-ad3909473e37"
  STEP: waiting for annotated pod running @ 05/18/24 13:22:48.428
  STEP: deleting the pod gracefully @ 05/18/24 13:22:48.431
  May 18 13:22:48.431: INFO: Deleting pod "var-expansion-71f0a019-a994-449c-8361-ad3909473e37" in namespace "var-expansion-3768"
  May 18 13:22:48.439: INFO: Wait up to 5m0s for pod "var-expansion-71f0a019-a994-449c-8361-ad3909473e37" to be fully deleted
  E0518 13:22:49.045410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:50.045611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:51.045997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:52.046150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:53.046786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:54.046853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:55.047209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:56.047464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:57.048244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:58.048324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:22:59.048369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:00.048714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:01.049385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:02.050024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:03.051115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:04.051170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:05.052241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:06.052437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:07.052541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:08.053032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:09.053902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:10.053977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:11.054265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:12.054453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:13.054514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:14.054607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:15.055365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:16.055429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:17.056237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:18.057205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:19.057920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:20.058699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:20.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3768" for this suite. @ 05/18/24 13:23:20.522
• [34.762 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 05/18/24 13:23:20.528
  May 18 13:23:20.528: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename aggregator @ 05/18/24 13:23:20.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:23:20.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:23:20.55
  May 18 13:23:20.553: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Registering the sample API server. @ 05/18/24 13:23:20.553
  May 18 13:23:20.724: INFO: Found ClusterRoles; assuming RBAC is enabled.
  May 18 13:23:20.754: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  E0518 13:23:21.059660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:22.060239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:22.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:23.060764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:24.060868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:24.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:25.061584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:26.061699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:26.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:27.062680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:28.063122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:28.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:29.063685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:30.063771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:30.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:31.064247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:32.064970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:32.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:33.065811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:34.065916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:34.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:35.066708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:36.066971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:36.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:37.067558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:38.068528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:38.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:39.069460      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:40.069577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:40.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:41.069663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:42.069780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:42.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:43.070375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:44.070543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:44.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0518 13:23:45.071602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:46.072223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:46.919: INFO: Waited 113.19694ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/18/24 13:23:46.956
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/18/24 13:23:46.96
  STEP: List APIServices @ 05/18/24 13:23:46.97
  May 18 13:23:46.975: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/18/24 13:23:46.975
  May 18 13:23:46.991: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/18/24 13:23:46.991
  May 18 13:23:47.002: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.May, 18, 13, 23, 46, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/18/24 13:23:47.002
  May 18 13:23:47.006: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-05-18 13:23:46 +0000 UTC Passed all checks passed}
  May 18 13:23:47.006: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 13:23:47.006: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/18/24 13:23:47.006
  May 18 13:23:47.018: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-832862589" @ 05/18/24 13:23:47.018
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/18/24 13:23:47.027
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/18/24 13:23:47.033
  STEP: Patch APIService Status @ 05/18/24 13:23:47.038
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/18/24 13:23:47.045
  May 18 13:23:47.048: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-05-18 13:23:46 +0000 UTC Passed all checks passed}
  May 18 13:23:47.048: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 13:23:47.048: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  May 18 13:23:47.048: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/18/24 13:23:47.048
  STEP: Confirm that the generated APIService has been deleted @ 05/18/24 13:23:47.058
  May 18 13:23:47.058: INFO: Requesting list of APIServices to confirm quantity
  May 18 13:23:47.062: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  May 18 13:23:47.062: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  E0518 13:23:47.073045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:47.164: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-8722" for this suite. @ 05/18/24 13:23:47.168
• [26.646 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 05/18/24 13:23:47.174
  May 18 13:23:47.174: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 13:23:47.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:23:47.194
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:23:47.197
  STEP: Creating pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134 @ 05/18/24 13:23:47.2
  E0518 13:23:48.073193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:49.073397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 13:23:49.218
  May 18 13:23:49.221: INFO: Initial restart count of pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 is 0
  May 18 13:23:49.225: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:23:50.073520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:51.073712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:51.231: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:23:52.074156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:53.075237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:53.235: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:23:54.075333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:55.075393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:55.241: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:23:56.076277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:57.076481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:57.246: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:23:58.076577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:23:59.076760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:23:59.252: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:00.076887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:01.077966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:01.256: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:02.078064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:03.078133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:03.260: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:04.078494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:05.079321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:05.266: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:06.080248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:07.080335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:07.270: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:08.081095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:09.081215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:09.274: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:10.081521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:11.081716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:11.280: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:12.081835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:13.082022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:13.283: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:14.082640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:15.082726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:15.288: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:16.083180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:17.084242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:17.294: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:18.084342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:19.084417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:19.298: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:20.084783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:21.084892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:21.304: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:22.085214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:23.085371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:23.310: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:24.086354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:25.086459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:25.314: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:26.086621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:27.087512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:27.319: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:28.088232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:29.088960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:29.325: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:30.089420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:31.089631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:31.331: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:32.089723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:33.089838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:33.336: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:34.089904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:35.089979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:35.342: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:36.090230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:37.090340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:37.346: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:38.091178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:39.091253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:39.351: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:40.092281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:41.092383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:41.355: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:42.093382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:43.093447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:43.359: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:44.093949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:45.094061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:45.365: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:46.094981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:47.095119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:47.370: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:48.096144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:49.096761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:49.374: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:50.096863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:51.096910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:51.379: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:52.096996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:53.097346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:53.384: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:54.097918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:55.098267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:55.388: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:56.098109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:57.098770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:57.393: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:24:58.099724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:24:59.100229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:24:59.398: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:00.101063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:01.101179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:01.404: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:02.101952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:03.102072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:03.408: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:04.103158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:05.103220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:05.412: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:06.104214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:07.104308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:07.417: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:08.105187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:09.105303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:09.421: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:10.106194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:11.106295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:11.426: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:12.107155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:13.108229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:13.430: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:14.108711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:15.109245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:15.435: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:16.110163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:17.110343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:17.440: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:18.111231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:19.112243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:19.446: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:20.112700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:21.112926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:21.451: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:22.113087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:23.113176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:23.456: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:24.113840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:25.114079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:25.461: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:26.114177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:27.114273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:27.466: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:28.115088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:29.115178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:29.470: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:30.116235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:31.116343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:31.475: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:32.116917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:33.117007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:33.479: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:34.118064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:35.118163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:35.483: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:36.118515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:37.118612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:37.486: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:38.119601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:39.119693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:39.491: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:40.119806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:41.120573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:41.495: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:42.121201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:43.121417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:43.501: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:44.122393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:45.122589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:45.507: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:46.123372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:47.123445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:47.512: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:48.124508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:49.124599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:49.517: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:50.124691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:51.124884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:51.523: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:52.124973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:53.125852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:53.527: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:54.125989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:55.126098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:55.532: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:56.126223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:57.126471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:57.536: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:25:58.126548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:25:59.126714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:25:59.542: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:00.126804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:01.126911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:01.547: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:02.127056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:03.127143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:03.551: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:04.127233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:05.128243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:05.556: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:06.129289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:07.129372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:07.561: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:08.129560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:09.129725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:09.567: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:10.130016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:11.130232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:11.572: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:12.130777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:13.130875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:13.577: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:14.130972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:15.131841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:15.582: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:16.132240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:17.132353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:17.587: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:18.132910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:19.133099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:19.592: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:20.133932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:21.134054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:21.597: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:22.134545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:23.134650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:23.602: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:24.134731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:25.134937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:25.607: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:26.135994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:27.136438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:27.612: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:28.136537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:29.136729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:29.617: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:30.137714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:31.138601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:31.621: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:32.139136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:33.139177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:33.625: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:34.140205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:35.140498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:35.630: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:36.141343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:37.141450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:37.635: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:38.141695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:39.142215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:39.639: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:40.142638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:41.143081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:41.645: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:42.143859      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:43.144162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:43.649: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:44.145229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:45.145533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:45.654: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:46.146577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:47.146727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:47.659: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:48.147331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:49.147459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:49.665: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:50.147823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:51.148477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:51.670: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:52.149204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:53.149292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:53.675: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:54.149833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:55.150208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:55.679: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:56.150266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:57.150351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:57.684: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:26:58.151308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:26:59.151414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:26:59.689: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:00.152292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:01.152410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:01.695: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:02.152837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:03.153180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:03.700: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:04.153704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:05.153791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:05.706: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:06.153881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:07.154042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:07.711: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:08.154167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:09.154427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:09.717: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:10.154781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:11.154958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:11.722: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:12.155290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:13.156232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:13.727: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:14.156748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:15.156967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:15.733: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:16.157589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:17.158519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:17.738: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:18.159151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:19.160215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:19.743: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:20.160288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:21.160462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:21.749: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:22.160557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:23.160715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:23.754: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:24.160954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:25.161662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:25.760: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:26.161748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:27.162305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:27.764: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:28.162416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:29.162620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:29.769: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:30.162959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:31.163154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:31.773: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:32.164038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:33.164357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:33.778: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:34.164467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:35.164564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:35.783: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:36.165404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:37.165667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:37.788: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:38.165882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:39.166110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:39.793: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:40.166883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:41.166999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:41.798: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:42.167172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:43.168238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:43.804: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:44.168873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:45.169369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:45.809: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:46.170389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:47.170581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:27:47.815: INFO: Get pod test-webserver-afd834ff-3ba0-4352-8ff7-290c3f8e1c92 in namespace container-probe-6134
  E0518 13:27:48.171226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:49.171338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/18/24 13:27:49.816
  May 18 13:27:49.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6134" for this suite. @ 05/18/24 13:27:49.837
• [242.671 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 05/18/24 13:27:49.846
  May 18 13:27:49.846: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename ingress @ 05/18/24 13:27:49.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:27:49.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:27:49.868
  STEP: getting /apis @ 05/18/24 13:27:49.871
  STEP: getting /apis/networking.k8s.io @ 05/18/24 13:27:49.874
  STEP: getting /apis/networking.k8s.iov1 @ 05/18/24 13:27:49.875
  STEP: creating @ 05/18/24 13:27:49.876
  STEP: getting @ 05/18/24 13:27:49.9
  STEP: listing @ 05/18/24 13:27:49.904
  STEP: watching @ 05/18/24 13:27:49.906
  May 18 13:27:49.906: INFO: starting watch
  STEP: cluster-wide listing @ 05/18/24 13:27:49.908
  STEP: cluster-wide watching @ 05/18/24 13:27:49.911
  May 18 13:27:49.911: INFO: starting watch
  STEP: patching @ 05/18/24 13:27:49.913
  STEP: updating @ 05/18/24 13:27:49.919
  May 18 13:27:49.929: INFO: waiting for watch events with expected annotations
  May 18 13:27:49.929: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/18/24 13:27:49.929
  STEP: updating /status @ 05/18/24 13:27:49.935
  STEP: get /status @ 05/18/24 13:27:49.944
  STEP: deleting @ 05/18/24 13:27:49.949
  STEP: deleting a collection @ 05/18/24 13:27:49.968
  May 18 13:27:49.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-1878" for this suite. @ 05/18/24 13:27:49.99
• [0.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 05/18/24 13:27:49.997
  May 18 13:27:49.997: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/18/24 13:27:49.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:27:50.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:27:50.021
  STEP: creating a target pod @ 05/18/24 13:27:50.024
  E0518 13:27:50.172354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:51.172476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/18/24 13:27:52.049
  E0518 13:27:52.173119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:53.173227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/18/24 13:27:54.064
  May 18 13:27:54.064: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9553 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:27:54.064: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:27:54.065: INFO: ExecWithOptions: Clientset creation
  May 18 13:27:54.065: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-9553/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  May 18 13:27:54.115: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/18/24 13:27:54.134
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/18/24 13:27:54.139
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/18/24 13:27:54.15
  May 18 13:27:54.154: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-9553" for this suite. @ 05/18/24 13:27:54.161
• [4.171 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/18/24 13:27:54.168
  May 18 13:27:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename events @ 05/18/24 13:27:54.169
  E0518 13:27:54.173700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:27:54.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:27:54.188
  STEP: creating a test event @ 05/18/24 13:27:54.191
  STEP: listing all events in all namespaces @ 05/18/24 13:27:54.195
  STEP: patching the test event @ 05/18/24 13:27:54.198
  STEP: fetching the test event @ 05/18/24 13:27:54.204
  STEP: updating the test event @ 05/18/24 13:27:54.207
  STEP: getting the test event @ 05/18/24 13:27:54.217
  STEP: deleting the test event @ 05/18/24 13:27:54.22
  STEP: listing all events in all namespaces @ 05/18/24 13:27:54.227
  May 18 13:27:54.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8365" for this suite. @ 05/18/24 13:27:54.233
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 05/18/24 13:27:54.239
  May 18 13:27:54.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:27:54.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:27:54.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:27:54.26
  E0518 13:27:55.173939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:56.174587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:57.175179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:58.175960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:27:59.176079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:00.176148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:01.176769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:02.176878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:03.176962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:04.177048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:05.177551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:06.178493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:07.179165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:08.180040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:09.180234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:10.180363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:11.180430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/18/24 13:28:11.267
  E0518 13:28:12.180562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:13.180969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:14.181068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:15.181269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:16.181435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 13:28:16.271
  STEP: Ensuring resource quota status is calculated @ 05/18/24 13:28:16.296
  E0518 13:28:17.181839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:18.181922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/18/24 13:28:18.3
  STEP: Ensuring resource quota status captures configMap creation @ 05/18/24 13:28:18.312
  E0518 13:28:19.182576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:20.182820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/18/24 13:28:20.317
  STEP: Ensuring resource quota status released usage @ 05/18/24 13:28:20.323
  E0518 13:28:21.183191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:22.183289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:22.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-800" for this suite. @ 05/18/24 13:28:22.331
• [28.097 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/18/24 13:28:22.337
  May 18 13:28:22.337: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/18/24 13:28:22.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:22.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:22.356
  STEP: creating @ 05/18/24 13:28:22.36
  STEP: getting @ 05/18/24 13:28:22.377
  STEP: listing in namespace @ 05/18/24 13:28:22.381
  STEP: patching @ 05/18/24 13:28:22.383
  STEP: deleting @ 05/18/24 13:28:22.39
  May 18 13:28:22.400: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1068" for this suite. @ 05/18/24 13:28:22.405
• [0.074 seconds]
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/18/24 13:28:22.411
  May 18 13:28:22.411: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename hostport @ 05/18/24 13:28:22.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:22.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:22.432
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/18/24 13:28:22.438
  E0518 13:28:23.183425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:24.183779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.33.93 on the node which pod1 resides and expect scheduled @ 05/18/24 13:28:24.453
  E0518 13:28:25.183884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:26.183976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.33.93 but use UDP protocol on the node which pod2 resides @ 05/18/24 13:28:26.468
  E0518 13:28:27.184380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:28.184472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:29.184564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:30.184650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:31.185095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:32.185304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/18/24 13:28:32.505
  May 18 13:28:32.505: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.33.93 http://127.0.0.1:54323/hostname] Namespace:hostport-487 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:28:32.505: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:28:32.506: INFO: ExecWithOptions: Clientset creation
  May 18 13:28:32.506: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-487/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.33.93+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.33.93, port: 54323 @ 05/18/24 13:28:32.556
  May 18 13:28:32.556: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.33.93:54323/hostname] Namespace:hostport-487 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:28:32.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:28:32.556: INFO: ExecWithOptions: Clientset creation
  May 18 13:28:32.556: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-487/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.33.93%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.33.93, port: 54323 UDP @ 05/18/24 13:28:32.607
  May 18 13:28:32.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.33.93 54323] Namespace:hostport-487 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:28:32.607: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:28:32.608: INFO: ExecWithOptions: Clientset creation
  May 18 13:28:32.608: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-487/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.33.93+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0518 13:28:33.185425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:34.185533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:35.185624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:36.185805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:37.186100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:37.660: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-487" for this suite. @ 05/18/24 13:28:37.664
• [15.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 05/18/24 13:28:37.672
  May 18 13:28:37.672: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:28:37.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:37.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:37.693
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:28:37.696
  E0518 13:28:38.186907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:39.187239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:40.187353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:41.187425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:28:41.723
  May 18 13:28:41.727: INFO: Trying to get logs from node ip-172-31-70-23 pod downwardapi-volume-4a0dd9e6-b857-4dbf-86f4-209a3687006f container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:28:41.742
  May 18 13:28:41.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9276" for this suite. @ 05/18/24 13:28:41.762
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 05/18/24 13:28:41.768
  May 18 13:28:41.768: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 13:28:41.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:41.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:41.789
  STEP: Given a ReplicationController is created @ 05/18/24 13:28:41.792
  STEP: When the matched label of one of its pods change @ 05/18/24 13:28:41.796
  May 18 13:28:41.799: INFO: Pod name pod-release: Found 0 pods out of 1
  E0518 13:28:42.188250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:43.189301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:44.189383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:45.189482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:46.189587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:46.803: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/18/24 13:28:46.814
  E0518 13:28:47.189864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:47.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-429" for this suite. @ 05/18/24 13:28:47.827
• [6.067 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 05/18/24 13:28:47.835
  May 18 13:28:47.835: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 13:28:47.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:47.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:47.858
  STEP: Creating configMap that has name configmap-test-emptyKey-30e78724-b67b-453d-8226-45253202b6ef @ 05/18/24 13:28:47.861
  May 18 13:28:47.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9069" for this suite. @ 05/18/24 13:28:47.867
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 05/18/24 13:28:47.874
  May 18 13:28:47.874: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 13:28:47.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:47.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:47.893
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/18/24 13:28:47.896
  May 18 13:28:47.904: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7753  ba4de720-78c3-479b-a66a-32afb6b8bb0a 36607 0 2024-05-18 13:28:47 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-05-18 13:28:47 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pj9mn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pj9mn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0518 13:28:48.190167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:49.190224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/18/24 13:28:49.912
  May 18 13:28:49.912: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7753 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:28:49.912: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:28:49.913: INFO: ExecWithOptions: Clientset creation
  May 18 13:28:49.913: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7753/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 05/18/24 13:28:49.979
  May 18 13:28:49.979: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7753 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:28:49.979: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:28:49.979: INFO: ExecWithOptions: Clientset creation
  May 18 13:28:49.979: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7753/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  May 18 13:28:50.031: INFO: Deleting pod test-dns-nameservers...
  May 18 13:28:50.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7753" for this suite. @ 05/18/24 13:28:50.05
• [2.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/18/24 13:28:50.057
  May 18 13:28:50.057: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename endpointslice @ 05/18/24 13:28:50.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:50.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:50.079
  E0518 13:28:50.190730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:51.190897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:52.191752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:53.191861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:54.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2508" for this suite. @ 05/18/24 13:28:54.137
• [4.087 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 05/18/24 13:28:54.144
  May 18 13:28:54.144: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:28:54.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:28:54.162
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:28:54.165
  STEP: Creating the pod @ 05/18/24 13:28:54.167
  E0518 13:28:54.192036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:55.192289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:56.192997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:28:56.710: INFO: Successfully updated pod "labelsupdatee84b8448-108c-4460-9309-a8f87c8eed0d"
  E0518 13:28:57.193306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:58.193383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:28:59.194363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:00.194400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:00.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8328" for this suite. @ 05/18/24 13:29:00.738
• [6.601 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 05/18/24 13:29:00.745
  May 18 13:29:00.745: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 13:29:00.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:00.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:00.766
  May 18 13:29:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:29:01.195173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:02.195195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:03.196237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0518 13:29:03.307465      19 warnings.go:70] unknown field "alpha"
  W0518 13:29:03.307484      19 warnings.go:70] unknown field "beta"
  W0518 13:29:03.307487      19 warnings.go:70] unknown field "delta"
  W0518 13:29:03.307490      19 warnings.go:70] unknown field "epsilon"
  W0518 13:29:03.307492      19 warnings.go:70] unknown field "gamma"
  May 18 13:29:03.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4582" for this suite. @ 05/18/24 13:29:03.856
• [3.117 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 05/18/24 13:29:03.862
  May 18 13:29:03.862: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 13:29:03.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:03.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:03.883
  STEP: Creating Indexed job @ 05/18/24 13:29:03.886
  STEP: Ensuring job reaches completions @ 05/18/24 13:29:03.892
  E0518 13:29:04.196819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:05.196905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:06.197950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:07.198489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:08.199300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:09.200241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:10.200277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:11.200385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 05/18/24 13:29:11.896
  May 18 13:29:11.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3946" for this suite. @ 05/18/24 13:29:11.903
• [8.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/18/24 13:29:11.912
  May 18 13:29:11.912: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename chunking @ 05/18/24 13:29:11.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:11.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:11.932
  STEP: creating a large number of resources @ 05/18/24 13:29:11.935
  E0518 13:29:12.201042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:13.202130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:14.202355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:15.203380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:16.203735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:17.204374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:18.204655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:19.204684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:20.205680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:21.206369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:22.207415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:23.208100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:24.208342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:25.209110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:26.209564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:27.209716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:28.210233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:29.210846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 05/18/24 13:29:29.62
  May 18 13:29:29.667: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 18 13:29:29.717: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 18 13:29:29.767: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May 18 13:29:29.817: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 18 13:29:29.868: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 18 13:29:29.919: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 18 13:29:29.967: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May 18 13:29:30.017: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 18 13:29:30.068: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 18 13:29:30.117: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 18 13:29:30.167: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  E0518 13:29:30.211278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:30.219: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 18 13:29:30.266: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 18 13:29:30.317: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 18 13:29:30.367: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 18 13:29:30.416: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 18 13:29:30.467: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 18 13:29:30.517: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 18 13:29:30.566: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 18 13:29:30.616: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May 18 13:29:30.667: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 18 13:29:30.717: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 18 13:29:30.767: INFO: Retrieved 17/17 results with rv 37360 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjAsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May 18 13:29:30.818: INFO: Retrieved 9/17 results with rv 37360 and continue 
  May 18 13:29:30.867: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 18 13:29:30.918: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 18 13:29:30.968: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  May 18 13:29:31.017: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 18 13:29:31.067: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 18 13:29:31.118: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 18 13:29:31.167: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  E0518 13:29:31.212182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:31.217: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 18 13:29:31.266: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 18 13:29:31.316: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 18 13:29:31.367: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May 18 13:29:31.417: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 18 13:29:31.466: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 18 13:29:31.517: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 18 13:29:31.567: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 18 13:29:31.616: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 18 13:29:31.667: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 18 13:29:31.718: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 18 13:29:31.767: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 18 13:29:31.818: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May 18 13:29:31.867: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 18 13:29:31.921: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 18 13:29:31.967: INFO: Retrieved 17/17 results with rv 37361 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjEsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  May 18 13:29:32.018: INFO: Retrieved 9/17 results with rv 37361 and continue 
  May 18 13:29:32.067: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  May 18 13:29:32.118: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  May 18 13:29:32.167: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  E0518 13:29:32.212883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:32.217: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  May 18 13:29:32.267: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  May 18 13:29:32.317: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  May 18 13:29:32.367: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  May 18 13:29:32.418: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  May 18 13:29:32.468: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  May 18 13:29:32.517: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  May 18 13:29:32.567: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  May 18 13:29:32.617: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  May 18 13:29:32.666: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  May 18 13:29:32.717: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  May 18 13:29:32.768: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  May 18 13:29:32.816: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  May 18 13:29:32.867: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  May 18 13:29:32.918: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  May 18 13:29:32.967: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  May 18 13:29:33.017: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  May 18 13:29:33.067: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  May 18 13:29:33.116: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  May 18 13:29:33.167: INFO: Retrieved 17/17 results with rv 37363 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzczNjMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  E0518 13:29:33.212970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:33.217: INFO: Retrieved 9/17 results with rv 37363 and continue 
  STEP: retrieving those results all at once @ 05/18/24 13:29:33.217
  May 18 13:29:33.272: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-8096" for this suite. @ 05/18/24 13:29:33.316
• [21.458 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/18/24 13:29:33.37
  May 18 13:29:33.370: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename apf @ 05/18/24 13:29:33.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:33.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:33.392
  STEP: getting /apis @ 05/18/24 13:29:33.394
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/18/24 13:29:33.397
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/18/24 13:29:33.398
  STEP: creating @ 05/18/24 13:29:33.399
  STEP: getting @ 05/18/24 13:29:33.418
  STEP: listing @ 05/18/24 13:29:33.42
  STEP: watching @ 05/18/24 13:29:33.427
  May 18 13:29:33.427: INFO: starting watch
  STEP: patching @ 05/18/24 13:29:33.428
  STEP: updating @ 05/18/24 13:29:33.432
  May 18 13:29:33.441: INFO: waiting for watch events with expected annotations
  May 18 13:29:33.441: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/18/24 13:29:33.441
  STEP: patching /status @ 05/18/24 13:29:33.443
  STEP: updating /status @ 05/18/24 13:29:33.449
  STEP: deleting @ 05/18/24 13:29:33.48
  STEP: deleting a collection @ 05/18/24 13:29:33.491
  May 18 13:29:33.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5849" for this suite. @ 05/18/24 13:29:33.519
• [0.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/18/24 13:29:33.528
  May 18 13:29:33.528: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename csi-storageclass @ 05/18/24 13:29:33.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:33.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:33.548
  STEP: Creating a StorageClass @ 05/18/24 13:29:33.551
  STEP: Get StorageClass "e2e-765lt" @ 05/18/24 13:29:33.555
  STEP: Patching the StorageClass "e2e-765lt" @ 05/18/24 13:29:33.558
  STEP: Delete StorageClass "e2e-765lt" @ 05/18/24 13:29:33.563
  STEP: Confirm deletion of StorageClass "e2e-765lt" @ 05/18/24 13:29:33.569
  STEP: Create a replacement StorageClass @ 05/18/24 13:29:33.571
  STEP: Updating StorageClass "e2e-v2-hvvmp" @ 05/18/24 13:29:33.575
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-hvvmp=updated" @ 05/18/24 13:29:33.583
  STEP: Deleting StorageClass "e2e-v2-hvvmp" via DeleteCollection @ 05/18/24 13:29:33.588
  STEP: Confirm deletion of StorageClass "e2e-v2-hvvmp" @ 05/18/24 13:29:33.594
  May 18 13:29:33.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-5096" for this suite. @ 05/18/24 13:29:33.602
• [0.079 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 05/18/24 13:29:33.607
  May 18 13:29:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 13:29:33.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:33.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:33.627
  E0518 13:29:34.213526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:35.213693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:36.213815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:37.213880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:38.214828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:39.214915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:40.214968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:41.215205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:42.216087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:43.216131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:44.216230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:45.216321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:46.216409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:47.216854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:48.217251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:49.217369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:50.217655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:51.217745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:52.218788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:53.218902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:54.219962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:55.220289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:29:55.692: INFO: Container started at 2024-05-18 13:29:34 +0000 UTC, pod became ready at 2024-05-18 13:29:53 +0000 UTC
  May 18 13:29:55.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1163" for this suite. @ 05/18/24 13:29:55.696
• [22.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 05/18/24 13:29:55.703
  May 18 13:29:55.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename containers @ 05/18/24 13:29:55.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:55.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:55.725
  STEP: Creating a pod to test override all @ 05/18/24 13:29:55.727
  E0518 13:29:56.220986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:57.221388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:58.221453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:29:59.221547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:29:59.746
  May 18 13:29:59.750: INFO: Trying to get logs from node ip-172-31-70-23 pod client-containers-ea26ff7f-9943-4ce1-9de2-0703a0097563 container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:29:59.757
  May 18 13:29:59.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6284" for this suite. @ 05/18/24 13:29:59.779
• [4.083 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 05/18/24 13:29:59.786
  May 18 13:29:59.786: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:29:59.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:29:59.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:29:59.807
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:29:59.81
  E0518 13:30:00.221651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:01.221741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:02.222552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:03.222954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:30:03.832
  May 18 13:30:03.837: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-694288c3-71e2-41c4-b3df-2b3c56e0ea2e container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:30:03.844
  May 18 13:30:03.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8478" for this suite. @ 05/18/24 13:30:03.863
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 05/18/24 13:30:03.87
  May 18 13:30:03.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:30:03.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:03.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:03.897
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:30:03.9
  E0518 13:30:04.223113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:05.223231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:06.223574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:07.223830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:30:07.924
  May 18 13:30:07.926: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-19691e13-5d02-4c60-bd02-356b7e3ce90b container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:30:07.934
  May 18 13:30:07.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9864" for this suite. @ 05/18/24 13:30:07.954
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 05/18/24 13:30:07.962
  May 18 13:30:07.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:30:07.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:07.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:07.989
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6613 @ 05/18/24 13:30:07.992
  STEP: changing the ExternalName service to type=ClusterIP @ 05/18/24 13:30:07.996
  STEP: creating replication controller externalname-service in namespace services-6613 @ 05/18/24 13:30:08.011
  I0518 13:30:08.021346      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6613, replica count: 2
  E0518 13:30:08.224289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:09.224648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:10.224850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:30:11.071713      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:30:11.071: INFO: Creating new exec pod
  E0518 13:30:11.225696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:12.226009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:13.227011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:14.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6613 exec execpod5swrt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May 18 13:30:14.178: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May 18 13:30:14.178: INFO: stdout: "externalname-service-lxrpn"
  May 18 13:30:14.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6613 exec execpod5swrt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.201 80'
  E0518 13:30:14.227764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:14.272: INFO: stderr: "+ nc -v -t -w 2 10.152.183.201 80\n+ echo hostName\nConnection to 10.152.183.201 80 port [tcp/http] succeeded!\n"
  May 18 13:30:14.272: INFO: stdout: "externalname-service-lxrpn"
  May 18 13:30:14.272: INFO: Cleaning up the ExternalName to ClusterIP test service
  May 18 13:30:14.288: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6613" for this suite. @ 05/18/24 13:30:14.292
• [6.337 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 05/18/24 13:30:14.299
  May 18 13:30:14.299: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context-test @ 05/18/24 13:30:14.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:14.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:14.321
  E0518 13:30:15.227953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:16.228028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:17.228850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:18.228945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:18.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5107" for this suite. @ 05/18/24 13:30:18.35
• [4.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/18/24 13:30:18.357
  May 18 13:30:18.357: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:30:18.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:18.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:18.376
  STEP: Creating projection with secret that has name projected-secret-test-5165c3f4-5b3d-4ef4-8182-c0f269ce65f7 @ 05/18/24 13:30:18.38
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:30:18.387
  E0518 13:30:19.229218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:20.229434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:21.229532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:22.229773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:30:22.407
  May 18 13:30:22.410: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-projected-secrets-359ad454-c083-4d3b-a739-4b4d8896c070 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:30:22.417
  May 18 13:30:22.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5534" for this suite. @ 05/18/24 13:30:22.435
• [4.084 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 05/18/24 13:30:22.441
  May 18 13:30:22.441: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:30:22.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:22.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:22.467
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/18/24 13:30:22.47
  E0518 13:30:23.229871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:24.230223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:25.230308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:26.230410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:30:26.493
  May 18 13:30:26.497: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-62a7c14a-43b0-4c00-a750-1c63e10f7ebe container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:30:26.504
  May 18 13:30:26.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-727" for this suite. @ 05/18/24 13:30:26.524
• [4.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/18/24 13:30:26.53
  May 18 13:30:26.530: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename init-container @ 05/18/24 13:30:26.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:26.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:26.551
  STEP: creating the pod @ 05/18/24 13:30:26.554
  May 18 13:30:26.554: INFO: PodSpec: initContainers in spec.initContainers
  E0518 13:30:27.231353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:28.232249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:29.233312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:30.233613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:31.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1263" for this suite. @ 05/18/24 13:30:31.214
• [4.691 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 05/18/24 13:30:31.221
  May 18 13:30:31.221: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 13:30:31.222
  E0518 13:30:31.234260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:31.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:31.242
  E0518 13:30:32.234605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:33.234752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:33.263: INFO: Deleting pod "var-expansion-e304014a-fae4-4d17-8c3c-1838c0641212" in namespace "var-expansion-5885"
  May 18 13:30:33.271: INFO: Wait up to 5m0s for pod "var-expansion-e304014a-fae4-4d17-8c3c-1838c0641212" to be fully deleted
  E0518 13:30:34.235182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:35.235277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:30:35.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5885" for this suite. @ 05/18/24 13:30:35.286
• [4.072 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 05/18/24 13:30:35.293
  May 18 13:30:35.293: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption @ 05/18/24 13:30:35.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:30:35.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:30:35.316
  May 18 13:30:35.332: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 13:30:36.235413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:37.235880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:38.235992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:39.236520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:40.237316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:41.237388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:42.237810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:43.238254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:44.239136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:45.239169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:46.239254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:47.239316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:48.240221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:49.240321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:50.240424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:51.240597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:52.241148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:53.241243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:54.241377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:55.241548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:56.242283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:57.242351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:58.242465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:30:59.242647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:00.242741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:01.242927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:02.243163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:03.243267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:04.243362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:05.243454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:06.243551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:07.244399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:08.245247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:09.245345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:10.245637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:11.245825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:12.245901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:13.246214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:14.246268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:15.246445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:16.246565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:17.247398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:18.247967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:19.248074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:20.248284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:21.248789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:22.248867      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:23.248975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:24.249075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:25.249301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:26.249886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:27.250865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:28.251168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:29.251251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:30.252230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:31.253329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:32.254414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:33.255303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:34.255437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:35.256279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:31:35.336: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/18/24 13:31:35.339
  May 18 13:31:35.359: INFO: Created pod: pod0-0-sched-preemption-low-priority
  May 18 13:31:35.365: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May 18 13:31:35.400: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May 18 13:31:35.406: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  May 18 13:31:35.424: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  May 18 13:31:35.431: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/18/24 13:31:35.431
  E0518 13:31:36.257035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:37.257335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/18/24 13:31:37.456
  E0518 13:31:38.257903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:39.258104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:40.258204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:41.258954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:31:41.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5510" for this suite. @ 05/18/24 13:31:41.559
• [66.272 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 05/18/24 13:31:41.566
  May 18 13:31:41.566: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 13:31:41.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:31:41.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:31:41.588
  May 18 13:31:41.610: INFO: created pod pod-service-account-defaultsa
  May 18 13:31:41.610: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  May 18 13:31:41.614: INFO: created pod pod-service-account-mountsa
  May 18 13:31:41.614: INFO: pod pod-service-account-mountsa service account token volume mount: true
  May 18 13:31:41.619: INFO: created pod pod-service-account-nomountsa
  May 18 13:31:41.619: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  May 18 13:31:41.625: INFO: created pod pod-service-account-defaultsa-mountspec
  May 18 13:31:41.625: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  May 18 13:31:41.633: INFO: created pod pod-service-account-mountsa-mountspec
  May 18 13:31:41.633: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  May 18 13:31:41.644: INFO: created pod pod-service-account-nomountsa-mountspec
  May 18 13:31:41.644: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  May 18 13:31:41.654: INFO: created pod pod-service-account-defaultsa-nomountspec
  May 18 13:31:41.654: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  May 18 13:31:41.659: INFO: created pod pod-service-account-mountsa-nomountspec
  May 18 13:31:41.659: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  May 18 13:31:41.673: INFO: created pod pod-service-account-nomountsa-nomountspec
  May 18 13:31:41.673: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  May 18 13:31:41.673: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-749" for this suite. @ 05/18/24 13:31:41.678
• [0.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 05/18/24 13:31:41.689
  May 18 13:31:41.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename var-expansion @ 05/18/24 13:31:41.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:31:41.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:31:41.711
  STEP: Creating a pod to test substitution in container's command @ 05/18/24 13:31:41.714
  E0518 13:31:42.260373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:43.261349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:44.261461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:45.261642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:31:45.736
  May 18 13:31:45.738: INFO: Trying to get logs from node ip-172-31-70-23 pod var-expansion-88d06f3b-4ad2-42dd-8593-30d935cf178f container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 13:31:45.745
  May 18 13:31:45.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8507" for this suite. @ 05/18/24 13:31:45.764
• [4.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/18/24 13:31:45.771
  May 18 13:31:45.771: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 13:31:45.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:31:45.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:31:45.791
  May 18 13:31:45.794: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  May 18 13:31:45.803: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0518 13:31:46.262665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:47.262646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:48.262745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:49.262818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:50.262977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:31:50.808: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/18/24 13:31:50.808
  May 18 13:31:50.808: INFO: Creating deployment "test-rolling-update-deployment"
  May 18 13:31:50.814: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  May 18 13:31:50.819: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0518 13:31:51.263161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:52.264236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:31:52.828: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  May 18 13:31:52.832: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  May 18 13:31:52.841: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3642",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d5aaaa55-2b32-4026-a861-7fd6b920a599",
      ResourceVersion: (string) (len=5) "38918",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635910,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 13:31:52.844: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3642",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e0aa08d4-cf89-44f7-b5b1-72fda09f2ae9",
      ResourceVersion: (string) (len=5) "38908",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635910,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "d5aaaa55-2b32-4026-a861-7fd6b920a599",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 35 61 61 61 61  35 35 2d 32 62 33 32 2d  |\"d5aaaa55-2b32-|
              00000120  34 30 32 36 2d 61 38 36  31 2d 37 66 64 36 62 39  |4026-a861-7fd6b9|
              00000130  32 30 61 35 39 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |20a599\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 13:31:52.846: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  May 18 13:31:52.846: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3642",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d1eab7d4-8775-4076-bc3c-96898062f174",
      ResourceVersion: (string) (len=5) "38917",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635905,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "d5aaaa55-2b32-4026-a861-7fd6b920a599",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635905,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 64 35 61 61 61 61 35  |"uid\":\"d5aaaa5|
              000000b0  35 2d 32 62 33 32 2d 34  30 32 36 2d 61 38 36 31  |5-2b32-4026-a861|
              000000c0  2d 37 66 64 36 62 39 32  30 61 35 39 39 5c 22 7d  |-7fd6b920a599\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 13:31:52.850: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-kqlhv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-kqlhv",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-3642",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ef959165-de5d-4290-92cb-629158f71503",
      ResourceVersion: (string) (len=5) "38907",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635910,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "e0aa08d4-cf89-44f7-b5b1-72fda09f2ae9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 30  61 61 30 38 64 34 2d 63  |d\":\"e0aa08d4-c|
              00000090  66 38 39 2d 34 34 66 37  2d 62 35 62 31 2d 37 32  |f89-44f7-b5b1-72|
              000000a0  66 64 61 30 39 66 32 61  65 39 5c 22 7d 22 3a 7b  |fda09f2ae9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 32 36 5c 22 7d  |2.168.225.226\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6k5jn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6k5jn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635912,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851635910,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.226",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.226"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851635910,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851635911,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://104afbc242057e027f9084e491bae080f4c585699ab01f4b670976e186b38279",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 13:31:52.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3642" for this suite. @ 05/18/24 13:31:52.855
• [7.090 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 05/18/24 13:31:52.861
  May 18 13:31:52.861: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:31:52.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:31:52.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:31:52.883
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:31:52.885
  E0518 13:31:53.264438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:54.264493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:55.265543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:56.265981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:31:56.909
  May 18 13:31:56.913: INFO: Trying to get logs from node ip-172-31-70-23 pod downwardapi-volume-60ae13f7-17ec-4888-af12-55f8643aa7de container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:31:56.917
  May 18 13:31:56.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4598" for this suite. @ 05/18/24 13:31:56.935
• [4.079 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 05/18/24 13:31:56.94
  May 18 13:31:56.940: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 13:31:56.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:31:56.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:31:56.959
  May 18 13:31:56.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:31:57.266935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:58.267946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:31:59.268841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0518 13:31:59.499950      19 warnings.go:70] unknown field "alpha"
  W0518 13:31:59.499971      19 warnings.go:70] unknown field "beta"
  W0518 13:31:59.499975      19 warnings.go:70] unknown field "delta"
  W0518 13:31:59.499978      19 warnings.go:70] unknown field "epsilon"
  W0518 13:31:59.499981      19 warnings.go:70] unknown field "gamma"
  May 18 13:32:00.048: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7883" for this suite. @ 05/18/24 13:32:00.052
• [3.118 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 05/18/24 13:32:00.058
  May 18 13:32:00.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:32:00.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:00.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:00.079
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-4526 @ 05/18/24 13:32:00.081
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/18/24 13:32:00.095
  STEP: creating service externalsvc in namespace services-4526 @ 05/18/24 13:32:00.095
  STEP: creating replication controller externalsvc in namespace services-4526 @ 05/18/24 13:32:00.106
  I0518 13:32:00.115156      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-4526, replica count: 2
  E0518 13:32:00.269891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:01.270065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:02.270250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:32:03.166366      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 05/18/24 13:32:03.17
  May 18 13:32:03.186: INFO: Creating new exec pod
  E0518 13:32:03.270993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:04.271190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:05.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-4526 exec execpodn4xzf -- /bin/sh -x -c nslookup nodeport-service.services-4526.svc.cluster.local'
  E0518 13:32:05.271916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:05.318: INFO: stderr: "+ nslookup nodeport-service.services-4526.svc.cluster.local\n"
  May 18 13:32:05.318: INFO: stdout: "Server:\t\t10.152.183.117\nAddress:\t10.152.183.117#53\n\nnodeport-service.services-4526.svc.cluster.local\tcanonical name = externalsvc.services-4526.svc.cluster.local.\nName:\texternalsvc.services-4526.svc.cluster.local\nAddress: 10.152.183.207\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-4526, will wait for the garbage collector to delete the pods @ 05/18/24 13:32:05.318
  May 18 13:32:05.381: INFO: Deleting ReplicationController externalsvc took: 7.542524ms
  May 18 13:32:05.481: INFO: Terminating ReplicationController externalsvc pods took: 100.154387ms
  E0518 13:32:06.271933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:07.272342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:08.272960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:08.298: INFO: Cleaning up the NodePort to ExternalName test service
  May 18 13:32:08.307: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4526" for this suite. @ 05/18/24 13:32:08.311
• [8.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 05/18/24 13:32:08.318
  May 18 13:32:08.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:32:08.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:08.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:08.337
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-863 @ 05/18/24 13:32:08.339
  STEP: changing the ExternalName service to type=NodePort @ 05/18/24 13:32:08.347
  STEP: creating replication controller externalname-service in namespace services-863 @ 05/18/24 13:32:08.366
  I0518 13:32:08.373129      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-863, replica count: 2
  E0518 13:32:09.273479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:10.273582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:11.273710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:32:11.424051      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:32:11.424: INFO: Creating new exec pod
  E0518 13:32:12.273844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:13.274284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:14.274373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:14.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  May 18 13:32:14.537: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  May 18 13:32:14.537: INFO: stdout: "externalname-service-t466f"
  May 18 13:32:14.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.119 80'
  May 18 13:32:14.631: INFO: stderr: "+ nc -v -t -w 2 10.152.183.119 80\nConnection to 10.152.183.119 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  May 18 13:32:14.631: INFO: stdout: ""
  E0518 13:32:15.274952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:15.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.119 80'
  May 18 13:32:15.631: INFO: stderr: "+ nc -v -t -w 2 10.152.183.119 80\n+ echo hostName\nConnection to 10.152.183.119 80 port [tcp/http] succeeded!\n"
  May 18 13:32:15.631: INFO: stdout: ""
  E0518 13:32:16.275192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:16.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.119 80'
  May 18 13:32:16.649: INFO: stderr: "+ nc -v -t -w 2 10.152.183.119 80\n+ echo hostName\nConnection to 10.152.183.119 80 port [tcp/http] succeeded!\n"
  May 18 13:32:16.649: INFO: stdout: "externalname-service-t466f"
  May 18 13:32:16.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.33.93 30660'
  May 18 13:32:16.768: INFO: stderr: "+ nc -v -t -w 2 172.31.33.93 30660\nConnection to 172.31.33.93 30660 port [tcp/*] succeeded!\n+ echo hostName\n"
  May 18 13:32:16.768: INFO: stdout: "externalname-service-kljvs"
  May 18 13:32:16.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-863 exec execpodx92pv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.70.23 30660'
  May 18 13:32:16.893: INFO: stderr: "+ nc -v -t -w 2 172.31.70.23 30660\n+ echo hostName\nConnection to 172.31.70.23 30660 port [tcp/*] succeeded!\n"
  May 18 13:32:16.893: INFO: stdout: "externalname-service-kljvs"
  May 18 13:32:16.893: INFO: Cleaning up the ExternalName to NodePort test service
  May 18 13:32:16.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-863" for this suite. @ 05/18/24 13:32:16.916
• [8.603 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 05/18/24 13:32:16.921
  May 18 13:32:16.921: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:32:16.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:16.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:16.941
  STEP: Setting up server cert @ 05/18/24 13:32:16.965
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:32:17.177
  STEP: Deploying the webhook pod @ 05/18/24 13:32:17.185
  STEP: Wait for the deployment to be ready @ 05/18/24 13:32:17.197
  May 18 13:32:17.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 13:32:17.275362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:18.275471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:32:19.215
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:32:19.225
  E0518 13:32:19.275746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:20.225: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  May 18 13:32:20.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:32:20.276459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6427-crds.webhook.example.com via the AdmissionRegistration API @ 05/18/24 13:32:20.742
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/18/24 13:32:20.758
  E0518 13:32:21.277339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:22.278111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:23.278214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:23.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-325" for this suite. @ 05/18/24 13:32:23.34
  STEP: Destroying namespace "webhook-markers-9620" for this suite. @ 05/18/24 13:32:23.348
• [6.433 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 05/18/24 13:32:23.355
  May 18 13:32:23.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:32:23.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:23.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:23.375
  STEP: Create set of pods @ 05/18/24 13:32:23.378
  May 18 13:32:23.386: INFO: created test-pod-1
  May 18 13:32:23.392: INFO: created test-pod-2
  May 18 13:32:23.397: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/18/24 13:32:23.397
  E0518 13:32:24.278352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:25.278498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/18/24 13:32:25.442
  May 18 13:32:25.445: INFO: Pod quantity 3 is different from expected quantity 0
  E0518 13:32:26.279104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:26.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4873" for this suite. @ 05/18/24 13:32:26.449
• [3.101 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 05/18/24 13:32:26.456
  May 18 13:32:26.456: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:32:26.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:26.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:26.48
  STEP: Counting existing ResourceQuota @ 05/18/24 13:32:26.483
  E0518 13:32:27.279927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:28.280246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:29.281142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:30.281234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:31.281442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 13:32:31.486
  STEP: Ensuring resource quota status is calculated @ 05/18/24 13:32:31.492
  E0518 13:32:32.281782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:33.281912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/18/24 13:32:33.498
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/18/24 13:32:33.516
  E0518 13:32:34.282008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:35.282096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/18/24 13:32:35.522
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/18/24 13:32:35.525
  STEP: Ensuring a pod cannot update its resource requirements @ 05/18/24 13:32:35.527
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/18/24 13:32:35.53
  E0518 13:32:36.282886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:37.283911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/18/24 13:32:37.535
  STEP: Ensuring resource quota status released the pod usage @ 05/18/24 13:32:37.554
  E0518 13:32:38.284533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:39.284716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:39.559: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7637" for this suite. @ 05/18/24 13:32:39.562
• [13.113 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 05/18/24 13:32:39.569
  May 18 13:32:39.569: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename cronjob @ 05/18/24 13:32:39.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:39.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:39.592
  STEP: Creating a cronjob @ 05/18/24 13:32:39.595
  STEP: creating @ 05/18/24 13:32:39.595
  STEP: getting @ 05/18/24 13:32:39.601
  STEP: listing @ 05/18/24 13:32:39.603
  STEP: watching @ 05/18/24 13:32:39.606
  May 18 13:32:39.606: INFO: starting watch
  STEP: cluster-wide listing @ 05/18/24 13:32:39.607
  STEP: cluster-wide watching @ 05/18/24 13:32:39.61
  May 18 13:32:39.610: INFO: starting watch
  STEP: patching @ 05/18/24 13:32:39.611
  STEP: updating @ 05/18/24 13:32:39.616
  May 18 13:32:39.627: INFO: waiting for watch events with expected annotations
  May 18 13:32:39.627: INFO: saw patched and updated annotations
  STEP: patching /status @ 05/18/24 13:32:39.627
  STEP: updating /status @ 05/18/24 13:32:39.631
  STEP: get /status @ 05/18/24 13:32:39.638
  STEP: deleting @ 05/18/24 13:32:39.641
  STEP: deleting a collection @ 05/18/24 13:32:39.656
  May 18 13:32:39.666: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4841" for this suite. @ 05/18/24 13:32:39.669
• [0.106 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 05/18/24 13:32:39.675
  May 18 13:32:39.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:32:39.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:39.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:39.695
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:32:39.698
  E0518 13:32:40.285626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:41.285743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:42.286431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:43.286520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:32:43.721
  May 18 13:32:43.726: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-d904c0a3-7608-4529-8036-435e24bcff28 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:32:43.737
  May 18 13:32:43.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6752" for this suite. @ 05/18/24 13:32:43.754
• [4.087 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 05/18/24 13:32:43.761
  May 18 13:32:43.761: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:32:43.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:43.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:43.78
  STEP: Counting existing ResourceQuota @ 05/18/24 13:32:43.784
  E0518 13:32:44.286596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:45.287451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:46.287557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:47.288409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:48.289048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 13:32:48.787
  STEP: Ensuring resource quota status is calculated @ 05/18/24 13:32:48.791
  E0518 13:32:49.289156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:50.289887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 05/18/24 13:32:50.796
  STEP: Ensuring resource quota status captures replication controller creation @ 05/18/24 13:32:50.816
  E0518 13:32:51.289957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:52.290259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 05/18/24 13:32:52.821
  STEP: Ensuring resource quota status released usage @ 05/18/24 13:32:52.828
  E0518 13:32:53.291069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:54.291255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:32:54.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8732" for this suite. @ 05/18/24 13:32:54.837
• [11.082 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 05/18/24 13:32:54.843
  May 18 13:32:54.843: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption @ 05/18/24 13:32:54.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:32:54.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:32:54.864
  May 18 13:32:54.880: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 13:32:55.291365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:56.291452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:57.291965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:58.292059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:32:59.292716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:00.292801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:01.293368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:02.293577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:03.293694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:04.293733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:05.293830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:06.293944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:07.294925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:08.295177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:09.295793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:10.296717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:11.297406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:12.297477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:13.298352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:14.298444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:15.298541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:16.298735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:17.299348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:18.300244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:19.300351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:20.300435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:21.300522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:22.301495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:23.301564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:24.301734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:25.302379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:26.302622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:27.302827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:28.302913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:29.303716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:30.303814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:31.304667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:32.304736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:33.305778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:34.305967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:35.307051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:36.307173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:37.307818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:38.308295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:39.309216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:40.309343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:41.309388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:42.309551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:43.309643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:44.309837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:45.310721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:46.310820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:47.310906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:48.311448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:49.311544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:50.312254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:51.312951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:52.313040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:53.314044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:54.314370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:33:54.885: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/18/24 13:33:54.888
  May 18 13:33:54.905: INFO: Created pod: pod0-0-sched-preemption-low-priority
  May 18 13:33:54.915: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  May 18 13:33:54.927: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  May 18 13:33:54.941: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  May 18 13:33:54.957: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  May 18 13:33:54.966: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/18/24 13:33:54.966
  E0518 13:33:55.314563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:56.314591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/18/24 13:33:56.992
  E0518 13:33:57.315562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:58.315641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:33:59.315787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:00.315861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:01.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4790" for this suite. @ 05/18/24 13:34:01.077
• [66.240 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 05/18/24 13:34:01.083
  May 18 13:34:01.083: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:34:01.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:01.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:01.102
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/18/24 13:34:01.105
  May 18 13:34:01.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4044 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  May 18 13:34:01.150: INFO: stderr: ""
  May 18 13:34:01.150: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/18/24 13:34:01.15
  May 18 13:34:01.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4044 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  May 18 13:34:01.194: INFO: stderr: ""
  May 18 13:34:01.194: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/18/24 13:34:01.194
  May 18 13:34:01.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-4044 delete pods e2e-test-httpd-pod'
  E0518 13:34:01.316079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:02.316171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:02.464: INFO: stderr: ""
  May 18 13:34:02.464: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 18 13:34:02.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4044" for this suite. @ 05/18/24 13:34:02.467
• [1.390 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 05/18/24 13:34:02.474
  May 18 13:34:02.474: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 13:34:02.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:02.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:02.492
  STEP: Creating a test namespace @ 05/18/24 13:34:02.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:02.51
  STEP: Creating a service in the namespace @ 05/18/24 13:34:02.513
  STEP: Deleting the namespace @ 05/18/24 13:34:02.523
  STEP: Waiting for the namespace to be removed. @ 05/18/24 13:34:02.529
  E0518 13:34:03.316928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:04.317031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:05.317969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:06.318038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:07.319108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:08.319214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/18/24 13:34:08.533
  STEP: Verifying there is no service in the namespace @ 05/18/24 13:34:08.561
  May 18 13:34:08.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4371" for this suite. @ 05/18/24 13:34:08.57
  STEP: Destroying namespace "nsdeletetest-4585" for this suite. @ 05/18/24 13:34:08.576
  May 18 13:34:08.579: INFO: Namespace nsdeletetest-4585 was already deleted
  STEP: Destroying namespace "nsdeletetest-4365" for this suite. @ 05/18/24 13:34:08.579
• [6.111 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/18/24 13:34:08.585
  May 18 13:34:08.585: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/18/24 13:34:08.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:08.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:08.604
  STEP: mirroring a new custom Endpoint @ 05/18/24 13:34:08.617
  May 18 13:34:08.627: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0518 13:34:09.320268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:10.320384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 05/18/24 13:34:10.633
  May 18 13:34:10.641: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0518 13:34:11.320546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:12.320603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 05/18/24 13:34:12.646
  May 18 13:34:12.658: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0518 13:34:13.321045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:14.321252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:14.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-6268" for this suite. @ 05/18/24 13:34:14.667
• [6.088 seconds]
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 05/18/24 13:34:14.673
  May 18 13:34:14.673: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:34:14.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:14.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:14.695
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:34:14.698
  E0518 13:34:15.322031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:16.322143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:34:16.717
  May 18 13:34:16.720: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-2d85298c-5c90-4f2b-872d-bd8af61694a2 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:34:16.736
  May 18 13:34:16.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7126" for this suite. @ 05/18/24 13:34:16.759
• [2.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/18/24 13:34:16.766
  May 18 13:34:16.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replicaset @ 05/18/24 13:34:16.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:16.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:16.786
  STEP: Create a ReplicaSet @ 05/18/24 13:34:16.789
  STEP: Verify that the required pods have come up @ 05/18/24 13:34:16.795
  May 18 13:34:16.798: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0518 13:34:17.322565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:18.322617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:19.322790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:20.322848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:21.322923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:21.802: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/18/24 13:34:21.802
  May 18 13:34:21.806: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/18/24 13:34:21.806
  STEP: DeleteCollection of the ReplicaSets @ 05/18/24 13:34:21.809
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/18/24 13:34:21.817
  May 18 13:34:21.820: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1222" for this suite. @ 05/18/24 13:34:21.824
• [5.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 05/18/24 13:34:21.837
  May 18 13:34:21.838: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:34:21.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:21.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:21.858
  STEP: creating service in namespace services-622 @ 05/18/24 13:34:21.86
  STEP: creating service affinity-clusterip-transition in namespace services-622 @ 05/18/24 13:34:21.861
  STEP: creating replication controller affinity-clusterip-transition in namespace services-622 @ 05/18/24 13:34:21.87
  I0518 13:34:21.875864      19 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-622, replica count: 3
  E0518 13:34:22.323712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:23.324088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:24.324269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:34:24.926986      19 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:34:24.935: INFO: Creating new exec pod
  E0518 13:34:25.325032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:26.325126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:27.325898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:27.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-622 exec execpod-affinityfvd9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  May 18 13:34:28.054: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  May 18 13:34:28.054: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:34:28.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-622 exec execpod-affinityfvd9c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.115 80'
  May 18 13:34:28.157: INFO: stderr: "+ nc -v -t -w 2 10.152.183.115 80\n+ echo hostName\nConnection to 10.152.183.115 80 port [tcp/http] succeeded!\n"
  May 18 13:34:28.157: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:34:28.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-622 exec execpod-affinityfvd9c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.115:80/ ; done'
  May 18 13:34:28.315: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n"
  May 18 13:34:28.315: INFO: stdout: "\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-hvbsk\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-hvbsk\naffinity-clusterip-transition-hvbsk\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-kfkcf\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-hvbsk\naffinity-clusterip-transition-kfkcf"
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-hvbsk
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-hvbsk
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-hvbsk
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-hvbsk
  May 18 13:34:28.315: INFO: Received response from host: affinity-clusterip-transition-kfkcf
  May 18 13:34:28.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-622 exec execpod-affinityfvd9c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.115:80/ ; done'
  E0518 13:34:28.326148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:28.461: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.115:80/\n"
  May 18 13:34:28.462: INFO: stdout: "\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs\naffinity-clusterip-transition-fsnrs"
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Received response from host: affinity-clusterip-transition-fsnrs
  May 18 13:34:28.462: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-622, will wait for the garbage collector to delete the pods @ 05/18/24 13:34:28.478
  May 18 13:34:28.540: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.610591ms
  May 18 13:34:28.640: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.425447ms
  E0518 13:34:29.327177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:30.327443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:31.328417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:31.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-622" for this suite. @ 05/18/24 13:34:31.862
• [10.030 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 05/18/24 13:34:31.868
  May 18 13:34:31.868: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 13:34:31.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:31.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:31.89
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/18/24 13:34:31.893
  May 18 13:34:31.893: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:34:32.329324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:33.125: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:34:33.329787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:34.330136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:35.330269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:36.330987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:37.331496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:34:38.090: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8797" for this suite. @ 05/18/24 13:34:38.096
• [6.236 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/18/24 13:34:38.104
  May 18 13:34:38.104: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:34:38.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:38.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:38.126
  STEP: Creating secret with name secret-test-58068948-e8e9-4aea-8bc1-94afecaa7863 @ 05/18/24 13:34:38.129
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:34:38.133
  E0518 13:34:38.331834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:39.331886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:40.332331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:41.332852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:34:42.155
  May 18 13:34:42.159: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-secrets-857fea80-8383-4cb6-8457-8a1ad650ab5e container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:34:42.168
  May 18 13:34:42.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9068" for this suite. @ 05/18/24 13:34:42.193
• [4.095 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 05/18/24 13:34:42.199
  May 18 13:34:42.199: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption @ 05/18/24 13:34:42.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:34:42.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:34:42.219
  May 18 13:34:42.235: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 13:34:42.333503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:43.333643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:44.333660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:45.333728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:46.334215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:47.335008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:48.335897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:49.336001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:50.336906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:51.337547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:52.338400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:53.338495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:54.338952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:55.339184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:56.339616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:57.340242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:58.340834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:34:59.341366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:00.341981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:01.343370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:02.344126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:03.344549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:04.345158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:05.345406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:06.345633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:07.346250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:08.346971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:09.347096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:10.347978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:11.348667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:12.348744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:13.349022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:14.349546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:15.349744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:16.349993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:17.350983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:18.351340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:19.351416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:20.351838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:21.352183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:22.352669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:23.353121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:24.354110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:25.354240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:26.354768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:27.354863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:28.355810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:29.356279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:30.357246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:31.357408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:32.358351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:33.359409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:34.359894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:35.360051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:36.360381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:37.361000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:38.361056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:39.361135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:40.361843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:41.361942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:35:42.240: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/18/24 13:35:42.244
  May 18 13:35:42.244: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/18/24 13:35:42.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:35:42.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:35:42.265
  STEP: Finding an available node @ 05/18/24 13:35:42.267
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/18/24 13:35:42.267
  E0518 13:35:42.362993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:43.363185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/18/24 13:35:44.288
  May 18 13:35:44.302: INFO: found a healthy node: ip-172-31-33-93
  E0518 13:35:44.363905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:45.364032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:46.364278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:47.364375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:48.364712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:49.364838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:35:50.358: INFO: pods created so far: [1 1 1]
  May 18 13:35:50.358: INFO: length of pods created so far: 3
  E0518 13:35:50.365088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:51.365222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:52.365241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:35:52.369: INFO: pods created so far: [2 2 1]
  E0518 13:35:53.366204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:54.366397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:55.366493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:56.366605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:57.367568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:58.367673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:35:59.368692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:35:59.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-7805" for this suite. @ 05/18/24 13:35:59.438
  May 18 13:35:59.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9351" for this suite. @ 05/18/24 13:35:59.447
• [77.255 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 05/18/24 13:35:59.454
  May 18 13:35:59.454: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:35:59.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:35:59.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:35:59.473
  STEP: Creating configMap with name projected-configmap-test-volume-map-030deb1d-73f2-4a93-8b5d-ca364d60e9a3 @ 05/18/24 13:35:59.476
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:35:59.483
  E0518 13:36:00.369156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:01.369329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:02.369554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:03.369640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:36:03.505
  May 18 13:36:03.508: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-projected-configmaps-f7f9cb06-94a7-444a-b459-7ffa3a16388e container agnhost-container: <nil>
  STEP: delete the pod @ 05/18/24 13:36:03.524
  May 18 13:36:03.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2244" for this suite. @ 05/18/24 13:36:03.544
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 05/18/24 13:36:03.551
  May 18 13:36:03.551: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename configmap @ 05/18/24 13:36:03.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:03.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:03.57
  STEP: Creating configMap with name configmap-test-upd-b5ee6199-80d4-4a5c-9f94-02447175acaa @ 05/18/24 13:36:03.575
  STEP: Creating the pod @ 05/18/24 13:36:03.579
  E0518 13:36:04.369687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:05.370667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 05/18/24 13:36:05.595
  STEP: Waiting for pod with binary data @ 05/18/24 13:36:05.602
  May 18 13:36:05.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8440" for this suite. @ 05/18/24 13:36:05.609
• [2.064 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 05/18/24 13:36:05.615
  May 18 13:36:05.615: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:36:05.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:05.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:05.635
  STEP: Setting up server cert @ 05/18/24 13:36:05.658
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:36:05.92
  STEP: Deploying the webhook pod @ 05/18/24 13:36:05.929
  STEP: Wait for the deployment to be ready @ 05/18/24 13:36:05.942
  May 18 13:36:05.948: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0518 13:36:06.371189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:07.371277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:36:07.959
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:36:07.969
  E0518 13:36:08.371910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:08.969: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/18/24 13:36:08.977
  STEP: create a pod @ 05/18/24 13:36:08.992
  E0518 13:36:09.372081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:10.372329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/18/24 13:36:11.009
  May 18 13:36:11.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=webhook-2810 attach --namespace=webhook-2810 to-be-attached-pod -i -c=container1'
  May 18 13:36:11.060: INFO: rc: 1
  May 18 13:36:11.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2810" for this suite. @ 05/18/24 13:36:11.107
  STEP: Destroying namespace "webhook-markers-5248" for this suite. @ 05/18/24 13:36:11.113
• [5.505 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 05/18/24 13:36:11.12
  May 18 13:36:11.120: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:36:11.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:11.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:11.144
  STEP: Setting up server cert @ 05/18/24 13:36:11.176
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:36:11.324
  STEP: Deploying the webhook pod @ 05/18/24 13:36:11.329
  STEP: Wait for the deployment to be ready @ 05/18/24 13:36:11.345
  May 18 13:36:11.351: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 13:36:11.372899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:12.373015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:36:13.362
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:36:13.373
  E0518 13:36:13.373981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:14.373: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0518 13:36:14.374014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/18/24 13:36:14.381
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/18/24 13:36:14.397
  May 18 13:36:14.397: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:36:14.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5932" for this suite. @ 05/18/24 13:36:14.454
  STEP: Destroying namespace "webhook-markers-1418" for this suite. @ 05/18/24 13:36:14.46
• [3.347 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/18/24 13:36:14.468
  May 18 13:36:14.468: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-runtime @ 05/18/24 13:36:14.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:14.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:14.489
  STEP: create the container @ 05/18/24 13:36:14.492
  W0518 13:36:14.500303      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/18/24 13:36:14.5
  E0518 13:36:15.374606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:16.375673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:17.376493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/18/24 13:36:17.521
  STEP: the container should be terminated @ 05/18/24 13:36:17.524
  STEP: the termination message should be set @ 05/18/24 13:36:17.524
  May 18 13:36:17.524: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/18/24 13:36:17.524
  May 18 13:36:17.538: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6479" for this suite. @ 05/18/24 13:36:17.541
• [3.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 05/18/24 13:36:17.547
  May 18 13:36:17.547: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:36:17.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:17.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:17.569
  STEP: creating a Pod with a static label @ 05/18/24 13:36:17.577
  STEP: watching for Pod to be ready @ 05/18/24 13:36:17.587
  May 18 13:36:17.589: INFO: observed Pod pod-test in namespace pods-7125 in phase Pending with labels: map[test-pod-static:true] & conditions []
  May 18 13:36:17.592: INFO: observed Pod pod-test in namespace pods-7125 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  }]
  May 18 13:36:17.612: INFO: observed Pod pod-test in namespace pods-7125 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  }]
  E0518 13:36:18.376605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:18.729: INFO: Found Pod pod-test in namespace pods-7125 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:18 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:36:17 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/18/24 13:36:18.733
  STEP: getting the Pod and ensuring that it's patched @ 05/18/24 13:36:18.742
  STEP: replacing the Pod's status Ready condition to False @ 05/18/24 13:36:18.744
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/18/24 13:36:18.755
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/18/24 13:36:18.755
  STEP: watching for the Pod to be deleted @ 05/18/24 13:36:18.765
  May 18 13:36:18.766: INFO: observed event type MODIFIED
  E0518 13:36:19.377073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:20.377302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:20.742: INFO: observed event type MODIFIED
  May 18 13:36:20.883: INFO: observed event type MODIFIED
  E0518 13:36:21.377497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:21.738: INFO: observed event type MODIFIED
  May 18 13:36:21.747: INFO: observed event type MODIFIED
  May 18 13:36:21.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7125" for this suite. @ 05/18/24 13:36:21.758
• [4.218 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 05/18/24 13:36:21.766
  May 18 13:36:21.766: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:36:21.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:21.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:21.785
  STEP: creating service multiprotocol-test in namespace services-1101 @ 05/18/24 13:36:21.788
  STEP: creating pod pod1 in namespace services-1101 @ 05/18/24 13:36:21.796
  STEP: Creating pod pod1 in namespace services-1101 @ 05/18/24 13:36:21.797
  E0518 13:36:22.378430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:23.378504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-1101 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/18/24 13:36:23.82
  May 18 13:36:23.830: INFO: successfully validated that service multiprotocol-test in namespace services-1101 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/18/24 13:36:23.83
  May 18 13:36:23.830: INFO: Creating new exec pod
  E0518 13:36:24.378791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:25.378893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:25.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80'
  May 18 13:36:25.939: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.160 80\nConnection to 10.152.183.160 80 port [tcp/http] succeeded!\n"
  May 18 13:36:25.939: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:36:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.160 80'
  E0518 13:36:26.379080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:27.379487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:28.379640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:29.379735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:30.040: INFO: stderr: "+ nc -v -u -w 2 10.152.183.160 80\n+ echo hostName\nConnection to 10.152.183.160 80 port [udp/*] succeeded!\n"
  May 18 13:36:30.040: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/18/24 13:36:30.04
  May 18 13:36:30.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80'
  May 18 13:36:30.151: INFO: stderr: "+ nc -v -t -w 2 10.152.183.160 80\n+ echo hostName\nConnection to 10.152.183.160 80 port [tcp/http] succeeded!\n"
  May 18 13:36:30.151: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:36:30.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.160 80'
  E0518 13:36:30.380033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:31.380206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:32.380394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:33.380907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:34.236: INFO: stderr: "+ nc -v -u -w 2 10.152.183.160 80\n+ echo hostName\nConnection to 10.152.183.160 80 port [udp/*] succeeded!\n"
  May 18 13:36:34.236: INFO: stdout: ""
  May 18 13:36:34.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.160 80'
  E0518 13:36:34.381244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:35.381319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:36.381583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:37.382564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:38.332: INFO: stderr: "+ nc -v -u -w 2 10.152.183.160 80\n+ echo hostName\nConnection to 10.152.183.160 80 port [udp/*] succeeded!\n"
  May 18 13:36:38.332: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/18/24 13:36:38.332
  May 18 13:36:38.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.160 80'
  E0518 13:36:38.383359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:39.384281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:40.385299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:41.385363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:42.385871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:42.437: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.160 80\nConnection to 10.152.183.160 80 port [udp/*] succeeded!\n"
  May 18 13:36:42.437: INFO: stdout: "pod1"
  May 18 13:36:42.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80'
  E0518 13:36:43.385963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:44.386039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:44.532: INFO: rc: 1
  May 18 13:36:44.532: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.160 80
  + echo hostName
  nc: connect to 10.152.183.160 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 18 13:36:44.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80'
  E0518 13:36:45.386572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:46.386656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:46.624: INFO: rc: 1
  May 18 13:36:46.624: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.160 80
  + echo hostName
  nc: connect to 10.152.183.160 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 18 13:36:46.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80'
  E0518 13:36:47.387523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:48.387700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:36:48.716: INFO: rc: 1
  May 18 13:36:48.716: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-1101 exec execpodrdfvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.160 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.160 80
  + echo hostName
  nc: connect to 10.152.183.160 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  May 18 13:36:48.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1101" for this suite. @ 05/18/24 13:36:48.721
• [26.962 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 05/18/24 13:36:48.728
  May 18 13:36:48.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:36:48.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:48.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:48.749
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/18/24 13:36:48.752
  E0518 13:36:49.388280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:50.388368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:36:50.771
  May 18 13:36:50.773: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-8ea4d7d4-df9d-4954-be7f-964b958ea559 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:36:50.779
  May 18 13:36:50.801: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6885" for this suite. @ 05/18/24 13:36:50.805
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 05/18/24 13:36:50.813
  May 18 13:36:50.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:36:50.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:50.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:50.832
  STEP: creating the pod @ 05/18/24 13:36:50.835
  May 18 13:36:50.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 create -f -'
  May 18 13:36:50.911: INFO: stderr: ""
  May 18 13:36:50.911: INFO: stdout: "pod/pause created\n"
  E0518 13:36:51.389208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:52.389576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/18/24 13:36:52.922
  May 18 13:36:52.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 label pods pause testing-label=testing-label-value'
  May 18 13:36:52.972: INFO: stderr: ""
  May 18 13:36:52.972: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/18/24 13:36:52.973
  May 18 13:36:52.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 get pod pause -L testing-label'
  May 18 13:36:53.017: INFO: stderr: ""
  May 18 13:36:53.017: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/18/24 13:36:53.017
  May 18 13:36:53.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 label pods pause testing-label-'
  May 18 13:36:53.073: INFO: stderr: ""
  May 18 13:36:53.073: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/18/24 13:36:53.073
  May 18 13:36:53.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 get pod pause -L testing-label'
  May 18 13:36:53.118: INFO: stderr: ""
  May 18 13:36:53.118: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 05/18/24 13:36:53.118
  May 18 13:36:53.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 delete --grace-period=0 --force -f -'
  May 18 13:36:53.169: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  May 18 13:36:53.169: INFO: stdout: "pod \"pause\" force deleted\n"
  May 18 13:36:53.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 get rc,svc -l name=pause --no-headers'
  May 18 13:36:53.216: INFO: stderr: "No resources found in kubectl-3695 namespace.\n"
  May 18 13:36:53.216: INFO: stdout: ""
  May 18 13:36:53.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-3695 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  May 18 13:36:53.256: INFO: stderr: ""
  May 18 13:36:53.256: INFO: stdout: ""
  May 18 13:36:53.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3695" for this suite. @ 05/18/24 13:36:53.261
• [2.456 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/18/24 13:36:53.269
  May 18 13:36:53.269: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename subpath @ 05/18/24 13:36:53.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:36:53.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:36:53.291
  STEP: Setting up data @ 05/18/24 13:36:53.294
  STEP: Creating pod pod-subpath-test-downwardapi-vwhv @ 05/18/24 13:36:53.303
  STEP: Creating a pod to test atomic-volume-subpath @ 05/18/24 13:36:53.303
  E0518 13:36:53.390269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:54.390332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:55.391241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:56.391347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:57.391813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:58.391893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:36:59.392143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:00.392221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:01.392802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:02.392924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:03.393668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:04.393804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:05.394402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:06.394503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:07.395537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:08.395647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:09.396235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:10.396419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:11.397479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:12.397752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:13.397926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:14.398035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:15.398099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:16.398955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:37:17.381
  May 18 13:37:17.385: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-subpath-test-downwardapi-vwhv container test-container-subpath-downwardapi-vwhv: <nil>
  STEP: delete the pod @ 05/18/24 13:37:17.392
  E0518 13:37:17.399620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-downwardapi-vwhv @ 05/18/24 13:37:17.409
  May 18 13:37:17.409: INFO: Deleting pod "pod-subpath-test-downwardapi-vwhv" in namespace "subpath-8611"
  May 18 13:37:17.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8611" for this suite. @ 05/18/24 13:37:17.416
• [24.153 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 05/18/24 13:37:17.422
  May 18 13:37:17.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:37:17.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:17.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:17.443
  STEP: fetching services @ 05/18/24 13:37:17.445
  May 18 13:37:17.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9663" for this suite. @ 05/18/24 13:37:17.451
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 05/18/24 13:37:17.458
  May 18 13:37:17.458: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 13:37:17.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:17.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:17.476
  STEP: apply creating a deployment @ 05/18/24 13:37:17.479
  May 18 13:37:17.492: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5625" for this suite. @ 05/18/24 13:37:17.495
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/18/24 13:37:17.502
  May 18 13:37:17.502: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename daemonsets @ 05/18/24 13:37:17.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:17.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:17.52
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/18/24 13:37:17.541
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/18/24 13:37:17.548
  May 18 13:37:17.550: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:17.550: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:17.553: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:37:17.553: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:37:18.399778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:18.553: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:18.553: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:18.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:37:18.557: INFO: Node ip-172-31-33-93 is running 0 daemon pod, expected 1
  E0518 13:37:19.399868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:19.554: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:19.554: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:19.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 13:37:19.557: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/18/24 13:37:19.559
  May 18 13:37:19.573: INFO: DaemonSet pods can't tolerate node ip-172-31-23-188 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:19.573: INFO: DaemonSet pods can't tolerate node ip-172-31-44-169 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  May 18 13:37:19.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  May 18 13:37:19.576: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/18/24 13:37:19.576
  E0518 13:37:20.399972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 05/18/24 13:37:20.584
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7189, will wait for the garbage collector to delete the pods @ 05/18/24 13:37:20.584
  May 18 13:37:20.645: INFO: Deleting DaemonSet.extensions daemon-set took: 7.094525ms
  May 18 13:37:20.746: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.366381ms
  E0518 13:37:21.400624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:21.951: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  May 18 13:37:21.951: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  May 18 13:37:21.955: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41569"},"items":null}

  May 18 13:37:21.958: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41569"},"items":null}

  May 18 13:37:21.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7189" for this suite. @ 05/18/24 13:37:21.973
• [4.480 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/18/24 13:37:21.983
  May 18 13:37:21.983: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sysctl @ 05/18/24 13:37:21.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:22.002
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/18/24 13:37:22.005
  STEP: Watching for error events or started pod @ 05/18/24 13:37:22.012
  E0518 13:37:22.401304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:23.401331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 05/18/24 13:37:24.016
  E0518 13:37:24.401901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:25.401996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 05/18/24 13:37:26.028
  STEP: Getting logs from the pod @ 05/18/24 13:37:26.028
  STEP: Checking that the sysctl is actually updated @ 05/18/24 13:37:26.04
  May 18 13:37:26.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7766" for this suite. @ 05/18/24 13:37:26.045
• [4.071 seconds]
------------------------------
SS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 05/18/24 13:37:26.054
  May 18 13:37:26.054: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename security-context-test @ 05/18/24 13:37:26.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:26.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:26.077
  E0518 13:37:26.402477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:27.402529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:28.103: INFO: Got logs for pod "busybox-privileged-false-24ec9c3a-71b1-4900-8aa3-7090168ec2ce": "ip: RTNETLINK answers: Operation not permitted\n"
  May 18 13:37:28.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8948" for this suite. @ 05/18/24 13:37:28.107
• [2.059 seconds]
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 05/18/24 13:37:28.114
  May 18 13:37:28.114: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename gc @ 05/18/24 13:37:28.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:28.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:28.134
  STEP: create the rc @ 05/18/24 13:37:28.14
  W0518 13:37:28.144091      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0518 13:37:28.403520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:29.404341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:30.404812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:31.420080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:32.420606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:33.453505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/18/24 13:37:34.147
  STEP: wait for the rc to be deleted @ 05/18/24 13:37:34.155
  E0518 13:37:34.453820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:35.163: INFO: 80 pods remaining
  May 18 13:37:35.165: INFO: 80 pods has nil DeletionTimestamp
  May 18 13:37:35.165: INFO: 
  E0518 13:37:35.455677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:36.165: INFO: 71 pods remaining
  May 18 13:37:36.166: INFO: 71 pods has nil DeletionTimestamp
  May 18 13:37:36.166: INFO: 
  E0518 13:37:36.456700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:37.164: INFO: 60 pods remaining
  May 18 13:37:37.164: INFO: 60 pods has nil DeletionTimestamp
  May 18 13:37:37.164: INFO: 
  E0518 13:37:37.457632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:38.163: INFO: 40 pods remaining
  May 18 13:37:38.164: INFO: 40 pods has nil DeletionTimestamp
  May 18 13:37:38.164: INFO: 
  E0518 13:37:38.458454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:39.163: INFO: 31 pods remaining
  May 18 13:37:39.163: INFO: 31 pods has nil DeletionTimestamp
  May 18 13:37:39.163: INFO: 
  E0518 13:37:39.459344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:40.167: INFO: 20 pods remaining
  May 18 13:37:40.167: INFO: 20 pods has nil DeletionTimestamp
  May 18 13:37:40.167: INFO: 
  E0518 13:37:40.460094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/18/24 13:37:41.164
  W0518 13:37:41.170110      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  May 18 13:37:41.170: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  May 18 13:37:41.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-490" for this suite. @ 05/18/24 13:37:41.173
• [13.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 05/18/24 13:37:41.194
  May 18 13:37:41.194: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename job @ 05/18/24 13:37:41.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:41.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:41.237
  STEP: Creating a suspended job @ 05/18/24 13:37:41.253
  STEP: Patching the Job @ 05/18/24 13:37:41.262
  STEP: Watching for Job to be patched @ 05/18/24 13:37:41.285
  May 18 13:37:41.287: INFO: Event ADDED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc] and annotations: map[]
  May 18 13:37:41.288: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc] and annotations: map[]
  May 18 13:37:41.288: INFO: Event MODIFIED found for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[]
  STEP: Updating the job @ 05/18/24 13:37:41.288
  STEP: Watching for Job to be updated @ 05/18/24 13:37:41.301
  May 18 13:37:41.303: INFO: Event MODIFIED found for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:41.303: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/18/24 13:37:41.303
  May 18 13:37:41.310: INFO: Job: e2e-wn6hc as labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched]
  STEP: Waiting for job to complete @ 05/18/24 13:37:41.31
  E0518 13:37:41.464303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:42.464670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:43.465553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:44.466014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:45.466688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:46.466746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:47.467213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:48.467323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 05/18/24 13:37:49.314
  STEP: Watching for Job to be deleted @ 05/18/24 13:37:49.325
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.327: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.328: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.328: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.328: INFO: Event MODIFIED observed for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  May 18 13:37:49.328: INFO: Event DELETED found for Job e2e-wn6hc in namespace job-8175 with labels: map[e2e-job-label:e2e-wn6hc e2e-wn6hc:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/18/24 13:37:49.328
  May 18 13:37:49.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8175" for this suite. @ 05/18/24 13:37:49.345
• [8.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 05/18/24 13:37:49.353
  May 18 13:37:49.353: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 13:37:49.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:49.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:49.375
  May 18 13:37:49.379: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:37:49.467815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:50.467902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/18/24 13:37:50.694
  May 18 13:37:50.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 create -f -'
  E0518 13:37:51.468808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:52.468874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:52.761: INFO: stderr: ""
  May 18 13:37:52.761: INFO: stdout: "e2e-test-crd-publish-openapi-4426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May 18 13:37:52.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 delete e2e-test-crd-publish-openapi-4426-crds test-foo'
  May 18 13:37:52.810: INFO: stderr: ""
  May 18 13:37:52.810: INFO: stdout: "e2e-test-crd-publish-openapi-4426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  May 18 13:37:52.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 apply -f -'
  May 18 13:37:52.864: INFO: stderr: ""
  May 18 13:37:52.864: INFO: stdout: "e2e-test-crd-publish-openapi-4426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  May 18 13:37:52.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 delete e2e-test-crd-publish-openapi-4426-crds test-foo'
  May 18 13:37:52.914: INFO: stderr: ""
  May 18 13:37:52.914: INFO: stdout: "e2e-test-crd-publish-openapi-4426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/18/24 13:37:52.914
  May 18 13:37:52.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 create -f -'
  May 18 13:37:52.964: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/18/24 13:37:52.964
  May 18 13:37:52.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 create -f -'
  May 18 13:37:53.006: INFO: rc: 1
  May 18 13:37:53.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 apply -f -'
  May 18 13:37:53.053: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/18/24 13:37:53.053
  May 18 13:37:53.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 create -f -'
  May 18 13:37:53.095: INFO: rc: 1
  May 18 13:37:53.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 --namespace=crd-publish-openapi-9938 apply -f -'
  May 18 13:37:53.141: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/18/24 13:37:53.141
  May 18 13:37:53.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 explain e2e-test-crd-publish-openapi-4426-crds'
  May 18 13:37:53.181: INFO: stderr: ""
  May 18 13:37:53.181: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4426-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/18/24 13:37:53.181
  May 18 13:37:53.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 explain e2e-test-crd-publish-openapi-4426-crds.metadata'
  May 18 13:37:53.220: INFO: stderr: ""
  May 18 13:37:53.220: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4426-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  May 18 13:37:53.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 explain e2e-test-crd-publish-openapi-4426-crds.spec'
  May 18 13:37:53.261: INFO: stderr: ""
  May 18 13:37:53.261: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4426-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  May 18 13:37:53.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 explain e2e-test-crd-publish-openapi-4426-crds.spec.bars'
  May 18 13:37:53.300: INFO: stderr: ""
  May 18 13:37:53.300: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4426-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/18/24 13:37:53.3
  May 18 13:37:53.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=crd-publish-openapi-9938 explain e2e-test-crd-publish-openapi-4426-crds.spec.bars2'
  May 18 13:37:53.338: INFO: rc: 1
  E0518 13:37:53.468972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:54.469199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:37:54.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9938" for this suite. @ 05/18/24 13:37:54.674
• [5.329 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 05/18/24 13:37:54.682
  May 18 13:37:54.682: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename field-validation @ 05/18/24 13:37:54.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:54.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:54.704
  STEP: apply creating a deployment @ 05/18/24 13:37:54.707
  May 18 13:37:54.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8723" for this suite. @ 05/18/24 13:37:54.72
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 05/18/24 13:37:54.728
  May 18 13:37:54.728: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:37:54.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:54.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:54.748
  STEP: validating cluster-info @ 05/18/24 13:37:54.752
  May 18 13:37:54.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-5155 cluster-info'
  May 18 13:37:54.793: INFO: stderr: ""
  May 18 13:37:54.793: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  May 18 13:37:54.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5155" for this suite. @ 05/18/24 13:37:54.797
• [0.075 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 05/18/24 13:37:54.803
  May 18 13:37:54.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 13:37:54.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:37:54.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:37:54.82
  STEP: Creating service test in namespace statefulset-8410 @ 05/18/24 13:37:54.824
  STEP: Creating stateful set ss in namespace statefulset-8410 @ 05/18/24 13:37:54.83
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8410 @ 05/18/24 13:37:54.837
  May 18 13:37:54.840: INFO: Found 0 stateful pods, waiting for 1
  E0518 13:37:55.470118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:56.470563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:57.471600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:58.471693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:37:59.472240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:00.473266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:01.474425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:02.474459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:03.475197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:04.476238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:04.843: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/18/24 13:38:04.843
  May 18 13:38:04.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 13:38:04.945: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 13:38:04.945: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 13:38:04.945: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 13:38:04.949: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0518 13:38:05.476310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:06.476406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:07.477072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:08.477163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:09.477233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:10.477423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:11.477526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:12.477641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:13.477708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:14.477793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:14.949: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 18 13:38:14.949: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 18 13:38:14.964: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  May 18 13:38:14.964: INFO: ss-0  ip-172-31-33-93  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:56 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:54 +0000 UTC  }]
  May 18 13:38:14.964: INFO: 
  May 18 13:38:14.964: INFO: StatefulSet ss has not reached scale 3, at 1
  E0518 13:38:15.478854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:15.968: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996612001s
  E0518 13:38:16.479579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:16.973: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991436909s
  E0518 13:38:17.480599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:17.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986438983s
  E0518 13:38:18.480788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:18.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981365815s
  E0518 13:38:19.480934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:19.987: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977297832s
  E0518 13:38:20.481015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:20.992: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97245673s
  E0518 13:38:21.481578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:21.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967713617s
  E0518 13:38:22.481644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:23.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963580101s
  E0518 13:38:23.481880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:24.006: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.233547ms
  E0518 13:38:24.482634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8410 @ 05/18/24 13:38:25.006
  May 18 13:38:25.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 13:38:25.111: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  May 18 13:38:25.111: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 13:38:25.111: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 13:38:25.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 13:38:25.209: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May 18 13:38:25.209: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 13:38:25.209: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 13:38:25.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  May 18 13:38:25.310: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  May 18 13:38:25.310: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  May 18 13:38:25.310: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  May 18 13:38:25.314: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:38:25.314: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  May 18 13:38:25.314: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/18/24 13:38:25.314
  May 18 13:38:25.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 13:38:25.406: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 13:38:25.406: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 13:38:25.406: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 13:38:25.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0518 13:38:25.483459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:25.496: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 13:38:25.496: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 13:38:25.496: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 13:38:25.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=statefulset-8410 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  May 18 13:38:25.596: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  May 18 13:38:25.596: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  May 18 13:38:25.596: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  May 18 13:38:25.596: INFO: Waiting for statefulset status.readyReplicas updated to 0
  May 18 13:38:25.600: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0518 13:38:26.484237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:27.485124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:28.485240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:29.485326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:30.485478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:31.485632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:32.485768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:33.485870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:34.486057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:35.486227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:35.606: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  May 18 13:38:35.606: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  May 18 13:38:35.606: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  May 18 13:38:35.619: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  May 18 13:38:35.619: INFO: ss-0  ip-172-31-33-93   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:56 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:37:54 +0000 UTC  }]
  May 18 13:38:35.619: INFO: ss-1  ip-172-31-70-23   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:16 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC  }]
  May 18 13:38:35.619: INFO: ss-2  ip-172-31-90-158  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:15 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC  }]
  May 18 13:38:35.619: INFO: 
  May 18 13:38:35.619: INFO: StatefulSet ss has not reached scale 0, at 3
  E0518 13:38:36.486761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:36.622: INFO: POD   NODE              PHASE      GRACE  CONDITIONS
  May 18 13:38:36.622: INFO: ss-2  ip-172-31-90-158  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:35 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:26 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-18 13:38:14 +0000 UTC  }]
  May 18 13:38:36.622: INFO: 
  May 18 13:38:36.622: INFO: StatefulSet ss has not reached scale 0, at 1
  E0518 13:38:37.487638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:37.627: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992207772s
  E0518 13:38:38.488224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:38.632: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.987616002s
  E0518 13:38:39.488310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:39.637: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.982556994s
  E0518 13:38:40.489139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:40.642: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.978818377s
  E0518 13:38:41.489927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:41.648: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.972931161s
  E0518 13:38:42.490087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:42.652: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.967827851s
  E0518 13:38:43.490992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:43.659: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.962873633s
  E0518 13:38:44.491183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:44.662: INFO: Verifying statefulset ss doesn't scale past 0 for another 956.725159ms
  E0518 13:38:45.491280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8410 @ 05/18/24 13:38:45.663
  May 18 13:38:45.668: INFO: Scaling statefulset ss to 0
  May 18 13:38:45.678: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 13:38:45.682: INFO: Deleting all statefulset in ns statefulset-8410
  May 18 13:38:45.684: INFO: Scaling statefulset ss to 0
  May 18 13:38:45.695: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 13:38:45.697: INFO: Deleting statefulset ss
  May 18 13:38:45.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8410" for this suite. @ 05/18/24 13:38:45.712
• [50.915 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 05/18/24 13:38:45.719
  May 18 13:38:45.719: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:38:45.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:38:45.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:38:45.756
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:38:45.759
  E0518 13:38:46.491389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:47.491459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:48.492473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:49.492576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:38:49.785
  May 18 13:38:49.788: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-20e1bcb6-0289-4c6b-912e-fec652d343e7 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:38:49.795
  May 18 13:38:49.812: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8782" for this suite. @ 05/18/24 13:38:49.815
• [4.101 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/18/24 13:38:49.821
  May 18 13:38:49.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/18/24 13:38:49.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:38:49.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:38:49.842
  STEP: getting /apis @ 05/18/24 13:38:49.848
  STEP: getting /apis/storage.k8s.io @ 05/18/24 13:38:49.851
  STEP: getting /apis/storage.k8s.io/v1 @ 05/18/24 13:38:49.852
  STEP: creating @ 05/18/24 13:38:49.853
  STEP: watching @ 05/18/24 13:38:49.867
  May 18 13:38:49.867: INFO: starting watch
  STEP: getting @ 05/18/24 13:38:49.874
  STEP: listing in namespace @ 05/18/24 13:38:49.877
  STEP: listing across namespaces @ 05/18/24 13:38:49.879
  STEP: patching @ 05/18/24 13:38:49.882
  STEP: updating @ 05/18/24 13:38:49.886
  May 18 13:38:49.891: INFO: waiting for watch events with expected annotations in namespace
  May 18 13:38:49.891: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/18/24 13:38:49.891
  STEP: deleting a collection @ 05/18/24 13:38:49.902
  May 18 13:38:49.916: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-5080" for this suite. @ 05/18/24 13:38:49.92
• [0.104 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 05/18/24 13:38:49.925
  May 18 13:38:49.925: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:38:49.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:38:49.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:38:49.945
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/18/24 13:38:49.948
  E0518 13:38:50.493268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:51.493363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:52.493751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:53.493860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:38:53.971
  May 18 13:38:53.975: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-e19e6835-4d2d-4269-bf67-0b1138dc74d6 container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:38:53.982
  May 18 13:38:53.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1720" for this suite. @ 05/18/24 13:38:54.001
• [4.081 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 05/18/24 13:38:54.007
  May 18 13:38:54.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 13:38:54.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:38:54.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:38:54.033
  STEP: Creating ReplicationController "e2e-rc-5cs76" @ 05/18/24 13:38:54.037
  May 18 13:38:54.042: INFO: Get Replication Controller "e2e-rc-5cs76" to confirm replicas
  E0518 13:38:54.493955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:55.043: INFO: Get Replication Controller "e2e-rc-5cs76" to confirm replicas
  May 18 13:38:55.047: INFO: Found 1 replicas for "e2e-rc-5cs76" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-5cs76" @ 05/18/24 13:38:55.047
  STEP: Updating a scale subresource @ 05/18/24 13:38:55.051
  STEP: Verifying replicas where modified for replication controller "e2e-rc-5cs76" @ 05/18/24 13:38:55.057
  May 18 13:38:55.057: INFO: Get Replication Controller "e2e-rc-5cs76" to confirm replicas
  E0518 13:38:55.494085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:38:56.057: INFO: Get Replication Controller "e2e-rc-5cs76" to confirm replicas
  May 18 13:38:56.062: INFO: Found 2 replicas for "e2e-rc-5cs76" replication controller
  May 18 13:38:56.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3147" for this suite. @ 05/18/24 13:38:56.066
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 05/18/24 13:38:56.073
  May 18 13:38:56.073: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:38:56.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:38:56.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:38:56.093
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/18/24 13:38:56.095
  E0518 13:38:56.494846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:57.495668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:58.495749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:38:59.496216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:39:00.118
  May 18 13:39:00.122: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-b994969c-a7c3-4a89-9822-6da1b43513fb container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:39:00.129
  May 18 13:39:00.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2738" for this suite. @ 05/18/24 13:39:00.148
• [4.081 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 05/18/24 13:39:00.154
  May 18 13:39:00.154: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename namespaces @ 05/18/24 13:39:00.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:00.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:00.175
  STEP: Read namespace status @ 05/18/24 13:39:00.177
  May 18 13:39:00.180: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/18/24 13:39:00.18
  May 18 13:39:00.186: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/18/24 13:39:00.186
  May 18 13:39:00.194: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  May 18 13:39:00.194: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9432" for this suite. @ 05/18/24 13:39:00.197
• [0.051 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 05/18/24 13:39:00.206
  May 18 13:39:00.206: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 13:39:00.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:00.223
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:00.226
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/18/24 13:39:00.228
  May 18 13:39:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:39:00.496857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:01.496946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:02.497699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:03.498046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:04.498468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/18/24 13:39:05.28
  May 18 13:39:05.280: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:39:05.498645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:39:06.495: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:39:06.499132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:07.499252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:08.499441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:09.499529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:10.499633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:11.499652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:39:11.570: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2912" for this suite. @ 05/18/24 13:39:11.578
• [11.380 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/18/24 13:39:11.586
  May 18 13:39:11.586: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename certificates @ 05/18/24 13:39:11.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:11.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:11.613
  STEP: getting /apis @ 05/18/24 13:39:11.858
  STEP: getting /apis/certificates.k8s.io @ 05/18/24 13:39:11.862
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/18/24 13:39:11.863
  STEP: creating @ 05/18/24 13:39:11.864
  STEP: getting @ 05/18/24 13:39:11.88
  STEP: listing @ 05/18/24 13:39:11.883
  STEP: watching @ 05/18/24 13:39:11.885
  May 18 13:39:11.885: INFO: starting watch
  STEP: patching @ 05/18/24 13:39:11.886
  STEP: updating @ 05/18/24 13:39:11.892
  May 18 13:39:11.899: INFO: waiting for watch events with expected annotations
  May 18 13:39:11.899: INFO: saw patched and updated annotations
  STEP: getting /approval @ 05/18/24 13:39:11.899
  STEP: patching /approval @ 05/18/24 13:39:11.901
  STEP: updating /approval @ 05/18/24 13:39:11.907
  STEP: getting /status @ 05/18/24 13:39:11.914
  STEP: patching /status @ 05/18/24 13:39:11.916
  STEP: updating /status @ 05/18/24 13:39:11.924
  STEP: deleting @ 05/18/24 13:39:11.931
  STEP: deleting a collection @ 05/18/24 13:39:11.941
  May 18 13:39:11.956: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-9554" for this suite. @ 05/18/24 13:39:11.961
• [0.384 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 05/18/24 13:39:11.97
  May 18 13:39:11.970: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename dns @ 05/18/24 13:39:11.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:11.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:11.99
  STEP: Creating a test externalName service @ 05/18/24 13:39:11.993
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:11.997
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:11.997
  STEP: creating a pod to probe DNS @ 05/18/24 13:39:11.997
  STEP: submitting the pod to kubernetes @ 05/18/24 13:39:11.997
  E0518 13:39:12.499762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:13.499863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 13:39:14.018
  STEP: looking for the results for each expected name from probers @ 05/18/24 13:39:14.021
  May 18 13:39:14.032: INFO: DNS probes using dns-test-093dc074-d5b1-4abe-a4e5-3c9ae5b6f7e1 succeeded

  STEP: changing the externalName to bar.example.com @ 05/18/24 13:39:14.032
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:14.042
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:14.042
  STEP: creating a second pod to probe DNS @ 05/18/24 13:39:14.042
  STEP: submitting the pod to kubernetes @ 05/18/24 13:39:14.042
  E0518 13:39:14.501816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:15.502151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 13:39:16.058
  STEP: looking for the results for each expected name from probers @ 05/18/24 13:39:16.062
  May 18 13:39:16.067: INFO: File wheezy_udp@dns-test-service-3.dns-7125.svc.cluster.local from pod  dns-7125/dns-test-e0b70ce1-d1c8-47d0-afea-f8fed36f9deb contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 18 13:39:16.072: INFO: File jessie_udp@dns-test-service-3.dns-7125.svc.cluster.local from pod  dns-7125/dns-test-e0b70ce1-d1c8-47d0-afea-f8fed36f9deb contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  May 18 13:39:16.072: INFO: Lookups using dns-7125/dns-test-e0b70ce1-d1c8-47d0-afea-f8fed36f9deb failed for: [wheezy_udp@dns-test-service-3.dns-7125.svc.cluster.local jessie_udp@dns-test-service-3.dns-7125.svc.cluster.local]

  May 18 13:39:16.091: INFO: Pod client logs for webserver: 
  May 18 13:39:16.103: INFO: Pod client logs for querier: 
  May 18 13:39:16.115: INFO: Pod client logs for jessie-querier: 
  E0518 13:39:16.503077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:17.503515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:18.503623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:19.503775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:20.503851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:39:21.072: INFO: DNS probes using dns-test-e0b70ce1-d1c8-47d0-afea-f8fed36f9deb succeeded

  STEP: changing the service to type=ClusterIP @ 05/18/24 13:39:21.073
  W0518 13:39:21.086170      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:21.086
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7125.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7125.svc.cluster.local; sleep 1; done
   @ 05/18/24 13:39:21.086
  STEP: creating a third pod to probe DNS @ 05/18/24 13:39:21.086
  STEP: submitting the pod to kubernetes @ 05/18/24 13:39:21.09
  E0518 13:39:21.504775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:22.504862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/18/24 13:39:23.103
  STEP: looking for the results for each expected name from probers @ 05/18/24 13:39:23.107
  May 18 13:39:23.117: INFO: DNS probes using dns-test-d5184d71-1475-4ecb-99ba-512c081abd2c succeeded

  STEP: deleting the pod @ 05/18/24 13:39:23.117
  STEP: deleting the pod @ 05/18/24 13:39:23.128
  STEP: deleting the pod @ 05/18/24 13:39:23.14
  STEP: deleting the test externalName service @ 05/18/24 13:39:23.155
  May 18 13:39:23.171: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7125" for this suite. @ 05/18/24 13:39:23.173
• [11.211 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 05/18/24 13:39:23.181
  May 18 13:39:23.181: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:39:23.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:23.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:23.202
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:39:23.207
  E0518 13:39:23.504996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:24.505236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:25.505824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:26.506029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:39:27.231
  May 18 13:39:27.233: INFO: Trying to get logs from node ip-172-31-33-93 pod downwardapi-volume-65e274ea-0229-4ba4-883a-b2bb5b1e7d71 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:39:27.246
  May 18 13:39:27.263: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9060" for this suite. @ 05/18/24 13:39:27.266
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 05/18/24 13:39:27.272
  May 18 13:39:27.272: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/18/24 13:39:27.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:39:27.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:39:27.29
  May 18 13:39:27.293: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 13:39:27.506187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:28.506301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:29.506413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:30.506470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:31.507520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:32.508093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:33.508944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:34.509037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:35.509981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:36.510645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:37.511441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:38.511718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:39.512041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:40.512187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:41.512578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:42.513019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:43.514031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:44.514111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:45.515009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:46.515161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:47.515765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:48.515874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:49.516169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:50.516258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:51.517297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:52.517472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:53.518458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:54.519236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:55.519576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:56.520233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:57.521221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:58.521318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:39:59.522218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:00.522297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:01.522550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:02.522744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:03.523483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:04.523578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:05.523957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:06.524149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:07.524340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:08.524350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:09.524543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:10.524917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:11.525801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:12.526415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:13.526540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:14.526613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:15.526682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:16.526807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:17.527569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:18.528231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:19.528466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:20.528552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:21.528800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:22.528958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:23.529058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:24.530043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:25.530733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:26.530819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:40:27.294: INFO: Waiting for terminating namespaces to be deleted...
  May 18 13:40:27.298: INFO: Starting informer...
  STEP: Starting pods... @ 05/18/24 13:40:27.298
  May 18 13:40:27.518: INFO: Pod1 is running on ip-172-31-33-93. Tainting Node
  E0518 13:40:27.531542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:28.531631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:29.531893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:40:29.741: INFO: Pod2 is running on ip-172-31-33-93. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/18/24 13:40:29.741
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/18/24 13:40:29.753
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/18/24 13:40:29.756
  E0518 13:40:30.531940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:31.532272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:32.532365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:33.532589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:34.532716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:35.533119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:40:35.546: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0518 13:40:36.534135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:37.534191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:38.534857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:39.534994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:40.535207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:41.535251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:42.535311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:43.536238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:44.536405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:45.536570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:46.536660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:47.537705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:48.537800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:49.538651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:50.538748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:51.538935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:52.539296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:53.539416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:54.540222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:55.540344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:40:55.579: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/18/24 13:40:55.589
  May 18 13:40:55.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-8961" for this suite. @ 05/18/24 13:40:55.595
• [88.332 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 05/18/24 13:40:55.605
  May 18 13:40:55.605: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename svcaccounts @ 05/18/24 13:40:55.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:40:55.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:40:55.628
  May 18 13:40:55.642: INFO: created pod
  E0518 13:40:56.541379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:57.542175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:58.542945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:40:59.543210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:40:59.656
  E0518 13:41:00.544257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:01.544453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:02.545378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:03.545457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:04.545619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:05.545716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:06.545834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:07.546530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:08.546843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:09.547125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:10.547170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:11.547372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:12.547470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:13.547519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:14.547959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:15.548232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:16.548924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:17.549120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:18.550150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:19.550194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:20.550304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:21.550419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:22.550514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:23.550612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:24.551386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:25.551487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:26.552227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:27.553189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:28.553472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:29.553537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:29.656: INFO: polling logs
  May 18 13:41:29.670: INFO: Pod logs: 
  I0518 13:40:56.527171       1 log.go:245] OK: Got token
  I0518 13:40:56.527221       1 log.go:245] validating with in-cluster discovery
  I0518 13:40:56.527471       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I0518 13:40:56.527518       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8060:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00044ce60), NotBefore:(*jwt.NumericDate)(0xc00044cf48), IssuedAt:(*jwt.NumericDate)(0xc00044ce70), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8060", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"00ca7d01-90ac-4a2e-8491-db117d5724c1"}}}
  I0518 13:40:56.534573       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0518 13:40:56.537312       1 log.go:245] OK: Validated signature on JWT
  I0518 13:40:56.537397       1 log.go:245] OK: Got valid claims from token!
  I0518 13:40:56.537425       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8060:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000126410), NotBefore:(*jwt.NumericDate)(0xc000126438), IssuedAt:(*jwt.NumericDate)(0xc000126418), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8060", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"00ca7d01-90ac-4a2e-8491-db117d5724c1"}}}

  May 18 13:41:29.670: INFO: completed pod
  May 18 13:41:29.677: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8060" for this suite. @ 05/18/24 13:41:29.681
• [34.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 05/18/24 13:41:29.688
  May 18 13:41:29.688: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-probe @ 05/18/24 13:41:29.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:41:29.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:41:29.71
  STEP: Creating pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064 @ 05/18/24 13:41:29.713
  E0518 13:41:30.553642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:31.554432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/18/24 13:41:31.727
  May 18 13:41:31.730: INFO: Initial restart count of pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd is 0
  May 18 13:41:31.733: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:32.555173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:33.555313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:33.738: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:34.556263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:35.556357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:35.742: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:36.557146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:37.557823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:37.747: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:38.558367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:39.558449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:39.752: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:40.558540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:41.558623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:41.756: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:42.559251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:43.559353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:43.761: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:44.560329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:45.560426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:45.766: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:46.560685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:47.561706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:47.770: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:48.562338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:49.562606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:49.774: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:50.563211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:51.564255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:51.777: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:52.564728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:53.565235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:53.783: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:54.566242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:55.566448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:55.787: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:56.567142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:57.567192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:57.792: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:41:58.567357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:41:59.567452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:41:59.798: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:00.568275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:01.568314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:01.802: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:02.568612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:03.568917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:03.807: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:04.569278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:05.569362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:05.813: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:06.569602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:07.569804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:07.818: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:08.570105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:09.570288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:09.823: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:10.570382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:11.570513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:11.830: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:12.570623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:13.570728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:13.835: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:14.570906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:15.571071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:15.838: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:16.571195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:17.571275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:17.844: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:18.572240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:19.572405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:19.850: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:20.572498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:21.572721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:21.854: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:22.572754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:23.572854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:23.859: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:24.573578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:25.574173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:25.864: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:26.574505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:27.574616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:27.869: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:28.575649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:29.575755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:29.875: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:30.576125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:31.576757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:31.880: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:32.577665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:33.578574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:33.885: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:34.579644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:35.579734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:35.891: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:36.580363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:37.581205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:37.896: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:38.581249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:39.581332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:39.901: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:40.581728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:41.581854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:41.906: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:42.582862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:43.583164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:43.911: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:44.583258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:45.584326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:45.916: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:46.584422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:47.584583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:47.922: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:48.584674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:49.585537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:49.927: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:50.585706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:51.585795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:51.931: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:52.586541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:53.586631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:53.935: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:54.587170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:55.588245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:55.939: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:56.589156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:57.590274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:57.944: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:42:58.590885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:42:59.591078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:42:59.949: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:00.591265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:01.592271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:01.956: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:02.592370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:03.592432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:03.960: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:04.592528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:05.593322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:05.966: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:06.594239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:07.594313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:07.971: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:08.594957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:09.595151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:09.976: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:10.595250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:11.596247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:11.981: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:12.597024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:13.597118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:13.985: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:14.597270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:15.597360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:15.989: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:16.598326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:17.598840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:17.995: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:18.598944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:19.599230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:19.999: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:20.600122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:21.600219      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:22.004: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:22.600311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:23.601253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:24.010: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:24.602217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:25.602317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:26.014: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:26.603342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:27.604223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:28.019: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:28.604350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:29.604531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:30.024: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:30.605136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:31.605311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:32.029: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:32.605412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:33.606242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:34.035: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:34.607008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:35.607177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:36.039: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:36.607516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:37.607652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:38.045: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:38.608583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:39.608683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:40.049: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:40.609636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:41.609727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:42.053: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:42.610597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:43.610692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:44.059: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:44.610744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:45.611477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:46.065: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:46.611785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:47.612601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:48.070: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:48.613393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:49.614255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:50.075: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:50.615016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:51.615167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:52.080: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:52.616138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:53.616517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:54.084: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:54.617041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:55.617143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:56.088: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:56.617979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:57.618071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:43:58.093: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:43:58.618268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:43:59.618481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:00.097: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:00.618535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:01.619370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:02.103: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:02.620221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:03.620541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:04.109: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:04.620843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:05.621034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:06.113: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:06.621400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:07.621603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:08.118: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:08.621877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:09.622127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:10.124: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:10.622861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:11.622951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:12.129: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:12.624027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:13.624122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:14.135: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:14.624682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:15.624922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:16.140: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:16.625211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:17.626247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:18.146: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:18.626443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:19.626682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:20.150: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:20.627488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:21.627581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:22.156: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:22.627646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:23.627736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:24.161: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:24.627830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:25.628823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:26.166: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:26.628914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:27.628962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:28.171: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:28.629056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:29.629237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:30.176: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:30.629768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:31.629949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:32.180: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:32.630998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:33.631163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:34.184: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:34.632227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:35.632414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:36.189: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:36.633372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:37.634270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:38.193: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:38.635340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:39.636232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:40.198: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:40.636382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:41.636468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:42.203: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:42.637217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:43.637306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:44.208: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:44.638361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:45.638701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:46.213: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:46.638990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:47.639170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:48.217: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:48.640181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:49.640399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:50.222: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:50.641146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:51.641239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:52.227: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:52.642198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:53.642273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:54.231: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:54.642905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:55.643582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:56.237: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:56.643680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:57.643762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:44:58.242: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:44:58.643815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:44:59.643911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:00.247: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:00.644013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:01.644142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:02.252: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:02.644245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:03.644317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:04.257: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:04.645012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:05.645133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:06.262: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:06.645822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:07.646824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:08.267: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:08.646932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:09.647176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:10.271: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:10.647727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:11.648275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:12.276: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:12.648346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:13.649157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:14.282: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:14.649679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:15.649793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:16.287: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:16.650512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:17.650792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:18.292: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:18.651162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:19.651268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:20.298: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:20.651381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:21.652274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:22.303: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:22.652359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:23.652448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:24.309: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:24.652839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:25.653023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:26.313: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:26.654147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:27.654254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:28.318: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:28.655224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:29.655329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:30.324: INFO: Get pod liveness-0083b621-6d65-4244-96ae-b8e12345a5dd in namespace container-probe-7064
  E0518 13:45:30.656247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:31.656469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/18/24 13:45:32.324
  May 18 13:45:32.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7064" for this suite. @ 05/18/24 13:45:32.343
• [242.660 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/18/24 13:45:32.348
  May 18 13:45:32.348: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename init-container @ 05/18/24 13:45:32.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:32.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:32.381
  STEP: creating the pod @ 05/18/24 13:45:32.384
  May 18 13:45:32.384: INFO: PodSpec: initContainers in spec.initContainers
  E0518 13:45:32.657526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:33.657713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:34.658473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:35.658558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:36.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8228" for this suite. @ 05/18/24 13:45:36.044
• [3.703 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 05/18/24 13:45:36.051
  May 18 13:45:36.051: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:45:36.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:36.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:36.07
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/18/24 13:45:36.072
  E0518 13:45:36.658847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:37.659786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:38.660113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:39.660212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:45:40.096
  May 18 13:45:40.099: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-9ea57cf4-4cb8-4354-b915-8c15d2f8eaba container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:45:40.115
  May 18 13:45:40.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8170" for this suite. @ 05/18/24 13:45:40.134
• [4.089 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 05/18/24 13:45:40.14
  May 18 13:45:40.140: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:45:40.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:40.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:40.158
  STEP: Setting up server cert @ 05/18/24 13:45:40.187
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:45:40.442
  STEP: Deploying the webhook pod @ 05/18/24 13:45:40.451
  STEP: Wait for the deployment to be ready @ 05/18/24 13:45:40.463
  May 18 13:45:40.469: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0518 13:45:40.660276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:41.660513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:45:42.481
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:45:42.49
  E0518 13:45:42.660815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:43.490: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/18/24 13:45:43.498
  STEP: create a pod that should be updated by the webhook @ 05/18/24 13:45:43.512
  May 18 13:45:43.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3548" for this suite. @ 05/18/24 13:45:43.584
  STEP: Destroying namespace "webhook-markers-905" for this suite. @ 05/18/24 13:45:43.593
• [3.460 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 05/18/24 13:45:43.6
  May 18 13:45:43.600: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:45:43.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:43.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:43.622
  STEP: Creating configMap with name projected-configmap-test-volume-fae53754-7f67-4c93-929b-f584023d30df @ 05/18/24 13:45:43.625
  STEP: Creating a pod to test consume configMaps @ 05/18/24 13:45:43.628
  E0518 13:45:43.660992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:44.661112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:45.662065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:46.662155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:45:47.647
  May 18 13:45:47.651: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-projected-configmaps-6d2b905d-ff43-4171-b29b-9aaa887a2a72 container agnhost-container: <nil>
  E0518 13:45:47.662432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 05/18/24 13:45:47.669
  May 18 13:45:47.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3263" for this suite. @ 05/18/24 13:45:47.689
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 05/18/24 13:45:47.695
  May 18 13:45:47.695: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:45:47.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:47.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:47.716
  STEP: Creating a pod to test downward API volume plugin @ 05/18/24 13:45:47.718
  E0518 13:45:48.663188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:49.664236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:50.664343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:51.664543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:45:51.741
  May 18 13:45:51.745: INFO: Trying to get logs from node ip-172-31-70-23 pod downwardapi-volume-90d9beab-25e9-47b1-ba3a-51739d219366 container client-container: <nil>
  STEP: delete the pod @ 05/18/24 13:45:51.752
  May 18 13:45:51.769: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4309" for this suite. @ 05/18/24 13:45:51.772
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 05/18/24 13:45:51.779
  May 18 13:45:51.779: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename runtimeclass @ 05/18/24 13:45:51.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:51.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:51.8
  E0518 13:45:52.665555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:53.665651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:45:53.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8187" for this suite. @ 05/18/24 13:45:53.835
• [2.065 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/18/24 13:45:53.843
  May 18 13:45:53.843: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename deployment @ 05/18/24 13:45:53.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:53.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:53.865
  May 18 13:45:53.867: INFO: Creating simple deployment test-new-deployment
  May 18 13:45:53.886: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0518 13:45:54.665970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:55.666082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 05/18/24 13:45:55.9
  STEP: updating a scale subresource @ 05/18/24 13:45:55.902
  STEP: verifying the deployment Spec.Replicas was modified @ 05/18/24 13:45:55.908
  STEP: Patch a scale subresource @ 05/18/24 13:45:55.912
  May 18 13:45:55.927: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2389",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4c07be1f-3efb-4309-a51d-b77680f03372",
      ResourceVersion: (string) (len=5) "46288",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851636753,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636753,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636753,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  May 18 13:45:55.935: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2389",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44fb301c-06cc-466d-a1c2-600184d8aef8",
      ResourceVersion: (string) (len=5) "46287",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851636753,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "4c07be1f-3efb-4309-a51d-b77680f03372",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 63 30 37 62 65  31 66 2d 33 65 66 62 2d  |\"4c07be1f-3efb-|
              00000120  34 33 30 39 2d 61 35 31  64 2d 62 37 37 36 38 30  |4309-a51d-b77680|
              00000130  66 30 33 33 37 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f03372\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  May 18 13:45:55.939: INFO: Pod "test-new-deployment-557759b7c7-fh2fj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-fh2fj",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2389",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8b6669e7-2bad-41b2-a969-02a5ae0e0401",
      ResourceVersion: (string) (len=5) "46292",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851636755,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "44fb301c-06cc-466d-a1c2-600184d8aef8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  66 62 33 30 31 63 2d 30  |d\":\"44fb301c-0|
              00000090  36 63 63 2d 34 36 36 64  2d 61 31 63 32 2d 36 30  |6cc-466d-a1c2-60|
              000000a0  30 31 38 34 64 38 61 65  66 38 5c 22 7d 22 3a 7b  |0184d8aef8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dzkkw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dzkkw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-70-23",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 13:45:55.941: INFO: Pod "test-new-deployment-557759b7c7-vhv8k" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-vhv8k",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2389",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c7ed1f43-2260-480a-88bb-75cc370123d1",
      ResourceVersion: (string) (len=5) "46282",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851636753,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "44fb301c-06cc-466d-a1c2-600184d8aef8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636753,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  66 62 33 30 31 63 2d 30  |d\":\"44fb301c-0|
              00000090  36 63 63 2d 34 36 36 64  2d 61 31 63 32 2d 36 30  |6cc-466d-a1c2-60|
              000000a0  30 31 38 34 64 38 61 65  66 38 5c 22 7d 22 3a 7b  |0184d8aef8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 32  35 2e 32 32 37 5c 22 7d  |2.168.225.227\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2t7r5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2t7r5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-33-93",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636753,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851636753,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.33.93",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.33.93"
        }
      },
      PodIP: (string) (len=15) "192.168.225.227",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.225.227"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851636753,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851636754,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e33ad88587c0236b78d45d45afda179eda3c4e1aa36e4f1bd05ae30c901b5b58",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  May 18 13:45:55.944: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2389" for this suite. @ 05/18/24 13:45:55.947
• [2.115 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/18/24 13:45:55.958
  May 18 13:45:55.958: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-runtime @ 05/18/24 13:45:55.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:56.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:56.061
  STEP: create the container @ 05/18/24 13:45:56.063
  W0518 13:45:56.075186      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/18/24 13:45:56.075
  E0518 13:45:56.666983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:57.667602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:45:58.667718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/18/24 13:45:59.092
  STEP: the container should be terminated @ 05/18/24 13:45:59.095
  STEP: the termination message should be set @ 05/18/24 13:45:59.095
  May 18 13:45:59.095: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/18/24 13:45:59.095
  May 18 13:45:59.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1616" for this suite. @ 05/18/24 13:45:59.117
• [3.163 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/18/24 13:45:59.122
  May 18 13:45:59.122: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename endpointslice @ 05/18/24 13:45:59.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:45:59.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:45:59.14
  E0518 13:45:59.668754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:00.669026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:01.669096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:02.669254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:03.669342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 05/18/24 13:46:04.205
  E0518 13:46:04.669444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:05.669648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:06.669811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:07.670042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:08.670293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 05/18/24 13:46:09.213
  E0518 13:46:09.670365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:10.670464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:11.671147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:12.671164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:13.671255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/18/24 13:46:14.222
  E0518 13:46:14.671347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:15.672246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:16.672433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:17.672523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:18.672616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 05/18/24 13:46:19.229
  May 18 13:46:19.247: INFO: EndpointSlice for Service endpointslice-818/example-named-port not found
  E0518 13:46:19.673547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:20.673753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:21.673863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:22.673947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:23.674052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:24.674382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:25.674484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:26.674635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:27.674724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:28.674817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:29.255: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-818" for this suite. @ 05/18/24 13:46:29.26
• [30.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 05/18/24 13:46:29.269
  May 18 13:46:29.269: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename replication-controller @ 05/18/24 13:46:29.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:29.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:29.292
  May 18 13:46:29.295: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0518 13:46:29.674912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/18/24 13:46:30.307
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/18/24 13:46:30.313
  E0518 13:46:30.675759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/18/24 13:46:31.32
  May 18 13:46:31.330: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/18/24 13:46:31.33
  E0518 13:46:31.675825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:32.342: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7188" for this suite. @ 05/18/24 13:46:32.346
• [3.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/18/24 13:46:32.352
  May 18 13:46:32.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename projected @ 05/18/24 13:46:32.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:32.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:32.376
  STEP: Creating projection with secret that has name projected-secret-test-map-46b54beb-3b93-4e61-bc84-0318d95d5012 @ 05/18/24 13:46:32.378
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:46:32.384
  E0518 13:46:32.676643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:33.676712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:34.676931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:35.677024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:46:36.407
  May 18 13:46:36.409: INFO: Trying to get logs from node ip-172-31-70-23 pod pod-projected-secrets-df62da39-1562-4260-8205-c00f85834ab5 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:46:36.415
  May 18 13:46:36.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-755" for this suite. @ 05/18/24 13:46:36.435
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 05/18/24 13:46:36.442
  May 18 13:46:36.442: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:46:36.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:36.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:36.463
  May 18 13:46:36.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 create -f -'
  May 18 13:46:36.543: INFO: stderr: ""
  May 18 13:46:36.544: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  May 18 13:46:36.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 create -f -'
  May 18 13:46:36.627: INFO: stderr: ""
  May 18 13:46:36.627: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/18/24 13:46:36.627
  E0518 13:46:36.677597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:37.631: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 13:46:37.631: INFO: Found 0 / 1
  E0518 13:46:37.678639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:38.631: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 13:46:38.631: INFO: Found 1 / 1
  May 18 13:46:38.631: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  May 18 13:46:38.635: INFO: Selector matched 1 pods for map[app:agnhost]
  May 18 13:46:38.635: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  May 18 13:46:38.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 describe pod agnhost-primary-svddg'
  E0518 13:46:38.678786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:38.685: INFO: stderr: ""
  May 18 13:46:38.685: INFO: stdout: "Name:             agnhost-primary-svddg\nNamespace:        kubectl-9475\nPriority:         0\nService Account:  default\nNode:             ip-172-31-33-93/172.31.33.93\nStart Time:       Sat, 18 May 2024 13:46:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.225.223\nIPs:\n  IP:           192.168.225.223\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://880d19e0f427176601cddeef41f58547229acc1bcbb0adda3719cb7e49a0f3ac\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 18 May 2024 13:46:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kj2nt (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-kj2nt:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9475/agnhost-primary-svddg to ip-172-31-33-93\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  May 18 13:46:38.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 describe rc agnhost-primary'
  May 18 13:46:38.735: INFO: stderr: ""
  May 18 13:46:38.735: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9475\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-svddg\n"
  May 18 13:46:38.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 describe service agnhost-primary'
  May 18 13:46:38.787: INFO: stderr: ""
  May 18 13:46:38.787: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9475\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.82\nIPs:               10.152.183.82\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.225.223:6379\nSession Affinity:  None\nEvents:            <none>\n"
  May 18 13:46:38.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 describe node ip-172-31-23-188'
  May 18 13:46:38.853: INFO: stderr: ""
  May 18 13:46:38.853: INFO: stdout: "Name:               ip-172-31-23-188\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-23-188\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 18 May 2024 11:50:25 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-23-188\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 18 May 2024 13:46:28 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 18 May 2024 12:03:23 +0000   Sat, 18 May 2024 12:03:23 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 18 May 2024 13:43:23 +0000   Sat, 18 May 2024 11:50:25 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 18 May 2024 13:43:23 +0000   Sat, 18 May 2024 11:50:25 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 18 May 2024 13:43:23 +0000   Sat, 18 May 2024 11:50:25 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 18 May 2024 13:43:23 +0000   Sat, 18 May 2024 11:52:07 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.23.188\n  Hostname:    ip-172-31-23-188\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7958140Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7855740Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2147ba7a5e1347efca08696be24ef7\n  System UUID:                ec2147ba-7a5e-1347-efca-08696be24ef7\n  Boot ID:                    e26fe1ac-ac2c-4918-9d6f-c0a0187ffbbb\n  Kernel Version:             6.5.0-1020-aws\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.29.5\n  Kube-Proxy Version:         v1.29.5\nNon-terminated Pods:          (3 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-6d758894cf-l5nfc                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         103m\n  kube-system                 calico-node-whg4g                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         103m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-87312adf0c3140c9-2hmj9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         100m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  May 18 13:46:38.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-9475 describe namespace kubectl-9475'
  May 18 13:46:38.906: INFO: stderr: ""
  May 18 13:46:38.906: INFO: stdout: "Name:         kubectl-9475\nLabels:       e2e-framework=kubectl\n              e2e-run=27a801cb-a3ce-417b-86ca-2e2c2343835c\n              kubernetes.io/metadata.name=kubectl-9475\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  May 18 13:46:38.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9475" for this suite. @ 05/18/24 13:46:38.912
• [2.478 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/18/24 13:46:38.92
  May 18 13:46:38.920: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename runtimeclass @ 05/18/24 13:46:38.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:38.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:38.944
  May 18 13:46:38.955: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1367" for this suite. @ 05/18/24 13:46:38.958
• [0.045 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 05/18/24 13:46:38.965
  May 18 13:46:38.965: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/18/24 13:46:38.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:38.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:38.987
  STEP: set up a multi version CRD @ 05/18/24 13:46:38.99
  May 18 13:46:38.990: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  E0518 13:46:39.679634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:40.680395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:41.680996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 05/18/24 13:46:42.07
  STEP: check the unserved version gets removed @ 05/18/24 13:46:42.09
  E0518 13:46:42.681817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 05/18/24 13:46:42.937
  E0518 13:46:43.682205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:44.682226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:45.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1506" for this suite. @ 05/18/24 13:46:45.404
• [6.447 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 05/18/24 13:46:45.412
  May 18 13:46:45.412: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename statefulset @ 05/18/24 13:46:45.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:46:45.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:46:45.431
  STEP: Creating service test in namespace statefulset-5293 @ 05/18/24 13:46:45.436
  STEP: Creating statefulset ss in namespace statefulset-5293 @ 05/18/24 13:46:45.443
  May 18 13:46:45.457: INFO: Found 0 stateful pods, waiting for 1
  E0518 13:46:45.682400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:46.682749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:47.683824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:48.683908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:49.684790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:50.685000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:51.685431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:52.685652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:53.685728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:54.685971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:46:55.455: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/18/24 13:46:55.463
  STEP: Getting /status @ 05/18/24 13:46:55.472
  May 18 13:46:55.476: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/18/24 13:46:55.476
  May 18 13:46:55.487: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/18/24 13:46:55.488
  May 18 13:46:55.489: INFO: Observed &StatefulSet event: ADDED
  May 18 13:46:55.489: INFO: Found Statefulset ss in namespace statefulset-5293 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  May 18 13:46:55.489: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/18/24 13:46:55.489
  May 18 13:46:55.489: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  May 18 13:46:55.497: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/18/24 13:46:55.497
  May 18 13:46:55.499: INFO: Observed &StatefulSet event: ADDED
  May 18 13:46:55.499: INFO: Deleting all statefulset in ns statefulset-5293
  May 18 13:46:55.505: INFO: Scaling statefulset ss to 0
  E0518 13:46:55.687066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:56.687182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:57.687215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:58.687292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:46:59.687437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:00.687458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:01.687714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:02.687798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:03.687902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:04.688972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:47:05.522: INFO: Waiting for statefulset status.replicas updated to 0
  May 18 13:47:05.526: INFO: Deleting statefulset ss
  May 18 13:47:05.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5293" for this suite. @ 05/18/24 13:47:05.552
• [20.149 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 05/18/24 13:47:05.561
  May 18 13:47:05.561: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:47:05.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:05.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:05.583
  STEP: Creating Pod @ 05/18/24 13:47:05.586
  E0518 13:47:05.689521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:06.689650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 05/18/24 13:47:07.611
  May 18 13:47:07.611: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9213 PodName:pod-sharedvolume-cb5dfa3a-e4c5-46ac-84d8-cfe9ced9ab9b ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  May 18 13:47:07.611: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  May 18 13:47:07.611: INFO: ExecWithOptions: Clientset creation
  May 18 13:47:07.612: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-9213/pods/pod-sharedvolume-cb5dfa3a-e4c5-46ac-84d8-cfe9ced9ab9b/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  May 18 13:47:07.674: INFO: Exec stderr: ""
  May 18 13:47:07.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9213" for this suite. @ 05/18/24 13:47:07.678
• [2.125 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/18/24 13:47:07.686
  May 18 13:47:07.686: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/18/24 13:47:07.686
  E0518 13:47:07.690258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:07.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:07.705
  STEP: Creating two CSIDrivers @ 05/18/24 13:47:07.708
  STEP: Getting "inline-driver-aa3ca2f4-0776-41cf-b281-9f8ed1170005" & "inline-driver-1a3a580f-8dc1-46c7-81f6-981c5402f606" @ 05/18/24 13:47:07.726
  STEP: Patching the CSIDriver "inline-driver-1a3a580f-8dc1-46c7-81f6-981c5402f606" @ 05/18/24 13:47:07.733
  STEP: Updating the CSIDriver "inline-driver-1a3a580f-8dc1-46c7-81f6-981c5402f606" @ 05/18/24 13:47:07.739
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-1580" @ 05/18/24 13:47:07.747
  STEP: Deleting CSIDriver "inline-driver-aa3ca2f4-0776-41cf-b281-9f8ed1170005" @ 05/18/24 13:47:07.75
  STEP: Confirm deletion of CSIDriver "inline-driver-aa3ca2f4-0776-41cf-b281-9f8ed1170005" @ 05/18/24 13:47:07.759
  STEP: Deleting CSIDriver "inline-driver-1a3a580f-8dc1-46c7-81f6-981c5402f606" via DeleteCollection @ 05/18/24 13:47:07.762
  STEP: Confirm deletion of CSIDriver "inline-driver-1a3a580f-8dc1-46c7-81f6-981c5402f606" @ 05/18/24 13:47:07.771
  May 18 13:47:07.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1580" for this suite. @ 05/18/24 13:47:07.778
• [0.100 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 05/18/24 13:47:07.786
  May 18 13:47:07.786: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:47:07.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:07.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:07.805
  STEP: Creating projection with secret that has name secret-emptykey-test-60cb83ce-85f8-45e7-acd8-6d356647e896 @ 05/18/24 13:47:07.809
  May 18 13:47:07.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3371" for this suite. @ 05/18/24 13:47:07.814
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 05/18/24 13:47:07.821
  May 18 13:47:07.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename resourcequota @ 05/18/24 13:47:07.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:07.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:07.839
  STEP: Counting existing ResourceQuota @ 05/18/24 13:47:07.842
  E0518 13:47:08.690408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:09.690566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:10.691600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:11.692591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:12.692684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/18/24 13:47:12.846
  STEP: Ensuring resource quota status is calculated @ 05/18/24 13:47:12.852
  E0518 13:47:13.693434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:14.694364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/18/24 13:47:14.858
  STEP: Creating a NodePort Service @ 05/18/24 13:47:14.874
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/18/24 13:47:14.898
  STEP: Ensuring resource quota status captures service creation @ 05/18/24 13:47:14.921
  E0518 13:47:15.695272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:16.696254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/18/24 13:47:16.928
  STEP: Ensuring resource quota status released usage @ 05/18/24 13:47:16.964
  E0518 13:47:17.696874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:18.696910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:47:18.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3841" for this suite. @ 05/18/24 13:47:18.975
• [11.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 05/18/24 13:47:18.982
  May 18 13:47:18.982: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename containers @ 05/18/24 13:47:18.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:18.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:19.002
  E0518 13:47:19.697141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:20.697364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:47:21.033: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4260" for this suite. @ 05/18/24 13:47:21.037
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 05/18/24 13:47:21.045
  May 18 13:47:21.045: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption @ 05/18/24 13:47:21.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:47:21.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:47:21.064
  May 18 13:47:21.081: INFO: Waiting up to 1m0s for all nodes to be ready
  E0518 13:47:21.697507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:22.698116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:23.698196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:24.698310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:25.698405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:26.698495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:27.698715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:28.698818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:29.699770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:30.699862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:31.699968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:32.700240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:33.700589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:34.700800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:35.701879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:36.702087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:37.703156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:38.703252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:39.704230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:40.704389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:41.705475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:42.705718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:43.706129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:44.706363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:45.706459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:46.706553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:47.706647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:48.706744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:49.706841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:50.707092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:51.707347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:52.708266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:53.708351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:54.708441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:55.709290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:56.709379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:57.710221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:58.710541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:47:59.711350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:00.711457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:01.712228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:02.712407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:03.712488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:04.712648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:05.712739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:06.713176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:07.714147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:08.714454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:09.714571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:10.714757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:11.714970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:12.715155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:13.716043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:14.716145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:15.716235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:16.717260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:17.717877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:18.717961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:19.718597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:20.718812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:21.087: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/18/24 13:48:21.091
  May 18 13:48:21.091: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/18/24 13:48:21.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:21.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:21.112
  May 18 13:48:21.129: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  May 18 13:48:21.133: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  May 18 13:48:21.206: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9877" for this suite. @ 05/18/24 13:48:21.21
  May 18 13:48:21.217: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9853" for this suite. @ 05/18/24 13:48:21.221
• [60.183 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 05/18/24 13:48:21.228
  May 18 13:48:21.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:48:21.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:21.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:21.249
  STEP: creating service in namespace services-6887 @ 05/18/24 13:48:21.252
  STEP: creating service affinity-nodeport-transition in namespace services-6887 @ 05/18/24 13:48:21.252
  STEP: creating replication controller affinity-nodeport-transition in namespace services-6887 @ 05/18/24 13:48:21.267
  I0518 13:48:21.277818      19 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-6887, replica count: 3
  E0518 13:48:21.719604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:22.720276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:23.720374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:48:24.328817      19 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:48:24.341: INFO: Creating new exec pod
  E0518 13:48:24.720855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:25.720957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:26.721975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:27.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  May 18 13:48:27.452: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  May 18 13:48:27.452: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:48:27.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.91 80'
  May 18 13:48:27.551: INFO: stderr: "+ nc -v -t -w 2 10.152.183.91 80\nConnection to 10.152.183.91 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  May 18 13:48:27.551: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:48:27.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.70.23 30706'
  May 18 13:48:27.638: INFO: stderr: "+ nc -v -t -w 2 172.31.70.23 30706\n+ echo hostName\nConnection to 172.31.70.23 30706 port [tcp/*] succeeded!\n"
  May 18 13:48:27.638: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:48:27.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.90.158 30706'
  E0518 13:48:27.722550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:27.760: INFO: stderr: "+ nc -v -t -w 2 172.31.90.158 30706\n+ echo hostName\nConnection to 172.31.90.158 30706 port [tcp/*] succeeded!\n"
  May 18 13:48:27.760: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:48:27.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.33.93:30706/ ; done'
  May 18 13:48:27.932: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n"
  May 18 13:48:27.932: INFO: stdout: "\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-5r2hl\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-5r2hl\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-vxqs5\naffinity-nodeport-transition-5r2hl\naffinity-nodeport-transition-vxqs5"
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-5r2hl
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-5r2hl
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-5r2hl
  May 18 13:48:27.932: INFO: Received response from host: affinity-nodeport-transition-vxqs5
  May 18 13:48:27.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-6887 exec execpod-affinity96t4t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.33.93:30706/ ; done'
  May 18 13:48:28.100: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.33.93:30706/\n"
  May 18 13:48:28.100: INFO: stdout: "\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4\naffinity-nodeport-transition-lc2r4"
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Received response from host: affinity-nodeport-transition-lc2r4
  May 18 13:48:28.100: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6887, will wait for the garbage collector to delete the pods @ 05/18/24 13:48:28.116
  May 18 13:48:28.178: INFO: Deleting ReplicationController affinity-nodeport-transition took: 7.170286ms
  May 18 13:48:28.279: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.779555ms
  E0518 13:48:28.723458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:29.723518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:30.723732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:31.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6887" for this suite. @ 05/18/24 13:48:31.409
• [10.189 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/18/24 13:48:31.418
  May 18 13:48:31.418: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:48:31.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:31.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:31.437
  May 18 13:48:31.483: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-387" for this suite. @ 05/18/24 13:48:31.487
• [0.077 seconds]
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/18/24 13:48:31.495
  May 18 13:48:31.495: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename events @ 05/18/24 13:48:31.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:31.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:31.515
  STEP: Create set of events @ 05/18/24 13:48:31.518
  STEP: get a list of Events with a label in the current namespace @ 05/18/24 13:48:31.533
  STEP: delete a list of events @ 05/18/24 13:48:31.536
  May 18 13:48:31.536: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/18/24 13:48:31.559
  May 18 13:48:31.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2441" for this suite. @ 05/18/24 13:48:31.567
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/18/24 13:48:31.574
  May 18 13:48:31.574: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename proxy @ 05/18/24 13:48:31.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:31.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:31.592
  STEP: starting an echo server on multiple ports @ 05/18/24 13:48:31.605
  STEP: creating replication controller proxy-service-mdd4p in namespace proxy-6274 @ 05/18/24 13:48:31.605
  I0518 13:48:31.615357      19 runners.go:197] Created replication controller with name: proxy-service-mdd4p, namespace: proxy-6274, replica count: 1
  E0518 13:48:31.724090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:48:32.666221      19 runners.go:197] proxy-service-mdd4p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0518 13:48:32.724456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:48:33.666340      19 runners.go:197] proxy-service-mdd4p Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:48:33.670: INFO: setup took 2.07525956s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/18/24 13:48:33.67
  May 18 13:48:33.678: INFO: (0) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.444103ms)
  May 18 13:48:33.678: INFO: (0) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.574269ms)
  May 18 13:48:33.678: INFO: (0) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 7.769751ms)
  May 18 13:48:33.679: INFO: (0) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 8.437668ms)
  May 18 13:48:33.680: INFO: (0) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 9.364448ms)
  May 18 13:48:33.680: INFO: (0) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 9.53551ms)
  May 18 13:48:33.681: INFO: (0) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 10.821124ms)
  May 18 13:48:33.681: INFO: (0) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 10.879029ms)
  May 18 13:48:33.681: INFO: (0) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 11.056387ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 10.961576ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 11.068091ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 11.109219ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 11.352973ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 11.113633ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 11.49023ms)
  May 18 13:48:33.682: INFO: (0) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 11.445531ms)
  May 18 13:48:33.686: INFO: (1) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 3.849316ms)
  May 18 13:48:33.686: INFO: (1) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 4.053926ms)
  May 18 13:48:33.686: INFO: (1) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 4.372874ms)
  May 18 13:48:33.687: INFO: (1) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 4.800052ms)
  May 18 13:48:33.687: INFO: (1) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.109106ms)
  May 18 13:48:33.688: INFO: (1) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.121149ms)
  May 18 13:48:33.688: INFO: (1) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.943045ms)
  May 18 13:48:33.689: INFO: (1) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 6.414873ms)
  May 18 13:48:33.689: INFO: (1) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.383536ms)
  May 18 13:48:33.689: INFO: (1) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.526811ms)
  May 18 13:48:33.689: INFO: (1) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.029382ms)
  May 18 13:48:33.690: INFO: (1) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.650732ms)
  May 18 13:48:33.690: INFO: (1) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.790894ms)
  May 18 13:48:33.690: INFO: (1) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.672295ms)
  May 18 13:48:33.691: INFO: (1) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.322752ms)
  May 18 13:48:33.691: INFO: (1) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.468838ms)
  May 18 13:48:33.694: INFO: (2) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 3.358128ms)
  May 18 13:48:33.694: INFO: (2) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 3.717768ms)
  May 18 13:48:33.695: INFO: (2) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 4.038078ms)
  May 18 13:48:33.696: INFO: (2) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 4.842725ms)
  May 18 13:48:33.696: INFO: (2) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.290346ms)
  May 18 13:48:33.697: INFO: (2) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.680374ms)
  May 18 13:48:33.697: INFO: (2) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.774243ms)
  May 18 13:48:33.697: INFO: (2) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 6.027284ms)
  May 18 13:48:33.697: INFO: (2) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.474681ms)
  May 18 13:48:33.698: INFO: (2) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.067053ms)
  May 18 13:48:33.698: INFO: (2) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.331374ms)
  May 18 13:48:33.698: INFO: (2) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 7.394002ms)
  May 18 13:48:33.699: INFO: (2) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.599558ms)
  May 18 13:48:33.699: INFO: (2) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.807179ms)
  May 18 13:48:33.699: INFO: (2) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.932212ms)
  May 18 13:48:33.699: INFO: (2) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.307048ms)
  May 18 13:48:33.703: INFO: (3) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 4.221829ms)
  May 18 13:48:33.704: INFO: (3) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 4.696093ms)
  May 18 13:48:33.705: INFO: (3) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.161344ms)
  May 18 13:48:33.705: INFO: (3) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.901587ms)
  May 18 13:48:33.705: INFO: (3) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.197905ms)
  May 18 13:48:33.706: INFO: (3) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 6.676617ms)
  May 18 13:48:33.706: INFO: (3) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.596894ms)
  May 18 13:48:33.707: INFO: (3) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.525025ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 8.134413ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 8.317842ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 8.535614ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.387897ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.742737ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 8.51103ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.721719ms)
  May 18 13:48:33.708: INFO: (3) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.581537ms)
  May 18 13:48:33.714: INFO: (4) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.460172ms)
  May 18 13:48:33.714: INFO: (4) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.783102ms)
  May 18 13:48:33.715: INFO: (4) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 6.697407ms)
  May 18 13:48:33.715: INFO: (4) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 7.124191ms)
  May 18 13:48:33.715: INFO: (4) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 7.200775ms)
  May 18 13:48:33.715: INFO: (4) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 7.24975ms)
  May 18 13:48:33.715: INFO: (4) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 7.388507ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.319787ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.357566ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 7.403048ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 7.546638ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.634643ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.587564ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.79423ms)
  May 18 13:48:33.716: INFO: (4) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 8.043362ms)
  May 18 13:48:33.717: INFO: (4) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.379387ms)
  May 18 13:48:33.721: INFO: (5) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 3.894727ms)
  May 18 13:48:33.721: INFO: (5) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 4.046018ms)
  May 18 13:48:33.721: INFO: (5) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 4.586377ms)
  May 18 13:48:33.722: INFO: (5) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 4.65935ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 5.917039ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 6.041846ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 6.527059ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.441656ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.585432ms)
  May 18 13:48:33.723: INFO: (5) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 6.556364ms)
  E0518 13:48:33.724730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:33.724: INFO: (5) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.722026ms)
  May 18 13:48:33.724: INFO: (5) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.482707ms)
  May 18 13:48:33.724: INFO: (5) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.632934ms)
  May 18 13:48:33.725: INFO: (5) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.876745ms)
  May 18 13:48:33.725: INFO: (5) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 8.195341ms)
  May 18 13:48:33.725: INFO: (5) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.197577ms)
  May 18 13:48:33.729: INFO: (6) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 3.933506ms)
  May 18 13:48:33.729: INFO: (6) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 4.296718ms)
  May 18 13:48:33.730: INFO: (6) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 4.290603ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 5.688675ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.993606ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.969034ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.143354ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 6.057682ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.01433ms)
  May 18 13:48:33.731: INFO: (6) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.096631ms)
  May 18 13:48:33.732: INFO: (6) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.020863ms)
  May 18 13:48:33.732: INFO: (6) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.149666ms)
  May 18 13:48:33.733: INFO: (6) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.436428ms)
  May 18 13:48:33.733: INFO: (6) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.703017ms)
  May 18 13:48:33.733: INFO: (6) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.77408ms)
  May 18 13:48:33.733: INFO: (6) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.919964ms)
  May 18 13:48:33.737: INFO: (7) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 3.544954ms)
  May 18 13:48:33.738: INFO: (7) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 4.190591ms)
  May 18 13:48:33.739: INFO: (7) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.279776ms)
  May 18 13:48:33.739: INFO: (7) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.483783ms)
  May 18 13:48:33.739: INFO: (7) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.859081ms)
  May 18 13:48:33.739: INFO: (7) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.950057ms)
  May 18 13:48:33.739: INFO: (7) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.885361ms)
  May 18 13:48:33.740: INFO: (7) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.760213ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.998111ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.473713ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.688316ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.891076ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.958631ms)
  May 18 13:48:33.741: INFO: (7) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 7.939111ms)
  May 18 13:48:33.742: INFO: (7) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.16082ms)
  May 18 13:48:33.742: INFO: (7) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.533935ms)
  May 18 13:48:33.746: INFO: (8) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 3.642122ms)
  May 18 13:48:33.746: INFO: (8) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 3.734701ms)
  May 18 13:48:33.746: INFO: (8) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 3.829209ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.428777ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 5.660423ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.852431ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.859804ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.827395ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.006961ms)
  May 18 13:48:33.748: INFO: (8) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.948235ms)
  May 18 13:48:33.749: INFO: (8) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 6.923767ms)
  May 18 13:48:33.749: INFO: (8) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.066721ms)
  May 18 13:48:33.749: INFO: (8) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.061432ms)
  May 18 13:48:33.750: INFO: (8) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.387099ms)
  May 18 13:48:33.750: INFO: (8) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.811713ms)
  May 18 13:48:33.750: INFO: (8) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.726733ms)
  May 18 13:48:33.754: INFO: (9) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 3.639595ms)
  May 18 13:48:33.754: INFO: (9) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 3.770745ms)
  May 18 13:48:33.755: INFO: (9) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.044256ms)
  May 18 13:48:33.755: INFO: (9) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.03641ms)
  May 18 13:48:33.756: INFO: (9) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.507103ms)
  May 18 13:48:33.756: INFO: (9) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.513088ms)
  May 18 13:48:33.756: INFO: (9) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.850281ms)
  May 18 13:48:33.756: INFO: (9) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.120731ms)
  May 18 13:48:33.757: INFO: (9) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 6.549286ms)
  May 18 13:48:33.758: INFO: (9) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 7.415925ms)
  May 18 13:48:33.758: INFO: (9) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.784085ms)
  May 18 13:48:33.758: INFO: (9) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.890874ms)
  May 18 13:48:33.758: INFO: (9) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 7.763666ms)
  May 18 13:48:33.758: INFO: (9) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.920821ms)
  May 18 13:48:33.759: INFO: (9) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.260036ms)
  May 18 13:48:33.759: INFO: (9) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.77669ms)
  May 18 13:48:33.762: INFO: (10) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 3.152947ms)
  May 18 13:48:33.763: INFO: (10) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 3.831637ms)
  May 18 13:48:33.765: INFO: (10) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.46427ms)
  May 18 13:48:33.765: INFO: (10) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.436543ms)
  May 18 13:48:33.765: INFO: (10) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.392747ms)
  May 18 13:48:33.765: INFO: (10) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 5.563803ms)
  May 18 13:48:33.765: INFO: (10) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 6.007684ms)
  May 18 13:48:33.766: INFO: (10) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.213684ms)
  May 18 13:48:33.766: INFO: (10) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.178106ms)
  May 18 13:48:33.766: INFO: (10) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.80032ms)
  May 18 13:48:33.766: INFO: (10) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 7.094399ms)
  May 18 13:48:33.767: INFO: (10) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.091811ms)
  May 18 13:48:33.767: INFO: (10) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.347583ms)
  May 18 13:48:33.768: INFO: (10) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.771683ms)
  May 18 13:48:33.768: INFO: (10) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.803009ms)
  May 18 13:48:33.769: INFO: (10) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 9.285962ms)
  May 18 13:48:33.774: INFO: (11) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.252678ms)
  May 18 13:48:33.774: INFO: (11) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.367655ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.776928ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.009483ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 6.096107ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.097254ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.298561ms)
  May 18 13:48:33.775: INFO: (11) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 6.129495ms)
  May 18 13:48:33.781: INFO: (11) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 12.361904ms)
  May 18 13:48:33.781: INFO: (11) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 12.333334ms)
  May 18 13:48:33.781: INFO: (11) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 12.452848ms)
  May 18 13:48:33.782: INFO: (11) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 12.882531ms)
  May 18 13:48:33.782: INFO: (11) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 13.301987ms)
  May 18 13:48:33.782: INFO: (11) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 13.680746ms)
  May 18 13:48:33.782: INFO: (11) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 13.767044ms)
  May 18 13:48:33.783: INFO: (11) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 13.917822ms)
  May 18 13:48:33.788: INFO: (12) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.182511ms)
  May 18 13:48:33.788: INFO: (12) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.288628ms)
  May 18 13:48:33.788: INFO: (12) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.333628ms)
  May 18 13:48:33.789: INFO: (12) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.573642ms)
  May 18 13:48:33.789: INFO: (12) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.620049ms)
  May 18 13:48:33.789: INFO: (12) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 6.101311ms)
  May 18 13:48:33.790: INFO: (12) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.647035ms)
  May 18 13:48:33.790: INFO: (12) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.924389ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.581956ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.655141ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.969462ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.00109ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 7.913787ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.118529ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.460631ms)
  May 18 13:48:33.791: INFO: (12) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 8.250134ms)
  May 18 13:48:33.795: INFO: (13) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 3.528905ms)
  May 18 13:48:33.795: INFO: (13) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 3.671883ms)
  May 18 13:48:33.796: INFO: (13) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 4.770209ms)
  May 18 13:48:33.797: INFO: (13) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.160768ms)
  May 18 13:48:33.798: INFO: (13) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.501605ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.168134ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.254573ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 7.245635ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 7.349273ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.350742ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 7.385086ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.40849ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.556063ms)
  May 18 13:48:33.799: INFO: (13) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.355052ms)
  May 18 13:48:33.800: INFO: (13) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.823936ms)
  May 18 13:48:33.800: INFO: (13) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.326258ms)
  May 18 13:48:33.803: INFO: (14) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 3.488463ms)
  May 18 13:48:33.804: INFO: (14) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 3.645064ms)
  May 18 13:48:33.805: INFO: (14) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.457912ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.350737ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.624967ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.602568ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 5.652211ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.089847ms)
  May 18 13:48:33.806: INFO: (14) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.142825ms)
  May 18 13:48:33.807: INFO: (14) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.546198ms)
  May 18 13:48:33.807: INFO: (14) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 6.883768ms)
  May 18 13:48:33.807: INFO: (14) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.028001ms)
  May 18 13:48:33.808: INFO: (14) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 7.481192ms)
  May 18 13:48:33.809: INFO: (14) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.439968ms)
  May 18 13:48:33.809: INFO: (14) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.562042ms)
  May 18 13:48:33.809: INFO: (14) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.782167ms)
  May 18 13:48:33.814: INFO: (15) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.124267ms)
  May 18 13:48:33.814: INFO: (15) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 5.325735ms)
  May 18 13:48:33.814: INFO: (15) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.54575ms)
  May 18 13:48:33.815: INFO: (15) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.936254ms)
  May 18 13:48:33.815: INFO: (15) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 6.115781ms)
  May 18 13:48:33.815: INFO: (15) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 6.552847ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.6157ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.635273ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.802185ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 7.760225ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 8.033723ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 7.871627ms)
  May 18 13:48:33.817: INFO: (15) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.435186ms)
  May 18 13:48:33.818: INFO: (15) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 8.616894ms)
  May 18 13:48:33.818: INFO: (15) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.508476ms)
  May 18 13:48:33.819: INFO: (15) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 9.578852ms)
  May 18 13:48:33.822: INFO: (16) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 3.561021ms)
  May 18 13:48:33.823: INFO: (16) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 4.287889ms)
  May 18 13:48:33.823: INFO: (16) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 4.446406ms)
  May 18 13:48:33.824: INFO: (16) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 5.002189ms)
  May 18 13:48:33.824: INFO: (16) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.34684ms)
  May 18 13:48:33.825: INFO: (16) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.692998ms)
  May 18 13:48:33.825: INFO: (16) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.367527ms)
  May 18 13:48:33.825: INFO: (16) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 6.647078ms)
  May 18 13:48:33.825: INFO: (16) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 6.7348ms)
  May 18 13:48:33.826: INFO: (16) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 7.080154ms)
  May 18 13:48:33.826: INFO: (16) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 7.482168ms)
  May 18 13:48:33.826: INFO: (16) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 7.572897ms)
  May 18 13:48:33.826: INFO: (16) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 7.795849ms)
  May 18 13:48:33.827: INFO: (16) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 7.860312ms)
  May 18 13:48:33.827: INFO: (16) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.261189ms)
  May 18 13:48:33.827: INFO: (16) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.577201ms)
  May 18 13:48:33.832: INFO: (17) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.058663ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.32509ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.302506ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 6.510845ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 6.712279ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 6.823005ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.668674ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.800124ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 6.783047ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 6.996154ms)
  May 18 13:48:33.834: INFO: (17) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 6.783156ms)
  May 18 13:48:33.835: INFO: (17) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 8.032863ms)
  May 18 13:48:33.836: INFO: (17) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 8.181001ms)
  May 18 13:48:33.836: INFO: (17) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.151156ms)
  May 18 13:48:33.836: INFO: (17) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.123816ms)
  May 18 13:48:33.836: INFO: (17) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.307284ms)
  May 18 13:48:33.840: INFO: (18) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 3.728717ms)
  May 18 13:48:33.841: INFO: (18) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 5.381576ms)
  May 18 13:48:33.841: INFO: (18) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 5.3416ms)
  May 18 13:48:33.841: INFO: (18) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 5.481168ms)
  May 18 13:48:33.841: INFO: (18) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.481188ms)
  May 18 13:48:33.842: INFO: (18) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 5.93335ms)
  May 18 13:48:33.843: INFO: (18) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.607685ms)
  May 18 13:48:33.843: INFO: (18) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 6.710274ms)
  May 18 13:48:33.843: INFO: (18) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 6.825182ms)
  May 18 13:48:33.843: INFO: (18) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 6.990269ms)
  May 18 13:48:33.844: INFO: (18) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 7.713819ms)
  May 18 13:48:33.844: INFO: (18) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 8.240235ms)
  May 18 13:48:33.844: INFO: (18) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 8.455083ms)
  May 18 13:48:33.845: INFO: (18) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.560246ms)
  May 18 13:48:33.845: INFO: (18) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 8.528097ms)
  May 18 13:48:33.845: INFO: (18) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 8.696191ms)
  May 18 13:48:33.849: INFO: (19) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 3.702132ms)
  May 18 13:48:33.850: INFO: (19) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh/proxy/rewriteme">test</a> (200; 4.857703ms)
  May 18 13:48:33.850: INFO: (19) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">... (200; 5.43882ms)
  May 18 13:48:33.850: INFO: (19) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:460/proxy/: tls baz (200; 5.431744ms)
  May 18 13:48:33.851: INFO: (19) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:462/proxy/: tls qux (200; 5.569373ms)
  May 18 13:48:33.851: INFO: (19) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.289299ms)
  May 18 13:48:33.852: INFO: (19) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname1/proxy/: foo (200; 6.656016ms)
  May 18 13:48:33.852: INFO: (19) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:162/proxy/: bar (200; 6.927806ms)
  May 18 13:48:33.852: INFO: (19) /api/v1/namespaces/proxy-6274/pods/http:proxy-service-mdd4p-j85nh:160/proxy/: foo (200; 6.882454ms)
  May 18 13:48:33.853: INFO: (19) /api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/proxy-service-mdd4p-j85nh:1080/proxy/rewriteme">test<... (200; 7.855178ms)
  May 18 13:48:33.853: INFO: (19) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname2/proxy/: tls qux (200; 7.991202ms)
  May 18 13:48:33.853: INFO: (19) /api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/: <a href="/api/v1/namespaces/proxy-6274/pods/https:proxy-service-mdd4p-j85nh:443/proxy/tlsrewritem... (200; 8.316103ms)
  May 18 13:48:33.854: INFO: (19) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname1/proxy/: foo (200; 8.697476ms)
  May 18 13:48:33.854: INFO: (19) /api/v1/namespaces/proxy-6274/services/http:proxy-service-mdd4p:portname2/proxy/: bar (200; 9.179917ms)
  May 18 13:48:33.854: INFO: (19) /api/v1/namespaces/proxy-6274/services/proxy-service-mdd4p:portname2/proxy/: bar (200; 9.311896ms)
  May 18 13:48:33.854: INFO: (19) /api/v1/namespaces/proxy-6274/services/https:proxy-service-mdd4p:tlsportname1/proxy/: tls baz (200; 9.274146ms)
  STEP: deleting ReplicationController proxy-service-mdd4p in namespace proxy-6274, will wait for the garbage collector to delete the pods @ 05/18/24 13:48:33.855
  May 18 13:48:33.917: INFO: Deleting ReplicationController proxy-service-mdd4p took: 8.412789ms
  May 18 13:48:34.018: INFO: Terminating ReplicationController proxy-service-mdd4p pods took: 101.042114ms
  E0518 13:48:34.725651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:35.725710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:48:36.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6274" for this suite. @ 05/18/24 13:48:36.424
• [4.857 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/18/24 13:48:36.432
  May 18 13:48:36.432: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename downward-api @ 05/18/24 13:48:36.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:36.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:36.451
  STEP: Creating a pod to test downward api env vars @ 05/18/24 13:48:36.455
  E0518 13:48:36.726597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:37.726705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:38.727406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:39.727488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:48:40.481
  May 18 13:48:40.485: INFO: Trying to get logs from node ip-172-31-33-93 pod downward-api-f9b2fe87-5f64-441d-9771-1af095a216d9 container dapi-container: <nil>
  STEP: delete the pod @ 05/18/24 13:48:40.493
  May 18 13:48:40.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5718" for this suite. @ 05/18/24 13:48:40.516
• [4.091 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/18/24 13:48:40.528
  May 18 13:48:40.528: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:48:40.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:40.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:40.551
  STEP: Creating secret with name secret-test-map-51c19294-81af-4255-89f6-b5ea67d46614 @ 05/18/24 13:48:40.555
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:48:40.561
  E0518 13:48:40.727866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:41.728539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:42.729220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:43.729545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:48:44.592
  May 18 13:48:44.596: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-secrets-f45f89ce-58ff-45d6-aa83-5589779831bc container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:48:44.603
  May 18 13:48:44.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9204" for this suite. @ 05/18/24 13:48:44.626
• [4.106 seconds]
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/18/24 13:48:44.634
  May 18 13:48:44.634: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename sysctl @ 05/18/24 13:48:44.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:44.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:44.652
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/18/24 13:48:44.657
  May 18 13:48:44.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6110" for this suite. @ 05/18/24 13:48:44.666
• [0.039 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/18/24 13:48:44.673
  May 18 13:48:44.673: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename init-container @ 05/18/24 13:48:44.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:48:44.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:48:44.691
  STEP: creating the pod @ 05/18/24 13:48:44.694
  May 18 13:48:44.694: INFO: PodSpec: initContainers in spec.initContainers
  E0518 13:48:44.729899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:45.729963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:46.729988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:47.730456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:48.730531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:49.730679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:50.730771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:51.731370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:52.731485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:53.731583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:54.732228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:55.732465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:56.733513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:57.733858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:58.733943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:48:59.734099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:00.734217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:01.734321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:02.735311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:03.735425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:04.735497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:05.735609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:06.736229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:07.736341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:08.736517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:09.737398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:10.737650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:11.738616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:12.738890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:13.738983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:14.739179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:15.739356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:16.739371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:17.739533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:18.740250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:19.740476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:20.740593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:21.740659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:22.740854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:23.741017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:24.741123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:25.460: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-061a7994-49a9-4fa5-ae3b-4e6e8e9bc651", GenerateName:"", Namespace:"init-container-2532", SelfLink:"", UID:"18ccad88-70b8-4d5f-806e-aeb72d69af47", ResourceVersion:"47712", Generation:0, CreationTimestamp:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"694956187"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0037e24f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 18, 13, 49, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0037e25a0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-dgrwf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00507d740), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dgrwf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dgrwf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dgrwf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0051770e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-33-93", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0002fef50), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005177170)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005177190)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005177198), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00517719c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000ef39b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 18, 13, 48, 46, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.33.93", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.33.93"}}, PodIP:"192.168.225.241", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.225.241"}}, StartTime:time.Date(2024, time.May, 18, 13, 48, 44, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002ff030)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002ff110)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://65f98a91d3ee12801991be6463de1b258cc414e2ee86c72edb563dd937779cb5", Started:(*bool)(0xc00517723a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00507d7c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00517724f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00507d780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc00517721f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  May 18 13:49:25.460: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2532" for this suite. @ 05/18/24 13:49:25.464
• [40.798 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/18/24 13:49:25.471
  May 18 13:49:25.471: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename pods @ 05/18/24 13:49:25.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:25.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:25.49
  STEP: creating the pod @ 05/18/24 13:49:25.494
  STEP: submitting the pod to kubernetes @ 05/18/24 13:49:25.494
  E0518 13:49:25.741501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:26.741686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/18/24 13:49:27.517
  STEP: updating the pod @ 05/18/24 13:49:27.52
  E0518 13:49:27.742410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:28.034: INFO: Successfully updated pod "pod-update-8b4607fa-5ad8-4af4-9750-340f7e3156b4"
  STEP: verifying the updated pod is in kubernetes @ 05/18/24 13:49:28.038
  May 18 13:49:28.044: INFO: Pod update OK
  May 18 13:49:28.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-93" for this suite. @ 05/18/24 13:49:28.049
• [2.588 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 05/18/24 13:49:28.059
  May 18 13:49:28.059: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename services @ 05/18/24 13:49:28.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:28.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:28.076
  STEP: creating service in namespace services-2234 @ 05/18/24 13:49:28.079
  STEP: creating service affinity-clusterip in namespace services-2234 @ 05/18/24 13:49:28.079
  STEP: creating replication controller affinity-clusterip in namespace services-2234 @ 05/18/24 13:49:28.09
  I0518 13:49:28.098656      19 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-2234, replica count: 3
  E0518 13:49:28.742644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:29.743361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:30.743462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0518 13:49:31.149883      19 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  May 18 13:49:31.160: INFO: Creating new exec pod
  E0518 13:49:31.743555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:32.743910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:33.744662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:34.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2234 exec execpod-affinityvl58j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  May 18 13:49:34.282: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  May 18 13:49:34.282: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:49:34.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2234 exec execpod-affinityvl58j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.87 80'
  May 18 13:49:34.372: INFO: stderr: "+ nc -v -t -w 2 10.152.183.87 80\n+ echo hostName\nConnection to 10.152.183.87 80 port [tcp/http] succeeded!\n"
  May 18 13:49:34.372: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  May 18 13:49:34.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=services-2234 exec execpod-affinityvl58j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.87:80/ ; done'
  May 18 13:49:34.524: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.87:80/\n"
  May 18 13:49:34.524: INFO: stdout: "\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn\naffinity-clusterip-zbrbn"
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Received response from host: affinity-clusterip-zbrbn
  May 18 13:49:34.524: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-2234, will wait for the garbage collector to delete the pods @ 05/18/24 13:49:34.541
  May 18 13:49:34.606: INFO: Deleting ReplicationController affinity-clusterip took: 9.863732ms
  May 18 13:49:34.707: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.626303ms
  E0518 13:49:34.745310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:35.746369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:36.746643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:37.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2234" for this suite. @ 05/18/24 13:49:37.63
• [9.579 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 05/18/24 13:49:37.639
  May 18 13:49:37.639: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename kubectl @ 05/18/24 13:49:37.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:37.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:37.664
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/18/24 13:49:37.667
  May 18 13:49:37.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6651 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  May 18 13:49:37.715: INFO: stderr: ""
  May 18 13:49:37.715: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/18/24 13:49:37.715
  May 18 13:49:37.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4194964957 --namespace=kubectl-6651 delete pods e2e-test-httpd-pod'
  E0518 13:49:37.746789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:38.747235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:39.520: INFO: stderr: ""
  May 18 13:49:39.520: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  May 18 13:49:39.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6651" for this suite. @ 05/18/24 13:49:39.525
• [1.893 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/18/24 13:49:39.532
  May 18 13:49:39.532: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename secrets @ 05/18/24 13:49:39.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:39.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:39.551
  STEP: Creating secret with name secret-test-d3fba26c-7b9a-4b9b-82e9-331a7194e8cb @ 05/18/24 13:49:39.553
  STEP: Creating a pod to test consume secrets @ 05/18/24 13:49:39.559
  E0518 13:49:39.747968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:40.748082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:41.748149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:42.748333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:49:43.583
  May 18 13:49:43.587: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-secrets-bda84154-efe7-4d0f-8abe-32e4b975cc14 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/18/24 13:49:43.594
  May 18 13:49:43.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5646" for this suite. @ 05/18/24 13:49:43.613
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 05/18/24 13:49:43.62
  May 18 13:49:43.620: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename emptydir @ 05/18/24 13:49:43.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:43.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:43.639
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/18/24 13:49:43.642
  E0518 13:49:43.748384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:44.748677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:45.748756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:46.748878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/18/24 13:49:47.667
  May 18 13:49:47.671: INFO: Trying to get logs from node ip-172-31-33-93 pod pod-9750726e-1ec5-421c-9586-37eae18c20ec container test-container: <nil>
  STEP: delete the pod @ 05/18/24 13:49:47.678
  May 18 13:49:47.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8549" for this suite. @ 05/18/24 13:49:47.697
• [4.084 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 05/18/24 13:49:47.704
  May 18 13:49:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/18/24 13:49:47.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:47.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:47.731
  STEP: create the container to handle the HTTPGet hook request. @ 05/18/24 13:49:47.738
  E0518 13:49:47.749030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:48.749209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:49.749293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/18/24 13:49:49.763
  E0518 13:49:50.749388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:51.750159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/18/24 13:49:51.781
  STEP: delete the pod with lifecycle hook @ 05/18/24 13:49:51.807
  E0518 13:49:52.750328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:53.750518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:53.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4652" for this suite. @ 05/18/24 13:49:53.831
• [6.134 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 05/18/24 13:49:53.838
  May 18 13:49:53.838: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:49:53.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:53.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:53.858
  STEP: Setting up server cert @ 05/18/24 13:49:53.881
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:49:53.997
  STEP: Deploying the webhook pod @ 05/18/24 13:49:54.006
  STEP: Wait for the deployment to be ready @ 05/18/24 13:49:54.021
  May 18 13:49:54.030: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 13:49:54.751118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:55.751281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:49:56.043
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:49:56.054
  E0518 13:49:56.752346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:49:57.054: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/18/24 13:49:57.128
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/18/24 13:49:57.152
  STEP: Deleting the collection of validation webhooks @ 05/18/24 13:49:57.174
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/18/24 13:49:57.229
  May 18 13:49:57.282: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5321" for this suite. @ 05/18/24 13:49:57.285
  STEP: Destroying namespace "webhook-markers-8080" for this suite. @ 05/18/24 13:49:57.293
• [3.462 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 05/18/24 13:49:57.3
  May 18 13:49:57.300: INFO: >>> kubeConfig: /tmp/kubeconfig-4194964957
  STEP: Building a namespace api object, basename webhook @ 05/18/24 13:49:57.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/18/24 13:49:57.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/18/24 13:49:57.317
  STEP: Setting up server cert @ 05/18/24 13:49:57.343
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/18/24 13:49:57.595
  STEP: Deploying the webhook pod @ 05/18/24 13:49:57.602
  STEP: Wait for the deployment to be ready @ 05/18/24 13:49:57.621
  May 18 13:49:57.630: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0518 13:49:57.753054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0518 13:49:58.753158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/18/24 13:49:59.643
  STEP: Verifying the service has paired with the endpoint @ 05/18/24 13:49:59.654
  E0518 13:49:59.754144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:50:00.655: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/18/24 13:50:00.664
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/18/24 13:50:00.682
  STEP: Creating a configMap that should not be mutated @ 05/18/24 13:50:00.689
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/18/24 13:50:00.701
  STEP: Creating a configMap that should be mutated @ 05/18/24 13:50:00.709
  E0518 13:50:00.755097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  May 18 13:50:00.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9276" for this suite. @ 05/18/24 13:50:00.782
  STEP: Destroying namespace "webhook-markers-9764" for this suite. @ 05/18/24 13:50:00.79
• [3.498 seconds]
------------------------------
SSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:88
  May 18 13:50:00.799: INFO: Running AfterSuite actions on node 1
  May 18 13:50:00.799: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.029 seconds]
------------------------------

Ran 388 of 7408 Specs in 6232.845 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7020 Skipped
PASS

Ginkgo ran 1 suite in 1h43m53.67591654s
Test Suite Passed
