  I0413 12:20:37.271201      21 e2e.go:117] Starting e2e run "0a2af82a-977a-4467-bc2e-9d348b0a2115" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1713010836 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 13 12:20:37.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:20:37.496: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 13 12:20:37.529: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 13 12:20:37.534: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Apr 13 12:20:37.535: INFO: e2e test version: v1.29.3
  Apr 13 12:20:37.536: INFO: kube-apiserver version: v1.29.3
  Apr 13 12:20:37.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:20:37.541: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 04/13/24 12:20:37.649
  Apr 13 12:20:37.649: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:20:37.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:37.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:37.671
  STEP: Creating a pod to test downward api env vars @ 04/13/24 12:20:37.674
  STEP: Saw pod success @ 04/13/24 12:20:45.709
  Apr 13 12:20:45.713: INFO: Trying to get logs from node ip-172-31-82-63 pod downward-api-172bf297-5cb5-447b-9b26-ee8b024f2064 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 12:20:45.731
  Apr 13 12:20:45.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7426" for this suite. @ 04/13/24 12:20:45.753
• [8.110 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 04/13/24 12:20:45.759
  Apr 13 12:20:45.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 12:20:45.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:45.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:45.779
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 12:20:45.782
  STEP: Saw pod success @ 04/13/24 12:20:51.811
  Apr 13 12:20:51.815: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-161b0d1f-2dc0-43d5-83a4-edb0201e5438 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 12:20:51.821
  Apr 13 12:20:51.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3536" for this suite. @ 04/13/24 12:20:51.84
• [6.088 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 04/13/24 12:20:51.847
  Apr 13 12:20:51.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename podtemplate @ 04/13/24 12:20:51.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:51.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:51.867
  STEP: Create set of pod templates @ 04/13/24 12:20:51.87
  Apr 13 12:20:51.876: INFO: created test-podtemplate-1
  Apr 13 12:20:51.882: INFO: created test-podtemplate-2
  Apr 13 12:20:51.888: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/13/24 12:20:51.888
  STEP: delete collection of pod templates @ 04/13/24 12:20:51.892
  Apr 13 12:20:51.892: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/13/24 12:20:51.909
  Apr 13 12:20:51.909: INFO: requesting list of pod templates to confirm quantity
  Apr 13 12:20:51.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1753" for this suite. @ 04/13/24 12:20:51.927
• [0.090 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 04/13/24 12:20:51.937
  Apr 13 12:20:51.937: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 12:20:51.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:51.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:51.958
  STEP: Creating simple DaemonSet "daemon-set" @ 04/13/24 12:20:51.984
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 12:20:51.989
  Apr 13 12:20:51.993: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:51.993: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:51.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 12:20:51.997: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:20:52.994: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:52.994: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:52.998: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 12:20:52.998: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:20:53.994: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:53.994: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:53.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 12:20:53.997: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:20:54.994: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:54.994: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:54.998: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 13 12:20:54.998: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:20:55.995: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:55.995: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:20:55.999: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 12:20:55.999: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/13/24 12:20:56.003
  STEP: DeleteCollection of the DaemonSets @ 04/13/24 12:20:56.007
  STEP: Verify that ReplicaSets have been deleted @ 04/13/24 12:20:56.015
  Apr 13 12:20:56.034: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4611"},"items":null}

  Apr 13 12:20:56.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4612"},"items":[{"metadata":{"name":"daemon-set-5xkc9","generateName":"daemon-set-","namespace":"daemonsets-2609","uid":"7a9d3465-0b4e-4005-ac3c-a07b6eb27069","resourceVersion":"4609","creationTimestamp":"2024-04-13T12:20:52Z","deletionTimestamp":"2024-04-13T12:21:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b892a086-43e5-4179-b4b4-da981c602c43","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b892a086-43e5-4179-b4b4-da981c602c43\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.57.194\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-p85d8","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-p85d8","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-35-229","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-35-229"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"}],"hostIP":"172.31.35.229","hostIPs":[{"ip":"172.31.35.229"}],"podIP":"192.168.57.194","podIPs":[{"ip":"192.168.57.194"}],"startTime":"2024-04-13T12:20:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-13T12:20:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://19ae29289e94afe143b264615c11d91280091356096369339ca56096e4198dd4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-7t62h","generateName":"daemon-set-","namespace":"daemonsets-2609","uid":"fbade743-4d54-4d40-b4f5-e687ac9f0d46","resourceVersion":"4610","creationTimestamp":"2024-04-13T12:20:51Z","deletionTimestamp":"2024-04-13T12:21:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b892a086-43e5-4179-b4b4-da981c602c43","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b892a086-43e5-4179-b4b4-da981c602c43\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.254.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-n8t75","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-n8t75","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-65-227","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-65-227"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:54Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:54Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:54Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"}],"hostIP":"172.31.65.227","hostIPs":[{"ip":"172.31.65.227"}],"podIP":"192.168.254.198","podIPs":[{"ip":"192.168.254.198"}],"startTime":"2024-04-13T12:20:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-13T12:20:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://754d28ffe231d40ddde1f4f37a976eb408e714a8445f8deed99924cf43f7a56f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-mmkmn","generateName":"daemon-set-","namespace":"daemonsets-2609","uid":"e9acd8e8-11f0-4256-8d64-c47997e9f5bd","resourceVersion":"4611","creationTimestamp":"2024-04-13T12:20:52Z","deletionTimestamp":"2024-04-13T12:21:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b892a086-43e5-4179-b4b4-da981c602c43","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b892a086-43e5-4179-b4b4-da981c602c43\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-13T12:20:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t5g8z","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t5g8z","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-82-63","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-82-63"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:55Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-13T12:20:52Z"}],"hostIP":"172.31.82.63","hostIPs":[{"ip":"172.31.82.63"}],"podIP":"192.168.172.196","podIPs":[{"ip":"192.168.172.196"}],"startTime":"2024-04-13T12:20:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-13T12:20:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://dcdfc3d2ca594ebfdbfd027a2f8e67f686ec84648553170709ad1ee02a45e988","started":true}],"qosClass":"BestEffort"}}]}

  Apr 13 12:20:56.051: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2609" for this suite. @ 04/13/24 12:20:56.054
• [4.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/13/24 12:20:56.061
  Apr 13 12:20:56.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 12:20:56.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:56.079
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:56.082
  Apr 13 12:20:56.086: INFO: Creating deployment "test-recreate-deployment"
  Apr 13 12:20:56.092: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 13 12:20:56.099: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  Apr 13 12:20:58.108: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 13 12:20:58.111: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 13 12:20:58.124: INFO: Updating deployment test-recreate-deployment
  Apr 13 12:20:58.124: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 13 12:20:58.277: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "39454beb-5121-45b9-948e-4c9b9ae576c6",
      ResourceVersion: (string) (len=4) "4691",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848607656,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607656,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 12:20:58.308: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "31f0a33e-ccb4-464c-9f37-142534c0e1b3",
      ResourceVersion: (string) (len=4) "4688",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848607658,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "39454beb-5121-45b9-948e-4c9b9ae576c6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 39 34 35 34 62  65 62 2d 35 31 32 31 2d  |\"39454beb-5121-|
              00000120  34 35 62 39 2d 39 34 38  65 2d 34 63 39 62 39 61  |45b9-948e-4c9b9a|
              00000130  65 35 37 36 63 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e576c6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:20:58.309: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 13 12:20:58.309: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e76fa9d5-6c28-4895-9ae9-4586cf784e0f",
      ResourceVersion: (string) (len=4) "4679",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848607656,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "39454beb-5121-45b9-948e-4c9b9ae576c6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 39 34 35 34 62  65 62 2d 35 31 32 31 2d  |\"39454beb-5121-|
              00000120  34 35 62 39 2d 39 34 38  65 2d 34 63 39 62 39 61  |45b9-948e-4c9b9a|
              00000130  65 35 37 36 63 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e576c6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:20:58.315: INFO: Pod "test-recreate-deployment-76fb77d45-b8s2z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-b8s2z",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-9676",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "105c32ec-d27a-44f8-8a4d-00319bb92ae1",
      ResourceVersion: (string) (len=4) "4689",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848607658,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "31f0a33e-ccb4-464c-9f37-142534c0e1b3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 31  66 30 61 33 33 65 2d 63  |d\":\"31f0a33e-c|
              00000090  63 62 34 2d 34 36 34 63  2d 39 66 33 37 2d 31 34  |cb4-464c-9f37-14|
              000000a0  32 35 33 34 63 30 65 31  62 33 5c 22 7d 22 3a 7b  |2534c0e1b3\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5n82t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5n82t",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848607658,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848607658,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:20:58.316: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9676" for this suite. @ 04/13/24 12:20:58.32
• [2.267 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 04/13/24 12:20:58.329
  Apr 13 12:20:58.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 12:20:58.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:20:58.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:20:58.349
  STEP: Creating a job @ 04/13/24 12:20:58.353
  STEP: Ensuring job reaches completions @ 04/13/24 12:20:58.359
  Apr 13 12:21:08.364: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5447" for this suite. @ 04/13/24 12:21:08.368
• [10.047 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 04/13/24 12:21:08.375
  Apr 13 12:21:08.375: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:21:08.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:21:08.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:21:08.396
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/13/24 12:21:08.4
  STEP: Saw pod success @ 04/13/24 12:21:10.42
  Apr 13 12:21:10.424: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-ec74a28f-ad13-4612-8583-b3560a1a4ba8 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 12:21:10.431
  Apr 13 12:21:10.446: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8594" for this suite. @ 04/13/24 12:21:10.45
• [2.081 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/13/24 12:21:10.457
  Apr 13 12:21:10.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 12:21:10.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:21:10.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:21:10.475
  STEP: Creating secret with name secret-test-423f1f82-edb4-4a72-a7ad-eb46b6e8eba9 @ 04/13/24 12:21:10.479
  STEP: Creating a pod to test consume secrets @ 04/13/24 12:21:10.484
  STEP: Saw pod success @ 04/13/24 12:21:12.503
  Apr 13 12:21:12.507: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-7560f7ef-9d2e-4509-89d3-06e3c5d60875 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 12:21:12.514
  Apr 13 12:21:12.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9747" for this suite. @ 04/13/24 12:21:12.533
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/13/24 12:21:12.541
  Apr 13 12:21:12.541: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 12:21:12.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:21:12.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:21:12.562
  STEP: set up a multi version CRD @ 04/13/24 12:21:12.567
  Apr 13 12:21:12.568: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: mark a version not serverd @ 04/13/24 12:21:15.916
  STEP: check the unserved version gets removed @ 04/13/24 12:21:15.932
  STEP: check the other version is not changed @ 04/13/24 12:21:16.731
  Apr 13 12:21:19.152: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1365" for this suite. @ 04/13/24 12:21:19.159
• [6.625 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/13/24 12:21:19.168
  Apr 13 12:21:19.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 12:21:19.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:21:19.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:21:19.185
  STEP: Creating projection with secret that has name projected-secret-test-map-eb2aeba6-0cc1-4997-9012-f5eb801bf161 @ 04/13/24 12:21:19.189
  STEP: Creating a pod to test consume secrets @ 04/13/24 12:21:19.193
  STEP: Saw pod success @ 04/13/24 12:21:23.215
  Apr 13 12:21:23.218: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-7700faff-6b3f-4e57-b6e3-b060f3885a9f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 12:21:23.224
  Apr 13 12:21:23.241: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2381" for this suite. @ 04/13/24 12:21:23.245
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 04/13/24 12:21:23.251
  Apr 13 12:21:23.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 12:21:23.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:21:23.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:21:23.27
  STEP: Creating service test in namespace statefulset-415 @ 04/13/24 12:21:23.273
  STEP: Creating stateful set ss in namespace statefulset-415 @ 04/13/24 12:21:23.281
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-415 @ 04/13/24 12:21:23.287
  Apr 13 12:21:23.290: INFO: Found 0 stateful pods, waiting for 1
  Apr 13 12:21:33.292: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/13/24 12:21:33.292
  Apr 13 12:21:33.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 12:21:33.399: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 12:21:33.399: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 12:21:33.399: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 12:21:33.403: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 13 12:21:43.405: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 12:21:43.405: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 13 12:21:43.424: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  Apr 13 12:21:43.424: INFO: ss-0  ip-172-31-82-63  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:24 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC  }]
  Apr 13 12:21:43.424: INFO: 
  Apr 13 12:21:43.424: INFO: StatefulSet ss has not reached scale 3, at 1
  Apr 13 12:21:44.430: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994623173s
  Apr 13 12:21:45.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989565685s
  Apr 13 12:21:46.440: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984466077s
  Apr 13 12:21:47.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978371096s
  Apr 13 12:21:48.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974258958s
  Apr 13 12:21:49.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968506326s
  Apr 13 12:21:50.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963307539s
  Apr 13 12:21:51.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957783639s
  Apr 13 12:21:52.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 951.918779ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-415 @ 04/13/24 12:21:53.473
  Apr 13 12:21:53.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 12:21:53.579: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 12:21:53.579: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 12:21:53.579: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 12:21:53.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 12:21:53.676: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 13 12:21:53.676: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 12:21:53.676: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 12:21:53.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 12:21:53.771: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 13 12:21:53.771: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 12:21:53.771: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 12:21:53.776: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 12:21:53.776: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 12:21:53.776: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/13/24 12:21:53.776
  Apr 13 12:21:53.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 12:21:53.867: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 12:21:53.867: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 12:21:53.867: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 12:21:53.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 12:21:53.949: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 12:21:53.949: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 12:21:53.949: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 12:21:53.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-415 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 12:21:54.046: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 12:21:54.046: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 12:21:54.046: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 12:21:54.046: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 13 12:21:54.050: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  Apr 13 12:22:04.055: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 12:22:04.055: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 12:22:04.055: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 12:22:04.070: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Apr 13 12:22:04.070: INFO: ss-0  ip-172-31-82-63   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:24 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC  }]
  Apr 13 12:22:04.070: INFO: ss-1  ip-172-31-65-227  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:44 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  }]
  Apr 13 12:22:04.070: INFO: ss-2  ip-172-31-35-229  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:44 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  }]
  Apr 13 12:22:04.070: INFO: 
  Apr 13 12:22:04.070: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 13 12:22:05.076: INFO: POD   NODE              PHASE      GRACE  CONDITIONS
  Apr 13 12:22:05.076: INFO: ss-0  ip-172-31-82-63   Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:22:04 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:23 +0000 UTC  }]
  Apr 13 12:22:05.076: INFO: ss-1  ip-172-31-65-227  Succeeded  0s     [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:22:04 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  }]
  Apr 13 12:22:05.076: INFO: ss-2  ip-172-31-35-229  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:22:04 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:54 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 12:21:43 +0000 UTC  }]
  Apr 13 12:22:05.076: INFO: 
  Apr 13 12:22:05.076: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 13 12:22:06.081: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.989776903s
  Apr 13 12:22:07.087: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.983749555s
  Apr 13 12:22:08.091: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978876413s
  Apr 13 12:22:09.096: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.97389516s
  Apr 13 12:22:10.101: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.969271117s
  Apr 13 12:22:11.105: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965121642s
  Apr 13 12:22:12.110: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960478537s
  Apr 13 12:22:13.115: INFO: Verifying statefulset ss doesn't scale past 0 for another 955.828369ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-415 @ 04/13/24 12:22:14.115
  Apr 13 12:22:14.120: INFO: Scaling statefulset ss to 0
  Apr 13 12:22:14.132: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 12:22:14.136: INFO: Deleting all statefulset in ns statefulset-415
  Apr 13 12:22:14.139: INFO: Scaling statefulset ss to 0
  Apr 13 12:22:14.150: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 12:22:14.153: INFO: Deleting statefulset ss
  Apr 13 12:22:14.166: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-415" for this suite. @ 04/13/24 12:22:14.169
• [50.925 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 04/13/24 12:22:14.176
  Apr 13 12:22:14.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename apf @ 04/13/24 12:22:14.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:22:14.194
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:22:14.197
  STEP: getting /apis @ 04/13/24 12:22:14.201
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/13/24 12:22:14.206
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/13/24 12:22:14.208
  STEP: creating @ 04/13/24 12:22:14.209
  STEP: getting @ 04/13/24 12:22:14.224
  STEP: listing @ 04/13/24 12:22:14.227
  STEP: watching @ 04/13/24 12:22:14.233
  Apr 13 12:22:14.233: INFO: starting watch
  STEP: patching @ 04/13/24 12:22:14.235
  STEP: updating @ 04/13/24 12:22:14.24
  Apr 13 12:22:14.250: INFO: waiting for watch events with expected annotations
  Apr 13 12:22:14.250: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 04/13/24 12:22:14.25
  STEP: patching /status @ 04/13/24 12:22:14.253
  STEP: updating /status @ 04/13/24 12:22:14.258
  STEP: deleting @ 04/13/24 12:22:14.287
  STEP: deleting a collection @ 04/13/24 12:22:14.301
  Apr 13 12:22:14.321: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5235" for this suite. @ 04/13/24 12:22:14.325
• [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 04/13/24 12:22:14.332
  Apr 13 12:22:14.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context-test @ 04/13/24 12:22:14.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:22:14.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:22:14.35
  Apr 13 12:22:18.376: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-245" for this suite. @ 04/13/24 12:22:18.379
• [4.054 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/13/24 12:22:18.386
  Apr 13 12:22:18.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename events @ 04/13/24 12:22:18.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:22:18.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:22:18.406
  STEP: creating a test event @ 04/13/24 12:22:18.41
  STEP: listing events in all namespaces @ 04/13/24 12:22:18.417
  STEP: listing events in test namespace @ 04/13/24 12:22:18.43
  STEP: listing events with field selection filtering on source @ 04/13/24 12:22:18.434
  STEP: listing events with field selection filtering on reportingController @ 04/13/24 12:22:18.438
  STEP: getting the test event @ 04/13/24 12:22:18.441
  STEP: patching the test event @ 04/13/24 12:22:18.444
  STEP: getting the test event @ 04/13/24 12:22:18.453
  STEP: updating the test event @ 04/13/24 12:22:18.457
  STEP: getting the test event @ 04/13/24 12:22:18.465
  STEP: deleting the test event @ 04/13/24 12:22:18.468
  STEP: listing events in all namespaces @ 04/13/24 12:22:18.475
  STEP: listing events in test namespace @ 04/13/24 12:22:18.488
  Apr 13 12:22:18.492: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1524" for this suite. @ 04/13/24 12:22:18.496
• [0.116 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/13/24 12:22:18.502
  Apr 13 12:22:18.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 12:22:18.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:22:18.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:22:18.519
  STEP: Creating configMap with name configmap-projected-all-test-volume-fd50efde-0ab8-4b89-8789-105c1e2247c2 @ 04/13/24 12:22:18.522
  STEP: Creating secret with name secret-projected-all-test-volume-5016d517-6d07-4727-85c9-63236b39155d @ 04/13/24 12:22:18.527
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/13/24 12:22:18.532
  STEP: Saw pod success @ 04/13/24 12:22:20.551
  Apr 13 12:22:20.555: INFO: Trying to get logs from node ip-172-31-82-63 pod projected-volume-22cfbb4f-3803-4ef5-b721-5e7dda99e7a1 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 12:22:20.561
  Apr 13 12:22:20.575: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2706" for this suite. @ 04/13/24 12:22:20.579
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/13/24 12:22:20.587
  Apr 13 12:22:20.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption @ 04/13/24 12:22:20.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:22:20.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:22:20.607
  Apr 13 12:22:20.624: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 13 12:23:20.629: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/13/24 12:23:20.633
  Apr 13 12:23:20.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/13/24 12:23:20.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:20.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:20.653
  Apr 13 12:23:20.672: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 13 12:23:20.676: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 13 12:23:20.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9186" for this suite. @ 04/13/24 12:23:20.745
  Apr 13 12:23:20.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5028" for this suite. @ 04/13/24 12:23:20.755
• [60.175 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/13/24 12:23:20.762
  Apr 13 12:23:20.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 12:23:20.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:20.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:20.781
  STEP: Creating a test headless service @ 04/13/24 12:23:20.784
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3722.svc.cluster.local;sleep 1; done
   @ 04/13/24 12:23:20.789
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3722.svc.cluster.local;sleep 1; done
   @ 04/13/24 12:23:20.789
  STEP: creating a pod to probe DNS @ 04/13/24 12:23:20.789
  STEP: submitting the pod to kubernetes @ 04/13/24 12:23:20.789
  STEP: retrieving the pod @ 04/13/24 12:23:26.819
  STEP: looking for the results for each expected name from probers @ 04/13/24 12:23:26.823
  Apr 13 12:23:26.842: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local from pod dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287: the server could not find the requested resource (get pods dns-test-116ef700-1644-4d53-9648-c93f6c125287)
  Apr 13 12:23:26.845: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local from pod dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287: the server could not find the requested resource (get pods dns-test-116ef700-1644-4d53-9648-c93f6c125287)
  Apr 13 12:23:26.849: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3722.svc.cluster.local from pod dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287: the server could not find the requested resource (get pods dns-test-116ef700-1644-4d53-9648-c93f6c125287)
  Apr 13 12:23:26.853: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3722.svc.cluster.local from pod dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287: the server could not find the requested resource (get pods dns-test-116ef700-1644-4d53-9648-c93f6c125287)
  Apr 13 12:23:26.853: INFO: Lookups using dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287 failed for: [jessie_udp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3722.svc.cluster.local jessie_udp@dns-test-service-2.dns-3722.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3722.svc.cluster.local]

  Apr 13 12:23:26.859: INFO: Pod client logs for webserver: 
  Apr 13 12:23:26.866: INFO: Pod client logs for querier: 
  Apr 13 12:23:26.872: INFO: Pod client logs for jessie-querier: 
  Apr 13 12:23:31.860: INFO: DNS probes using dns-3722/dns-test-116ef700-1644-4d53-9648-c93f6c125287 succeeded

  STEP: deleting the pod @ 04/13/24 12:23:31.861
  STEP: deleting the test headless service @ 04/13/24 12:23:31.882
  Apr 13 12:23:31.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3722" for this suite. @ 04/13/24 12:23:31.901
• [11.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/13/24 12:23:31.918
  Apr 13 12:23:31.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption @ 04/13/24 12:23:31.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:31.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:31.95
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:23:31.959
  STEP: Updating PodDisruptionBudget status @ 04/13/24 12:23:33.965
  STEP: Waiting for all pods to be running @ 04/13/24 12:23:33.975
  Apr 13 12:23:33.981: INFO: running pods: 0 < 1
  STEP: locating a running pod @ 04/13/24 12:23:35.982
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:23:35.995
  STEP: Patching PodDisruptionBudget status @ 04/13/24 12:23:36.002
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:23:36.01
  Apr 13 12:23:36.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9602" for this suite. @ 04/13/24 12:23:36.019
• [4.109 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.027
  Apr 13 12:23:36.027: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename watch @ 04/13/24 12:23:36.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.044
  STEP: creating a new configmap @ 04/13/24 12:23:36.048
  STEP: modifying the configmap once @ 04/13/24 12:23:36.052
  STEP: modifying the configmap a second time @ 04/13/24 12:23:36.06
  STEP: deleting the configmap @ 04/13/24 12:23:36.069
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/13/24 12:23:36.074
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/13/24 12:23:36.076
  Apr 13 12:23:36.076: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9190  efaa5bd0-6a4a-415c-a980-b6e5538d5610 5775 0 2024-04-13 12:23:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-13 12:23:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 12:23:36.076: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9190  efaa5bd0-6a4a-415c-a980-b6e5538d5610 5776 0 2024-04-13 12:23:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-13 12:23:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 12:23:36.076: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9190" for this suite. @ 04/13/24 12:23:36.082
• [0.062 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.09
  Apr 13 12:23:36.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename events @ 04/13/24 12:23:36.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.109
  STEP: Create set of events @ 04/13/24 12:23:36.112
  STEP: get a list of Events with a label in the current namespace @ 04/13/24 12:23:36.128
  STEP: delete a list of events @ 04/13/24 12:23:36.131
  Apr 13 12:23:36.131: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/13/24 12:23:36.152
  Apr 13 12:23:36.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6849" for this suite. @ 04/13/24 12:23:36.158
• [0.077 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.167
  Apr 13 12:23:36.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sysctl @ 04/13/24 12:23:36.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.185
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/13/24 12:23:36.188
  Apr 13 12:23:36.192: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9614" for this suite. @ 04/13/24 12:23:36.195
• [0.034 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.202
  Apr 13 12:23:36.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename tables @ 04/13/24 12:23:36.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.22
  Apr 13 12:23:36.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6136" for this suite. @ 04/13/24 12:23:36.23
• [0.036 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.238
  Apr 13 12:23:36.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 12:23:36.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.255
  Apr 13 12:23:36.297: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7727" for this suite. @ 04/13/24 12:23:36.301
• [0.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/13/24 12:23:36.309
  Apr 13 12:23:36.309: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename watch @ 04/13/24 12:23:36.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:36.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:36.328
  STEP: getting a starting resourceVersion @ 04/13/24 12:23:36.331
  STEP: starting a background goroutine to produce watch events @ 04/13/24 12:23:36.335
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/13/24 12:23:36.335
  Apr 13 12:23:39.115: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4257" for this suite. @ 04/13/24 12:23:39.165
• [2.910 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/13/24 12:23:39.219
  Apr 13 12:23:39.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:23:39.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:23:39.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:23:39.24
  Apr 13 12:24:39.258: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8542" for this suite. @ 04/13/24 12:24:39.262
• [60.050 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 04/13/24 12:24:39.27
  Apr 13 12:24:39.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 12:24:39.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:24:39.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:24:39.29
  STEP: Setting up server cert @ 04/13/24 12:24:39.318
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 12:24:39.574
  STEP: Deploying the webhook pod @ 04/13/24 12:24:39.581
  STEP: Wait for the deployment to be ready @ 04/13/24 12:24:39.592
  Apr 13 12:24:39.599: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  Apr 13 12:24:41.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 12, 24, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 12, 24, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 12, 24, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 12, 24, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 04/13/24 12:24:43.618
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 12:24:43.63
  Apr 13 12:24:44.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/13/24 12:24:44.641
  STEP: create a pod that should be denied by the webhook @ 04/13/24 12:24:44.657
  STEP: create a pod that causes the webhook to hang @ 04/13/24 12:24:44.668
  STEP: create a configmap that should be denied by the webhook @ 04/13/24 12:24:54.677
  STEP: create a configmap that should be admitted by the webhook @ 04/13/24 12:24:54.709
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/13/24 12:24:54.718
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/13/24 12:24:54.726
  STEP: create a namespace that bypass the webhook @ 04/13/24 12:24:54.732
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/13/24 12:24:54.747
  Apr 13 12:24:54.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6367" for this suite. @ 04/13/24 12:24:54.803
  STEP: Destroying namespace "webhook-markers-6702" for this suite. @ 04/13/24 12:24:54.81
  STEP: Destroying namespace "exempted-namespace-5153" for this suite. @ 04/13/24 12:24:54.817
• [15.555 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 04/13/24 12:24:54.825
  Apr 13 12:24:54.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:24:54.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:24:54.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:24:54.841
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/13/24 12:24:54.845
  STEP: Saw pod success @ 04/13/24 12:24:56.863
  Apr 13 12:24:56.868: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-8245ca30-7ef2-4cec-b6d4-54e728495ca4 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 12:24:56.878
  Apr 13 12:24:56.894: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-749" for this suite. @ 04/13/24 12:24:56.898
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/13/24 12:24:56.905
  Apr 13 12:24:56.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:24:56.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:24:56.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:24:56.924
  STEP: Creating pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504 @ 04/13/24 12:24:56.927
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 12:24:58.945
  Apr 13 12:24:58.948: INFO: Initial restart count of pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 is 0
  Apr 13 12:24:58.952: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:00.957: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:02.963: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:04.968: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:06.974: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:08.979: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:10.985: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:12.990: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:14.995: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:17.000: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:19.005: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:21.010: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:23.016: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:25.021: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:27.026: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:29.031: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:31.036: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:33.042: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:35.047: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:37.051: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:39.057: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:41.062: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:43.067: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:45.072: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:47.077: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:49.082: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:51.088: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:53.093: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:55.098: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:57.103: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:25:59.109: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:01.114: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:03.119: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:05.124: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:07.129: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:09.135: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:11.140: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:13.146: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:15.151: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:17.156: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:19.161: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:21.166: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:23.171: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:25.177: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:27.182: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:29.187: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:31.194: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:33.200: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:35.205: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:37.211: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:39.216: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:41.222: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:43.227: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:45.233: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:47.238: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:49.243: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:51.249: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:53.254: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:55.259: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:57.265: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:26:59.272: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:01.277: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:03.283: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:05.289: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:07.295: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:09.300: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:11.305: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:13.311: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:15.315: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:17.320: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:19.325: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:21.330: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:23.336: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:25.342: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:27.347: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:29.352: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:31.358: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:33.362: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:35.367: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:37.372: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:39.378: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:41.383: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:43.389: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:45.394: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:47.399: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:49.404: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:51.410: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:53.415: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:55.419: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:57.424: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:27:59.430: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:01.435: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:03.440: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:05.445: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:07.451: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:09.456: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:11.460: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:13.466: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:15.470: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:17.475: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:19.482: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:21.487: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:23.493: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:25.497: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:27.503: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:29.508: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:31.514: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:33.518: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:35.524: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:37.529: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:39.535: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:41.540: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:43.546: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:45.550: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:47.556: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:49.562: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:51.567: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:53.573: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:55.578: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  Apr 13 12:28:57.584: INFO: Get pod busybox-f5feb659-f8da-4818-add3-2d8e57aa0065 in namespace container-probe-9504
  STEP: deleting the pod @ 04/13/24 12:28:59.584
  Apr 13 12:28:59.600: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9504" for this suite. @ 04/13/24 12:28:59.605
• [242.706 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/13/24 12:28:59.611
  Apr 13 12:28:59.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 12:28:59.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:28:59.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:28:59.631
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/13/24 12:28:59.635
  Apr 13 12:28:59.635: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:29:00.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:29:05.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1271" for this suite. @ 04/13/24 12:29:05.923
• [6.317 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 04/13/24 12:29:05.929
  Apr 13 12:29:05.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 12:29:05.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:05.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:05.946
  STEP: Create a ReplicaSet @ 04/13/24 12:29:05.949
  STEP: Verify that the required pods have come up @ 04/13/24 12:29:05.954
  Apr 13 12:29:05.956: INFO: Pod name sample-pod: Found 0 pods out of 3
  Apr 13 12:29:10.961: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/13/24 12:29:10.962
  Apr 13 12:29:10.965: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/13/24 12:29:10.965
  STEP: DeleteCollection of the ReplicaSets @ 04/13/24 12:29:10.968
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/13/24 12:29:10.975
  Apr 13 12:29:10.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9911" for this suite. @ 04/13/24 12:29:10.983
• [5.068 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/13/24 12:29:10.997
  Apr 13 12:29:10.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption @ 04/13/24 12:29:10.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:11.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:11.021
  STEP: Creating a kubernetes client @ 04/13/24 12:29:11.026
  Apr 13 12:29:11.026: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption-2 @ 04/13/24 12:29:11.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:11.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:11.047
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:29:11.062
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:29:13.072
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:29:13.081
  STEP: listing a collection of PDBs across all namespaces @ 04/13/24 12:29:15.086
  STEP: listing a collection of PDBs in namespace disruption-1620 @ 04/13/24 12:29:15.089
  STEP: deleting a collection of PDBs @ 04/13/24 12:29:15.093
  STEP: Waiting for the PDB collection to be deleted @ 04/13/24 12:29:15.105
  Apr 13 12:29:15.108: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-5667" for this suite. @ 04/13/24 12:29:15.112
  Apr 13 12:29:15.120: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1620" for this suite. @ 04/13/24 12:29:15.124
• [4.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 04/13/24 12:29:15.132
  Apr 13 12:29:15.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename lease-test @ 04/13/24 12:29:15.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:15.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:15.148
  Apr 13 12:29:15.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-858" for this suite. @ 04/13/24 12:29:15.206
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 04/13/24 12:29:15.212
  Apr 13 12:29:15.212: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:29:15.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:15.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:15.23
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 12:29:15.234
  STEP: Saw pod success @ 04/13/24 12:29:17.252
  Apr 13 12:29:17.255: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-558d4712-c0c0-4ed9-b045-7f649b6b3a4f container client-container: <nil>
  STEP: delete the pod @ 04/13/24 12:29:17.273
  Apr 13 12:29:17.289: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7401" for this suite. @ 04/13/24 12:29:17.293
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 04/13/24 12:29:17.301
  Apr 13 12:29:17.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pod-network-test @ 04/13/24 12:29:17.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:17.321
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:17.325
  STEP: Performing setup for networking test in namespace pod-network-test-9645 @ 04/13/24 12:29:17.328
  STEP: creating a selector @ 04/13/24 12:29:17.328
  STEP: Creating the service pods in kubernetes @ 04/13/24 12:29:17.328
  Apr 13 12:29:17.328: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/13/24 12:29:39.432
  Apr 13 12:29:41.463: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 13 12:29:41.463: INFO: Going to poll 192.168.57.200 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:29:41.467: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.57.200:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:29:41.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:29:41.467: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:29:41.467: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.57.200%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 13 12:29:41.533: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 13 12:29:41.533: INFO: Going to poll 192.168.254.201 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:29:41.537: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.254.201:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:29:41.537: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:29:41.537: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:29:41.537: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.254.201%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 13 12:29:41.590: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 13 12:29:41.590: INFO: Going to poll 192.168.172.213 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:29:41.593: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.172.213:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:29:41.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:29:41.594: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:29:41.594: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.172.213%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 13 12:29:41.650: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 13 12:29:41.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9645" for this suite. @ 04/13/24 12:29:41.655
• [24.361 seconds]
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/13/24 12:29:41.662
  Apr 13 12:29:41.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 12:29:41.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:41.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:41.679
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5409 @ 04/13/24 12:29:41.682
  STEP: changing the ExternalName service to type=ClusterIP @ 04/13/24 12:29:41.688
  STEP: creating replication controller externalname-service in namespace services-5409 @ 04/13/24 12:29:41.7
  I0413 12:29:41.708540      21 runners.go:197] Created replication controller with name: externalname-service, namespace: services-5409, replica count: 2
  I0413 12:29:44.759450      21 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 12:29:44.759: INFO: Creating new exec pod
  Apr 13 12:29:47.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5409 exec execpod6kwqs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 13 12:29:47.878: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 13 12:29:47.878: INFO: stdout: "externalname-service-dsm5r"
  Apr 13 12:29:47.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5409 exec execpod6kwqs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Apr 13 12:29:47.961: INFO: stderr: "+ nc -v -t -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Apr 13 12:29:47.961: INFO: stdout: "externalname-service-dsm5r"
  Apr 13 12:29:47.961: INFO: Cleaning up the ExternalName to ClusterIP test service
  Apr 13 12:29:47.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5409" for this suite. @ 04/13/24 12:29:47.984
• [6.328 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 04/13/24 12:29:47.99
  Apr 13 12:29:47.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename chunking @ 04/13/24 12:29:47.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:29:48.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:29:48.006
  STEP: creating a large number of resources @ 04/13/24 12:29:48.009
  STEP: retrieving those results in paged fashion several times @ 04/13/24 12:30:05.696
  Apr 13 12:30:05.744: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  Apr 13 12:30:05.795: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  Apr 13 12:30:05.844: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  Apr 13 12:30:05.894: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  Apr 13 12:30:05.945: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  Apr 13 12:30:05.995: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  Apr 13 12:30:06.045: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  Apr 13 12:30:06.095: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  Apr 13 12:30:06.144: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  Apr 13 12:30:06.194: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  Apr 13 12:30:06.245: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  Apr 13 12:30:06.295: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  Apr 13 12:30:06.344: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  Apr 13 12:30:06.395: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  Apr 13 12:30:06.445: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  Apr 13 12:30:06.494: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  Apr 13 12:30:06.545: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  Apr 13 12:30:06.595: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  Apr 13 12:30:06.645: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  Apr 13 12:30:06.696: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  Apr 13 12:30:06.745: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  Apr 13 12:30:06.794: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  Apr 13 12:30:06.845: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  Apr 13 12:30:06.894: INFO: Retrieved 9/17 results with rv 7793 and continue 
  Apr 13 12:30:06.944: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  Apr 13 12:30:06.995: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  Apr 13 12:30:07.044: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  Apr 13 12:30:07.094: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  Apr 13 12:30:07.145: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  Apr 13 12:30:07.194: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  Apr 13 12:30:07.244: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  Apr 13 12:30:07.294: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  Apr 13 12:30:07.345: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  Apr 13 12:30:07.394: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  Apr 13 12:30:07.445: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  Apr 13 12:30:07.494: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  Apr 13 12:30:07.544: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  Apr 13 12:30:07.595: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  Apr 13 12:30:07.647: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  Apr 13 12:30:07.694: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  Apr 13 12:30:07.745: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  Apr 13 12:30:07.795: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  Apr 13 12:30:07.845: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  Apr 13 12:30:07.895: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  Apr 13 12:30:07.945: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  Apr 13 12:30:07.994: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  Apr 13 12:30:08.045: INFO: Retrieved 17/17 results with rv 7793 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  Apr 13 12:30:08.094: INFO: Retrieved 9/17 results with rv 7793 and continue 
  Apr 13 12:30:08.144: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  Apr 13 12:30:08.195: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  Apr 13 12:30:08.245: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  Apr 13 12:30:08.294: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  Apr 13 12:30:08.345: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  Apr 13 12:30:08.395: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  Apr 13 12:30:08.445: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  Apr 13 12:30:08.495: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  Apr 13 12:30:08.545: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  Apr 13 12:30:08.595: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  Apr 13 12:30:08.645: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  Apr 13 12:30:08.694: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  Apr 13 12:30:08.744: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  Apr 13 12:30:08.795: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  Apr 13 12:30:08.845: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  Apr 13 12:30:08.894: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  Apr 13 12:30:08.945: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  Apr 13 12:30:08.995: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  Apr 13 12:30:09.045: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  Apr 13 12:30:09.095: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  Apr 13 12:30:09.144: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  Apr 13 12:30:09.194: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  Apr 13 12:30:09.245: INFO: Retrieved 17/17 results with rv 7797 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Nzc5Nywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  Apr 13 12:30:09.294: INFO: Retrieved 9/17 results with rv 7797 and continue 
  STEP: retrieving those results all at once @ 04/13/24 12:30:09.294
  Apr 13 12:30:09.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-3730" for this suite. @ 04/13/24 12:30:09.395
• [21.457 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 04/13/24 12:30:09.448
  Apr 13 12:30:09.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 12:30:09.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:09.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:09.465
  Apr 13 12:30:09.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  W0413 12:30:12.005555      21 warnings.go:70] unknown field "alpha"
  W0413 12:30:12.005573      21 warnings.go:70] unknown field "beta"
  W0413 12:30:12.005575      21 warnings.go:70] unknown field "delta"
  W0413 12:30:12.005578      21 warnings.go:70] unknown field "epsilon"
  W0413 12:30:12.005581      21 warnings.go:70] unknown field "gamma"
  Apr 13 12:30:12.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7763" for this suite. @ 04/13/24 12:30:12.553
• [3.115 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 04/13/24 12:30:12.563
  Apr 13 12:30:12.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename discovery @ 04/13/24 12:30:12.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:12.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:12.581
  STEP: Setting up server cert @ 04/13/24 12:30:12.585
  STEP: Requesting APIResourceList from "/api/v1" @ 04/13/24 12:30:12.844
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 04/13/24 12:30:12.845
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 04/13/24 12:30:12.846
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 04/13/24 12:30:12.848
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 04/13/24 12:30:12.849
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 04/13/24 12:30:12.85
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 04/13/24 12:30:12.851
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 04/13/24 12:30:12.852
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 04/13/24 12:30:12.854
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 04/13/24 12:30:12.855
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 04/13/24 12:30:12.856
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 04/13/24 12:30:12.857
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 04/13/24 12:30:12.858
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 04/13/24 12:30:12.859
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 04/13/24 12:30:12.861
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 04/13/24 12:30:12.862
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 04/13/24 12:30:12.863
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 04/13/24 12:30:12.864
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 04/13/24 12:30:12.865
  Apr 13 12:30:12.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6957" for this suite. @ 04/13/24 12:30:12.87
• [0.315 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 04/13/24 12:30:12.878
  Apr 13 12:30:12.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename podtemplate @ 04/13/24 12:30:12.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:12.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:12.896
  STEP: Create a pod template @ 04/13/24 12:30:12.899
  STEP: Replace a pod template @ 04/13/24 12:30:12.906
  Apr 13 12:30:12.913: INFO: Found updated podtemplate annotation: "true"

  Apr 13 12:30:12.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4867" for this suite. @ 04/13/24 12:30:12.917
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 04/13/24 12:30:12.923
  Apr 13 12:30:12.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:30:12.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:12.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:12.939
  STEP: Starting the proxy @ 04/13/24 12:30:12.942
  Apr 13 12:30:12.943: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5305 proxy --unix-socket=/tmp/kubectl-proxy-unix2098743331/test'
  STEP: retrieving proxy /api/ output @ 04/13/24 12:30:12.972
  Apr 13 12:30:12.972: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5305" for this suite. @ 04/13/24 12:30:12.976
• [0.060 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 04/13/24 12:30:12.983
  Apr 13 12:30:12.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 12:30:12.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:12.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:12.998
  STEP: Creating configMap with name projected-configmap-test-volume-map-93521907-cb96-4cbc-acb8-0e97c3e2cf6b @ 04/13/24 12:30:13.001
  STEP: Creating a pod to test consume configMaps @ 04/13/24 12:30:13.005
  STEP: Saw pod success @ 04/13/24 12:30:17.027
  Apr 13 12:30:17.030: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-f57d34ec-d3c8-4d2c-ab36-addb9336bc04 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 12:30:17.036
  Apr 13 12:30:17.052: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8632" for this suite. @ 04/13/24 12:30:17.055
• [4.079 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 04/13/24 12:30:17.062
  Apr 13 12:30:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 12:30:17.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:17.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:17.077
  STEP: Creating namespace "e2e-ns-b5djq" @ 04/13/24 12:30:17.08
  Apr 13 12:30:17.093: INFO: Namespace "e2e-ns-b5djq-3772" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-b5djq-3772" @ 04/13/24 12:30:17.093
  Apr 13 12:30:17.101: INFO: Namespace "e2e-ns-b5djq-3772" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-b5djq-3772" @ 04/13/24 12:30:17.101
  Apr 13 12:30:17.110: INFO: Namespace "e2e-ns-b5djq-3772" has []v1.FinalizerName{"kubernetes"}
  Apr 13 12:30:17.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4927" for this suite. @ 04/13/24 12:30:17.113
  STEP: Destroying namespace "e2e-ns-b5djq-3772" for this suite. @ 04/13/24 12:30:17.119
• [0.063 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 04/13/24 12:30:17.125
  Apr 13 12:30:17.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:30:17.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:17.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:17.141
  STEP: create deployment with httpd image @ 04/13/24 12:30:17.144
  Apr 13 12:30:17.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1141 create -f -'
  Apr 13 12:30:17.212: INFO: stderr: ""
  Apr 13 12:30:17.212: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/13/24 12:30:17.212
  Apr 13 12:30:17.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1141 diff -f -'
  Apr 13 12:30:21.487: INFO: rc: 1
  Apr 13 12:30:21.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1141 delete -f -'
  Apr 13 12:30:21.535: INFO: stderr: ""
  Apr 13 12:30:21.535: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 13 12:30:21.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1141" for this suite. @ 04/13/24 12:30:21.539
• [4.420 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/13/24 12:30:21.546
  Apr 13 12:30:21.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 12:30:21.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:21.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:21.566
  Apr 13 12:30:21.569: INFO: Creating deployment "webserver-deployment"
  Apr 13 12:30:21.573: INFO: Waiting for observed generation 1
  Apr 13 12:30:23.584: INFO: Waiting for all required pods to come up
  Apr 13 12:30:23.587: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/13/24 12:30:23.587
  Apr 13 12:30:23.587: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 13 12:30:23.594: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Apr 13 12:30:23.604: INFO: Updating deployment webserver-deployment
  Apr 13 12:30:23.604: INFO: Waiting for observed generation 2
  Apr 13 12:30:25.613: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 13 12:30:25.616: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 13 12:30:25.619: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 13 12:30:25.628: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 13 12:30:25.628: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 13 12:30:25.631: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 13 12:30:25.637: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 13 12:30:25.637: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 13 12:30:25.645: INFO: Updating deployment webserver-deployment
  Apr 13 12:30:25.645: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 13 12:30:25.652: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 13 12:30:25.656: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 13 12:30:25.671: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "036bcfcf-431e-479d-87bc-124479467480",
      ResourceVersion: (string) (len=4) "8657",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 12:30:25.679: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
      ResourceVersion: (string) (len=4) "8660",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "036bcfcf-431e-479d-87bc-124479467480",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 33 36 62 63 66  63 66 2d 34 33 31 65 2d  |\"036bcfcf-431e-|
              00000120  34 37 39 64 2d 38 37 62  63 2d 31 32 34 34 37 39  |479d-87bc-124479|
              00000130  34 36 37 34 38 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |467480\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:30:25.679: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 13 12:30:25.679: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
      ResourceVersion: (string) (len=4) "8658",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "036bcfcf-431e-479d-87bc-124479467480",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 33 36 62 63 66  63 66 2d 34 33 31 65 2d  |\"036bcfcf-431e-|
              00000120  34 37 39 64 2d 38 37 62  63 2d 31 32 34 34 37 39  |479d-87bc-124479|
              00000130  34 36 37 34 38 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |467480\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:30:25.693: INFO: Pod "webserver-deployment-557759b7c7-6nqmx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6nqmx",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aae2bc3b-7cf0-4a20-941b-f8aa8f309cdf",
      ResourceVersion: (string) (len=4) "8524",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 35  34 2e 32 30 34 5c 22 7d  |2.168.254.204\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n54n5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n54n5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-65-227",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.65.227",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.65.227"
        }
      },
      PodIP: (string) (len=15) "192.168.254.204",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.254.204"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c523e2e2de44f59758975ad3ec97bd728c29f0134c49642bd9968b20bc7eb734",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.696: INFO: Pod "webserver-deployment-557759b7c7-7jfhv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7jfhv",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "52e2ee98-df10-4b44-8858-e59fd5b3be66",
      ResourceVersion: (string) (len=4) "8545",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 37  32 2e 32 32 30 5c 22 7d  |2.168.172.220\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-l8ltv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-l8ltv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.220",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.220"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://dff7b88c5c702e7d38a3af61c744ec657dcbdd8af858db615f910a088ae8657a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.697: INFO: Pod "webserver-deployment-557759b7c7-8bbld" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8bbld",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "57642b3f-495a-456f-8738-25fdc425a423",
      ResourceVersion: (string) (len=4) "8533",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 35 37  2e 32 30 32 5c 22 7d 22  |2.168.57.202\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s66bx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s66bx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.202",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.202"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0a9beb3d79a33f2ee5e0472d542cef7d6cb49d4f3550c11789dc35592a34dd9e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.699: INFO: Pod "webserver-deployment-557759b7c7-bc82d" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bc82d",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eb721bad-4beb-48b9-b61e-3b446168d275",
      ResourceVersion: (string) (len=4) "8521",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 35  34 2e 32 30 33 5c 22 7d  |2.168.254.203\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ntrg9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ntrg9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-65-227",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.65.227",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.65.227"
        }
      },
      PodIP: (string) (len=15) "192.168.254.203",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.254.203"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8980cc48585a87149a00b52c38f62208f0861b13dae7b0728d81d35ce4f2af0d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.700: INFO: Pod "webserver-deployment-557759b7c7-j2t4d" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-j2t4d",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a5be529f-edf7-4f5a-b6ba-dc4fd251bb01",
      ResourceVersion: (string) (len=4) "8542",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 37  32 2e 32 31 39 5c 22 7d  |2.168.172.219\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q6wmn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q6wmn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.219",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.219"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://844130c1a62f9d4f1e7633396c63975bcc5d352685c59d49693a69b3f8813729",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.701: INFO: Pod "webserver-deployment-557759b7c7-lkqlk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-lkqlk",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "35ad1608-cda7-4461-a2b9-2c4d1a04c349",
      ResourceVersion: (string) (len=4) "8663",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608225,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-npsgv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-npsgv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.705: INFO: Pod "webserver-deployment-557759b7c7-p7z97" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-p7z97",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d407c0eb-5baa-4add-872b-9295d306bb97",
      ResourceVersion: (string) (len=4) "8527",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 35 37  2e 32 30 34 5c 22 7d 22  |2.168.57.204\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r7xsp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r7xsp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.204",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.204"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b54566115d163086f03daadf48e1fe0dbe60fecaedb7ae1601fcd93bdd994558",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.706: INFO: Pod "webserver-deployment-557759b7c7-plh5s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-plh5s",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c39b9a66-ed05-43a1-8b44-954b8dd4d094",
      ResourceVersion: (string) (len=4) "8666",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608225,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s4lpd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s4lpd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.708: INFO: Pod "webserver-deployment-557759b7c7-qvlmj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-qvlmj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "20b214ae-9b52-46bf-b6e3-e07563b45aaa",
      ResourceVersion: (string) (len=4) "8539",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 37  32 2e 32 32 31 5c 22 7d  |2.168.172.221\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4zqr4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4zqr4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.221",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.221"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://23146017d776971d81a60f27b3978d305cc1771adc09c4b0967946dad8a24c2c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.710: INFO: Pod "webserver-deployment-557759b7c7-wbk9x" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-wbk9x",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "530b822b-0fbb-48be-ac78-c7b6d5ac603d",
      ResourceVersion: (string) (len=4) "8518",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 35  34 2e 32 30 32 5c 22 7d  |2.168.254.202\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bfw6g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bfw6g",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-65-227",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608222,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608221,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.65.227",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.65.227"
        }
      },
      PodIP: (string) (len=15) "192.168.254.202",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.254.202"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848608222,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://28f6dad9cb84ece80024df2854b6be85fa59b946a1a2cfce402569b2b4f9919e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.712: INFO: Pod "webserver-deployment-557759b7c7-wh9zs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-wh9zs",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c9e7564d-7e60-484d-8747-c3349e62e16b",
      ResourceVersion: (string) (len=4) "8671",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608225,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4be3120f-9ae9-4434-85b0-9df70da4cf68",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  65 33 31 32 30 66 2d 39  |d\":\"4be3120f-9|
              00000090  61 65 39 2d 34 34 33 34  2d 38 35 62 30 2d 39 64  |ae9-4434-85b0-9d|
              000000a0  66 37 30 64 61 34 63 66  36 38 5c 22 7d 22 3a 7b  |f70da4cf68\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p6xps",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p6xps",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.713: INFO: Pod "webserver-deployment-9b4f5bf69-4vmvn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-4vmvn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d4624090-98e8-4816-810d-bb0adf294be6",
      ResourceVersion: (string) (len=4) "8642",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 35 37 2e 32 30  37 5c 22 7d 22 3a 7b 22  |68.57.207\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qmpnv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qmpnv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.207",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.207"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.715: INFO: Pod "webserver-deployment-9b4f5bf69-65flj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-65flj",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "57bd89e5-7d63-4ce4-99c1-acecc06c11ed",
      ResourceVersion: (string) (len=4) "8645",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 35 37 2e 32 30  36 5c 22 7d 22 3a 7b 22  |68.57.206\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d2lxs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d2lxs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.206",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.206"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.718: INFO: Pod "webserver-deployment-9b4f5bf69-685z2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-685z2",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "327d29aa-01f7-44d3-893f-b0311197bcc2",
      ResourceVersion: (string) (len=4) "8651",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 37 32 2e 32  32 33 5c 22 7d 22 3a 7b  |68.172.223\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lj7vz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lj7vz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.223",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.223"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.719: INFO: Pod "webserver-deployment-9b4f5bf69-6lxr4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-6lxr4",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f17034fb-fc93-49cf-9948-4d2b7872c720",
      ResourceVersion: (string) (len=4) "8639",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 35 34 2e 32  30 35 5c 22 7d 22 3a 7b  |68.254.205\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w6frr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w6frr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-65-227",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608224,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.65.227",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.65.227"
        }
      },
      PodIP: (string) (len=15) "192.168.254.205",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.254.205"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.720: INFO: Pod "webserver-deployment-9b4f5bf69-8lzzz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-8lzzz",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d5d75c9-b778-499e-9348-33dc191e45d8",
      ResourceVersion: (string) (len=4) "8667",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608225,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xq7bq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xq7bq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.722: INFO: Pod "webserver-deployment-9b4f5bf69-8z9cb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-8z9cb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d09d7350-f552-4ee2-92d0-0b969aced0e0",
      ResourceVersion: (string) (len=4) "8670",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608225,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tc9pt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tc9pt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.723: INFO: Pod "webserver-deployment-9b4f5bf69-bzwm7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bzwm7",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1174",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ce3127b9-7dc3-4b92-965c-5e08864da1cf",
      ResourceVersion: (string) (len=4) "8654",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "263f38a0-c07a-4ec3-8435-3e0b108d8bd0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 36  33 66 33 38 61 30 2d 63  |d\":\"263f38a0-c|
              00000090  30 37 61 2d 34 65 63 33  2d 38 34 33 35 2d 33 65  |07a-4ec3-8435-3e|
              000000a0  30 62 31 30 38 64 38 62  64 30 5c 22 7d 22 3a 7b  |0b108d8bd0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 37 32 2e 32  32 32 5c 22 7d 22 3a 7b  |68.172.222\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vzqkx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vzqkx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608225,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848608223,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.222",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.222"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848608223,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:30:25.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1174" for this suite. @ 04/13/24 12:30:25.748
• [4.229 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 04/13/24 12:30:25.775
  Apr 13 12:30:25.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 12:30:25.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:25.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:25.799
  STEP: Creating ReplicationController "e2e-rc-2w6sx" @ 04/13/24 12:30:25.802
  Apr 13 12:30:25.807: INFO: Get Replication Controller "e2e-rc-2w6sx" to confirm replicas
  Apr 13 12:30:26.807: INFO: Get Replication Controller "e2e-rc-2w6sx" to confirm replicas
  Apr 13 12:30:26.811: INFO: Found 1 replicas for "e2e-rc-2w6sx" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-2w6sx" @ 04/13/24 12:30:26.811
  STEP: Updating a scale subresource @ 04/13/24 12:30:26.814
  STEP: Verifying replicas where modified for replication controller "e2e-rc-2w6sx" @ 04/13/24 12:30:26.82
  Apr 13 12:30:26.820: INFO: Get Replication Controller "e2e-rc-2w6sx" to confirm replicas
  Apr 13 12:30:27.820: INFO: Get Replication Controller "e2e-rc-2w6sx" to confirm replicas
  Apr 13 12:30:27.824: INFO: Found 2 replicas for "e2e-rc-2w6sx" replication controller
  Apr 13 12:30:27.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3084" for this suite. @ 04/13/24 12:30:27.828
• [2.059 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/13/24 12:30:27.834
  Apr 13 12:30:27.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption @ 04/13/24 12:30:27.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:27.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:27.853
  STEP: Waiting for the pdb to be processed @ 04/13/24 12:30:27.86
  STEP: Waiting for all pods to be running @ 04/13/24 12:30:29.891
  Apr 13 12:30:29.897: INFO: running pods: 0 < 3
  Apr 13 12:30:31.905: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1925" for this suite. @ 04/13/24 12:30:31.91
• [4.085 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 04/13/24 12:30:31.92
  Apr 13 12:30:31.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 12:30:31.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:31.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:31.946
  Apr 13 12:30:31.986: INFO: Create a RollingUpdate DaemonSet
  Apr 13 12:30:31.992: INFO: Check that daemon pods launch on every node of the cluster
  Apr 13 12:30:31.998: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:31.998: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:32.001: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 12:30:32.001: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:30:32.997: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:32.997: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:33.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 12:30:33.007: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  Apr 13 12:30:33.997: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:33.997: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:34.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 12:30:34.000: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Apr 13 12:30:34.000: INFO: Update the DaemonSet to trigger a rollout
  Apr 13 12:30:34.012: INFO: Updating DaemonSet daemon-set
  Apr 13 12:30:35.024: INFO: Roll back the DaemonSet before rollout is complete
  Apr 13 12:30:35.033: INFO: Updating DaemonSet daemon-set
  Apr 13 12:30:35.033: INFO: Make sure DaemonSet rollback is complete
  Apr 13 12:30:35.036: INFO: Wrong image for pod: daemon-set-gdsv7. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 13 12:30:35.036: INFO: Pod daemon-set-gdsv7 is not available
  Apr 13 12:30:35.040: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:35.040: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:36.042: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:36.042: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:37.037: INFO: Pod daemon-set-lp6vb is not available
  Apr 13 12:30:37.040: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:37.040: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 12:30:37.047
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2349, will wait for the garbage collector to delete the pods @ 04/13/24 12:30:37.047
  Apr 13 12:30:37.109: INFO: Deleting DaemonSet.extensions daemon-set took: 8.597246ms
  Apr 13 12:30:37.210: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.081211ms
  Apr 13 12:30:38.315: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 12:30:38.315: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 12:30:38.319: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9388"},"items":null}

  Apr 13 12:30:38.321: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9388"},"items":null}

  Apr 13 12:30:38.334: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2349" for this suite. @ 04/13/24 12:30:38.338
• [6.424 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 04/13/24 12:30:38.344
  Apr 13 12:30:38.344: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename controllerrevisions @ 04/13/24 12:30:38.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:38.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:38.36
  STEP: Creating DaemonSet "e2e-f7xj4-daemon-set" @ 04/13/24 12:30:38.382
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 12:30:38.387
  Apr 13 12:30:38.393: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:38.393: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:38.396: INFO: Number of nodes with available pods controlled by daemonset e2e-f7xj4-daemon-set: 0
  Apr 13 12:30:38.396: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  Apr 13 12:30:39.393: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:39.393: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:39.396: INFO: Number of nodes with available pods controlled by daemonset e2e-f7xj4-daemon-set: 2
  Apr 13 12:30:39.396: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  Apr 13 12:30:40.392: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:40.392: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 12:30:40.396: INFO: Number of nodes with available pods controlled by daemonset e2e-f7xj4-daemon-set: 3
  Apr 13 12:30:40.396: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-f7xj4-daemon-set
  STEP: Confirm DaemonSet "e2e-f7xj4-daemon-set" successfully created with "daemonset-name=e2e-f7xj4-daemon-set" label @ 04/13/24 12:30:40.4
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-f7xj4-daemon-set" @ 04/13/24 12:30:40.407
  Apr 13 12:30:40.410: INFO: Located ControllerRevision: "e2e-f7xj4-daemon-set-dc46d46b8"
  STEP: Patching ControllerRevision "e2e-f7xj4-daemon-set-dc46d46b8" @ 04/13/24 12:30:40.414
  Apr 13 12:30:40.420: INFO: e2e-f7xj4-daemon-set-dc46d46b8 has been patched
  STEP: Create a new ControllerRevision @ 04/13/24 12:30:40.42
  Apr 13 12:30:40.426: INFO: Created ControllerRevision: e2e-f7xj4-daemon-set-76966d9946
  STEP: Confirm that there are two ControllerRevisions @ 04/13/24 12:30:40.426
  Apr 13 12:30:40.426: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 13 12:30:40.431: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-f7xj4-daemon-set-dc46d46b8" @ 04/13/24 12:30:40.431
  STEP: Confirm that there is only one ControllerRevision @ 04/13/24 12:30:40.436
  Apr 13 12:30:40.436: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 13 12:30:40.440: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-f7xj4-daemon-set-76966d9946" @ 04/13/24 12:30:40.443
  Apr 13 12:30:40.453: INFO: e2e-f7xj4-daemon-set-76966d9946 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/13/24 12:30:40.453
  W0413 12:30:40.460145      21 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/13/24 12:30:40.46
  Apr 13 12:30:40.460: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 13 12:30:41.460: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 13 12:30:41.465: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-f7xj4-daemon-set-76966d9946=updated" @ 04/13/24 12:30:41.465
  STEP: Confirm that there is only one ControllerRevision @ 04/13/24 12:30:41.473
  Apr 13 12:30:41.473: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 13 12:30:41.477: INFO: Found 1 ControllerRevisions
  Apr 13 12:30:41.479: INFO: ControllerRevision "e2e-f7xj4-daemon-set-779c8764f9" has revision 3
  STEP: Deleting DaemonSet "e2e-f7xj4-daemon-set" @ 04/13/24 12:30:41.482
  STEP: deleting DaemonSet.extensions e2e-f7xj4-daemon-set in namespace controllerrevisions-7155, will wait for the garbage collector to delete the pods @ 04/13/24 12:30:41.482
  Apr 13 12:30:41.543: INFO: Deleting DaemonSet.extensions e2e-f7xj4-daemon-set took: 6.019158ms
  Apr 13 12:30:41.643: INFO: Terminating DaemonSet.extensions e2e-f7xj4-daemon-set pods took: 100.346437ms
  Apr 13 12:30:43.047: INFO: Number of nodes with available pods controlled by daemonset e2e-f7xj4-daemon-set: 0
  Apr 13 12:30:43.047: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-f7xj4-daemon-set
  Apr 13 12:30:43.051: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9511"},"items":null}

  Apr 13 12:30:43.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9511"},"items":null}

  Apr 13 12:30:43.065: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-7155" for this suite. @ 04/13/24 12:30:43.069
• [4.730 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/13/24 12:30:43.074
  Apr 13 12:30:43.074: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename proxy @ 04/13/24 12:30:43.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:43.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:43.092
  Apr 13 12:30:43.095: INFO: Creating pod...
  Apr 13 12:30:45.112: INFO: Creating service...
  Apr 13 12:30:45.128: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/DELETE
  Apr 13 12:30:45.133: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 13 12:30:45.133: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/GET
  Apr 13 12:30:45.136: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 13 12:30:45.136: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/HEAD
  Apr 13 12:30:45.139: INFO: http.Client request:HEAD | StatusCode:200
  Apr 13 12:30:45.139: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 13 12:30:45.143: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 13 12:30:45.143: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/PATCH
  Apr 13 12:30:45.146: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 13 12:30:45.146: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/POST
  Apr 13 12:30:45.151: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 13 12:30:45.151: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/pods/agnhost/proxy/some/path/with/PUT
  Apr 13 12:30:45.154: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 13 12:30:45.154: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/DELETE
  Apr 13 12:30:45.159: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 13 12:30:45.159: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/GET
  Apr 13 12:30:45.164: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 13 12:30:45.164: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/HEAD
  Apr 13 12:30:45.168: INFO: http.Client request:HEAD | StatusCode:200
  Apr 13 12:30:45.169: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/OPTIONS
  Apr 13 12:30:45.173: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 13 12:30:45.173: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/PATCH
  Apr 13 12:30:45.177: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 13 12:30:45.177: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/POST
  Apr 13 12:30:45.182: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 13 12:30:45.182: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1407/services/test-service/proxy/some/path/with/PUT
  Apr 13 12:30:45.185: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 13 12:30:45.186: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1407" for this suite. @ 04/13/24 12:30:45.189
• [2.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 04/13/24 12:30:45.195
  Apr 13 12:30:45.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:30:45.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:30:45.208
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:30:45.213
  STEP: Discovering how many secrets are in namespace by default @ 04/13/24 12:30:45.216
  STEP: Counting existing ResourceQuota @ 04/13/24 12:30:50.22
  STEP: Creating a ResourceQuota @ 04/13/24 12:30:55.224
  STEP: Ensuring resource quota status is calculated @ 04/13/24 12:30:55.232
  STEP: Creating a Secret @ 04/13/24 12:30:57.237
  STEP: Ensuring resource quota status captures secret creation @ 04/13/24 12:30:57.249
  STEP: Deleting a secret @ 04/13/24 12:30:59.254
  STEP: Ensuring resource quota status released usage @ 04/13/24 12:30:59.261
  Apr 13 12:31:01.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6529" for this suite. @ 04/13/24 12:31:01.27
• [16.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 04/13/24 12:31:01.277
  Apr 13 12:31:01.277: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 12:31:01.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:01.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:01.295
  STEP: create the deployment @ 04/13/24 12:31:01.299
  W0413 12:31:01.303791      21 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/13/24 12:31:01.303
  STEP: delete the deployment @ 04/13/24 12:31:01.816
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/13/24 12:31:01.823
  STEP: Gathering metrics @ 04/13/24 12:31:02.341
  W0413 12:31:02.346935      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 12:31:02.346: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 12:31:02.347: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7060" for this suite. @ 04/13/24 12:31:02.35
• [1.079 seconds]
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/13/24 12:31:02.356
  Apr 13 12:31:02.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 12:31:02.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:02.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:02.373
  STEP: Create a pod @ 04/13/24 12:31:02.378
  STEP: patching /status @ 04/13/24 12:31:04.395
  Apr 13 12:31:04.402: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 13 12:31:04.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-711" for this suite. @ 04/13/24 12:31:04.406
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 04/13/24 12:31:04.417
  Apr 13 12:31:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:31:04.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:04.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:04.431
  STEP: Creating configMap with name configmap-test-volume-0fd91f9c-063f-41ad-8361-7977d26044f8 @ 04/13/24 12:31:04.434
  STEP: Creating a pod to test consume configMaps @ 04/13/24 12:31:04.439
  STEP: Saw pod success @ 04/13/24 12:31:08.458
  Apr 13 12:31:08.461: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-configmaps-a76360ca-98f5-4cc4-ac2d-20096d86e9a4 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 12:31:08.477
  Apr 13 12:31:08.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1378" for this suite. @ 04/13/24 12:31:08.5
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/13/24 12:31:08.508
  Apr 13 12:31:08.508: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 12:31:08.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:08.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:08.522
  Apr 13 12:31:08.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3783" for this suite. @ 04/13/24 12:31:08.533
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 04/13/24 12:31:08.54
  Apr 13 12:31:08.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/13/24 12:31:08.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:08.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:08.558
  STEP: getting /apis @ 04/13/24 12:31:08.56
  STEP: getting /apis/storage.k8s.io @ 04/13/24 12:31:08.564
  STEP: getting /apis/storage.k8s.io/v1 @ 04/13/24 12:31:08.565
  STEP: creating @ 04/13/24 12:31:08.566
  STEP: watching @ 04/13/24 12:31:08.585
  Apr 13 12:31:08.585: INFO: starting watch
  STEP: getting @ 04/13/24 12:31:08.592
  STEP: listing in namespace @ 04/13/24 12:31:08.595
  STEP: listing across namespaces @ 04/13/24 12:31:08.598
  STEP: patching @ 04/13/24 12:31:08.601
  STEP: updating @ 04/13/24 12:31:08.606
  Apr 13 12:31:08.611: INFO: waiting for watch events with expected annotations in namespace
  Apr 13 12:31:08.611: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/13/24 12:31:08.611
  STEP: deleting a collection @ 04/13/24 12:31:08.623
  Apr 13 12:31:08.637: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-4836" for this suite. @ 04/13/24 12:31:08.641
• [0.107 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 04/13/24 12:31:08.647
  Apr 13 12:31:08.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:31:08.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:08.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:08.663
  STEP: Counting existing ResourceQuota @ 04/13/24 12:31:08.666
  STEP: Creating a ResourceQuota @ 04/13/24 12:31:13.67
  STEP: Ensuring resource quota status is calculated @ 04/13/24 12:31:13.677
  Apr 13 12:31:15.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5971" for this suite. @ 04/13/24 12:31:15.685
• [7.044 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 04/13/24 12:31:15.691
  Apr 13 12:31:15.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:31:15.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:15.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:15.708
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 12:31:15.711
  STEP: Saw pod success @ 04/13/24 12:31:19.735
  Apr 13 12:31:19.738: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-6279eea3-ced3-4798-8220-e8e68920af00 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 12:31:19.744
  Apr 13 12:31:19.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8256" for this suite. @ 04/13/24 12:31:19.765
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 04/13/24 12:31:19.771
  Apr 13 12:31:19.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/13/24 12:31:19.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:19.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:19.788
  STEP: fetching the /apis discovery document @ 04/13/24 12:31:19.791
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/13/24 12:31:19.793
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/13/24 12:31:19.793
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/13/24 12:31:19.793
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/13/24 12:31:19.794
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/13/24 12:31:19.794
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/13/24 12:31:19.795
  Apr 13 12:31:19.795: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5971" for this suite. @ 04/13/24 12:31:19.799
• [0.036 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 04/13/24 12:31:19.807
  Apr 13 12:31:19.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 12:31:19.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:19.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:19.823
  STEP: create the rc1 @ 04/13/24 12:31:19.829
  STEP: create the rc2 @ 04/13/24 12:31:19.834
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/13/24 12:31:25.848
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/13/24 12:31:26.293
  STEP: wait for the rc to be deleted @ 04/13/24 12:31:26.299
  Apr 13 12:31:31.312: INFO: 70 pods remaining
  Apr 13 12:31:31.312: INFO: 70 pods has nil DeletionTimestamp
  Apr 13 12:31:31.312: INFO: 
  STEP: Gathering metrics @ 04/13/24 12:31:36.313
  W0413 12:31:36.321138      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 12:31:36.321: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 12:31:36.323: INFO: Deleting pod "simpletest-rc-to-be-deleted-22hgc" in namespace "gc-4905"
  Apr 13 12:31:36.338: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bkrr" in namespace "gc-4905"
  Apr 13 12:31:36.353: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bss5" in namespace "gc-4905"
  Apr 13 12:31:36.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bxkq" in namespace "gc-4905"
  Apr 13 12:31:36.389: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hlpb" in namespace "gc-4905"
  Apr 13 12:31:36.404: INFO: Deleting pod "simpletest-rc-to-be-deleted-45hnq" in namespace "gc-4905"
  Apr 13 12:31:36.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-4djw2" in namespace "gc-4905"
  Apr 13 12:31:36.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fz8b" in namespace "gc-4905"
  Apr 13 12:31:36.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k92v" in namespace "gc-4905"
  Apr 13 12:31:36.462: INFO: Deleting pod "simpletest-rc-to-be-deleted-562g8" in namespace "gc-4905"
  Apr 13 12:31:36.473: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tpk4" in namespace "gc-4905"
  Apr 13 12:31:36.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zctj" in namespace "gc-4905"
  Apr 13 12:31:36.502: INFO: Deleting pod "simpletest-rc-to-be-deleted-62bts" in namespace "gc-4905"
  Apr 13 12:31:36.516: INFO: Deleting pod "simpletest-rc-to-be-deleted-64tbb" in namespace "gc-4905"
  Apr 13 12:31:36.526: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hr75" in namespace "gc-4905"
  Apr 13 12:31:36.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cg8x" in namespace "gc-4905"
  Apr 13 12:31:36.551: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ksnc" in namespace "gc-4905"
  Apr 13 12:31:36.565: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zqv2" in namespace "gc-4905"
  Apr 13 12:31:36.578: INFO: Deleting pod "simpletest-rc-to-be-deleted-8k5fx" in namespace "gc-4905"
  Apr 13 12:31:36.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-9bzdv" in namespace "gc-4905"
  Apr 13 12:31:36.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-9g94f" in namespace "gc-4905"
  Apr 13 12:31:36.616: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mzrd" in namespace "gc-4905"
  Apr 13 12:31:36.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-9w4cf" in namespace "gc-4905"
  Apr 13 12:31:36.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-bggwp" in namespace "gc-4905"
  Apr 13 12:31:36.671: INFO: Deleting pod "simpletest-rc-to-be-deleted-br9x9" in namespace "gc-4905"
  Apr 13 12:31:36.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-bzqsj" in namespace "gc-4905"
  Apr 13 12:31:36.699: INFO: Deleting pod "simpletest-rc-to-be-deleted-c898x" in namespace "gc-4905"
  Apr 13 12:31:36.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-cprxj" in namespace "gc-4905"
  Apr 13 12:31:36.727: INFO: Deleting pod "simpletest-rc-to-be-deleted-db6zf" in namespace "gc-4905"
  Apr 13 12:31:36.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-dcsm7" in namespace "gc-4905"
  Apr 13 12:31:36.769: INFO: Deleting pod "simpletest-rc-to-be-deleted-df2wc" in namespace "gc-4905"
  Apr 13 12:31:36.780: INFO: Deleting pod "simpletest-rc-to-be-deleted-dg7ts" in namespace "gc-4905"
  Apr 13 12:31:36.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-dn5rw" in namespace "gc-4905"
  Apr 13 12:31:36.811: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsdg4" in namespace "gc-4905"
  Apr 13 12:31:36.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-f94ns" in namespace "gc-4905"
  Apr 13 12:31:36.847: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffwfp" in namespace "gc-4905"
  Apr 13 12:31:36.864: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhbtj" in namespace "gc-4905"
  Apr 13 12:31:36.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-fwkhz" in namespace "gc-4905"
  Apr 13 12:31:36.888: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzrb6" in namespace "gc-4905"
  Apr 13 12:31:36.902: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8pgm" in namespace "gc-4905"
  Apr 13 12:31:36.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqqhd" in namespace "gc-4905"
  Apr 13 12:31:36.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-hb5t7" in namespace "gc-4905"
  Apr 13 12:31:36.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-hr6bh" in namespace "gc-4905"
  Apr 13 12:31:36.961: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsws2" in namespace "gc-4905"
  Apr 13 12:31:36.975: INFO: Deleting pod "simpletest-rc-to-be-deleted-j9jmh" in namespace "gc-4905"
  Apr 13 12:31:37.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-jlpkn" in namespace "gc-4905"
  Apr 13 12:31:37.013: INFO: Deleting pod "simpletest-rc-to-be-deleted-jp55l" in namespace "gc-4905"
  Apr 13 12:31:37.028: INFO: Deleting pod "simpletest-rc-to-be-deleted-jxmqx" in namespace "gc-4905"
  Apr 13 12:31:37.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-k6699" in namespace "gc-4905"
  Apr 13 12:31:37.057: INFO: Deleting pod "simpletest-rc-to-be-deleted-km9tp" in namespace "gc-4905"
  Apr 13 12:31:37.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4905" for this suite. @ 04/13/24 12:31:37.077
• [17.282 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/13/24 12:31:37.09
  Apr 13 12:31:37.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename prestop @ 04/13/24 12:31:37.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:37.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:37.111
  STEP: Creating server pod server in namespace prestop-8230 @ 04/13/24 12:31:37.114
  STEP: Waiting for pods to come up. @ 04/13/24 12:31:37.122
  STEP: Creating tester pod tester in namespace prestop-8230 @ 04/13/24 12:31:39.136
  STEP: Deleting pre-stop pod @ 04/13/24 12:31:41.155
  Apr 13 12:31:46.167: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 04/13/24 12:31:46.168
  Apr 13 12:31:46.178: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-8230" for this suite. @ 04/13/24 12:31:46.181
• [9.100 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 04/13/24 12:31:46.19
  Apr 13 12:31:46.190: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:31:46.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:46.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:46.209
  STEP: Creating configMap with name configmap-test-upd-e5f85dbc-d631-4b39-bbe8-717a3273f622 @ 04/13/24 12:31:46.215
  STEP: Creating the pod @ 04/13/24 12:31:46.22
  STEP: Waiting for pod with text data @ 04/13/24 12:31:48.237
  STEP: Waiting for pod with binary data @ 04/13/24 12:31:48.243
  Apr 13 12:31:48.249: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6" for this suite. @ 04/13/24 12:31:48.253
• [2.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 04/13/24 12:31:48.26
  Apr 13 12:31:48.260: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:31:48.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:48.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:48.278
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/13/24 12:31:48.281
  STEP: Saw pod success @ 04/13/24 12:31:52.301
  Apr 13 12:31:52.304: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-44cfb6a2-77b2-4008-90f6-77194ffc18c2 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 12:31:52.31
  Apr 13 12:31:52.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-299" for this suite. @ 04/13/24 12:31:52.33
• [4.078 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/13/24 12:31:52.338
  Apr 13 12:31:52.338: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 12:31:52.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:52.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:52.354
  STEP: Creating secret with name secret-test-map-344ade9c-903b-449f-83cb-943f99926096 @ 04/13/24 12:31:52.357
  STEP: Creating a pod to test consume secrets @ 04/13/24 12:31:52.362
  STEP: Saw pod success @ 04/13/24 12:31:54.38
  Apr 13 12:31:54.383: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-26afab6b-1c6d-4548-9601-6e657491ea1a container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 12:31:54.389
  Apr 13 12:31:54.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8166" for this suite. @ 04/13/24 12:31:54.41
• [2.077 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/13/24 12:31:54.415
  Apr 13 12:31:54.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 12:31:54.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:54.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:54.433
  Apr 13 12:31:56.453: INFO: Deleting pod "var-expansion-22455813-1c79-4b50-8a72-439ba495141c" in namespace "var-expansion-133"
  Apr 13 12:31:56.461: INFO: Wait up to 5m0s for pod "var-expansion-22455813-1c79-4b50-8a72-439ba495141c" to be fully deleted
  Apr 13 12:31:58.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-133" for this suite. @ 04/13/24 12:31:58.473
• [4.066 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 04/13/24 12:31:58.482
  Apr 13 12:31:58.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 12:31:58.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:58.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:58.5
  STEP: Read namespace status @ 04/13/24 12:31:58.503
  Apr 13 12:31:58.506: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/13/24 12:31:58.506
  Apr 13 12:31:58.511: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/13/24 12:31:58.511
  Apr 13 12:31:58.518: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 13 12:31:58.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8863" for this suite. @ 04/13/24 12:31:58.522
• [0.048 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/13/24 12:31:58.53
  Apr 13 12:31:58.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 12:31:58.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:31:58.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:31:58.546
  STEP: creating the pod @ 04/13/24 12:31:58.549
  STEP: submitting the pod to kubernetes @ 04/13/24 12:31:58.549
  W0413 12:31:58.557836      21 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: verifying the pod is in kubernetes @ 04/13/24 12:32:00.571
  STEP: updating the pod @ 04/13/24 12:32:00.574
  Apr 13 12:32:01.088: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7938b814-c61c-479a-975c-31fec7e4f162"
  Apr 13 12:32:05.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8580" for this suite. @ 04/13/24 12:32:05.104
• [6.581 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/13/24 12:32:05.111
  Apr 13 12:32:05.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/13/24 12:32:05.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:32:05.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:32:05.137
  STEP: Setting up the test @ 04/13/24 12:32:05.14
  STEP: Creating hostNetwork=false pod @ 04/13/24 12:32:05.14
  STEP: Creating hostNetwork=true pod @ 04/13/24 12:32:07.161
  STEP: Running the test @ 04/13/24 12:32:09.182
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/13/24 12:32:09.182
  Apr 13 12:32:09.182: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.182: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.182: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 13 12:32:09.234: INFO: Exec stderr: ""
  Apr 13 12:32:09.234: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.234: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.234: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 13 12:32:09.282: INFO: Exec stderr: ""
  Apr 13 12:32:09.282: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.282: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.282: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 13 12:32:09.326: INFO: Exec stderr: ""
  Apr 13 12:32:09.326: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.326: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.326: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 13 12:32:09.374: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/13/24 12:32:09.374
  Apr 13 12:32:09.374: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.374: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.374: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 13 12:32:09.413: INFO: Exec stderr: ""
  Apr 13 12:32:09.413: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.413: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.414: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.414: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 13 12:32:09.458: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/13/24 12:32:09.458
  Apr 13 12:32:09.458: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.458: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.458: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 13 12:32:09.510: INFO: Exec stderr: ""
  Apr 13 12:32:09.510: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.511: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.511: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 13 12:32:09.562: INFO: Exec stderr: ""
  Apr 13 12:32:09.562: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.563: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.563: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 13 12:32:09.602: INFO: Exec stderr: ""
  Apr 13 12:32:09.602: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2860 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:32:09.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:32:09.602: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:32:09.602: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2860/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 13 12:32:09.646: INFO: Exec stderr: ""
  Apr 13 12:32:09.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-2860" for this suite. @ 04/13/24 12:32:09.65
• [4.545 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 04/13/24 12:32:09.657
  Apr 13 12:32:09.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 12:32:09.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:32:09.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:32:09.673
  STEP: Setting up server cert @ 04/13/24 12:32:09.698
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 12:32:09.864
  STEP: Deploying the webhook pod @ 04/13/24 12:32:09.873
  STEP: Wait for the deployment to be ready @ 04/13/24 12:32:09.886
  Apr 13 12:32:09.895: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/13/24 12:32:11.915
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 12:32:11.928
  Apr 13 12:32:12.928: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/13/24 12:32:12.935
  STEP: create a configmap that should be updated by the webhook @ 04/13/24 12:32:12.949
  Apr 13 12:32:13.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6630" for this suite. @ 04/13/24 12:32:13.014
  STEP: Destroying namespace "webhook-markers-1103" for this suite. @ 04/13/24 12:32:13.019
• [3.369 seconds]
------------------------------
SSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/13/24 12:32:13.027
  Apr 13 12:32:13.027: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename cronjob @ 04/13/24 12:32:13.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:32:13.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:32:13.045
  STEP: Creating a ForbidConcurrent cronjob @ 04/13/24 12:32:13.048
  STEP: Ensuring a job is scheduled @ 04/13/24 12:32:13.054
  STEP: Ensuring exactly one is scheduled @ 04/13/24 12:33:01.061
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/13/24 12:33:01.065
  STEP: Ensuring no more jobs are scheduled @ 04/13/24 12:33:01.068
  STEP: Removing cronjob @ 04/13/24 12:38:01.079
  Apr 13 12:38:01.087: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8648" for this suite. @ 04/13/24 12:38:01.093
• [348.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/13/24 12:38:01.111
  Apr 13 12:38:01.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:38:01.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:38:01.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:38:01.135
  STEP: Creating pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886 @ 04/13/24 12:38:01.139
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 12:38:03.159
  Apr 13 12:38:03.162: INFO: Initial restart count of pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a is 0
  Apr 13 12:38:03.165: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:05.169: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:07.174: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:09.179: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:11.184: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:13.188: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:15.193: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:17.198: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:19.202: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:21.207: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:23.212: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:25.216: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:27.221: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:29.226: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:31.232: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:33.236: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:35.241: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:37.246: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:39.250: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:41.256: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:43.261: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:45.266: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:47.271: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:49.275: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:51.280: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:53.285: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:55.289: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:57.294: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:38:59.298: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:01.303: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:03.307: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:05.311: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:07.317: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:09.321: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:11.327: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:13.332: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:15.336: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:17.341: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:19.348: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:21.353: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:23.358: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:25.363: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:27.368: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:29.373: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:31.378: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:33.383: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:35.388: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:37.395: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:39.399: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:41.405: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:43.409: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:45.414: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:47.419: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:49.424: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:51.430: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:53.434: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:55.439: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:57.444: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:39:59.448: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:01.453: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:03.458: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:05.463: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:07.468: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:09.474: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:11.479: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:13.483: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:15.489: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:17.494: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:19.499: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:21.503: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:23.509: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:25.513: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:27.518: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:29.522: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:31.527: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:33.532: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:35.537: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:37.542: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:39.547: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:41.552: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:43.558: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:45.562: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:47.568: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:49.573: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:51.578: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:53.583: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:55.589: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:57.594: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:40:59.599: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:01.604: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:03.609: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:05.612: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:07.617: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:09.622: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:11.628: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:13.632: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:15.636: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:17.641: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:19.646: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:21.651: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:23.657: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:25.661: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:27.666: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:29.671: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:31.675: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:33.680: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:35.684: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:37.690: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:39.695: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:41.700: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:43.704: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:45.709: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:47.714: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:49.718: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:51.723: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:53.728: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:55.732: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:57.738: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:41:59.744: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  Apr 13 12:42:01.748: INFO: Get pod liveness-dbfdf8ad-d434-4dc1-8ebf-6cd27c97780a in namespace container-probe-5886
  STEP: deleting the pod @ 04/13/24 12:42:03.749
  Apr 13 12:42:03.764: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5886" for this suite. @ 04/13/24 12:42:03.768
• [242.664 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 04/13/24 12:42:03.776
  Apr 13 12:42:03.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 12:42:03.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:03.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:03.8
  Apr 13 12:42:03.830: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"05ef74fd-bfdd-408a-b472-c6b04a1b86d9", Controller:(*bool)(0xc0020f94a6), BlockOwnerDeletion:(*bool)(0xc0020f94a7)}}
  Apr 13 12:42:03.836: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"10be060e-7c16-48b1-abc2-e18948765805", Controller:(*bool)(0xc0020f96de), BlockOwnerDeletion:(*bool)(0xc0020f96df)}}
  Apr 13 12:42:03.843: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3df817b3-cfaa-4af9-b399-56c6fca17cfe", Controller:(*bool)(0xc0020ff16a), BlockOwnerDeletion:(*bool)(0xc0020ff16b)}}
  Apr 13 12:42:08.855: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1851" for this suite. @ 04/13/24 12:42:08.858
• [5.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 04/13/24 12:42:08.866
  Apr 13 12:42:08.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubelet-test @ 04/13/24 12:42:08.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:08.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:08.883
  Apr 13 12:42:10.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-197" for this suite. @ 04/13/24 12:42:10.929
• [2.070 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 04/13/24 12:42:10.936
  Apr 13 12:42:10.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:42:10.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:10.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:10.953
  STEP: Creating configMap with name configmap-test-volume-map-64099945-5c81-45d0-8cac-bb204c613659 @ 04/13/24 12:42:10.956
  STEP: Creating a pod to test consume configMaps @ 04/13/24 12:42:10.961
  STEP: Saw pod success @ 04/13/24 12:42:14.982
  Apr 13 12:42:14.985: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-configmaps-00618fc2-afd3-4b4e-8a66-eef51b67ae66 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 12:42:15.003
  Apr 13 12:42:15.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4118" for this suite. @ 04/13/24 12:42:15.023
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 04/13/24 12:42:15.029
  Apr 13 12:42:15.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:42:15.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:15.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:15.049
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/13/24 12:42:15.052
  STEP: Saw pod success @ 04/13/24 12:42:19.073
  Apr 13 12:42:19.077: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-b60483f0-2291-4521-ae2d-2d56870fd43c container test-container: <nil>
  STEP: delete the pod @ 04/13/24 12:42:19.083
  Apr 13 12:42:19.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1733" for this suite. @ 04/13/24 12:42:19.1
• [4.078 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 04/13/24 12:42:19.107
  Apr 13 12:42:19.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:42:19.108
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:19.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:19.122
  STEP: Creating a pod to test downward api env vars @ 04/13/24 12:42:19.127
  STEP: Saw pod success @ 04/13/24 12:42:21.143
  Apr 13 12:42:21.146: INFO: Trying to get logs from node ip-172-31-35-229 pod downward-api-9bb26b71-6b51-449b-a63c-757717010dac container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 12:42:21.153
  Apr 13 12:42:21.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6428" for this suite. @ 04/13/24 12:42:21.176
• [2.075 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 04/13/24 12:42:21.182
  Apr 13 12:42:21.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename server-version @ 04/13/24 12:42:21.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:21.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:21.199
  STEP: Request ServerVersion @ 04/13/24 12:42:21.202
  STEP: Confirm major version @ 04/13/24 12:42:21.203
  Apr 13 12:42:21.203: INFO: Major version: 1
  STEP: Confirm minor version @ 04/13/24 12:42:21.203
  Apr 13 12:42:21.203: INFO: cleanMinorVersion: 29
  Apr 13 12:42:21.203: INFO: Minor version: 29
  Apr 13 12:42:21.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2609" for this suite. @ 04/13/24 12:42:21.207
• [0.030 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 04/13/24 12:42:21.212
  Apr 13 12:42:21.212: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:42:21.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:42:21.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:42:21.231
  STEP: Creating configMap with name configmap-test-upd-6379d341-9040-41ed-aeb9-6603c0a19339 @ 04/13/24 12:42:21.238
  STEP: Creating the pod @ 04/13/24 12:42:21.243
  STEP: Updating configmap configmap-test-upd-6379d341-9040-41ed-aeb9-6603c0a19339 @ 04/13/24 12:42:23.272
  STEP: waiting to observe update in volume @ 04/13/24 12:42:23.277
  Apr 13 12:43:49.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4690" for this suite. @ 04/13/24 12:43:49.654
• [88.447 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 04/13/24 12:43:49.66
  Apr 13 12:43:49.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pod-network-test @ 04/13/24 12:43:49.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:43:49.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:43:49.676
  STEP: Performing setup for networking test in namespace pod-network-test-6456 @ 04/13/24 12:43:49.681
  STEP: creating a selector @ 04/13/24 12:43:49.681
  STEP: Creating the service pods in kubernetes @ 04/13/24 12:43:49.681
  Apr 13 12:43:49.681: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/13/24 12:44:01.766
  Apr 13 12:44:03.786: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 13 12:44:03.786: INFO: Breadth first check of 192.168.57.254 on host 172.31.35.229...
  Apr 13 12:44:03.790: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.218:9080/dial?request=hostname&protocol=udp&host=192.168.57.254&port=8081&tries=1'] Namespace:pod-network-test-6456 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:44:03.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:44:03.790: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:44:03.790: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6456/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.57.254%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 12:44:03.846: INFO: Waiting for responses: map[]
  Apr 13 12:44:03.846: INFO: reached 192.168.57.254 after 0/1 tries
  Apr 13 12:44:03.846: INFO: Breadth first check of 192.168.254.241 on host 172.31.65.227...
  Apr 13 12:44:03.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.218:9080/dial?request=hostname&protocol=udp&host=192.168.254.241&port=8081&tries=1'] Namespace:pod-network-test-6456 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:44:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:44:03.850: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:44:03.850: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6456/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.254.241%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 12:44:03.901: INFO: Waiting for responses: map[]
  Apr 13 12:44:03.901: INFO: reached 192.168.254.241 after 0/1 tries
  Apr 13 12:44:03.901: INFO: Breadth first check of 192.168.172.217 on host 172.31.82.63...
  Apr 13 12:44:03.904: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.218:9080/dial?request=hostname&protocol=udp&host=192.168.172.217&port=8081&tries=1'] Namespace:pod-network-test-6456 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:44:03.904: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:44:03.905: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:44:03.905: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6456/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.172.217%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 12:44:03.948: INFO: Waiting for responses: map[]
  Apr 13 12:44:03.948: INFO: reached 192.168.172.217 after 0/1 tries
  Apr 13 12:44:03.948: INFO: Going to retry 0 out of 3 pods....
  Apr 13 12:44:03.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6456" for this suite. @ 04/13/24 12:44:03.952
• [14.298 seconds]
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/13/24 12:44:03.958
  Apr 13 12:44:03.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 12:44:03.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:44:03.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:44:03.975
  STEP: Creating a pod to test env composition @ 04/13/24 12:44:03.978
  STEP: Saw pod success @ 04/13/24 12:44:08.001
  Apr 13 12:44:08.004: INFO: Trying to get logs from node ip-172-31-35-229 pod var-expansion-1c3923be-fec0-443f-8908-d3474be08df3 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 12:44:08.011
  Apr 13 12:44:08.028: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3862" for this suite. @ 04/13/24 12:44:08.031
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/13/24 12:44:08.04
  Apr 13 12:44:08.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 12:44:08.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:44:08.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:44:08.056
  STEP: creating the pod @ 04/13/24 12:44:08.059
  STEP: submitting the pod to kubernetes @ 04/13/24 12:44:08.059
  STEP: verifying QOS class is set on the pod @ 04/13/24 12:44:08.066
  Apr 13 12:44:08.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9209" for this suite. @ 04/13/24 12:44:08.077
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/13/24 12:44:08.083
  Apr 13 12:44:08.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/13/24 12:44:08.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:44:08.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:44:08.102
  Apr 13 12:44:08.105: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 13 12:45:08.105: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 12:45:08.110: INFO: Starting informer...
  STEP: Starting pods... @ 04/13/24 12:45:08.11
  Apr 13 12:45:08.328: INFO: Pod1 is running on ip-172-31-82-63. Tainting Node
  Apr 13 12:45:10.550: INFO: Pod2 is running on ip-172-31-82-63. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/13/24 12:45:10.55
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/13/24 12:45:10.56
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/13/24 12:45:10.567
  Apr 13 12:45:16.454: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Apr 13 12:45:36.492: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/13/24 12:45:36.502
  Apr 13 12:45:36.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-6918" for this suite. @ 04/13/24 12:45:36.509
• [88.433 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 04/13/24 12:45:36.517
  Apr 13 12:45:36.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:45:36.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:45:36.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:45:36.54
  STEP: creating Agnhost RC @ 04/13/24 12:45:36.544
  Apr 13 12:45:36.544: INFO: namespace kubectl-8459
  Apr 13 12:45:36.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8459 create -f -'
  Apr 13 12:45:36.630: INFO: stderr: ""
  Apr 13 12:45:36.630: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/13/24 12:45:36.63
  Apr 13 12:45:37.634: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 12:45:37.634: INFO: Found 1 / 1
  Apr 13 12:45:37.634: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 13 12:45:37.638: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 12:45:37.638: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 13 12:45:37.638: INFO: wait on agnhost-primary startup in kubectl-8459 
  Apr 13 12:45:37.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8459 logs agnhost-primary-4nqcm agnhost-primary'
  Apr 13 12:45:37.690: INFO: stderr: ""
  Apr 13 12:45:37.690: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/13/24 12:45:37.69
  Apr 13 12:45:37.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8459 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 13 12:45:37.742: INFO: stderr: ""
  Apr 13 12:45:37.742: INFO: stdout: "service/rm2 exposed\n"
  Apr 13 12:45:37.751: INFO: Service rm2 in namespace kubectl-8459 found.
  STEP: exposing service @ 04/13/24 12:45:39.759
  Apr 13 12:45:39.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8459 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 13 12:45:39.812: INFO: stderr: ""
  Apr 13 12:45:39.812: INFO: stdout: "service/rm3 exposed\n"
  Apr 13 12:45:39.821: INFO: Service rm3 in namespace kubectl-8459 found.
  Apr 13 12:45:41.829: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8459" for this suite. @ 04/13/24 12:45:41.832
• [5.323 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/13/24 12:45:41.84
  Apr 13 12:45:41.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/13/24 12:45:41.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:45:41.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:45:41.858
  STEP: Cleaning up the secret @ 04/13/24 12:45:43.89
  STEP: Cleaning up the configmap @ 04/13/24 12:45:43.897
  STEP: Cleaning up the pod @ 04/13/24 12:45:43.903
  Apr 13 12:45:43.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-2292" for this suite. @ 04/13/24 12:45:43.918
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 04/13/24 12:45:43.924
  Apr 13 12:45:43.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 12:45:43.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:45:43.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:45:43.941
  STEP: Setting up server cert @ 04/13/24 12:45:43.962
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 12:45:44.316
  STEP: Deploying the webhook pod @ 04/13/24 12:45:44.326
  STEP: Wait for the deployment to be ready @ 04/13/24 12:45:44.342
  Apr 13 12:45:44.364: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/13/24 12:45:46.376
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 12:45:46.386
  Apr 13 12:45:47.387: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 13 12:45:47.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5906-crds.webhook.example.com via the AdmissionRegistration API @ 04/13/24 12:45:47.908
  STEP: Creating a custom resource while v1 is storage version @ 04/13/24 12:45:47.923
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/13/24 12:45:49.955
  STEP: Patching the custom resource while v2 is storage version @ 04/13/24 12:45:49.974
  Apr 13 12:45:50.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-18" for this suite. @ 04/13/24 12:45:50.564
  STEP: Destroying namespace "webhook-markers-8433" for this suite. @ 04/13/24 12:45:50.571
• [6.654 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 04/13/24 12:45:50.578
  Apr 13 12:45:50.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 12:45:50.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:45:50.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:45:50.608
  STEP: Setting up server cert @ 04/13/24 12:45:50.631
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 12:45:50.873
  STEP: Deploying the webhook pod @ 04/13/24 12:45:50.878
  STEP: Wait for the deployment to be ready @ 04/13/24 12:45:50.89
  Apr 13 12:45:50.898: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/13/24 12:45:52.909
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 12:45:52.917
  Apr 13 12:45:53.918: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/13/24 12:45:53.989
  STEP: Creating a configMap that should be mutated @ 04/13/24 12:45:53.998
  STEP: Deleting the collection of validation webhooks @ 04/13/24 12:45:54.016
  STEP: Creating a configMap that should not be mutated @ 04/13/24 12:45:54.057
  Apr 13 12:45:54.105: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6499" for this suite. @ 04/13/24 12:45:54.109
  STEP: Destroying namespace "webhook-markers-6694" for this suite. @ 04/13/24 12:45:54.117
• [3.544 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 04/13/24 12:45:54.122
  Apr 13 12:45:54.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:45:54.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:45:54.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:45:54.14
  STEP: Creating a ResourceQuota with best effort scope @ 04/13/24 12:45:54.143
  STEP: Ensuring ResourceQuota status is calculated @ 04/13/24 12:45:54.149
  STEP: Creating a ResourceQuota with not best effort scope @ 04/13/24 12:45:56.153
  STEP: Ensuring ResourceQuota status is calculated @ 04/13/24 12:45:56.16
  STEP: Creating a best-effort pod @ 04/13/24 12:45:58.164
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/13/24 12:45:58.179
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/13/24 12:46:00.183
  STEP: Deleting the pod @ 04/13/24 12:46:02.189
  STEP: Ensuring resource quota status released the pod usage @ 04/13/24 12:46:02.204
  STEP: Creating a not best-effort pod @ 04/13/24 12:46:04.208
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/13/24 12:46:04.219
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/13/24 12:46:06.224
  STEP: Deleting the pod @ 04/13/24 12:46:08.228
  STEP: Ensuring resource quota status released the pod usage @ 04/13/24 12:46:08.241
  Apr 13 12:46:10.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-336" for this suite. @ 04/13/24 12:46:10.249
• [16.133 seconds]
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 04/13/24 12:46:10.255
  Apr 13 12:46:10.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename endpointslice @ 04/13/24 12:46:10.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:46:10.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:46:10.278
  STEP: getting /apis @ 04/13/24 12:46:10.284
  STEP: getting /apis/discovery.k8s.io @ 04/13/24 12:46:10.294
  STEP: getting /apis/discovery.k8s.iov1 @ 04/13/24 12:46:10.295
  STEP: creating @ 04/13/24 12:46:10.297
  STEP: getting @ 04/13/24 12:46:10.318
  STEP: listing @ 04/13/24 12:46:10.321
  STEP: watching @ 04/13/24 12:46:10.325
  Apr 13 12:46:10.325: INFO: starting watch
  STEP: cluster-wide listing @ 04/13/24 12:46:10.331
  STEP: cluster-wide watching @ 04/13/24 12:46:10.334
  Apr 13 12:46:10.334: INFO: starting watch
  STEP: patching @ 04/13/24 12:46:10.336
  STEP: updating @ 04/13/24 12:46:10.362
  Apr 13 12:46:10.374: INFO: waiting for watch events with expected annotations
  Apr 13 12:46:10.375: INFO: saw patched and updated annotations
  STEP: deleting @ 04/13/24 12:46:10.375
  STEP: deleting a collection @ 04/13/24 12:46:10.387
  Apr 13 12:46:10.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2346" for this suite. @ 04/13/24 12:46:10.405
• [0.156 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 04/13/24 12:46:10.411
  Apr 13 12:46:10.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 12:46:10.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:46:10.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:46:10.427
  Apr 13 12:46:10.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  W0413 12:46:10.430976      21 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc000ce5f30 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0413 12:46:12.965756      21 warnings.go:70] unknown field "alpha"
  W0413 12:46:12.965775      21 warnings.go:70] unknown field "beta"
  W0413 12:46:12.965779      21 warnings.go:70] unknown field "delta"
  W0413 12:46:12.965782      21 warnings.go:70] unknown field "epsilon"
  W0413 12:46:12.965785      21 warnings.go:70] unknown field "gamma"
  Apr 13 12:46:13.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4273" for this suite. @ 04/13/24 12:46:13.507
• [3.103 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 04/13/24 12:46:13.514
  Apr 13 12:46:13.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/13/24 12:46:13.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:46:13.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:46:13.531
  Apr 13 12:46:13.534: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:46:19.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-769" for this suite. @ 04/13/24 12:46:19.742
• [6.237 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/13/24 12:46:19.751
  Apr 13 12:46:19.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename taint-single-pod @ 04/13/24 12:46:19.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:46:19.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:46:19.768
  Apr 13 12:46:19.771: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 13 12:47:19.772: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 12:47:19.777: INFO: Starting informer...
  STEP: Starting pod... @ 04/13/24 12:47:19.777
  Apr 13 12:47:19.995: INFO: Pod is running on ip-172-31-82-63. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/13/24 12:47:19.995
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/13/24 12:47:20.004
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/13/24 12:47:20.009
  Apr 13 12:47:20.009: INFO: Pod wasn't evicted. Proceeding
  Apr 13 12:47:20.009: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/13/24 12:47:20.023
  STEP: Waiting some time to make sure that toleration time passed. @ 04/13/24 12:47:20.031
  Apr 13 12:48:35.031: INFO: Pod wasn't evicted. Test successful
  Apr 13 12:48:35.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-5414" for this suite. @ 04/13/24 12:48:35.036
• [135.292 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 04/13/24 12:48:35.043
  Apr 13 12:48:35.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:48:35.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:35.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:35.062
  STEP: Creating configMap that has name configmap-test-emptyKey-6c1e3fae-47d8-4741-a161-49e8882932e1 @ 04/13/24 12:48:35.065
  Apr 13 12:48:35.067: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-147" for this suite. @ 04/13/24 12:48:35.07
• [0.032 seconds]
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 04/13/24 12:48:35.076
  Apr 13 12:48:35.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename events @ 04/13/24 12:48:35.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:35.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:35.091
  STEP: Create set of events @ 04/13/24 12:48:35.094
  Apr 13 12:48:35.101: INFO: created test-event-1
  Apr 13 12:48:35.106: INFO: created test-event-2
  Apr 13 12:48:35.111: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/13/24 12:48:35.111
  STEP: delete collection of events @ 04/13/24 12:48:35.114
  Apr 13 12:48:35.114: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/13/24 12:48:35.137
  Apr 13 12:48:35.137: INFO: requesting list of events to confirm quantity
  Apr 13 12:48:35.140: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3156" for this suite. @ 04/13/24 12:48:35.144
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/13/24 12:48:35.152
  Apr 13 12:48:35.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-runtime @ 04/13/24 12:48:35.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:35.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:35.168
  STEP: create the container @ 04/13/24 12:48:35.172
  W0413 12:48:35.178219      21 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/13/24 12:48:35.178
  STEP: get the container status @ 04/13/24 12:48:38.199
  STEP: the container should be terminated @ 04/13/24 12:48:38.203
  STEP: the termination message should be set @ 04/13/24 12:48:38.203
  Apr 13 12:48:38.203: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/13/24 12:48:38.203
  Apr 13 12:48:38.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3568" for this suite. @ 04/13/24 12:48:38.222
• [3.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/13/24 12:48:38.23
  Apr 13 12:48:38.230: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 12:48:38.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:38.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:38.245
  STEP: Creating a test headless service @ 04/13/24 12:48:38.258
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2120.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2120.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
   @ 04/13/24 12:48:38.274
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2120.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2120.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2120.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2120.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2120.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
   @ 04/13/24 12:48:38.274
  STEP: creating a pod to probe DNS @ 04/13/24 12:48:38.275
  STEP: submitting the pod to kubernetes @ 04/13/24 12:48:38.275
  STEP: retrieving the pod @ 04/13/24 12:48:44.309
  STEP: looking for the results for each expected name from probers @ 04/13/24 12:48:44.312
  Apr 13 12:48:44.317: INFO: Unable to read wheezy_udp@dns-test-service.dns-2120.svc.cluster.local from pod dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1: the server could not find the requested resource (get pods dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1)
  Apr 13 12:48:44.322: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2120.svc.cluster.local from pod dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1: the server could not find the requested resource (get pods dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1)
  Apr 13 12:48:44.326: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local from pod dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1: the server could not find the requested resource (get pods dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1)
  Apr 13 12:48:44.329: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local from pod dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1: the server could not find the requested resource (get pods dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1)
  Apr 13 12:48:44.374: INFO: Lookups using dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1 failed for: [wheezy_udp@dns-test-service.dns-2120.svc.cluster.local wheezy_tcp@dns-test-service.dns-2120.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2120.svc.cluster.local]

  Apr 13 12:48:44.391: INFO: Pod client logs for webserver: 
  Apr 13 12:48:44.398: INFO: Pod client logs for querier: 
  Apr 13 12:48:44.403: INFO: Pod client logs for jessie-querier: 
  Apr 13 12:48:49.385: INFO: DNS probes using dns-2120/dns-test-c4084b8b-2d40-4141-8211-ae99bb1261b1 succeeded

  STEP: deleting the pod @ 04/13/24 12:48:49.385
  STEP: deleting the test service @ 04/13/24 12:48:49.405
  STEP: deleting the test headless service @ 04/13/24 12:48:49.429
  Apr 13 12:48:49.446: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2120" for this suite. @ 04/13/24 12:48:49.451
• [11.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 04/13/24 12:48:49.456
  Apr 13 12:48:49.456: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 12:48:49.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:49.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:49.481
  Apr 13 12:48:49.488: INFO: Got root ca configmap in namespace "svcaccounts-2654"
  Apr 13 12:48:49.495: INFO: Deleted root ca configmap in namespace "svcaccounts-2654"
  STEP: waiting for a new root ca configmap created @ 04/13/24 12:48:49.995
  Apr 13 12:48:49.999: INFO: Recreated root ca configmap in namespace "svcaccounts-2654"
  Apr 13 12:48:50.005: INFO: Updated root ca configmap in namespace "svcaccounts-2654"
  STEP: waiting for the root ca configmap reconciled @ 04/13/24 12:48:50.505
  Apr 13 12:48:50.509: INFO: Reconciled root ca configmap in namespace "svcaccounts-2654"
  Apr 13 12:48:50.509: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2654" for this suite. @ 04/13/24 12:48:50.513
• [1.065 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 04/13/24 12:48:50.521
  Apr 13 12:48:50.521: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:48:50.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:50.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:50.538
  STEP: validating api versions @ 04/13/24 12:48:50.541
  Apr 13 12:48:50.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1203 api-versions'
  Apr 13 12:48:50.686: INFO: stderr: ""
  Apr 13 12:48:50.686: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 13 12:48:50.687: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1203" for this suite. @ 04/13/24 12:48:50.691
• [0.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 04/13/24 12:48:50.699
  Apr 13 12:48:50.699: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:48:50.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:48:50.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:48:50.714
  STEP: Creating pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351 @ 04/13/24 12:48:50.717
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 12:48:52.734
  Apr 13 12:48:52.737: INFO: Initial restart count of pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 is 0
  Apr 13 12:48:52.740: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:48:54.744: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:48:56.749: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:48:58.754: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:00.759: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:02.764: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:04.769: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:06.774: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:08.778: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:10.783: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:12.787: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:14.792: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:16.795: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:18.800: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:20.804: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:22.809: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:24.814: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:26.818: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:28.822: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:30.827: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:32.830: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:34.835: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:36.840: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:38.845: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:40.849: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:42.854: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:44.858: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:46.862: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:48.867: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:50.871: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:52.876: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:54.880: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:56.884: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:49:58.888: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:00.892: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:02.897: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:04.902: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:06.906: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:08.911: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:10.915: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:12.921: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:14.926: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:16.931: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:18.936: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:20.940: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:22.946: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:24.951: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:26.956: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:28.960: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:30.965: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:32.969: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:34.974: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:36.979: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:38.984: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:40.989: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:42.994: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:44.999: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:47.003: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:49.008: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:51.014: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:53.019: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:55.025: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:57.029: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:50:59.034: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:01.040: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:03.045: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:05.050: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:07.056: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:09.061: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:11.066: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:13.072: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:15.077: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:17.082: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:19.087: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:21.092: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:23.097: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:25.101: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:27.106: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:29.110: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:31.115: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:33.119: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:35.124: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:37.129: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:39.134: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:41.139: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:43.143: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:45.148: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:47.153: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:49.158: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:51.163: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:53.167: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:55.173: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:57.177: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:51:59.183: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:01.187: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:03.192: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:05.197: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:07.201: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:09.206: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:11.212: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:13.216: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:15.220: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:17.225: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:19.230: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:21.234: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:23.239: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:25.243: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:27.248: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:29.253: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:31.258: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:33.263: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:35.267: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:37.272: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:39.278: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:41.284: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:43.288: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:45.292: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:47.296: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:49.301: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  Apr 13 12:52:51.308: INFO: Get pod test-grpc-b58da8b6-7996-48cb-9651-ed5037cfa581 in namespace container-probe-6351
  STEP: deleting the pod @ 04/13/24 12:52:53.308
  Apr 13 12:52:53.322: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6351" for this suite. @ 04/13/24 12:52:53.326
• [242.633 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 04/13/24 12:52:53.332
  Apr 13 12:52:53.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subpath @ 04/13/24 12:52:53.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:52:53.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:52:53.348
  STEP: Setting up data @ 04/13/24 12:52:53.351
  STEP: Creating pod pod-subpath-test-projected-zs7v @ 04/13/24 12:52:53.361
  STEP: Creating a pod to test atomic-volume-subpath @ 04/13/24 12:52:53.361
  STEP: Saw pod success @ 04/13/24 12:53:15.43
  Apr 13 12:53:15.434: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-subpath-test-projected-zs7v container test-container-subpath-projected-zs7v: <nil>
  STEP: delete the pod @ 04/13/24 12:53:15.45
  STEP: Deleting pod pod-subpath-test-projected-zs7v @ 04/13/24 12:53:15.464
  Apr 13 12:53:15.464: INFO: Deleting pod "pod-subpath-test-projected-zs7v" in namespace "subpath-7686"
  Apr 13 12:53:15.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7686" for this suite. @ 04/13/24 12:53:15.472
• [22.147 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 04/13/24 12:53:15.479
  Apr 13 12:53:15.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:53:15.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:15.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:15.499
  STEP: Creating a ResourceQuota @ 04/13/24 12:53:15.502
  STEP: Getting a ResourceQuota @ 04/13/24 12:53:15.506
  STEP: Updating a ResourceQuota @ 04/13/24 12:53:15.512
  STEP: Verifying a ResourceQuota was modified @ 04/13/24 12:53:15.516
  STEP: Deleting a ResourceQuota @ 04/13/24 12:53:15.52
  STEP: Verifying the deleted ResourceQuota @ 04/13/24 12:53:15.525
  Apr 13 12:53:15.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5613" for this suite. @ 04/13/24 12:53:15.532
• [0.060 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/13/24 12:53:15.54
  Apr 13 12:53:15.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename proxy @ 04/13/24 12:53:15.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:15.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:15.553
  Apr 13 12:53:15.556: INFO: Creating pod...
  Apr 13 12:53:17.573: INFO: Creating service...
  Apr 13 12:53:17.583: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=DELETE
  Apr 13 12:53:17.589: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 13 12:53:17.589: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=OPTIONS
  Apr 13 12:53:17.593: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 13 12:53:17.594: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=PATCH
  Apr 13 12:53:17.596: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 13 12:53:17.596: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=POST
  Apr 13 12:53:17.600: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 13 12:53:17.600: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=PUT
  Apr 13 12:53:17.603: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 13 12:53:17.603: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 13 12:53:17.607: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 13 12:53:17.607: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 13 12:53:17.612: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 13 12:53:17.612: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 13 12:53:17.618: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 13 12:53:17.618: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=POST
  Apr 13 12:53:17.622: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 13 12:53:17.622: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 13 12:53:17.628: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 13 12:53:17.628: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=GET
  Apr 13 12:53:17.631: INFO: http.Client request:GET StatusCode:301
  Apr 13 12:53:17.631: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=GET
  Apr 13 12:53:17.635: INFO: http.Client request:GET StatusCode:301
  Apr 13 12:53:17.635: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/pods/agnhost/proxy?method=HEAD
  Apr 13 12:53:17.638: INFO: http.Client request:HEAD StatusCode:301
  Apr 13 12:53:17.638: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5038/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 13 12:53:17.641: INFO: http.Client request:HEAD StatusCode:301
  Apr 13 12:53:17.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5038" for this suite. @ 04/13/24 12:53:17.645
• [2.114 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 04/13/24 12:53:17.654
  Apr 13 12:53:17.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 12:53:17.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:17.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:17.671
  STEP: Creating configMap configmap-9485/configmap-test-d95ba5df-637a-4eb6-a6aa-62fda90b7780 @ 04/13/24 12:53:17.675
  STEP: Creating a pod to test consume configMaps @ 04/13/24 12:53:17.678
  STEP: Saw pod success @ 04/13/24 12:53:21.699
  Apr 13 12:53:21.702: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-71d3d0a7-4942-436a-903d-ab3c07c3043d container env-test: <nil>
  STEP: delete the pod @ 04/13/24 12:53:21.708
  Apr 13 12:53:21.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9485" for this suite. @ 04/13/24 12:53:21.727
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 04/13/24 12:53:21.733
  Apr 13 12:53:21.733: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 12:53:21.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:21.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:21.75
  STEP: creating a ReplicationController @ 04/13/24 12:53:21.756
  STEP: waiting for RC to be added @ 04/13/24 12:53:21.762
  STEP: waiting for available Replicas @ 04/13/24 12:53:21.762
  STEP: patching ReplicationController @ 04/13/24 12:53:23.252
  STEP: waiting for RC to be modified @ 04/13/24 12:53:23.259
  STEP: patching ReplicationController status @ 04/13/24 12:53:23.259
  STEP: waiting for RC to be modified @ 04/13/24 12:53:23.265
  STEP: waiting for available Replicas @ 04/13/24 12:53:23.265
  STEP: fetching ReplicationController status @ 04/13/24 12:53:23.269
  STEP: patching ReplicationController scale @ 04/13/24 12:53:23.272
  STEP: waiting for RC to be modified @ 04/13/24 12:53:23.279
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/13/24 12:53:23.279
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/13/24 12:53:23.954
  STEP: updating ReplicationController status @ 04/13/24 12:53:23.957
  STEP: waiting for RC to be modified @ 04/13/24 12:53:23.962
  STEP: listing all ReplicationControllers @ 04/13/24 12:53:23.962
  STEP: checking that ReplicationController has expected values @ 04/13/24 12:53:23.968
  STEP: deleting ReplicationControllers by collection @ 04/13/24 12:53:23.968
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/13/24 12:53:23.977
  Apr 13 12:53:24.021: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0413 12:53:24.022126      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-3441" for this suite. @ 04/13/24 12:53:24.025
• [2.298 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 04/13/24 12:53:24.031
  Apr 13 12:53:24.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 12:53:24.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:24.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:24.049
  E0413 12:53:25.022497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:26.022581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/13/24 12:53:26.077
  Apr 13 12:53:26.077: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1561 pod-service-account-4e64f0a2-10e8-4f8b-9c26-4557222f0c1f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/13/24 12:53:26.172
  Apr 13 12:53:26.172: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1561 pod-service-account-4e64f0a2-10e8-4f8b-9c26-4557222f0c1f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/13/24 12:53:26.255
  Apr 13 12:53:26.255: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1561 pod-service-account-4e64f0a2-10e8-4f8b-9c26-4557222f0c1f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 13 12:53:26.346: INFO: Got root ca configmap in namespace "svcaccounts-1561"
  Apr 13 12:53:26.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1561" for this suite. @ 04/13/24 12:53:26.352
• [2.329 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 04/13/24 12:53:26.361
  Apr 13 12:53:26.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 12:53:26.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:26.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:26.377
  STEP: Creating a job @ 04/13/24 12:53:26.38
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/13/24 12:53:26.385
  E0413 12:53:27.022702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:28.022806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/13/24 12:53:28.391
  STEP: updating /status @ 04/13/24 12:53:28.396
  STEP: get /status @ 04/13/24 12:53:28.428
  Apr 13 12:53:28.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7118" for this suite. @ 04/13/24 12:53:28.434
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 04/13/24 12:53:28.44
  Apr 13 12:53:28.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subpath @ 04/13/24 12:53:28.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:28.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:28.456
  STEP: Setting up data @ 04/13/24 12:53:28.459
  STEP: Creating pod pod-subpath-test-configmap-v64d @ 04/13/24 12:53:28.469
  STEP: Creating a pod to test atomic-volume-subpath @ 04/13/24 12:53:28.469
  E0413 12:53:29.023502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:30.023726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:31.023915      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:32.024358      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:33.024517      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:34.024612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:35.024668      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:36.024989      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:37.025704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:38.025781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:39.026468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:40.026573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:41.026674      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:42.026758      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:43.026865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:44.027680      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:45.027747      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:46.027829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:47.027958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:48.028063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:49.028166      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:50.028369      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:51.029049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:52.029158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:53:52.537
  Apr 13 12:53:52.541: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-subpath-test-configmap-v64d container test-container-subpath-configmap-v64d: <nil>
  STEP: delete the pod @ 04/13/24 12:53:52.554
  STEP: Deleting pod pod-subpath-test-configmap-v64d @ 04/13/24 12:53:52.575
  Apr 13 12:53:52.575: INFO: Deleting pod "pod-subpath-test-configmap-v64d" in namespace "subpath-93"
  Apr 13 12:53:52.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-93" for this suite. @ 04/13/24 12:53:52.587
• [24.154 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 04/13/24 12:53:52.595
  Apr 13 12:53:52.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename endpointslice @ 04/13/24 12:53:52.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:52.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:52.621
  E0413 12:53:53.029242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:54.029463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:55.029554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:56.029658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:53:56.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1654" for this suite. @ 04/13/24 12:53:56.689
• [4.101 seconds]
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 04/13/24 12:53:56.696
  Apr 13 12:53:56.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubelet-test @ 04/13/24 12:53:56.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:53:56.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:53:56.713
  STEP: Waiting for pod completion @ 04/13/24 12:53:56.724
  E0413 12:53:57.030394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:58.030527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:53:59.031531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:00.031629      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:00.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7551" for this suite. @ 04/13/24 12:54:00.745
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 04/13/24 12:54:00.753
  Apr 13 12:54:00.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:54:00.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:00.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:00.77
  STEP: Counting existing ResourceQuota @ 04/13/24 12:54:00.773
  E0413 12:54:01.032153      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:02.032896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:03.033358      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:04.033554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:05.034097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/13/24 12:54:05.776
  STEP: Ensuring resource quota status is calculated @ 04/13/24 12:54:05.782
  E0413 12:54:06.034610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:07.035627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 04/13/24 12:54:07.786
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/13/24 12:54:07.802
  E0413 12:54:08.036565      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:09.037152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/13/24 12:54:09.807
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/13/24 12:54:09.81
  STEP: Ensuring a pod cannot update its resource requirements @ 04/13/24 12:54:09.812
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/13/24 12:54:09.817
  E0413 12:54:10.037739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:11.037849      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/13/24 12:54:11.821
  STEP: Ensuring resource quota status released the pod usage @ 04/13/24 12:54:11.838
  E0413 12:54:12.038661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:13.038912      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:13.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4546" for this suite. @ 04/13/24 12:54:13.847
• [13.108 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 04/13/24 12:54:13.861
  Apr 13 12:54:13.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:54:13.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:13.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:13.879
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 12:54:13.881
  E0413 12:54:14.039390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:15.040081      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:16.040985      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:17.041081      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:54:17.906
  Apr 13 12:54:17.910: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-8d2ab402-487f-4f68-9f94-b84e3c6bfcf7 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 12:54:17.917
  Apr 13 12:54:17.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9460" for this suite. @ 04/13/24 12:54:17.937
• [4.083 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/13/24 12:54:17.944
  Apr 13 12:54:17.944: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-runtime @ 04/13/24 12:54:17.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:17.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:17.958
  STEP: create the container @ 04/13/24 12:54:17.961
  W0413 12:54:17.969167      21 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/13/24 12:54:17.969
  E0413 12:54:18.041373      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:19.041492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:20.041856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/13/24 12:54:20.986
  STEP: the container should be terminated @ 04/13/24 12:54:20.99
  STEP: the termination message should be set @ 04/13/24 12:54:20.99
  Apr 13 12:54:20.990: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/13/24 12:54:20.99
  Apr 13 12:54:21.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3632" for this suite. @ 04/13/24 12:54:21.009
• [3.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 04/13/24 12:54:21.02
  Apr 13 12:54:21.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 12:54:21.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:21.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:21.04
  E0413 12:54:21.041920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with terminating scope @ 04/13/24 12:54:21.043
  STEP: Ensuring ResourceQuota status is calculated @ 04/13/24 12:54:21.047
  E0413 12:54:22.042481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:23.042592      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 04/13/24 12:54:23.05
  STEP: Ensuring ResourceQuota status is calculated @ 04/13/24 12:54:23.055
  E0413 12:54:24.042682      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:25.042772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 04/13/24 12:54:25.06
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/13/24 12:54:25.073
  E0413 12:54:26.043567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:27.043914      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/13/24 12:54:27.078
  E0413 12:54:28.044004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:29.044087      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/13/24 12:54:29.083
  STEP: Ensuring resource quota status released the pod usage @ 04/13/24 12:54:29.096
  E0413 12:54:30.044208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:31.044300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 04/13/24 12:54:31.101
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/13/24 12:54:31.117
  E0413 12:54:32.044671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:33.044776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/13/24 12:54:33.122
  E0413 12:54:34.044858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:35.045062      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/13/24 12:54:35.127
  STEP: Ensuring resource quota status released the pod usage @ 04/13/24 12:54:35.141
  E0413 12:54:36.045213      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:37.045734      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:37.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4561" for this suite. @ 04/13/24 12:54:37.15
• [16.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 04/13/24 12:54:37.157
  Apr 13 12:54:37.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:54:37.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:37.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:37.174
  STEP: Creating a pod to test downward api env vars @ 04/13/24 12:54:37.177
  E0413 12:54:38.045870      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:39.045930      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:40.046055      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:41.046134      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:54:41.201
  Apr 13 12:54:41.204: INFO: Trying to get logs from node ip-172-31-82-63 pod downward-api-9273c0fc-469c-4e74-ae1c-2ad22e60aa32 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 12:54:41.211
  Apr 13 12:54:41.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5388" for this suite. @ 04/13/24 12:54:41.23
• [4.079 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 04/13/24 12:54:41.236
  Apr 13 12:54:41.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:54:41.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:41.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:41.253
  STEP: starting the proxy server @ 04/13/24 12:54:41.256
  Apr 13 12:54:41.256: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1151 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/13/24 12:54:41.285
  Apr 13 12:54:41.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1151" for this suite. @ 04/13/24 12:54:41.295
• [0.066 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/13/24 12:54:41.302
  Apr 13 12:54:41.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:54:41.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:54:41.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:54:41.316
  STEP: Creating pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491 @ 04/13/24 12:54:41.319
  E0413 12:54:42.046505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:43.046582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 12:54:43.343
  Apr 13 12:54:43.347: INFO: Initial restart count of pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 is 0
  Apr 13 12:54:43.350: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:44.046705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:45.047544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:45.355: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:46.047681      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:47.048010      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:47.362: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:48.048125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:49.048224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:49.368: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:50.048600      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:51.048689      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:51.374: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:52.048808      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:53.048865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:53.380: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:54.049764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:55.049990      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:55.384: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:56.050463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:57.051543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:57.389: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:54:58.051605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:54:59.051780      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:54:59.395: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:00.051883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:01.052731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:01.400: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:02.052831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:03.053184      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:03.404: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:04.053347      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:05.053433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:05.409: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:06.053931      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:07.054428      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:07.414: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:08.054472      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:09.054557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:09.419: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:10.055645      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:11.055754      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:11.424: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:12.056786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:13.056883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:13.428: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:14.057326      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:15.057499      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:15.433: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:16.057794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:17.058523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:17.438: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:18.058902      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:19.059543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:19.443: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:20.059930      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:21.060039      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:21.448: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:22.060484      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:23.060572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:23.452: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:24.060810      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:25.061728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:25.458: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:26.061820      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:27.062783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:27.463: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:28.062873      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:29.063524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:29.468: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:30.063934      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:31.064098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:31.473: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  E0413 12:55:32.064127      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:33.064247      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:33.478: INFO: Get pod busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 in namespace container-probe-4491
  Apr 13 12:55:33.478: INFO: Restart count of pod container-probe-4491/busybox-6eec9d91-155c-4b42-baa2-8e40dd7e78d7 is now 1 (50.1314058s elapsed)
  STEP: deleting the pod @ 04/13/24 12:55:33.478
  Apr 13 12:55:33.493: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4491" for this suite. @ 04/13/24 12:55:33.497
• [52.202 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 04/13/24 12:55:33.504
  Apr 13 12:55:33.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pod-network-test @ 04/13/24 12:55:33.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:55:33.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:55:33.525
  STEP: Performing setup for networking test in namespace pod-network-test-2704 @ 04/13/24 12:55:33.528
  STEP: creating a selector @ 04/13/24 12:55:33.528
  STEP: Creating the service pods in kubernetes @ 04/13/24 12:55:33.528
  Apr 13 12:55:33.528: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0413 12:55:34.065135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:35.065189      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:36.065293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:37.065670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:38.066477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:39.066572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:40.066672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:41.066770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:42.066853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:43.066954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:44.067049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:45.067139      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:46.068131      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:47.068500      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:48.069144      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:49.069243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:50.069363      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:51.069449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:52.070297      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:53.070437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:54.070855      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:55.071687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/13/24 12:55:55.632
  E0413 12:55:56.072362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:55:57.072805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:57.663: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 13 12:55:57.663: INFO: Going to poll 192.168.57.200 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:55:57.666: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.57.200 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2704 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:55:57.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:55:57.666: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:55:57.667: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2704/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.57.200+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0413 12:55:58.073694      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:58.713: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 13 12:55:58.713: INFO: Going to poll 192.168.254.242 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:55:58.718: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.254.242 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2704 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:55:58.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:55:58.718: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:55:58.718: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2704/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.254.242+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0413 12:55:59.074535      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:55:59.772: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 13 12:55:59.772: INFO: Going to poll 192.168.172.202 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 13 12:55:59.776: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.172.202 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2704 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:55:59.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:55:59.777: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:55:59.777: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2704/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.172.202+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0413 12:56:00.074934      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:00.828: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 13 12:56:00.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2704" for this suite. @ 04/13/24 12:56:00.833
• [27.335 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/13/24 12:56:00.84
  Apr 13 12:56:00.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 12:56:00.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:00.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:00.857
  STEP: creating the pod @ 04/13/24 12:56:00.86
  STEP: setting up watch @ 04/13/24 12:56:00.86
  STEP: submitting the pod to kubernetes @ 04/13/24 12:56:00.964
  STEP: verifying the pod is in kubernetes @ 04/13/24 12:56:00.974
  STEP: verifying pod creation was observed @ 04/13/24 12:56:00.979
  E0413 12:56:01.075276      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:02.075506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/13/24 12:56:02.992
  STEP: verifying pod deletion was observed @ 04/13/24 12:56:02.999
  E0413 12:56:03.076244      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:04.076360      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:04.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7459" for this suite. @ 04/13/24 12:56:04.228
• [3.394 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/13/24 12:56:04.234
  Apr 13 12:56:04.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 12:56:04.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:04.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:04.25
  Apr 13 12:56:04.253: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 12:56:05.076954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/13/24 12:56:05.599
  Apr 13 12:56:05.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 create -f -'
  E0413 12:56:06.077966      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:07.078786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:07.668: INFO: stderr: ""
  Apr 13 12:56:07.668: INFO: stdout: "e2e-test-crd-publish-openapi-1069-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 13 12:56:07.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 delete e2e-test-crd-publish-openapi-1069-crds test-foo'
  Apr 13 12:56:07.716: INFO: stderr: ""
  Apr 13 12:56:07.716: INFO: stdout: "e2e-test-crd-publish-openapi-1069-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 13 12:56:07.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 apply -f -'
  Apr 13 12:56:07.768: INFO: stderr: ""
  Apr 13 12:56:07.768: INFO: stdout: "e2e-test-crd-publish-openapi-1069-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 13 12:56:07.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 delete e2e-test-crd-publish-openapi-1069-crds test-foo'
  Apr 13 12:56:07.813: INFO: stderr: ""
  Apr 13 12:56:07.813: INFO: stdout: "e2e-test-crd-publish-openapi-1069-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/13/24 12:56:07.813
  Apr 13 12:56:07.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 create -f -'
  Apr 13 12:56:07.854: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/13/24 12:56:07.854
  Apr 13 12:56:07.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 create -f -'
  Apr 13 12:56:07.894: INFO: rc: 1
  Apr 13 12:56:07.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 apply -f -'
  Apr 13 12:56:07.942: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/13/24 12:56:07.942
  Apr 13 12:56:07.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 create -f -'
  Apr 13 12:56:07.983: INFO: rc: 1
  Apr 13 12:56:07.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 --namespace=crd-publish-openapi-2034 apply -f -'
  Apr 13 12:56:08.031: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/13/24 12:56:08.031
  Apr 13 12:56:08.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 explain e2e-test-crd-publish-openapi-1069-crds'
  Apr 13 12:56:08.068: INFO: stderr: ""
  Apr 13 12:56:08.068: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1069-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/13/24 12:56:08.068
  Apr 13 12:56:08.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 explain e2e-test-crd-publish-openapi-1069-crds.metadata'
  E0413 12:56:08.079125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:08.105: INFO: stderr: ""
  Apr 13 12:56:08.105: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1069-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 13 12:56:08.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 explain e2e-test-crd-publish-openapi-1069-crds.spec'
  Apr 13 12:56:08.143: INFO: stderr: ""
  Apr 13 12:56:08.143: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1069-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 13 12:56:08.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 explain e2e-test-crd-publish-openapi-1069-crds.spec.bars'
  Apr 13 12:56:08.179: INFO: stderr: ""
  Apr 13 12:56:08.179: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1069-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/13/24 12:56:08.179
  Apr 13 12:56:08.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-2034 explain e2e-test-crd-publish-openapi-1069-crds.spec.bars2'
  Apr 13 12:56:08.218: INFO: rc: 1
  E0413 12:56:09.079556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:09.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2034" for this suite. @ 04/13/24 12:56:09.454
• [5.227 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/13/24 12:56:09.461
  Apr 13 12:56:09.461: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl-logs @ 04/13/24 12:56:09.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:09.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:09.478
  STEP: creating an pod @ 04/13/24 12:56:09.481
  Apr 13 12:56:09.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Apr 13 12:56:09.531: INFO: stderr: ""
  Apr 13 12:56:09.531: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/13/24 12:56:09.532
  Apr 13 12:56:09.532: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0413 12:56:10.079824      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:11.079911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:11.541: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/13/24 12:56:11.541
  Apr 13 12:56:11.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator'
  Apr 13 12:56:11.595: INFO: stderr: ""
  Apr 13 12:56:11.595: INFO: stdout: "I0413 12:56:10.102801       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/4m5 361\nI0413 12:56:10.302897       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/4nnv 219\nI0413 12:56:10.503431       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/fjj8 478\nI0413 12:56:10.703729       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2s4s 275\nI0413 12:56:10.902890       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/k2q 252\nI0413 12:56:11.103146       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/hrf 546\nI0413 12:56:11.303463       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/pj7 320\nI0413 12:56:11.503753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/bb2 268\n"
  STEP: limiting log lines @ 04/13/24 12:56:11.595
  Apr 13 12:56:11.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator --tail=1'
  Apr 13 12:56:11.645: INFO: stderr: ""
  Apr 13 12:56:11.645: INFO: stdout: "I0413 12:56:11.503753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/bb2 268\n"
  Apr 13 12:56:11.645: INFO: got output "I0413 12:56:11.503753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/bb2 268\n"
  STEP: limiting log bytes @ 04/13/24 12:56:11.645
  Apr 13 12:56:11.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator --limit-bytes=1'
  Apr 13 12:56:11.690: INFO: stderr: ""
  Apr 13 12:56:11.690: INFO: stdout: "I"
  Apr 13 12:56:11.690: INFO: got output "I"
  STEP: exposing timestamps @ 04/13/24 12:56:11.69
  Apr 13 12:56:11.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 13 12:56:11.735: INFO: stderr: ""
  Apr 13 12:56:11.735: INFO: stdout: "2024-04-13T12:56:11.703059719Z I0413 12:56:11.702980       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/9zm 280\n"
  Apr 13 12:56:11.735: INFO: got output "2024-04-13T12:56:11.703059719Z I0413 12:56:11.702980       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/9zm 280\n"
  STEP: restricting to a time range @ 04/13/24 12:56:11.735
  E0413 12:56:12.080382      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:13.080478      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:14.081325      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:14.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator --since=1s'
  Apr 13 12:56:14.284: INFO: stderr: ""
  Apr 13 12:56:14.284: INFO: stdout: "I0413 12:56:13.302941       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/9qfm 569\nI0413 12:56:13.503170       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/8rh 477\nI0413 12:56:13.703457       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/ggg 228\nI0413 12:56:13.903768       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/7kh 504\nI0413 12:56:14.103002       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7gwd 291\n"
  Apr 13 12:56:14.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 logs logs-generator logs-generator --since=24h'
  Apr 13 12:56:14.332: INFO: stderr: ""
  Apr 13 12:56:14.332: INFO: stdout: "I0413 12:56:10.102801       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/4m5 361\nI0413 12:56:10.302897       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/4nnv 219\nI0413 12:56:10.503431       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/fjj8 478\nI0413 12:56:10.703729       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2s4s 275\nI0413 12:56:10.902890       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/k2q 252\nI0413 12:56:11.103146       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/hrf 546\nI0413 12:56:11.303463       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/pj7 320\nI0413 12:56:11.503753       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/bb2 268\nI0413 12:56:11.702980       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/9zm 280\nI0413 12:56:11.903165       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/pqz 330\nI0413 12:56:12.103462       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/6wgg 553\nI0413 12:56:12.303756       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/x5p 273\nI0413 12:56:12.502890       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/dznb 220\nI0413 12:56:12.703149       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/xxtd 486\nI0413 12:56:12.903446       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/xnh 465\nI0413 12:56:13.103749       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/vqwt 550\nI0413 12:56:13.302941       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/9qfm 569\nI0413 12:56:13.503170       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/8rh 477\nI0413 12:56:13.703457       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/ggg 228\nI0413 12:56:13.903768       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/7kh 504\nI0413 12:56:14.103002       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7gwd 291\nI0413 12:56:14.303158       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/p2j 381\n"
  Apr 13 12:56:14.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-logs-7137 delete pod logs-generator'
  E0413 12:56:15.082097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:15.551: INFO: stderr: ""
  Apr 13 12:56:15.551: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 13 12:56:15.551: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-7137" for this suite. @ 04/13/24 12:56:15.554
• [6.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/13/24 12:56:15.561
  Apr 13 12:56:15.561: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-runtime @ 04/13/24 12:56:15.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:15.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:15.578
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/13/24 12:56:15.589
  E0413 12:56:16.082494      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:17.082590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:18.083559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:19.083658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:20.083756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:21.084186      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:22.084751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:23.085526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:24.086444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:25.086579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:26.087319      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:27.087937      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:28.088960      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:29.089165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:30.089370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:31.090444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:32.090489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:33.091542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/13/24 12:56:33.678
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/13/24 12:56:33.682
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/13/24 12:56:33.688
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 04/13/24 12:56:33.688
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/13/24 12:56:33.71
  E0413 12:56:34.091690      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:35.092282      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/13/24 12:56:35.725
  E0413 12:56:36.093211      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:37.094194      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/13/24 12:56:37.737
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/13/24 12:56:37.744
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 04/13/24 12:56:37.744
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/13/24 12:56:37.768
  E0413 12:56:38.094868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/13/24 12:56:38.778
  E0413 12:56:39.095554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/13/24 12:56:39.787
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/13/24 12:56:39.793
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 04/13/24 12:56:39.793
  Apr 13 12:56:39.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1584" for this suite. @ 04/13/24 12:56:39.822
• [24.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 04/13/24 12:56:39.829
  Apr 13 12:56:39.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 12:56:39.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:39.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:39.847
  Apr 13 12:56:39.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8939 version'
  Apr 13 12:56:39.884: INFO: stderr: ""
  Apr 13 12:56:39.884: INFO: stdout: "Client Version: v1.29.3\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.3\n"
  Apr 13 12:56:39.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8939" for this suite. @ 04/13/24 12:56:39.888
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 04/13/24 12:56:39.894
  Apr 13 12:56:39.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-pred @ 04/13/24 12:56:39.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:39.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:39.91
  Apr 13 12:56:39.915: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 13 12:56:39.922: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 12:56:39.925: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-35-229 before test
  Apr 13 12:56:39.929: INFO: nginx-ingress-controller-kubernetes-worker-tchsj from ingress-nginx-kubernetes-worker started at 2024-04-13 12:16:24 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.929: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: calico-node-mrwfw from kube-system started at 2024-04-13 12:19:51 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.929: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: sonobuoy-e2e-job-e3618131f41d4cd5 from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 12:56:39.929: INFO: 	Container e2e ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-2fnld from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 12:56:39.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 12:56:39.929: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-65-227 before test
  Apr 13 12:56:39.937: INFO: nginx-ingress-controller-kubernetes-worker-fr5bd from ingress-nginx-kubernetes-worker started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.937: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 12:56:39.937: INFO: calico-node-lfv4l from kube-system started at 2024-04-13 12:20:12 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.937: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 12:56:39.938: INFO: coredns-bddfd76d7-xzr8q from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.938: INFO: 	Container coredns ready: true, restart count 0
  Apr 13 12:56:39.938: INFO: kube-state-metrics-78c475f58b-tmplf from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.938: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 13 12:56:39.938: INFO: metrics-server-v0.6.3-69d7fbfdf8-c2gtp from kube-system started at 2024-04-13 12:12:03 +0000 UTC (2 container statuses recorded)
  Apr 13 12:56:39.938: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 13 12:56:39.938: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 13 12:56:39.938: INFO: dashboard-metrics-scraper-5dd7cb5fc-fljfb from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.938: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 13 12:56:39.939: INFO: kubernetes-dashboard-7b899cb9d9-ss9wp from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.939: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 13 12:56:39.939: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-qn24t from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 12:56:39.939: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 12:56:39.939: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 12:56:39.939: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-63 before test
  Apr 13 12:56:39.946: INFO: nginx-ingress-controller-kubernetes-worker-x6l7w from ingress-nginx-kubernetes-worker started at 2024-04-13 12:47:31 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.946: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 12:56:39.946: INFO: calico-node-9p4gt from kube-system started at 2024-04-13 12:20:01 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.946: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 12:56:39.946: INFO: sonobuoy from sonobuoy started at 2024-04-13 12:20:25 +0000 UTC (1 container statuses recorded)
  Apr 13 12:56:39.946: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 13 12:56:39.946: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-sbrvb from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 12:56:39.946: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 12:56:39.946: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/13/24 12:56:39.946
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17c5d83f5e7b3427], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 04/13/24 12:56:39.97
  E0413 12:56:40.095695      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:40.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3119" for this suite. @ 04/13/24 12:56:40.971
• [1.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 04/13/24 12:56:40.978
  Apr 13 12:56:40.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:56:40.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:40.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:40.992
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/13/24 12:56:40.996
  E0413 12:56:41.095777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:42.095872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:43.096498      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:44.096726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:56:45.017
  Apr 13 12:56:45.020: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-09b34150-bfcc-4e2e-a057-8adb339fcc69 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 12:56:45.026
  Apr 13 12:56:45.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8997" for this suite. @ 04/13/24 12:56:45.05
• [4.079 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/13/24 12:56:45.057
  Apr 13 12:56:45.057: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-runtime @ 04/13/24 12:56:45.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:45.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:45.075
  STEP: create the container @ 04/13/24 12:56:45.08
  W0413 12:56:45.089439      21 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/13/24 12:56:45.089
  E0413 12:56:45.097391      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:46.097684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:47.098794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:48.098887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/13/24 12:56:48.11
  STEP: the container should be terminated @ 04/13/24 12:56:48.113
  STEP: the termination message should be set @ 04/13/24 12:56:48.113
  Apr 13 12:56:48.113: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/13/24 12:56:48.113
  Apr 13 12:56:48.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3401" for this suite. @ 04/13/24 12:56:48.133
• [3.082 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/13/24 12:56:48.139
  Apr 13 12:56:48.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 12:56:48.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:48.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:48.156
  E0413 12:56:49.098989      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:50.099079      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:51.099483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:52.099691      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:53.100350      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:54.101346      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:56:54.218
  Apr 13 12:56:54.222: INFO: Trying to get logs from node ip-172-31-35-229 pod client-envvars-20e8497e-05b5-402c-9aeb-88320a60ac6a container env3cont: <nil>
  STEP: delete the pod @ 04/13/24 12:56:54.237
  Apr 13 12:56:54.254: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3557" for this suite. @ 04/13/24 12:56:54.258
• [6.123 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 04/13/24 12:56:54.263
  Apr 13 12:56:54.263: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename runtimeclass @ 04/13/24 12:56:54.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:54.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:54.28
  Apr 13 12:56:54.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7354" for this suite. @ 04/13/24 12:56:54.294
• [0.036 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 04/13/24 12:56:54.299
  Apr 13 12:56:54.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 12:56:54.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:54.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:54.319
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/13/24 12:56:54.322
  E0413 12:56:55.101434      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:56:56.101534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/13/24 12:56:56.353
  STEP: Then the orphan pod is adopted @ 04/13/24 12:56:56.359
  E0413 12:56:57.102583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/13/24 12:56:57.367
  Apr 13 12:56:57.370: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/13/24 12:56:57.381
  E0413 12:56:58.103566      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:56:58.389: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4333" for this suite. @ 04/13/24 12:56:58.393
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 04/13/24 12:56:58.399
  Apr 13 12:56:58.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 12:56:58.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:56:58.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:56:58.415
  STEP: Creating the pod @ 04/13/24 12:56:58.418
  E0413 12:56:59.103719      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:00.103805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:00.961: INFO: Successfully updated pod "annotationupdatee1f85f5b-aecf-4e4c-b086-1c4415063694"
  E0413 12:57:01.104586      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:02.104680      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:03.104995      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:04.105101      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:04.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8363" for this suite. @ 04/13/24 12:57:04.986
• [6.594 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/13/24 12:57:04.993
  Apr 13 12:57:04.993: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename containers @ 04/13/24 12:57:04.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:05.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:05.009
  STEP: Creating a pod to test override command @ 04/13/24 12:57:05.014
  E0413 12:57:05.105467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:06.105609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:07.105852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:08.105970      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:57:09.035
  Apr 13 12:57:09.039: INFO: Trying to get logs from node ip-172-31-35-229 pod client-containers-b86198ac-c290-4ff6-b0df-4ca892d2954f container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 12:57:09.046
  Apr 13 12:57:09.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6006" for this suite. @ 04/13/24 12:57:09.065
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 04/13/24 12:57:09.071
  Apr 13 12:57:09.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 12:57:09.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:09.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:09.088
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 12:57:09.091
  E0413 12:57:09.106029      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:10.106388      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:11.106489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:12.106583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:13.106682      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 12:57:13.118
  Apr 13 12:57:13.123: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-0fe67b3c-d14b-49cd-8f7b-48a84cba1e60 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 12:57:13.129
  Apr 13 12:57:13.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3803" for this suite. @ 04/13/24 12:57:13.148
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/13/24 12:57:13.155
  Apr 13 12:57:13.155: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 12:57:13.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:13.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:13.171
  Apr 13 12:57:13.174: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 13 12:57:13.183: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0413 12:57:14.106776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:15.107552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:16.107650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:17.107747      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:18.108105      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:18.188: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 12:57:18.188
  Apr 13 12:57:18.188: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 13 12:57:18.196: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 13 12:57:18.212: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0413 12:57:19.108314      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:20.108403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:20.221: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 13 12:57:20.224: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 13 12:57:20.234: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ef5c2b06-5918-4dff-9ec8-9188760872c9",
      ResourceVersion: (string) (len=5) "18496",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609838,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 12:57:20.238: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1395aa60-4a4a-4d9a-a1f9-305600eaa87f",
      ResourceVersion: (string) (len=5) "18486",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609838,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ef5c2b06-5918-4dff-9ec8-9188760872c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 66 35 63 32 62  30 36 2d 35 39 31 38 2d  |\"ef5c2b06-5918-|
              00000120  34 64 66 66 2d 39 65 63  38 2d 39 31 38 38 37 36  |4dff-9ec8-918876|
              00000130  30 38 37 32 63 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0872c9\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:57:20.238: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 13 12:57:20.239: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "840d1bf6-8b94-44ad-8396-e6d27b2370ac",
      ResourceVersion: (string) (len=5) "18495",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609833,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ef5c2b06-5918-4dff-9ec8-9188760872c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609833,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 65 66 35 63 32 62 30  |"uid\":\"ef5c2b0|
              000000b0  36 2d 35 39 31 38 2d 34  64 66 66 2d 39 65 63 38  |6-5918-4dff-9ec8|
              000000c0  2d 39 31 38 38 37 36 30  38 37 32 63 39 5c 22 7d  |-9188760872c9\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 12:57:20.243: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-25srx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-25srx",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-2158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "36bf2bf1-3310-4350-9102-1490f72b7c55",
      ResourceVersion: (string) (len=5) "18485",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609838,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "1395aa60-4a4a-4d9a-a1f9-305600eaa87f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 33  39 35 61 61 36 30 2d 34  |d\":\"1395aa60-4|
              00000090  61 34 61 2d 34 64 39 61  2d 61 31 66 39 2d 33 30  |a4a-4d9a-a1f9-30|
              000000a0  35 36 30 30 65 61 61 38  37 66 5c 22 7d 22 3a 7b  |5600eaa87f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 35 37  2e 32 30 34 5c 22 7d 22  |2.168.57.204\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gstdq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gstdq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609839,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609838,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.204",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.204"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609838,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848609838,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://ba03a182f3512000e6f46f032d13f09a3c3daacf6378b51160d63d59f3f7fc29",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 12:57:20.244: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2158" for this suite. @ 04/13/24 12:57:20.248
• [7.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/13/24 12:57:20.256
  Apr 13 12:57:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 12:57:20.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:20.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:20.273
  STEP: Creating a test externalName service @ 04/13/24 12:57:20.276
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:20.28
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:20.28
  STEP: creating a pod to probe DNS @ 04/13/24 12:57:20.28
  STEP: submitting the pod to kubernetes @ 04/13/24 12:57:20.28
  E0413 12:57:21.108792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:22.108972      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 12:57:22.297
  STEP: looking for the results for each expected name from probers @ 04/13/24 12:57:22.299
  Apr 13 12:57:22.309: INFO: DNS probes using dns-test-52c1e558-99bc-45e3-a94b-b02f4778dfd9 succeeded

  STEP: changing the externalName to bar.example.com @ 04/13/24 12:57:22.309
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:22.318
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:22.318
  STEP: creating a second pod to probe DNS @ 04/13/24 12:57:22.318
  STEP: submitting the pod to kubernetes @ 04/13/24 12:57:22.318
  E0413 12:57:23.109842      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:24.109943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 12:57:24.331
  STEP: looking for the results for each expected name from probers @ 04/13/24 12:57:24.335
  Apr 13 12:57:24.340: INFO: File wheezy_udp@dns-test-service-3.dns-8851.svc.cluster.local from pod  dns-8851/dns-test-48c215ca-fd3a-49c5-bb95-8f40ac8fc3c5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 13 12:57:24.344: INFO: File jessie_udp@dns-test-service-3.dns-8851.svc.cluster.local from pod  dns-8851/dns-test-48c215ca-fd3a-49c5-bb95-8f40ac8fc3c5 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 13 12:57:24.344: INFO: Lookups using dns-8851/dns-test-48c215ca-fd3a-49c5-bb95-8f40ac8fc3c5 failed for: [wheezy_udp@dns-test-service-3.dns-8851.svc.cluster.local jessie_udp@dns-test-service-3.dns-8851.svc.cluster.local]

  Apr 13 12:57:24.351: INFO: Pod client logs for webserver: 
  Apr 13 12:57:24.357: INFO: Pod client logs for querier: 
  Apr 13 12:57:24.364: INFO: Pod client logs for jessie-querier: 
  E0413 12:57:25.109979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:26.110056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:27.110146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:28.110325      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:29.110482      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:29.345: INFO: DNS probes using dns-test-48c215ca-fd3a-49c5-bb95-8f40ac8fc3c5 succeeded

  STEP: changing the service to type=ClusterIP @ 04/13/24 12:57:29.345
  W0413 12:57:29.358040      21 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:29.358
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8851.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8851.svc.cluster.local; sleep 1; done
   @ 04/13/24 12:57:29.358
  STEP: creating a third pod to probe DNS @ 04/13/24 12:57:29.358
  STEP: submitting the pod to kubernetes @ 04/13/24 12:57:29.362
  E0413 12:57:30.110593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:31.110671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 12:57:31.376
  STEP: looking for the results for each expected name from probers @ 04/13/24 12:57:31.38
  Apr 13 12:57:31.388: INFO: DNS probes using dns-test-071e5925-67d9-4295-9199-408f7f790113 succeeded

  STEP: deleting the pod @ 04/13/24 12:57:31.388
  STEP: deleting the pod @ 04/13/24 12:57:31.402
  STEP: deleting the pod @ 04/13/24 12:57:31.416
  STEP: deleting the test externalName service @ 04/13/24 12:57:31.431
  Apr 13 12:57:31.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8851" for this suite. @ 04/13/24 12:57:31.451
• [11.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/13/24 12:57:31.46
  Apr 13 12:57:31.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename conformance-tests @ 04/13/24 12:57:31.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:31.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:31.477
  STEP: Getting node addresses @ 04/13/24 12:57:31.48
  Apr 13 12:57:31.480: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 13 12:57:31.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-9155" for this suite. @ 04/13/24 12:57:31.488
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 04/13/24 12:57:31.494
  Apr 13 12:57:31.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 12:57:31.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:31.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:31.509
  STEP: Creating Pod @ 04/13/24 12:57:31.512
  E0413 12:57:32.111514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:33.111595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/13/24 12:57:33.531
  Apr 13 12:57:33.531: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-281 PodName:pod-sharedvolume-f25d8e73-3b7d-4035-af0a-b3f4839abad2 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 12:57:33.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 12:57:33.531: INFO: ExecWithOptions: Clientset creation
  Apr 13 12:57:33.531: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-281/pods/pod-sharedvolume-f25d8e73-3b7d-4035-af0a-b3f4839abad2/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 13 12:57:33.584: INFO: Exec stderr: ""
  Apr 13 12:57:33.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-281" for this suite. @ 04/13/24 12:57:33.588
• [2.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/13/24 12:57:33.605
  Apr 13 12:57:33.605: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 12:57:33.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:33.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:33.622
  STEP: creating a Deployment @ 04/13/24 12:57:33.629
  STEP: waiting for Deployment to be created @ 04/13/24 12:57:33.635
  STEP: waiting for all Replicas to be Ready @ 04/13/24 12:57:33.637
  Apr 13 12:57:33.638: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.638: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.647: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.647: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.666: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.666: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.687: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 13 12:57:33.688: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0413 12:57:34.112308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:34.367: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 13 12:57:34.367: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 13 12:57:34.720: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/13/24 12:57:34.72
  Apr 13 12:57:34.729: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/13/24 12:57:34.729
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 0
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.731: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.739: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.739: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.749: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.749: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:34.764: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:34.764: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:34.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:34.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  E0413 12:57:35.112770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:35.378: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:35.378: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:35.400: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  STEP: listing Deployments @ 04/13/24 12:57:35.4
  Apr 13 12:57:35.412: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/13/24 12:57:35.412
  Apr 13 12:57:35.423: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/13/24 12:57:35.423
  Apr 13 12:57:35.429: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:35.432: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:35.449: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:35.471: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:35.482: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0413 12:57:36.112938      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:36.418: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:36.450: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 13 12:57:36.461: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0413 12:57:37.113309      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:37.743: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/13/24 12:57:37.765
  STEP: fetching the DeploymentStatus @ 04/13/24 12:57:37.775
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 1
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 2
  Apr 13 12:57:37.780: INFO: observed Deployment test-deployment in namespace deployment-1747 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/13/24 12:57:37.78
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.789: INFO: observed event type MODIFIED
  Apr 13 12:57:37.794: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 13 12:57:37.799: INFO: ReplicaSet "test-deployment-7fcc79b8c7":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-7fcc79b8c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1747",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "908e8c21-d67f-4a36-9ede-1ec8a34e611e",
      ResourceVersion: (string) (len=5) "18745",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848609853,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "d4a8dfc4-de81-4b01-80ee-52d85d1149cc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609855,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 64 34 61 38  64 66 63 34 2d 64 65 38  |":\"d4a8dfc4-de8|
              00000130  31 2d 34 62 30 31 2d 38  30 65 65 2d 35 32 64 38  |1-4b01-80ee-52d8|
              00000140  35 64 31 31 34 39 63 63  5c 22 7d 22 3a 7b 7d 7d  |5d1149cc\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848609855,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Apr 13 12:57:37.813: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1747" for this suite. @ 04/13/24 12:57:37.817
• [4.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/13/24 12:57:37.823
  Apr 13 12:57:37.823: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 12:57:37.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:37.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:37.841
  E0413 12:57:38.113605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:39.113811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:40.114446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:41.114518      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:42.114832      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:43.114918      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:44.116037      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:45.116083      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:46.116501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:47.116773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:48.116865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:49.116972      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:50.117919      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:51.117998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:52.118113      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:53.118207      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:54.119252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:55.120205      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:56.120792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:57.120894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:58.120978      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:57:59.121079      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 12:57:59.913: INFO: Container started at 2024-04-13 12:57:38 +0000 UTC, pod became ready at 2024-04-13 12:57:58 +0000 UTC
  Apr 13 12:57:59.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5844" for this suite. @ 04/13/24 12:57:59.917
• [22.101 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 04/13/24 12:57:59.924
  Apr 13 12:57:59.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 12:57:59.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:57:59.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:57:59.942
  STEP: creating an Endpoint @ 04/13/24 12:57:59.95
  STEP: waiting for available Endpoint @ 04/13/24 12:57:59.956
  STEP: listing all Endpoints @ 04/13/24 12:57:59.958
  STEP: updating the Endpoint @ 04/13/24 12:57:59.961
  STEP: fetching the Endpoint @ 04/13/24 12:57:59.967
  STEP: patching the Endpoint @ 04/13/24 12:57:59.97
  STEP: fetching the Endpoint @ 04/13/24 12:57:59.977
  STEP: deleting the Endpoint by Collection @ 04/13/24 12:57:59.98
  STEP: waiting for Endpoint deletion @ 04/13/24 12:57:59.987
  STEP: fetching the Endpoint @ 04/13/24 12:57:59.989
  Apr 13 12:57:59.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9239" for this suite. @ 04/13/24 12:57:59.995
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/13/24 12:58:00.002
  Apr 13 12:58:00.002: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename cronjob @ 04/13/24 12:58:00.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 12:58:00.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 12:58:00.018
  STEP: Creating a ReplaceConcurrent cronjob @ 04/13/24 12:58:00.021
  STEP: Ensuring a job is scheduled @ 04/13/24 12:58:00.028
  E0413 12:58:00.121550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:01.121664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:02.121993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:03.122252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:04.122561      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:05.123573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:06.124488      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:07.124757      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:08.125308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:09.125420      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:10.126292      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:11.126468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:12.127182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:13.127281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:14.127924      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:15.128115      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:16.128128      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:17.128367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:18.128660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:19.128832      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:20.129342      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:21.129534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:22.130235      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:23.130485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:24.130773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:25.130880      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:26.131540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:27.131756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:28.132760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:29.133060      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:30.133877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:31.134068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:32.134167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:33.134501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:34.135242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:35.135349      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:36.135438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:37.135533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:38.136194      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:39.136305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:40.136476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:41.136514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:42.136786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:43.137072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:44.137863      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:45.137983      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:46.138867      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:47.139536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:48.139793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:49.139894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:50.140620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:51.141035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:52.141372      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:53.141472      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:54.141526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:55.141799      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:56.142575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:57.142658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:58.142974      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:58:59.143549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:00.143783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:01.143897      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/13/24 12:59:02.032
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/13/24 12:59:02.036
  STEP: Ensuring the job is replaced with a new one @ 04/13/24 12:59:02.038
  E0413 12:59:02.144183      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:03.144444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:04.144926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:05.145018      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:06.145173      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:07.145472      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:08.146081      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:09.146197      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:10.146618      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:11.147557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:12.148459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:13.148675      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:14.148974      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:15.149094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:16.149181      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:17.149281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:18.149333      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:19.149619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:20.150402      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:21.150492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:22.150786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:23.150877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:24.151658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:25.151789      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:26.152692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:27.152786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:28.153692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:29.153894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:30.154625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:31.155628      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:32.156090      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:33.156158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:34.156786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:35.156994      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:36.157091      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:37.157342      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:38.157672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:39.157768      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:40.158490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:41.158587      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:42.159187      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:43.159270      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:44.159944      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:45.160041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:46.160126      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:47.160367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:48.161402      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:49.162096      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:50.162177      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:51.162414      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:52.163376      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:53.163487      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:54.164544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:55.164778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:56.165469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:57.165771      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:58.166194      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 12:59:59.166398      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:00.166847      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:01.166933      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/13/24 13:00:02.043
  Apr 13 13:00:02.049: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8669" for this suite. @ 04/13/24 13:00:02.053
• [122.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 04/13/24 13:00:02.06
  Apr 13 13:00:02.060: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:00:02.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:02.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:02.079
  STEP: Setting up server cert @ 04/13/24 13:00:02.101
  E0413 13:00:02.167865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:00:02.288
  STEP: Deploying the webhook pod @ 04/13/24 13:00:02.298
  STEP: Wait for the deployment to be ready @ 04/13/24 13:00:02.311
  Apr 13 13:00:02.317: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0413 13:00:03.168539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:04.168622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:00:04.329
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:00:04.338
  E0413 13:00:05.168715      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:00:05.338: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 13 13:00:05.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9452-crds.webhook.example.com via the AdmissionRegistration API @ 04/13/24 13:00:05.86
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/13/24 13:00:05.874
  E0413 13:00:06.169469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:07.169753      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:08.170477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:00:08.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5551" for this suite. @ 04/13/24 13:00:08.472
  STEP: Destroying namespace "webhook-markers-7954" for this suite. @ 04/13/24 13:00:08.48
• [6.426 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 04/13/24 13:00:08.489
  Apr 13 13:00:08.489: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:00:08.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:08.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:08.503
  STEP: Setting up server cert @ 04/13/24 13:00:08.527
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:00:08.886
  STEP: Deploying the webhook pod @ 04/13/24 13:00:08.891
  STEP: Wait for the deployment to be ready @ 04/13/24 13:00:08.903
  Apr 13 13:00:08.911: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:00:09.170904      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:10.170975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:00:10.923
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:00:10.934
  E0413 13:00:11.171858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:00:11.937: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/13/24 13:00:11.944
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/13/24 13:00:11.945
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/13/24 13:00:11.957
  E0413 13:00:12.172310      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/13/24 13:00:12.969
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/13/24 13:00:12.969
  E0413 13:00:13.173239      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/13/24 13:00:13.997
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/13/24 13:00:13.997
  E0413 13:00:14.173852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:15.173969      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:16.174070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:17.174870      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:18.174985      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/13/24 13:00:19.028
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/13/24 13:00:19.028
  E0413 13:00:19.176064      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:20.176155      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:21.176288      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:22.176361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:23.176435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:00:24.116: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8076" for this suite. @ 04/13/24 13:00:24.119
  STEP: Destroying namespace "webhook-markers-7370" for this suite. @ 04/13/24 13:00:24.125
• [15.641 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/13/24 13:00:24.131
  Apr 13 13:00:24.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:00:24.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:24.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:24.147
  STEP: Creating projection with secret that has name projected-secret-test-95fd42a2-3e7d-4d15-b92d-8db60d678e55 @ 04/13/24 13:00:24.15
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:00:24.154
  E0413 13:00:24.176911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:25.177116      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:00:26.17
  Apr 13 13:00:26.173: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-cb592943-cf7e-4e6a-aced-fce38c68c649 container projected-secret-volume-test: <nil>
  E0413 13:00:26.177190      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/13/24 13:00:26.188
  Apr 13 13:00:26.204: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9715" for this suite. @ 04/13/24 13:00:26.207
• [2.081 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 04/13/24 13:00:26.213
  Apr 13 13:00:26.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:00:26.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:26.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:26.23
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/13/24 13:00:26.233
  E0413 13:00:27.177364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:28.177502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:00:28.251
  Apr 13 13:00:28.255: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-02632fc3-5882-45bb-aeda-b5e8c909e914 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:00:28.26
  Apr 13 13:00:28.276: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2826" for this suite. @ 04/13/24 13:00:28.279
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/13/24 13:00:28.286
  Apr 13 13:00:28.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename cronjob @ 04/13/24 13:00:28.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:28.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:28.302
  STEP: Creating a cronjob @ 04/13/24 13:00:28.307
  STEP: creating @ 04/13/24 13:00:28.307
  STEP: getting @ 04/13/24 13:00:28.315
  STEP: listing @ 04/13/24 13:00:28.318
  STEP: watching @ 04/13/24 13:00:28.32
  Apr 13 13:00:28.320: INFO: starting watch
  STEP: cluster-wide listing @ 04/13/24 13:00:28.321
  STEP: cluster-wide watching @ 04/13/24 13:00:28.325
  Apr 13 13:00:28.325: INFO: starting watch
  STEP: patching @ 04/13/24 13:00:28.326
  STEP: updating @ 04/13/24 13:00:28.332
  Apr 13 13:00:28.341: INFO: waiting for watch events with expected annotations
  Apr 13 13:00:28.341: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/13/24 13:00:28.341
  STEP: updating /status @ 04/13/24 13:00:28.348
  STEP: get /status @ 04/13/24 13:00:28.355
  STEP: deleting @ 04/13/24 13:00:28.358
  STEP: deleting a collection @ 04/13/24 13:00:28.371
  Apr 13 13:00:28.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1121" for this suite. @ 04/13/24 13:00:28.385
• [0.107 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/13/24 13:00:28.393
  Apr 13 13:00:28.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:00:28.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:28.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:28.407
  STEP: Creating a pod to test substitution in container's args @ 04/13/24 13:00:28.41
  E0413 13:00:29.177612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:30.177712      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:31.177833      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:32.178050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:00:32.432
  Apr 13 13:00:32.436: INFO: Trying to get logs from node ip-172-31-82-63 pod var-expansion-e1b19ec6-bcd3-49a1-8ce2-e712b453ddb4 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 13:00:32.441
  Apr 13 13:00:32.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4455" for this suite. @ 04/13/24 13:00:32.461
• [4.075 seconds]
------------------------------
S
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 04/13/24 13:00:32.468
  Apr 13 13:00:32.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:00:32.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:32.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:32.486
  STEP: creating a Service @ 04/13/24 13:00:32.492
  STEP: watching for the Service to be added @ 04/13/24 13:00:32.508
  Apr 13 13:00:32.510: INFO: Found Service test-service-6h9lq in namespace services-308 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31783}]
  Apr 13 13:00:32.510: INFO: Service test-service-6h9lq created
  STEP: Getting /status @ 04/13/24 13:00:32.51
  Apr 13 13:00:32.515: INFO: Service test-service-6h9lq has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/13/24 13:00:32.515
  STEP: watching for the Service to be patched @ 04/13/24 13:00:32.521
  Apr 13 13:00:32.522: INFO: observed Service test-service-6h9lq in namespace services-308 with annotations: map[] & LoadBalancer: {[]}
  Apr 13 13:00:32.522: INFO: Found Service test-service-6h9lq in namespace services-308 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Apr 13 13:00:32.522: INFO: Service test-service-6h9lq has service status patched
  STEP: updating the ServiceStatus @ 04/13/24 13:00:32.522
  Apr 13 13:00:32.530: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/13/24 13:00:32.53
  Apr 13 13:00:32.532: INFO: Observed Service test-service-6h9lq in namespace services-308 with annotations: map[] & Conditions: {[]}
  Apr 13 13:00:32.532: INFO: Observed event: &Service{ObjectMeta:{test-service-6h9lq  services-308  3d96a8f9-2fb0-486c-bae3-b47e787d657c 19739 0 2024-04-13 13:00:32 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-13 13:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-13 13:00:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:31783,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.215,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.215],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 13 13:00:32.533: INFO: Found Service test-service-6h9lq in namespace services-308 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 13 13:00:32.533: INFO: Service test-service-6h9lq has service status updated
  STEP: patching the service @ 04/13/24 13:00:32.533
  STEP: watching for the Service to be patched @ 04/13/24 13:00:32.545
  Apr 13 13:00:32.547: INFO: observed Service test-service-6h9lq in namespace services-308 with labels: map[test-service-static:true]
  Apr 13 13:00:32.547: INFO: observed Service test-service-6h9lq in namespace services-308 with labels: map[test-service-static:true]
  Apr 13 13:00:32.547: INFO: observed Service test-service-6h9lq in namespace services-308 with labels: map[test-service-static:true]
  Apr 13 13:00:32.547: INFO: Found Service test-service-6h9lq in namespace services-308 with labels: map[test-service:patched test-service-static:true]
  Apr 13 13:00:32.547: INFO: Service test-service-6h9lq patched
  STEP: deleting the service @ 04/13/24 13:00:32.547
  STEP: watching for the Service to be deleted @ 04/13/24 13:00:32.561
  Apr 13 13:00:32.562: INFO: Observed event: ADDED
  Apr 13 13:00:32.563: INFO: Observed event: MODIFIED
  Apr 13 13:00:32.563: INFO: Observed event: MODIFIED
  Apr 13 13:00:32.563: INFO: Observed event: MODIFIED
  Apr 13 13:00:32.563: INFO: Found Service test-service-6h9lq in namespace services-308 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 13 13:00:32.563: INFO: Service test-service-6h9lq deleted
  Apr 13 13:00:32.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-308" for this suite. @ 04/13/24 13:00:32.566
• [0.104 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/13/24 13:00:32.572
  Apr 13 13:00:32.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption @ 04/13/24 13:00:32.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:00:32.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:00:32.588
  Apr 13 13:00:32.605: INFO: Waiting up to 1m0s for all nodes to be ready
  E0413 13:00:33.178235      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:34.178482      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:35.178605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:36.178687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:37.179207      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:38.179319      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:39.179476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:40.179567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:41.180018      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:42.180217      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:43.180605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:44.180711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:45.181557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:46.182022      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:47.182408      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:48.182487      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:49.182543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:50.183522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:51.183856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:52.184023      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:53.184752      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:54.184835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:55.184945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:56.185159      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:57.185485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:58.185625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:00:59.185713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:00.186157      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:01.186882      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:02.187529      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:03.187857      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:04.188338      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:05.188402      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:06.189293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:07.189413      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:08.189522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:09.189625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:10.189912      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:11.190019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:12.190212      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:13.190459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:14.192747      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:15.192869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:16.193755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:17.194607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:18.195525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:19.195635      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:20.195731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:21.195828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:22.195987      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:23.196436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:24.196605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:25.196755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:26.197031      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:27.197683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:28.197966      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:29.198869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:30.199520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:31.199677      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:32.199788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:32.611: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/13/24 13:01:32.614
  Apr 13 13:01:32.614: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/13/24 13:01:32.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:01:32.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:01:32.636
  STEP: Finding an available node @ 04/13/24 13:01:32.639
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/13/24 13:01:32.639
  E0413 13:01:33.200620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:34.200932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/13/24 13:01:34.662
  Apr 13 13:01:34.673: INFO: found a healthy node: ip-172-31-82-63
  E0413 13:01:35.201951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:36.201969      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:37.202053      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:38.202256      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:39.202486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:40.203223      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:40.734: INFO: pods created so far: [1 1 1]
  Apr 13 13:01:40.734: INFO: length of pods created so far: 3
  E0413 13:01:41.203750      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:42.203853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:42.748: INFO: pods created so far: [2 2 1]
  E0413 13:01:43.204170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:44.204450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:45.205491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:46.205704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:47.205856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:48.206403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:49.206545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:49.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9375" for this suite. @ 04/13/24 13:01:49.815
  Apr 13 13:01:49.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8790" for this suite. @ 04/13/24 13:01:49.825
• [77.260 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 04/13/24 13:01:49.832
  Apr 13 13:01:49.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:01:49.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:01:49.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:01:49.853
  STEP: Setting up server cert @ 04/13/24 13:01:49.872
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:01:50.078
  STEP: Deploying the webhook pod @ 04/13/24 13:01:50.088
  STEP: Wait for the deployment to be ready @ 04/13/24 13:01:50.108
  Apr 13 13:01:50.115: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:01:50.207159      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:51.207563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:01:52.128
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:01:52.139
  E0413 13:01:52.208152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:53.140: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/13/24 13:01:53.148
  STEP: create a pod that should be updated by the webhook @ 04/13/24 13:01:53.162
  E0413 13:01:53.209075      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:53.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3315" for this suite. @ 04/13/24 13:01:53.228
  STEP: Destroying namespace "webhook-markers-1920" for this suite. @ 04/13/24 13:01:53.235
• [3.409 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 04/13/24 13:01:53.242
  Apr 13 13:01:53.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename init-container @ 04/13/24 13:01:53.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:01:53.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:01:53.259
  STEP: creating the pod @ 04/13/24 13:01:53.262
  Apr 13 13:01:53.262: INFO: PodSpec: initContainers in spec.initContainers
  E0413 13:01:54.209492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:55.210521      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:56.211084      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:57.211528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:01:57.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-462" for this suite. @ 04/13/24 13:01:57.344
• [4.108 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 04/13/24 13:01:57.35
  Apr 13 13:01:57.350: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 13:01:57.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:01:57.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:01:57.371
  STEP: create the rc @ 04/13/24 13:01:57.378
  W0413 13:01:57.384533      21 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0413 13:01:58.212296      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:01:59.213373      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:00.213755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:01.214308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:02.266509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:03.267538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/13/24 13:02:03.39
  STEP: wait for the rc to be deleted @ 04/13/24 13:02:03.396
  E0413 13:02:04.267651      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:05.268683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:06.268822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:07.268917      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:08.269228      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/13/24 13:02:08.401
  E0413 13:02:09.269524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:10.269760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:11.269943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:12.270033      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:13.270647      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:14.271552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:15.271739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:16.271879      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:17.272710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:18.272823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:19.272911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:20.273070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:21.273265      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:22.273701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:23.273901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:24.274941      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:25.275035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:26.275136      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:27.275666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:28.275844      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:29.276482      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:30.276571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:31.276774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:32.277167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:33.277269      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:34.277380      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:35.277563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:36.277672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:37.277893      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:38.278106      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/13/24 13:02:38.409
  W0413 13:02:38.414061      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 13:02:38.414: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 13:02:38.414: INFO: Deleting pod "simpletest.rc-289vz" in namespace "gc-6320"
  Apr 13 13:02:38.427: INFO: Deleting pod "simpletest.rc-28xq7" in namespace "gc-6320"
  Apr 13 13:02:38.437: INFO: Deleting pod "simpletest.rc-2bg5k" in namespace "gc-6320"
  Apr 13 13:02:38.448: INFO: Deleting pod "simpletest.rc-2jrqw" in namespace "gc-6320"
  Apr 13 13:02:38.460: INFO: Deleting pod "simpletest.rc-45sjk" in namespace "gc-6320"
  Apr 13 13:02:38.474: INFO: Deleting pod "simpletest.rc-45zdx" in namespace "gc-6320"
  Apr 13 13:02:38.487: INFO: Deleting pod "simpletest.rc-47pd7" in namespace "gc-6320"
  Apr 13 13:02:38.499: INFO: Deleting pod "simpletest.rc-49lpm" in namespace "gc-6320"
  Apr 13 13:02:38.512: INFO: Deleting pod "simpletest.rc-4k8k2" in namespace "gc-6320"
  Apr 13 13:02:38.527: INFO: Deleting pod "simpletest.rc-4kbtj" in namespace "gc-6320"
  Apr 13 13:02:38.540: INFO: Deleting pod "simpletest.rc-4ngzn" in namespace "gc-6320"
  Apr 13 13:02:38.563: INFO: Deleting pod "simpletest.rc-4sq6s" in namespace "gc-6320"
  Apr 13 13:02:38.572: INFO: Deleting pod "simpletest.rc-4w9sp" in namespace "gc-6320"
  Apr 13 13:02:38.585: INFO: Deleting pod "simpletest.rc-4zx8b" in namespace "gc-6320"
  Apr 13 13:02:38.598: INFO: Deleting pod "simpletest.rc-58wfg" in namespace "gc-6320"
  Apr 13 13:02:38.611: INFO: Deleting pod "simpletest.rc-5km89" in namespace "gc-6320"
  Apr 13 13:02:38.624: INFO: Deleting pod "simpletest.rc-5wdmr" in namespace "gc-6320"
  Apr 13 13:02:38.637: INFO: Deleting pod "simpletest.rc-5wftl" in namespace "gc-6320"
  Apr 13 13:02:38.649: INFO: Deleting pod "simpletest.rc-67lc8" in namespace "gc-6320"
  Apr 13 13:02:38.661: INFO: Deleting pod "simpletest.rc-6dx6w" in namespace "gc-6320"
  Apr 13 13:02:38.674: INFO: Deleting pod "simpletest.rc-6kr75" in namespace "gc-6320"
  Apr 13 13:02:38.689: INFO: Deleting pod "simpletest.rc-6pvcl" in namespace "gc-6320"
  Apr 13 13:02:38.702: INFO: Deleting pod "simpletest.rc-76vc8" in namespace "gc-6320"
  Apr 13 13:02:38.717: INFO: Deleting pod "simpletest.rc-7bqhd" in namespace "gc-6320"
  Apr 13 13:02:38.728: INFO: Deleting pod "simpletest.rc-8qtl8" in namespace "gc-6320"
  Apr 13 13:02:38.740: INFO: Deleting pod "simpletest.rc-8s4c7" in namespace "gc-6320"
  Apr 13 13:02:38.752: INFO: Deleting pod "simpletest.rc-9v56c" in namespace "gc-6320"
  Apr 13 13:02:38.763: INFO: Deleting pod "simpletest.rc-b89nn" in namespace "gc-6320"
  Apr 13 13:02:38.784: INFO: Deleting pod "simpletest.rc-bf27b" in namespace "gc-6320"
  Apr 13 13:02:38.795: INFO: Deleting pod "simpletest.rc-bq2tz" in namespace "gc-6320"
  Apr 13 13:02:38.807: INFO: Deleting pod "simpletest.rc-bz5wr" in namespace "gc-6320"
  Apr 13 13:02:38.819: INFO: Deleting pod "simpletest.rc-c8vnt" in namespace "gc-6320"
  Apr 13 13:02:38.829: INFO: Deleting pod "simpletest.rc-cc57j" in namespace "gc-6320"
  Apr 13 13:02:38.844: INFO: Deleting pod "simpletest.rc-cpd5z" in namespace "gc-6320"
  Apr 13 13:02:38.863: INFO: Deleting pod "simpletest.rc-ct7ls" in namespace "gc-6320"
  Apr 13 13:02:38.873: INFO: Deleting pod "simpletest.rc-dhbww" in namespace "gc-6320"
  Apr 13 13:02:38.887: INFO: Deleting pod "simpletest.rc-dz9rt" in namespace "gc-6320"
  Apr 13 13:02:38.900: INFO: Deleting pod "simpletest.rc-fjnlg" in namespace "gc-6320"
  Apr 13 13:02:38.914: INFO: Deleting pod "simpletest.rc-fpnhm" in namespace "gc-6320"
  Apr 13 13:02:38.926: INFO: Deleting pod "simpletest.rc-fthn8" in namespace "gc-6320"
  Apr 13 13:02:38.940: INFO: Deleting pod "simpletest.rc-g27lt" in namespace "gc-6320"
  Apr 13 13:02:38.953: INFO: Deleting pod "simpletest.rc-gk9nd" in namespace "gc-6320"
  Apr 13 13:02:38.969: INFO: Deleting pod "simpletest.rc-gkgfj" in namespace "gc-6320"
  Apr 13 13:02:38.983: INFO: Deleting pod "simpletest.rc-h4n2k" in namespace "gc-6320"
  Apr 13 13:02:38.996: INFO: Deleting pod "simpletest.rc-hc8rz" in namespace "gc-6320"
  Apr 13 13:02:39.008: INFO: Deleting pod "simpletest.rc-hmjxd" in namespace "gc-6320"
  Apr 13 13:02:39.021: INFO: Deleting pod "simpletest.rc-htdmj" in namespace "gc-6320"
  Apr 13 13:02:39.033: INFO: Deleting pod "simpletest.rc-hxx6k" in namespace "gc-6320"
  Apr 13 13:02:39.048: INFO: Deleting pod "simpletest.rc-jknpq" in namespace "gc-6320"
  Apr 13 13:02:39.062: INFO: Deleting pod "simpletest.rc-jp2v6" in namespace "gc-6320"
  Apr 13 13:02:39.081: INFO: Deleting pod "simpletest.rc-kf6pl" in namespace "gc-6320"
  Apr 13 13:02:39.097: INFO: Deleting pod "simpletest.rc-kpg7x" in namespace "gc-6320"
  Apr 13 13:02:39.109: INFO: Deleting pod "simpletest.rc-kqksp" in namespace "gc-6320"
  Apr 13 13:02:39.124: INFO: Deleting pod "simpletest.rc-l2klb" in namespace "gc-6320"
  Apr 13 13:02:39.139: INFO: Deleting pod "simpletest.rc-l47r4" in namespace "gc-6320"
  Apr 13 13:02:39.155: INFO: Deleting pod "simpletest.rc-ldnvt" in namespace "gc-6320"
  Apr 13 13:02:39.168: INFO: Deleting pod "simpletest.rc-lgdpb" in namespace "gc-6320"
  Apr 13 13:02:39.183: INFO: Deleting pod "simpletest.rc-lmq25" in namespace "gc-6320"
  Apr 13 13:02:39.195: INFO: Deleting pod "simpletest.rc-m6cr9" in namespace "gc-6320"
  Apr 13 13:02:39.209: INFO: Deleting pod "simpletest.rc-mtc78" in namespace "gc-6320"
  Apr 13 13:02:39.219: INFO: Deleting pod "simpletest.rc-mw6hs" in namespace "gc-6320"
  Apr 13 13:02:39.232: INFO: Deleting pod "simpletest.rc-n9qt8" in namespace "gc-6320"
  Apr 13 13:02:39.250: INFO: Deleting pod "simpletest.rc-njsmj" in namespace "gc-6320"
  Apr 13 13:02:39.264: INFO: Deleting pod "simpletest.rc-nk4rj" in namespace "gc-6320"
  Apr 13 13:02:39.278: INFO: Deleting pod "simpletest.rc-nkdks" in namespace "gc-6320"
  E0413 13:02:39.278275      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:39.290: INFO: Deleting pod "simpletest.rc-nr8kf" in namespace "gc-6320"
  Apr 13 13:02:39.313: INFO: Deleting pod "simpletest.rc-ntj26" in namespace "gc-6320"
  Apr 13 13:02:39.372: INFO: Deleting pod "simpletest.rc-pcncv" in namespace "gc-6320"
  Apr 13 13:02:39.426: INFO: Deleting pod "simpletest.rc-pm2pb" in namespace "gc-6320"
  Apr 13 13:02:39.468: INFO: Deleting pod "simpletest.rc-q279v" in namespace "gc-6320"
  Apr 13 13:02:39.511: INFO: Deleting pod "simpletest.rc-q8pmk" in namespace "gc-6320"
  Apr 13 13:02:39.563: INFO: Deleting pod "simpletest.rc-qrls6" in namespace "gc-6320"
  Apr 13 13:02:39.616: INFO: Deleting pod "simpletest.rc-qsfdp" in namespace "gc-6320"
  Apr 13 13:02:39.666: INFO: Deleting pod "simpletest.rc-r5btl" in namespace "gc-6320"
  Apr 13 13:02:39.714: INFO: Deleting pod "simpletest.rc-rhdgz" in namespace "gc-6320"
  Apr 13 13:02:39.767: INFO: Deleting pod "simpletest.rc-s87x9" in namespace "gc-6320"
  Apr 13 13:02:39.817: INFO: Deleting pod "simpletest.rc-sdj64" in namespace "gc-6320"
  Apr 13 13:02:39.862: INFO: Deleting pod "simpletest.rc-tpg9w" in namespace "gc-6320"
  Apr 13 13:02:39.919: INFO: Deleting pod "simpletest.rc-tsz7w" in namespace "gc-6320"
  Apr 13 13:02:39.965: INFO: Deleting pod "simpletest.rc-vktbp" in namespace "gc-6320"
  Apr 13 13:02:40.013: INFO: Deleting pod "simpletest.rc-vrrml" in namespace "gc-6320"
  Apr 13 13:02:40.081: INFO: Deleting pod "simpletest.rc-vxg5z" in namespace "gc-6320"
  Apr 13 13:02:40.121: INFO: Deleting pod "simpletest.rc-w4wbp" in namespace "gc-6320"
  Apr 13 13:02:40.169: INFO: Deleting pod "simpletest.rc-w9674" in namespace "gc-6320"
  Apr 13 13:02:40.219: INFO: Deleting pod "simpletest.rc-wdh44" in namespace "gc-6320"
  Apr 13 13:02:40.267: INFO: Deleting pod "simpletest.rc-wxr7b" in namespace "gc-6320"
  E0413 13:02:40.278790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:40.330: INFO: Deleting pod "simpletest.rc-wz6h2" in namespace "gc-6320"
  Apr 13 13:02:40.371: INFO: Deleting pod "simpletest.rc-x2ks7" in namespace "gc-6320"
  Apr 13 13:02:40.427: INFO: Deleting pod "simpletest.rc-x56rv" in namespace "gc-6320"
  Apr 13 13:02:40.466: INFO: Deleting pod "simpletest.rc-x5v7j" in namespace "gc-6320"
  Apr 13 13:02:40.514: INFO: Deleting pod "simpletest.rc-xr2z4" in namespace "gc-6320"
  Apr 13 13:02:40.567: INFO: Deleting pod "simpletest.rc-xs8fl" in namespace "gc-6320"
  Apr 13 13:02:40.615: INFO: Deleting pod "simpletest.rc-xslf6" in namespace "gc-6320"
  Apr 13 13:02:40.702: INFO: Deleting pod "simpletest.rc-xt48g" in namespace "gc-6320"
  Apr 13 13:02:40.716: INFO: Deleting pod "simpletest.rc-z6wg9" in namespace "gc-6320"
  Apr 13 13:02:40.778: INFO: Deleting pod "simpletest.rc-zf4q8" in namespace "gc-6320"
  Apr 13 13:02:40.816: INFO: Deleting pod "simpletest.rc-zgdv4" in namespace "gc-6320"
  Apr 13 13:02:40.880: INFO: Deleting pod "simpletest.rc-zhqj7" in namespace "gc-6320"
  Apr 13 13:02:40.915: INFO: Deleting pod "simpletest.rc-zlhfs" in namespace "gc-6320"
  Apr 13 13:02:40.967: INFO: Deleting pod "simpletest.rc-zs4zz" in namespace "gc-6320"
  Apr 13 13:02:41.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6320" for this suite. @ 04/13/24 13:02:41.062
• [43.772 seconds]
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 04/13/24 13:02:41.122
  Apr 13 13:02:41.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 13:02:41.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:41.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:41.148
  Apr 13 13:02:41.171: INFO: created pod pod-service-account-defaultsa
  Apr 13 13:02:41.171: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Apr 13 13:02:41.179: INFO: created pod pod-service-account-mountsa
  Apr 13 13:02:41.179: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 13 13:02:41.188: INFO: created pod pod-service-account-nomountsa
  Apr 13 13:02:41.188: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 13 13:02:41.197: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 13 13:02:41.197: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 13 13:02:41.204: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 13 13:02:41.204: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 13 13:02:41.210: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 13 13:02:41.210: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 13 13:02:41.216: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 13 13:02:41.216: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 13 13:02:41.224: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 13 13:02:41.224: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 13 13:02:41.230: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 13 13:02:41.230: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 13 13:02:41.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7535" for this suite. @ 04/13/24 13:02:41.238
• [0.126 seconds]
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 04/13/24 13:02:41.248
  Apr 13 13:02:41.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename apf @ 04/13/24 13:02:41.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:41.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:41.266
  STEP: getting /apis @ 04/13/24 13:02:41.27
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/13/24 13:02:41.274
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/13/24 13:02:41.275
  STEP: creating @ 04/13/24 13:02:41.277
  E0413 13:02:41.279441      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting @ 04/13/24 13:02:41.297
  STEP: listing @ 04/13/24 13:02:41.301
  STEP: watching @ 04/13/24 13:02:41.304
  Apr 13 13:02:41.304: INFO: starting watch
  STEP: patching @ 04/13/24 13:02:41.306
  STEP: updating @ 04/13/24 13:02:41.311
  Apr 13 13:02:41.321: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 04/13/24 13:02:41.321
  STEP: patching /status @ 04/13/24 13:02:41.324
  STEP: updating /status @ 04/13/24 13:02:41.331
  STEP: deleting @ 04/13/24 13:02:41.341
  STEP: deleting a collection @ 04/13/24 13:02:41.357
  Apr 13 13:02:41.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-1805" for this suite. @ 04/13/24 13:02:41.387
• [0.146 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 04/13/24 13:02:41.395
  Apr 13 13:02:41.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:02:41.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:41.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:41.415
  Apr 13 13:02:41.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 create -f -'
  Apr 13 13:02:41.862: INFO: stderr: ""
  Apr 13 13:02:41.862: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 13 13:02:41.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 create -f -'
  Apr 13 13:02:42.154: INFO: stderr: ""
  Apr 13 13:02:42.154: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/13/24 13:02:42.154
  E0413 13:02:42.281002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:43.158: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:02:43.158: INFO: Found 0 / 1
  E0413 13:02:43.281784      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:44.158: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:02:44.158: INFO: Found 1 / 1
  Apr 13 13:02:44.158: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 13 13:02:44.161: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:02:44.161: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 13 13:02:44.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 describe pod agnhost-primary-hsg65'
  Apr 13 13:02:44.221: INFO: stderr: ""
  Apr 13 13:02:44.221: INFO: stdout: "Name:             agnhost-primary-hsg65\nNamespace:        kubectl-5246\nPriority:         0\nService Account:  default\nNode:             ip-172-31-65-227/172.31.65.227\nStart Time:       Sat, 13 Apr 2024 13:02:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.254.224\nIPs:\n  IP:           192.168.254.224\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://96eac73ffc5f7d1ab94f016e2799b71482c0ed6506697a56568b754f3a616da6\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 13 Apr 2024 13:02:43 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6mtmc (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-6mtmc:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5246/agnhost-primary-hsg65 to ip-172-31-65-227\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 13 13:02:44.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 describe rc agnhost-primary'
  Apr 13 13:02:44.274: INFO: stderr: ""
  Apr 13 13:02:44.274: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5246\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-hsg65\n"
  Apr 13 13:02:44.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 describe service agnhost-primary'
  E0413 13:02:44.282597      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:44.331: INFO: stderr: ""
  Apr 13 13:02:44.331: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5246\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.178\nIPs:               10.152.183.178\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.254.224:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 13 13:02:44.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 describe node ip-172-31-28-251'
  Apr 13 13:02:44.444: INFO: stderr: ""
  Apr 13 13:02:44.444: INFO: stdout: "Name:               ip-172-31-28-251\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-28-251\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 13 Apr 2024 11:58:53 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-28-251\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 13 Apr 2024 13:02:37 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 13 Apr 2024 12:19:44 +0000   Sat, 13 Apr 2024 12:19:44 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 13 Apr 2024 13:01:35 +0000   Sat, 13 Apr 2024 12:14:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 13 Apr 2024 13:01:35 +0000   Sat, 13 Apr 2024 12:14:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 13 Apr 2024 13:01:35 +0000   Sat, 13 Apr 2024 12:14:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 13 Apr 2024 13:01:35 +0000   Sat, 13 Apr 2024 12:14:19 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.28.251\n  Hostname:    ip-172-31-28-251\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7958124Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7855724Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2719781626ced70834bfcd0491dbeb\n  System UUID:                ec271978-1626-ced7-0834-bfcd0491dbeb\n  Boot ID:                    85f660a5-141a-4e52-8339-10b8cbf60f07\n  Kernel Version:             6.5.0-1017-aws\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.29.3\n  Kube-Proxy Version:         v1.29.3\nNon-terminated Pods:          (3 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-55f66c499c-lprbm                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\n  kube-system                 calico-node-jxpjg                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         43m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-4tkxv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 52m                kube-proxy       \n  Normal   Starting                 56m                kube-proxy       \n  Normal   Starting                 44m                kube-proxy       \n  Normal   Starting                 53m                kube-proxy       \n  Normal   Starting                 50m                kube-proxy       \n  Normal   Starting                 54m                kube-proxy       \n  Normal   Starting                 51m                kube-proxy       \n  Normal   Starting                 58m                kube-proxy       \n  Normal   Starting                 49m                kube-proxy       \n  Normal   Starting                 60m                kube-proxy       \n  Normal   Starting                 54m                kube-proxy       \n  Normal   Starting                 55m                kube-proxy       \n  Normal   Starting                 57m                kube-proxy       \n  Normal   Starting                 50m                kube-proxy       \n  Normal   Starting                 47m                kube-proxy       \n  Normal   Starting                 45m                kube-proxy       \n  Normal   Starting                 59m                kube-proxy       \n  Normal   Starting                 46m                kube-proxy       \n  Normal   Starting                 45m                kube-proxy       \n  Normal   Starting                 43m                kube-proxy       \n  Normal   Starting                 48m                kube-proxy       \n  Normal   Starting                 58m                kube-proxy       \n  Normal   NodeHasSufficientPID     60m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    60m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  60m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  60m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      60m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 60m                kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    59m (x2 over 59m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 59m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      59m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  59m (x2 over 59m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     59m (x2 over 59m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  59m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     59m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   Starting                 59m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      59m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  59m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  59m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    59m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   RegisteredNode           58m                node-controller  Node ip-172-31-28-251 event: Registered Node ip-172-31-28-251 in Controller\n  Warning  InvalidDiskCapacity      58m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 58m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     58m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  58m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  58m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    58m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeReady                57m                kubelet          Node ip-172-31-28-251 status is now: NodeReady\n  Normal   NodeHasNoDiskPressure    57m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  57m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  57m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      57m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 57m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     57m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeReady                57m (x2 over 57m)  kubelet          Node ip-172-31-28-251 status is now: NodeReady\n  Normal   NodeAllocatableEnforced  56m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    56m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     56m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  56m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      56m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 56m                kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    55m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     55m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  55m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  55m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      55m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 55m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      54m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 54m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  54m                kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 54m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      54m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  54m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  54m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     53m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    53m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  53m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  53m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      53m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 53m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  52m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  52m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    52m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 52m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     52m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      52m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 51m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     51m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    51m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  51m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  51m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           50m                node-controller  Node ip-172-31-28-251 event: Registered Node ip-172-31-28-251 in Controller\n  Normal   NodeAllocatableEnforced  50m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      50m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 50m                kubelet          Starting kubelet.\n  Normal   Starting                 50m                kubelet          Starting kubelet.\n  Normal   NodeAllocatableEnforced  50m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     50m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   Starting                 49m                kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    49m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      49m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  49m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     49m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  49m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeNotReady             48m                node-controller  Node ip-172-31-28-251 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  48m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      48m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 48m                kubelet          Starting kubelet.\n  Normal   NodeReady                48m (x2 over 48m)  kubelet          Node ip-172-31-28-251 status is now: NodeReady\n  Normal   NodeHasSufficientPID     48m (x3 over 48m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    48m (x3 over 48m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  48m (x3 over 48m)  kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientMemory  47m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    47m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     47m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  47m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      47m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 47m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      46m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  46m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  46m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    46m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     46m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   Starting                 46m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      45m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientPID     45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  45m                kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 45m                kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  45m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    45m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 45m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      45m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientPID     44m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  44m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    44m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeAllocatableEnforced  44m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      44m                kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 44m                kubelet          Starting kubelet.\n  Normal   Starting                 43m                kubelet          Starting kubelet.\n  Normal   NodeAllocatableEnforced  43m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  43m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    43m                kubelet          Node ip-172-31-28-251 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     43m                kubelet          Node ip-172-31-28-251 status is now: NodeHasSufficientPID\n"
  Apr 13 13:02:44.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5246 describe namespace kubectl-5246'
  Apr 13 13:02:44.499: INFO: stderr: ""
  Apr 13 13:02:44.499: INFO: stdout: "Name:         kubectl-5246\nLabels:       e2e-framework=kubectl\n              e2e-run=0a2af82a-977a-4467-bc2e-9d348b0a2115\n              kubernetes.io/metadata.name=kubectl-5246\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 13 13:02:44.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5246" for this suite. @ 04/13/24 13:02:44.503
• [3.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 04/13/24 13:02:44.51
  Apr 13 13:02:44.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:02:44.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:44.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:44.53
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:02:44.533
  E0413 13:02:45.282724      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:46.282810      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:47.283529      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:48.283611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:02:48.558
  Apr 13 13:02:48.561: INFO: Trying to get logs from node ip-172-31-35-229 pod downwardapi-volume-07add18c-edc3-46ed-a415-ec04b5d1e836 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:02:48.58
  Apr 13 13:02:48.595: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4064" for this suite. @ 04/13/24 13:02:48.599
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 04/13/24 13:02:48.605
  Apr 13 13:02:48.605: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 13:02:48.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:48.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:48.625
  STEP: Creating simple DaemonSet "daemon-set" @ 04/13/24 13:02:48.646
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 13:02:48.653
  Apr 13 13:02:48.657: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:48.657: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:48.660: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:02:48.660: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:02:49.284095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:49.657: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:49.657: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:49.660: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:02:49.660: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:02:50.284557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:50.658: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:50.658: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:50.662: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:02:50.662: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/13/24 13:02:50.666
  Apr 13 13:02:50.680: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:50.680: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:50.686: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:02:50.686: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  E0413 13:02:51.284756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:51.681: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:51.681: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:51.684: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:02:51.684: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  E0413 13:02:52.285417      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:52.682: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:52.682: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:52.685: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:02:52.685: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 13:02:52.688
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1987, will wait for the garbage collector to delete the pods @ 04/13/24 13:02:52.688
  Apr 13 13:02:52.749: INFO: Deleting DaemonSet.extensions daemon-set took: 6.352507ms
  Apr 13 13:02:52.849: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.309566ms
  E0413 13:02:53.285655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:54.285979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:54.554: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:02:54.554: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 13:02:54.557: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23175"},"items":null}

  Apr 13 13:02:54.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23175"},"items":null}

  Apr 13 13:02:54.572: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1987" for this suite. @ 04/13/24 13:02:54.575
• [5.977 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 04/13/24 13:02:54.582
  Apr 13 13:02:54.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:02:54.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:54.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:54.6
  STEP: Setting up server cert @ 04/13/24 13:02:54.623
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:02:54.759
  STEP: Deploying the webhook pod @ 04/13/24 13:02:54.765
  STEP: Wait for the deployment to be ready @ 04/13/24 13:02:54.777
  Apr 13 13:02:54.786: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:02:55.286634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:02:56.286738      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:02:56.797
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:02:56.808
  E0413 13:02:57.287340      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:57.808: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/13/24 13:02:57.817
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/13/24 13:02:57.833
  STEP: Creating a configMap that should not be mutated @ 04/13/24 13:02:57.84
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/13/24 13:02:57.85
  STEP: Creating a configMap that should be mutated @ 04/13/24 13:02:57.857
  Apr 13 13:02:57.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8706" for this suite. @ 04/13/24 13:02:57.922
  STEP: Destroying namespace "webhook-markers-5" for this suite. @ 04/13/24 13:02:57.929
• [3.353 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 04/13/24 13:02:57.935
  Apr 13 13:02:57.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:02:57.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:57.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:57.953
  STEP: creating a ConfigMap @ 04/13/24 13:02:57.956
  STEP: fetching the ConfigMap @ 04/13/24 13:02:57.96
  STEP: patching the ConfigMap @ 04/13/24 13:02:57.963
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/13/24 13:02:57.968
  STEP: deleting the ConfigMap by collection with a label selector @ 04/13/24 13:02:57.972
  STEP: listing all ConfigMaps in test namespace @ 04/13/24 13:02:57.979
  Apr 13 13:02:57.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8688" for this suite. @ 04/13/24 13:02:57.985
• [0.056 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 04/13/24 13:02:57.992
  Apr 13 13:02:57.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 13:02:57.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:02:58.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:02:58.008
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/13/24 13:02:58.035
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 13:02:58.039
  Apr 13 13:02:58.044: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:58.044: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:58.046: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:02:58.046: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:02:58.287471      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:02:59.044: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:59.044: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:02:59.047: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 13 13:02:59.047: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:02:59.288072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:00.044: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:00.044: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:00.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:03:00.048: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/13/24 13:03:00.051
  Apr 13 13:03:00.068: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:00.068: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:00.072: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:03:00.072: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  E0413 13:03:00.288782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:01.068: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:01.068: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:01.072: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:03:01.072: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  E0413 13:03:01.289509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:02.067: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:02.067: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:03:02.071: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:03:02.071: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/13/24 13:03:02.071
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 13:03:02.078
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3248, will wait for the garbage collector to delete the pods @ 04/13/24 13:03:02.078
  Apr 13 13:03:02.140: INFO: Deleting DaemonSet.extensions daemon-set took: 9.329893ms
  Apr 13 13:03:02.241: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.807574ms
  E0413 13:03:02.290061      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:03.291010      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:03.545: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:03:03.545: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 13:03:03.548: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23426"},"items":null}

  Apr 13 13:03:03.551: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23426"},"items":null}

  Apr 13 13:03:03.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3248" for this suite. @ 04/13/24 13:03:03.566
• [5.580 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/13/24 13:03:03.572
  Apr 13 13:03:03.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 13:03:03.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:03.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:03.59
  Apr 13 13:03:03.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:03:04.291863      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/13/24 13:03:04.88
  Apr 13 13:03:04.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-5548 --namespace=crd-publish-openapi-5548 create -f -'
  E0413 13:03:05.292400      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:06.292459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:06.945: INFO: stderr: ""
  Apr 13 13:03:06.945: INFO: stdout: "e2e-test-crd-publish-openapi-3354-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 13 13:03:06.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-5548 --namespace=crd-publish-openapi-5548 delete e2e-test-crd-publish-openapi-3354-crds test-cr'
  Apr 13 13:03:06.992: INFO: stderr: ""
  Apr 13 13:03:06.992: INFO: stdout: "e2e-test-crd-publish-openapi-3354-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 13 13:03:06.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-5548 --namespace=crd-publish-openapi-5548 apply -f -'
  Apr 13 13:03:07.041: INFO: stderr: ""
  Apr 13 13:03:07.041: INFO: stdout: "e2e-test-crd-publish-openapi-3354-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 13 13:03:07.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-5548 --namespace=crd-publish-openapi-5548 delete e2e-test-crd-publish-openapi-3354-crds test-cr'
  Apr 13 13:03:07.099: INFO: stderr: ""
  Apr 13 13:03:07.099: INFO: stdout: "e2e-test-crd-publish-openapi-3354-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/13/24 13:03:07.099
  Apr 13 13:03:07.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-5548 explain e2e-test-crd-publish-openapi-3354-crds'
  Apr 13 13:03:07.138: INFO: stderr: ""
  Apr 13 13:03:07.138: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-3354-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0413 13:03:07.293456      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:08.293522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:03:08.358: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5548" for this suite. @ 04/13/24 13:03:08.366
• [4.802 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 04/13/24 13:03:08.375
  Apr 13 13:03:08.375: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:03:08.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:08.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:08.393
  STEP: Creating configMap with name configmap-test-volume-c179db04-0134-4efa-b212-363d40ef4c61 @ 04/13/24 13:03:08.397
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:03:08.403
  E0413 13:03:09.293650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:10.293763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:11.293903      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:12.294257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:03:12.426
  Apr 13 13:03:12.430: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-333956e6-4789-4c70-b623-2b1908724115 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:03:12.44
  Apr 13 13:03:12.454: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4461" for this suite. @ 04/13/24 13:03:12.457
• [4.090 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 04/13/24 13:03:12.465
  Apr 13 13:03:12.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename endpointslice @ 04/13/24 13:03:12.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:12.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:12.484
  Apr 13 13:03:12.498: INFO: Endpoints addresses: [172.31.28.251 172.31.84.4] , ports: [6443]
  Apr 13 13:03:12.498: INFO: EndpointSlices addresses: [172.31.28.251 172.31.84.4] , ports: [6443]
  Apr 13 13:03:12.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7858" for this suite. @ 04/13/24 13:03:12.503
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 04/13/24 13:03:12.509
  Apr 13 13:03:12.509: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-pred @ 04/13/24 13:03:12.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:12.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:12.527
  Apr 13 13:03:12.530: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 13 13:03:12.537: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 13:03:12.540: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-35-229 before test
  Apr 13 13:03:12.545: INFO: nginx-ingress-controller-kubernetes-worker-tchsj from ingress-nginx-kubernetes-worker started at 2024-04-13 12:16:24 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.545: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: calico-node-mrwfw from kube-system started at 2024-04-13 12:19:51 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.545: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: sonobuoy-e2e-job-e3618131f41d4cd5 from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:03:12.545: INFO: 	Container e2e ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-2fnld from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:03:12.545: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:03:12.545: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-65-227 before test
  Apr 13 13:03:12.551: INFO: nginx-ingress-controller-kubernetes-worker-fr5bd from ingress-nginx-kubernetes-worker started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: calico-node-lfv4l from kube-system started at 2024-04-13 12:20:12 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: coredns-bddfd76d7-xzr8q from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container coredns ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: kube-state-metrics-78c475f58b-tmplf from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: metrics-server-v0.6.3-69d7fbfdf8-c2gtp from kube-system started at 2024-04-13 12:12:03 +0000 UTC (2 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: dashboard-metrics-scraper-5dd7cb5fc-fljfb from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: kubernetes-dashboard-7b899cb9d9-ss9wp from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-qn24t from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:03:12.551: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:03:12.551: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-63 before test
  Apr 13 13:03:12.555: INFO: nginx-ingress-controller-kubernetes-worker-x6l7w from ingress-nginx-kubernetes-worker started at 2024-04-13 12:47:31 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.555: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:03:12.555: INFO: calico-node-9p4gt from kube-system started at 2024-04-13 12:20:01 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.555: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:03:12.555: INFO: sonobuoy from sonobuoy started at 2024-04-13 12:20:25 +0000 UTC (1 container statuses recorded)
  Apr 13 13:03:12.555: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 13 13:03:12.555: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-sbrvb from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:03:12.555: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:03:12.555: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-35-229 @ 04/13/24 13:03:12.577
  STEP: verifying the node has the label node ip-172-31-65-227 @ 04/13/24 13:03:12.588
  STEP: verifying the node has the label node ip-172-31-82-63 @ 04/13/24 13:03:12.6
  Apr 13 13:03:12.614: INFO: Pod nginx-ingress-controller-kubernetes-worker-fr5bd requesting resource cpu=0m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod nginx-ingress-controller-kubernetes-worker-tchsj requesting resource cpu=0m on Node ip-172-31-35-229
  Apr 13 13:03:12.614: INFO: Pod nginx-ingress-controller-kubernetes-worker-x6l7w requesting resource cpu=0m on Node ip-172-31-82-63
  Apr 13 13:03:12.614: INFO: Pod calico-node-9p4gt requesting resource cpu=250m on Node ip-172-31-82-63
  Apr 13 13:03:12.614: INFO: Pod calico-node-lfv4l requesting resource cpu=250m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod calico-node-mrwfw requesting resource cpu=250m on Node ip-172-31-35-229
  Apr 13 13:03:12.614: INFO: Pod coredns-bddfd76d7-xzr8q requesting resource cpu=100m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod kube-state-metrics-78c475f58b-tmplf requesting resource cpu=0m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-c2gtp requesting resource cpu=5m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-fljfb requesting resource cpu=0m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod kubernetes-dashboard-7b899cb9d9-ss9wp requesting resource cpu=0m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-82-63
  Apr 13 13:03:12.614: INFO: Pod sonobuoy-e2e-job-e3618131f41d4cd5 requesting resource cpu=0m on Node ip-172-31-35-229
  Apr 13 13:03:12.614: INFO: Pod sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-2fnld requesting resource cpu=0m on Node ip-172-31-35-229
  Apr 13 13:03:12.614: INFO: Pod sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-qn24t requesting resource cpu=0m on Node ip-172-31-65-227
  Apr 13 13:03:12.614: INFO: Pod sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-sbrvb requesting resource cpu=0m on Node ip-172-31-82-63
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/13/24 13:03:12.614
  Apr 13 13:03:12.614: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-82-63
  Apr 13 13:03:12.621: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-35-229
  Apr 13 13:03:12.628: INFO: Creating a pod which consumes cpu=1151m on Node ip-172-31-65-227
  E0413 13:03:13.294499      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:14.294599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/13/24 13:03:14.652
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-175b946d-106b-420b-90eb-85dee74c709e.17c5d89acafcd388], Reason = [Scheduled], Message = [Successfully assigned sched-pred-364/filler-pod-175b946d-106b-420b-90eb-85dee74c709e to ip-172-31-82-63] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-175b946d-106b-420b-90eb-85dee74c709e.17c5d89ae8f72885], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-175b946d-106b-420b-90eb-85dee74c709e.17c5d89ae9ed2a3f], Reason = [Created], Message = [Created container filler-pod-175b946d-106b-420b-90eb-85dee74c709e] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-175b946d-106b-420b-90eb-85dee74c709e.17c5d89aece09e18], Reason = [Started], Message = [Started container filler-pod-175b946d-106b-420b-90eb-85dee74c709e] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-94795914-04eb-407e-9a96-346c5421f1a6.17c5d89acbdc2767], Reason = [Scheduled], Message = [Successfully assigned sched-pred-364/filler-pod-94795914-04eb-407e-9a96-346c5421f1a6 to ip-172-31-65-227] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-94795914-04eb-407e-9a96-346c5421f1a6.17c5d89aeccbf471], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.9"] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-94795914-04eb-407e-9a96-346c5421f1a6.17c5d89af159e1b8], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.9" in 76ms (76ms including waiting)] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-94795914-04eb-407e-9a96-346c5421f1a6.17c5d89af32a0753], Reason = [Created], Message = [Created container filler-pod-94795914-04eb-407e-9a96-346c5421f1a6] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-94795914-04eb-407e-9a96-346c5421f1a6.17c5d89af604ef62], Reason = [Started], Message = [Started container filler-pod-94795914-04eb-407e-9a96-346c5421f1a6] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62.17c5d89acb6cc4b0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-364/filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62 to ip-172-31-35-229] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62.17c5d89ae9d38ec2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62.17c5d89aeb090fab], Reason = [Created], Message = [Created container filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62.17c5d89aeddeb3e8], Reason = [Started], Message = [Started container filler-pod-e9b3e6a0-f9ce-4338-8d39-a55c06a3cc62] @ 04/13/24 13:03:14.656
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17c5d89b44949e63], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 04/13/24 13:03:14.673
  E0413 13:03:15.294755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-35-229 @ 04/13/24 13:03:15.67
  STEP: verifying the node doesn't have the label node @ 04/13/24 13:03:15.683
  STEP: removing the label node off the node ip-172-31-65-227 @ 04/13/24 13:03:15.69
  STEP: verifying the node doesn't have the label node @ 04/13/24 13:03:15.704
  STEP: removing the label node off the node ip-172-31-82-63 @ 04/13/24 13:03:15.709
  STEP: verifying the node doesn't have the label node @ 04/13/24 13:03:15.72
  Apr 13 13:03:15.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-364" for this suite. @ 04/13/24 13:03:15.73
• [3.228 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 04/13/24 13:03:15.737
  Apr 13 13:03:15.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:03:15.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:15.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:15.756
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:03:15.759
  E0413 13:03:16.295059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:17.295669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:03:17.778
  Apr 13 13:03:17.782: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-585dc18b-7bf7-49f4-975d-91d5fc2f2663 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:03:17.789
  Apr 13 13:03:17.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4428" for this suite. @ 04/13/24 13:03:17.806
• [2.075 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/13/24 13:03:17.812
  Apr 13 13:03:17.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption @ 04/13/24 13:03:17.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:03:17.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:03:17.833
  Apr 13 13:03:17.851: INFO: Waiting up to 1m0s for all nodes to be ready
  E0413 13:03:18.296385      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:19.296493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:20.296623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:21.296685      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:22.297207      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:23.297315      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:24.297408      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:25.297546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:26.298233      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:27.299158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:28.300145      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:29.300179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:30.300635      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:31.300759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:32.301551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:33.302066      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:34.302454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:35.302564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:36.303350      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:37.303534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:38.304454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:39.304619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:40.304715      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:41.304892      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:42.305058      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:43.305333      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:44.306309      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:45.306463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:46.307056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:47.307339      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:48.307481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:49.307705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:50.307881      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:51.308245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:52.308517      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:53.308697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:54.309053      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:55.309177      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:56.309293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:57.309578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:58.310127      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:03:59.310228      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:00.310503      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:01.310620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:02.311469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:03.311562      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:04.311681      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:05.311920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:06.312541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:07.312883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:08.313224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:09.313313      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:10.313403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:11.313589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:12.314223      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:13.314466      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:14.315282      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:15.315462      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:16.316142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:17.316610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:17.855: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/13/24 13:04:17.859
  Apr 13 13:04:17.880: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 13 13:04:17.889: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 13 13:04:17.905: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 13 13:04:17.913: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 13 13:04:17.928: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 13 13:04:17.935: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/13/24 13:04:17.935
  E0413 13:04:18.316891      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:19.316939      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/13/24 13:04:19.967
  E0413 13:04:20.316976      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:21.317092      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:22.317673      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:23.317759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:24.051: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5486" for this suite. @ 04/13/24 13:04:24.055
• [66.249 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 04/13/24 13:04:24.062
  Apr 13 13:04:24.062: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:04:24.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:04:24.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:04:24.081
  STEP: Creating service test in namespace statefulset-9073 @ 04/13/24 13:04:24.084
  STEP: Looking for a node to schedule stateful set and pod @ 04/13/24 13:04:24.09
  STEP: Creating pod with conflicting port in namespace statefulset-9073 @ 04/13/24 13:04:24.095
  STEP: Waiting until pod test-pod will start running in namespace statefulset-9073 @ 04/13/24 13:04:24.105
  E0413 13:04:24.318369      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:25.318560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-9073 @ 04/13/24 13:04:26.113
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9073 @ 04/13/24 13:04:26.118
  Apr 13 13:04:26.132: INFO: Observed stateful pod in namespace: statefulset-9073, name: ss-0, uid: 89bb059d-ddc3-4740-986b-4ff98fd6d263, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 13 13:04:26.154: INFO: Observed stateful pod in namespace: statefulset-9073, name: ss-0, uid: 89bb059d-ddc3-4740-986b-4ff98fd6d263, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 13 13:04:26.162: INFO: Observed stateful pod in namespace: statefulset-9073, name: ss-0, uid: 89bb059d-ddc3-4740-986b-4ff98fd6d263, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 13 13:04:26.167: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9073
  STEP: Removing pod with conflicting port in namespace statefulset-9073 @ 04/13/24 13:04:26.167
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9073 and will be in running state @ 04/13/24 13:04:26.181
  E0413 13:04:26.318955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:27.319278      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:28.189: INFO: Deleting all statefulset in ns statefulset-9073
  Apr 13 13:04:28.192: INFO: Scaling statefulset ss to 0
  E0413 13:04:28.319881      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:29.321146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:30.321246      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:31.321333      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:32.321553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:33.321645      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:34.321756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:35.321872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:36.322074      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:37.322988      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:38.210: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 13:04:38.213: INFO: Deleting statefulset ss
  Apr 13 13:04:38.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9073" for this suite. @ 04/13/24 13:04:38.229
• [14.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 04/13/24 13:04:38.235
  Apr 13 13:04:38.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:04:38.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:04:38.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:04:38.256
  STEP: Setting up server cert @ 04/13/24 13:04:38.284
  E0413 13:04:38.323580      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:04:38.676
  STEP: Deploying the webhook pod @ 04/13/24 13:04:38.685
  STEP: Wait for the deployment to be ready @ 04/13/24 13:04:38.698
  Apr 13 13:04:38.709: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:04:39.324034      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:40.324102      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:04:40.721
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:04:40.732
  E0413 13:04:41.324894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:41.732: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 13 13:04:41.741: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-189-crds.webhook.example.com via the AdmissionRegistration API @ 04/13/24 13:04:42.254
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/13/24 13:04:42.268
  E0413 13:04:42.325176      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:43.325479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:44.326044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:44.848: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9106" for this suite. @ 04/13/24 13:04:44.853
  STEP: Destroying namespace "webhook-markers-2590" for this suite. @ 04/13/24 13:04:44.861
• [6.632 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 04/13/24 13:04:44.868
  Apr 13 13:04:44.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:04:44.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:04:44.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:04:44.885
  STEP: creating service multiprotocol-test in namespace services-6770 @ 04/13/24 13:04:44.889
  STEP: creating pod pod1 in namespace services-6770 @ 04/13/24 13:04:44.898
  STEP: Creating pod pod1 in namespace services-6770 @ 04/13/24 13:04:44.898
  E0413 13:04:45.326633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:46.326735      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-6770 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 04/13/24 13:04:46.923
  Apr 13 13:04:46.936: INFO: successfully validated that service multiprotocol-test in namespace services-6770 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 04/13/24 13:04:46.936
  Apr 13 13:04:46.936: INFO: Creating new exec pod
  E0413 13:04:47.327617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:48.327838      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:48.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Apr 13 13:04:49.054: INFO: stderr: "+ nc -v -t -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Apr 13 13:04:49.054: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:04:49.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.123 80'
  E0413 13:04:49.328146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:50.328334      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:51.328781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:52.329567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:53.143: INFO: stderr: "+ nc -v -u -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [udp/*] succeeded!\n"
  Apr 13 13:04:53.143: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 04/13/24 13:04:53.143
  Apr 13 13:04:53.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Apr 13 13:04:53.254: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.123 80\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Apr 13 13:04:53.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:04:53.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.123 80'
  E0413 13:04:53.329904      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:54.330414      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:55.330702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:56.331535      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:57.331778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:04:57.360: INFO: stderr: "+ nc -v -u -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [udp/*] succeeded!\n"
  Apr 13 13:04:57.360: INFO: stdout: ""
  Apr 13 13:04:57.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.123 80'
  E0413 13:04:58.332843      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:04:59.333702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:00.334765      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:01.335823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:01.458: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.123 80\nConnection to 10.152.183.123 80 port [udp/*] succeeded!\n"
  Apr 13 13:05:01.458: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 04/13/24 13:05:01.458
  Apr 13 13:05:01.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.123 80'
  E0413 13:05:02.336786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:03.336908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:04.337124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:05.337242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:05.569: INFO: stderr: "+ nc -v -u -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [udp/*] succeeded!\n"
  Apr 13 13:05:05.569: INFO: stdout: "pod1"
  Apr 13 13:05:05.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  E0413 13:05:06.337512      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:07.337808      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:07.662: INFO: rc: 1
  Apr 13 13:05:07.662: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.123 80
  + echo hostName
  nc: connect to 10.152.183.123 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 13 13:05:07.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  E0413 13:05:08.338857      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:09.339536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:09.754: INFO: rc: 1
  Apr 13 13:05:09.754: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.123 80
  + echo hostName
  nc: connect to 10.152.183.123 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 13 13:05:09.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  E0413 13:05:10.339741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:11.339804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:11.850: INFO: rc: 1
  Apr 13 13:05:11.850: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6770 exec execpodlzwfr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.123 80
  + echo hostName
  nc: connect to 10.152.183.123 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 13 13:05:11.850: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6770" for this suite. @ 04/13/24 13:05:11.855
• [26.995 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/13/24 13:05:11.863
  Apr 13 13:05:11.863: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:05:11.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:11.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:11.884
  STEP: Creating secret with name secret-test-a0c74f92-c591-433e-80ab-eee78435642e @ 04/13/24 13:05:11.887
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:05:11.893
  E0413 13:05:12.340284      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:13.340504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:14.341297      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:15.341996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:05:15.917
  Apr 13 13:05:15.920: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-737ec68e-ae17-4efa-b9cc-78e54e7691a6 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:05:15.931
  Apr 13 13:05:15.947: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2654" for this suite. @ 04/13/24 13:05:15.951
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 04/13/24 13:05:15.959
  Apr 13 13:05:15.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:05:15.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:15.976
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:15.981
  STEP: Creating the pod @ 04/13/24 13:05:15.985
  E0413 13:05:16.342070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:17.342464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:18.342835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:18.529: INFO: Successfully updated pod "labelsupdate6af30ef6-0601-47b4-b455-acf6e49cf232"
  E0413 13:05:19.343610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:20.344016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:21.344129      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:22.344671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:22.554: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3274" for this suite. @ 04/13/24 13:05:22.559
• [6.608 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/13/24 13:05:22.567
  Apr 13 13:05:22.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:05:22.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:22.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:22.588
  STEP: Creating a pod to test substitution in volume subpath @ 04/13/24 13:05:22.592
  E0413 13:05:23.344772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:24.344918      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:25.345010      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:26.345790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:05:26.617
  Apr 13 13:05:26.621: INFO: Trying to get logs from node ip-172-31-35-229 pod var-expansion-87d2fce9-e146-435a-9fe9-9b1315217afa container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 13:05:26.633
  Apr 13 13:05:26.648: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-880" for this suite. @ 04/13/24 13:05:26.652
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 04/13/24 13:05:26.658
  Apr 13 13:05:26.658: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 13:05:26.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:26.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:26.677
  STEP: Creating a job @ 04/13/24 13:05:26.681
  STEP: Ensuring active pods == parallelism @ 04/13/24 13:05:26.685
  E0413 13:05:27.345820      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:28.345951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/13/24 13:05:28.691
  Apr 13 13:05:29.208: INFO: Successfully updated pod "adopt-release-tjd9w"
  STEP: Checking that the Job readopts the Pod @ 04/13/24 13:05:29.208
  E0413 13:05:29.346762      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:30.346887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/13/24 13:05:31.218
  E0413 13:05:31.347447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:31.728: INFO: Successfully updated pod "adopt-release-tjd9w"
  STEP: Checking that the Job releases the Pod @ 04/13/24 13:05:31.728
  E0413 13:05:32.347823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:33.347909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:33.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1272" for this suite. @ 04/13/24 13:05:33.742
• [7.090 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 04/13/24 13:05:33.749
  Apr 13 13:05:33.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 13:05:33.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:33.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:33.77
  STEP: Creating a pod to test service account token:  @ 04/13/24 13:05:33.774
  E0413 13:05:34.348050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:35.348181      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:36.348793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:37.349279      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:05:37.797
  Apr 13 13:05:37.800: INFO: Trying to get logs from node ip-172-31-35-229 pod test-pod-fb218876-ebeb-4e6c-9f31-9c12610949ee container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:05:37.807
  Apr 13 13:05:37.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9104" for this suite. @ 04/13/24 13:05:37.828
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/13/24 13:05:37.836
  Apr 13 13:05:37.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename watch @ 04/13/24 13:05:37.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:37.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:37.854
  STEP: creating a watch on configmaps with label A @ 04/13/24 13:05:37.859
  STEP: creating a watch on configmaps with label B @ 04/13/24 13:05:37.861
  STEP: creating a watch on configmaps with label A or B @ 04/13/24 13:05:37.862
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/13/24 13:05:37.864
  Apr 13 13:05:37.868: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24617 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:37.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24617 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/13/24 13:05:37.869
  Apr 13 13:05:37.876: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24618 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:37.876: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24618 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/13/24 13:05:37.876
  Apr 13 13:05:37.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24619 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:37.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24619 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/13/24 13:05:37.884
  Apr 13 13:05:37.891: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24620 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:37.891: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9188  4db90fbf-d477-4937-9be0-b3c51206da25 24620 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/13/24 13:05:37.891
  Apr 13 13:05:37.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9188  adad40fc-2196-4a43-acc8-435f7410e373 24621 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:37.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9188  adad40fc-2196-4a43-acc8-435f7410e373 24621 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0413 13:05:38.349856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:39.350854      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:40.350965      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:41.351052      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:42.351317      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:43.352130      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:44.352304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:45.352492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:46.352654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:47.353728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/13/24 13:05:47.896
  Apr 13 13:05:47.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9188  adad40fc-2196-4a43-acc8-435f7410e373 24701 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:05:47.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9188  adad40fc-2196-4a43-acc8-435f7410e373 24701 0 2024-04-13 13:05:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-13 13:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0413 13:05:48.354385      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:49.354501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:50.354574      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:51.354620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:52.354939      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:53.355520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:54.356216      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:55.356336      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:56.356514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:57.357527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:05:57.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9188" for this suite. @ 04/13/24 13:05:57.911
• [20.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 04/13/24 13:05:57.919
  Apr 13 13:05:57.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:05:57.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:05:57.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:05:57.941
  STEP: Setting up server cert @ 04/13/24 13:05:57.962
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:05:58.312
  STEP: Deploying the webhook pod @ 04/13/24 13:05:58.321
  STEP: Wait for the deployment to be ready @ 04/13/24 13:05:58.335
  Apr 13 13:05:58.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:05:58.357819      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:05:59.358094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:06:00.357
  E0413 13:06:00.358154      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:06:00.369
  E0413 13:06:01.358491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:06:01.369: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 13 13:06:01.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/13/24 13:06:01.89
  STEP: Creating a custom resource that should be denied by the webhook @ 04/13/24 13:06:01.905
  E0413 13:06:02.359561      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:03.359737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/13/24 13:06:03.922
  STEP: Updating the custom resource with disallowed data should be denied @ 04/13/24 13:06:03.931
  STEP: Deleting the custom resource should be denied @ 04/13/24 13:06:03.939
  STEP: Remove the offending key and value from the custom resource data @ 04/13/24 13:06:03.947
  STEP: Deleting the updated custom resource should be successful @ 04/13/24 13:06:03.956
  E0413 13:06:04.360171      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:06:04.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3349" for this suite. @ 04/13/24 13:06:04.524
  STEP: Destroying namespace "webhook-markers-547" for this suite. @ 04/13/24 13:06:04.531
• [6.617 seconds]
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/13/24 13:06:04.537
  Apr 13 13:06:04.537: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:06:04.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:04.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:04.555
  STEP: Creating secret with name secret-test-cc4f34b3-010f-44b8-811f-db24dfaa2ab5 @ 04/13/24 13:06:04.581
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:06:04.588
  E0413 13:06:05.360393      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:06.360483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:07.360501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:08.360605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:06:08.611
  Apr 13 13:06:08.616: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-0c3dd92b-a039-4aa3-95b4-ae9b03535aec container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:06:08.634
  Apr 13 13:06:08.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8081" for this suite. @ 04/13/24 13:06:08.653
  STEP: Destroying namespace "secret-namespace-9967" for this suite. @ 04/13/24 13:06:08.661
• [4.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 04/13/24 13:06:08.668
  Apr 13 13:06:08.668: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/13/24 13:06:08.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:08.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:08.688
  STEP: create the container to handle the HTTPGet hook request. @ 04/13/24 13:06:08.695
  E0413 13:06:09.361522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:10.362463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/13/24 13:06:10.716
  E0413 13:06:11.362551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:12.363548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/13/24 13:06:12.738
  STEP: delete the pod with lifecycle hook @ 04/13/24 13:06:12.756
  E0413 13:06:13.363605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:14.364268      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:06:14.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5303" for this suite. @ 04/13/24 13:06:14.779
• [6.118 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 04/13/24 13:06:14.786
  Apr 13 13:06:14.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subpath @ 04/13/24 13:06:14.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:14.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:14.805
  STEP: Setting up data @ 04/13/24 13:06:14.809
  STEP: Creating pod pod-subpath-test-downwardapi-xf2c @ 04/13/24 13:06:14.817
  STEP: Creating a pod to test atomic-volume-subpath @ 04/13/24 13:06:14.817
  E0413 13:06:15.364374      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:16.364499      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:17.364515      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:18.364726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:19.364811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:20.365877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:21.365996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:22.366651      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:23.366735      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:24.367573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:25.368306      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:26.368447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:27.368700      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:28.368807      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:29.369661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:30.369773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:31.370038      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:32.370370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:33.370827      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:34.371513      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:35.371820      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:36.372009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:37.372531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:38.372653      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:06:38.901
  Apr 13 13:06:38.908: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-subpath-test-downwardapi-xf2c container test-container-subpath-downwardapi-xf2c: <nil>
  STEP: delete the pod @ 04/13/24 13:06:38.915
  STEP: Deleting pod pod-subpath-test-downwardapi-xf2c @ 04/13/24 13:06:38.929
  Apr 13 13:06:38.929: INFO: Deleting pod "pod-subpath-test-downwardapi-xf2c" in namespace "subpath-2963"
  Apr 13 13:06:38.933: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2963" for this suite. @ 04/13/24 13:06:38.936
• [24.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 04/13/24 13:06:38.942
  Apr 13 13:06:38.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:06:38.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:38.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:38.964
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:06:38.968
  E0413 13:06:39.373281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:40.373352      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:41.373463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:42.373537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:06:42.992
  Apr 13 13:06:42.996: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-fce65e53-1778-4d14-8e49-258f625b8808 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:06:43.004
  Apr 13 13:06:43.021: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3190" for this suite. @ 04/13/24 13:06:43.026
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 04/13/24 13:06:43.034
  Apr 13 13:06:43.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-pred @ 04/13/24 13:06:43.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:43.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:43.056
  Apr 13 13:06:43.060: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 13 13:06:43.070: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 13:06:43.074: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-35-229 before test
  Apr 13 13:06:43.079: INFO: nginx-ingress-controller-kubernetes-worker-tchsj from ingress-nginx-kubernetes-worker started at 2024-04-13 12:16:24 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.079: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: calico-node-mrwfw from kube-system started at 2024-04-13 12:19:51 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.079: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: sonobuoy-e2e-job-e3618131f41d4cd5 from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:06:43.079: INFO: 	Container e2e ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-2fnld from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:06:43.079: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:06:43.079: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-65-227 before test
  Apr 13 13:06:43.087: INFO: nginx-ingress-controller-kubernetes-worker-fr5bd from ingress-nginx-kubernetes-worker started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: calico-node-lfv4l from kube-system started at 2024-04-13 12:20:12 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: coredns-bddfd76d7-xzr8q from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container coredns ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: kube-state-metrics-78c475f58b-tmplf from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: metrics-server-v0.6.3-69d7fbfdf8-c2gtp from kube-system started at 2024-04-13 12:12:03 +0000 UTC (2 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: dashboard-metrics-scraper-5dd7cb5fc-fljfb from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: kubernetes-dashboard-7b899cb9d9-ss9wp from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-qn24t from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:06:43.087: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:06:43.087: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-63 before test
  Apr 13 13:06:43.095: INFO: nginx-ingress-controller-kubernetes-worker-x6l7w from ingress-nginx-kubernetes-worker started at 2024-04-13 12:47:31 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.095: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:06:43.095: INFO: calico-node-9p4gt from kube-system started at 2024-04-13 12:20:01 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.095: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:06:43.095: INFO: sonobuoy from sonobuoy started at 2024-04-13 12:20:25 +0000 UTC (1 container statuses recorded)
  Apr 13 13:06:43.095: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 13 13:06:43.095: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-sbrvb from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:06:43.095: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:06:43.095: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/13/24 13:06:43.095
  E0413 13:06:43.374102      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:44.374282      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/13/24 13:06:45.117
  STEP: Trying to apply a random label on the found node. @ 04/13/24 13:06:45.128
  STEP: verifying the node has the label kubernetes.io/e2e-1f1c6d49-456d-470a-9937-d854e1ca02af 42 @ 04/13/24 13:06:45.138
  STEP: Trying to relaunch the pod, now with labels. @ 04/13/24 13:06:45.141
  E0413 13:06:45.374540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:46.374649      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-1f1c6d49-456d-470a-9937-d854e1ca02af off the node ip-172-31-82-63 @ 04/13/24 13:06:47.162
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-1f1c6d49-456d-470a-9937-d854e1ca02af @ 04/13/24 13:06:47.173
  Apr 13 13:06:47.176: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6711" for this suite. @ 04/13/24 13:06:47.18
• [4.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/13/24 13:06:47.186
  Apr 13 13:06:47.186: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 13:06:47.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:47.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:47.208
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/13/24 13:06:47.211
  Apr 13 13:06:47.220: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1975  744c498c-78e0-40b9-8e24-4cd105e34933 25136 0 2024-04-13 13:06:47 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-13 13:06:47 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ltfdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ltfdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0413 13:06:47.375113      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:48.375224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/13/24 13:06:49.229
  Apr 13 13:06:49.229: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1975 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:06:49.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:06:49.230: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:06:49.230: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1975/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/13/24 13:06:49.291
  Apr 13 13:06:49.291: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1975 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:06:49.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:06:49.292: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:06:49.292: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1975/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 13 13:06:49.355: INFO: Deleting pod test-dns-nameservers...
  Apr 13 13:06:49.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1975" for this suite. @ 04/13/24 13:06:49.37
  E0413 13:06:49.375676      21 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 04/13/24 13:06:49.38
  Apr 13 13:06:49.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:06:49.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:06:49.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:06:49.399
  E0413 13:06:50.375829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:51.375935      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:52.376626      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:53.377438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:54.377646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:55.377856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:56.378465      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:57.379447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:58.379538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:06:59.379632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:00.379821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:01.379901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:02.380593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:03.380710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:04.380794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:05.381506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:06.381835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/13/24 13:07:06.408
  E0413 13:07:07.382726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:08.382817      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:09.383728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:10.384169      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:11.384274      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/13/24 13:07:11.413
  STEP: Ensuring resource quota status is calculated @ 04/13/24 13:07:11.418
  E0413 13:07:12.385057      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:13.385155      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 04/13/24 13:07:13.424
  STEP: Ensuring resource quota status captures configMap creation @ 04/13/24 13:07:13.435
  E0413 13:07:14.385254      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:15.385471      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 04/13/24 13:07:15.439
  STEP: Ensuring resource quota status released usage @ 04/13/24 13:07:15.446
  E0413 13:07:16.385786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:17.386766      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:07:17.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9654" for this suite. @ 04/13/24 13:07:17.455
• [28.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/13/24 13:07:17.461
  Apr 13 13:07:17.461: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:07:17.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:07:17.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:07:17.482
  STEP: creating the pod with failed condition @ 04/13/24 13:07:17.486
  E0413 13:07:18.387559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:19.388375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:20.388501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:21.388708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:22.389069      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:23.389372      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:24.389451      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:25.389551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:26.390608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:27.390684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:28.390947      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:29.391043      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:30.391537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:31.392295      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:32.392473      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:33.392540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:34.392958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:35.393059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:36.393155      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:37.393666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:38.393783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:39.393874      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:40.394000      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:41.394202      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:42.394708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:43.394797      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:44.394884      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:45.395792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:46.395887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:47.396706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:48.396845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:49.396948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:50.396986      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:51.397192      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:52.397645      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:53.397737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:54.397932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:55.398142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:56.398503      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:57.399541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:58.399644      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:07:59.399728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:00.399828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:01.400003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:02.401063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:03.401137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:04.401247      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:05.401357      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:06.401522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:07.401632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:08.402477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:09.403535      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:10.403649      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:11.403760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:12.404568      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:13.404911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:14.405166      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:15.406243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:16.407058      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:17.407791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:18.408867      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:19.408936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:20.409044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:21.409149      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:22.409621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:23.409698      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:24.409967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:25.410071      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:26.410480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:27.410986      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:28.411111      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:29.411199      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:30.411300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:31.411389      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:32.411604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:33.411697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:34.411792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:35.411894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:36.412943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:37.413830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:38.414371      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:39.414826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:40.415527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:41.415625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:42.416665      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:43.417109      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:44.417213      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:45.417400      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:46.418356      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:47.418607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:48.419549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:49.420545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:50.421491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:51.421842      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:52.422614      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:53.422710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:54.423558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:55.423739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:56.424380      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:57.424744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:58.424886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:08:59.425036      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:00.425074      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:01.425276      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:02.425362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:03.425477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:04.425854      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:05.425911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:06.426001      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:07.426403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:08.427456      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:09.427511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:10.427581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:11.427669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:12.428688      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:13.428783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:14.428891      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:15.429090      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:16.429127      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:17.429612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/13/24 13:09:17.495
  Apr 13 13:09:18.009: INFO: Successfully updated pod "var-expansion-42300776-5542-4b88-be31-676e091ad8a0"
  STEP: waiting for pod running @ 04/13/24 13:09:18.009
  E0413 13:09:18.429744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:19.430034      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/13/24 13:09:20.018
  Apr 13 13:09:20.018: INFO: Deleting pod "var-expansion-42300776-5542-4b88-be31-676e091ad8a0" in namespace "var-expansion-7622"
  Apr 13 13:09:20.028: INFO: Wait up to 5m0s for pod "var-expansion-42300776-5542-4b88-be31-676e091ad8a0" to be fully deleted
  E0413 13:09:20.430115      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:21.430222      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:22.430789      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:23.431039      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:24.431407      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:25.431858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:26.432828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:27.433046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:28.433732      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:29.433851      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:30.434873      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:31.434968      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:32.435513      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:33.436564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:34.437096      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:35.437240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:36.437859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:37.438773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:38.439044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:39.439072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:40.440029      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:41.440089      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:42.440193      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:43.440523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:44.441509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:45.441739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:46.441879      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:47.442347      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:48.443042      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:49.443591      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:50.443684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:51.443794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:09:52.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7622" for this suite. @ 04/13/24 13:09:52.117
• [154.663 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 04/13/24 13:09:52.124
  Apr 13 13:09:52.124: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:09:52.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:09:52.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:09:52.153
  STEP: Creating service test in namespace statefulset-3173 @ 04/13/24 13:09:52.158
  STEP: Creating statefulset ss in namespace statefulset-3173 @ 04/13/24 13:09:52.164
  Apr 13 13:09:52.177: INFO: Found 0 stateful pods, waiting for 1
  E0413 13:09:52.444574      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:53.444801      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:54.444859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:55.444989      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:56.445027      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:57.446017      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:58.446135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:09:59.446375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:00.446461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:01.447526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:10:02.176: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/13/24 13:10:02.184
  STEP: updating a scale subresource @ 04/13/24 13:10:02.188
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/13/24 13:10:02.194
  STEP: Patch a scale subresource @ 04/13/24 13:10:02.197
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/13/24 13:10:02.204
  Apr 13 13:10:02.211: INFO: Deleting all statefulset in ns statefulset-3173
  Apr 13 13:10:02.216: INFO: Scaling statefulset ss to 0
  E0413 13:10:02.447915      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:03.448112      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:04.448233      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:05.448324      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:06.449257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:07.449652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:08.449776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:09.449877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:10.450207      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:11.450300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:10:12.235: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 13:10:12.239: INFO: Deleting statefulset ss
  Apr 13 13:10:12.253: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3173" for this suite. @ 04/13/24 13:10:12.258
• [20.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 04/13/24 13:10:12.264
  Apr 13 13:10:12.264: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:10:12.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:10:12.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:10:12.285
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:10:12.289
  E0413 13:10:12.450735      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:13.450822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:14.451670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:15.451755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:10:16.311
  Apr 13 13:10:16.314: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-fe29c26e-54a9-4da2-a667-2456a028cd75 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:10:16.325
  Apr 13 13:10:16.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8423" for this suite. @ 04/13/24 13:10:16.347
• [4.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/13/24 13:10:16.353
  Apr 13 13:10:16.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-watch @ 04/13/24 13:10:16.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:10:16.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:10:16.379
  Apr 13 13:10:16.382: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:10:16.452045      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:17.452300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:18.452486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 04/13/24 13:10:18.923
  Apr 13 13:10:18.928: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:18Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:18Z]] name:name1 resourceVersion:25817 uid:ce342ab2-2eb4-44a4-a1f6-ccc9de5369ff] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:10:19.452779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:20.452868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:21.452928      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:22.453853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:23.454234      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:24.454471      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:25.455528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:26.456522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:27.457584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:28.457878      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 04/13/24 13:10:28.928
  Apr 13 13:10:28.934: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:28Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:28Z]] name:name2 resourceVersion:25850 uid:aef82305-0cfe-45ce-816d-977af4cf8524] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:10:29.457982      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:30.458190      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:31.458436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:32.458477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:33.459524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:34.459654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:35.460668      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:36.460766      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:37.461829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:38.461935      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 04/13/24 13:10:38.935
  Apr 13 13:10:38.941: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:18Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:38Z]] name:name1 resourceVersion:25870 uid:ce342ab2-2eb4-44a4-a1f6-ccc9de5369ff] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:10:39.462289      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:40.462549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:41.462554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:42.463454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:43.463579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:44.463648      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:45.463822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:46.464032      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:47.464107      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:48.464300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 04/13/24 13:10:48.941
  Apr 13 13:10:48.948: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:28Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:48Z]] name:name2 resourceVersion:25890 uid:aef82305-0cfe-45ce-816d-977af4cf8524] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:10:49.464405      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:50.464549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:51.464718      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:52.465660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:53.465774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:54.465956      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:55.467024      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:56.467124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:57.467252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:10:58.467531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 04/13/24 13:10:58.949
  Apr 13 13:10:58.957: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:18Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:38Z]] name:name1 resourceVersion:25910 uid:ce342ab2-2eb4-44a4-a1f6-ccc9de5369ff] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:10:59.468027      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:00.468214      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:01.468422      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:02.468582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:03.468756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:04.468900      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:05.469111      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:06.469230      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:07.469596      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:08.470522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 04/13/24 13:11:08.958
  Apr 13 13:11:08.967: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-13T13:10:28Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-13T13:10:48Z]] name:name2 resourceVersion:25932 uid:aef82305-0cfe-45ce-816d-977af4cf8524] num:map[num1:9223372036854775807 num2:1000000]]}
  E0413 13:11:09.470604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:10.471526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:11.472461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:12.472560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:13.472739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:14.472832      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:15.473117      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:16.473901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:17.474785      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:18.475044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:19.475221      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:19.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-1921" for this suite. @ 04/13/24 13:11:19.489
• [63.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/13/24 13:11:19.5
  Apr 13 13:11:19.500: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 13:11:19.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:11:19.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:11:19.522
  Apr 13 13:11:19.534: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0413 13:11:20.475665      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:21.475779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:22.476692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:23.476793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:24.476901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:24.539: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 13:11:24.539
  Apr 13 13:11:24.539: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0413 13:11:25.477116      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:26.477418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:26.544: INFO: Creating deployment "test-rollover-deployment"
  Apr 13 13:11:26.555: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0413 13:11:27.477509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:28.477602      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:28.564: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 13 13:11:28.571: INFO: Ensure that both replica sets have 1 created replica
  Apr 13 13:11:28.578: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 13 13:11:28.589: INFO: Updating deployment test-rollover-deployment
  Apr 13 13:11:28.589: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0413 13:11:29.477752      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:30.477942      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:30.598: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 13 13:11:30.605: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 13 13:11:30.612: INFO: all replica sets need to contain the pod-template-hash label
  Apr 13 13:11:30.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:11:31.478655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:32.478758      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:32.621: INFO: all replica sets need to contain the pod-template-hash label
  Apr 13 13:11:32.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:11:33.478851      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:34.478957      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:34.620: INFO: all replica sets need to contain the pod-template-hash label
  Apr 13 13:11:34.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:11:35.479563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:36.479666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:36.621: INFO: all replica sets need to contain the pod-template-hash label
  Apr 13 13:11:36.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:11:37.480224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:38.480327      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:38.621: INFO: all replica sets need to contain the pod-template-hash label
  Apr 13 13:11:38.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 11, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 11, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:11:39.480543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:40.480629      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:40.621: INFO: 
  Apr 13 13:11:40.621: INFO: Ensure that both old replica sets have no replicas
  Apr 13 13:11:40.632: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2ee7868-67d7-4b7d-a167-a84a2e5da94c",
      ResourceVersion: (string) (len=5) "26095",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610686,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610699,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610686,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610686,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610699,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610686,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 13:11:40.636: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e24d171b-3c86-4e9c-b9cd-1a206f83ad45",
      ResourceVersion: (string) (len=5) "26085",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610688,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "c2ee7868-67d7-4b7d-a167-a84a2e5da94c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 32 65 65 37 38  36 38 2d 36 37 64 37 2d  |\"c2ee7868-67d7-|
              00000120  34 62 37 64 2d 61 31 36  37 2d 61 38 34 61 32 65  |4b7d-a167-a84a2e|
              00000130  35 64 61 39 34 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5da94c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610699,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:11:40.637: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 13 13:11:40.637: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e2509d51-95ad-4607-9d78-5da091bcd295",
      ResourceVersion: (string) (len=5) "26094",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610679,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "c2ee7868-67d7-4b7d-a167-a84a2e5da94c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610679,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610699,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  63 32 65 65 37 38 36 38  2d 36 37 64 37 2d 34 62  |c2ee7868-67d7-4b|
              000000c0  37 64 2d 61 31 36 37 2d  61 38 34 61 32 65 35 64  |7d-a167-a84a2e5d|
              000000d0  61 39 34 63 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |a94c\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610699,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:11:40.638: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7e3a50d4-56a7-4676-82f4-01c11a329281",
      ResourceVersion: (string) (len=5) "26046",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610686,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "c2ee7868-67d7-4b7d-a167-a84a2e5da94c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 32 65 65 37 38  36 38 2d 36 37 64 37 2d  |\"c2ee7868-67d7-|
              00000120  34 62 37 64 2d 61 31 36  37 2d 61 38 34 61 32 65  |4b7d-a167-a84a2e|
              00000130  35 64 61 39 34 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5da94c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:11:40.642: INFO: Pod "test-rollover-deployment-68774655d5-9lpgh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-9lpgh",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-3175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f722e036-5dee-487d-a1e1-271567542f09",
      ResourceVersion: (string) (len=5) "26061",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610688,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "e24d171b-3c86-4e9c-b9cd-1a206f83ad45",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 32  34 64 31 37 31 62 2d 33  |d\":\"e24d171b-3|
              00000090  63 38 36 2d 34 65 39 63  2d 62 39 63 64 2d 31 61  |c86-4e9c-b9cd-1a|
              000000a0  32 30 36 66 38 33 61 64  34 35 5c 22 7d 22 3a 7b  |206f83ad45\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610689,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 35 37  2e 32 30 31 5c 22 7d 22  |2.168.57.201\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mxhb9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mxhb9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610689,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610689,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610689,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848610688,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.201",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.201"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848610688,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848610689,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://c026137dac48efd2c139067052a1845c4670ec716005f9e0cfeb9732ab817802",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 13:11:40.644: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3175" for this suite. @ 04/13/24 13:11:40.648
• [21.156 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/13/24 13:11:40.656
  Apr 13 13:11:40.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/13/24 13:11:40.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:11:40.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:11:40.676
  STEP: Creating 50 configmaps @ 04/13/24 13:11:40.679
  STEP: Creating RC which spawns configmap-volume pods @ 04/13/24 13:11:40.911
  Apr 13 13:11:41.033: INFO: Pod name wrapped-volume-race-fc363ee2-5837-47cc-bff2-f1308afa9d86: Found 3 pods out of 5
  E0413 13:11:41.481154      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:42.482244      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:43.482375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:44.482502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:45.483545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:46.039: INFO: Pod name wrapped-volume-race-fc363ee2-5837-47cc-bff2-f1308afa9d86: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/13/24 13:11:46.039
  STEP: Creating RC which spawns configmap-volume pods @ 04/13/24 13:11:46.06
  Apr 13 13:11:46.072: INFO: Pod name wrapped-volume-race-ee52a573-3b64-468e-96a9-2b7688187d11: Found 0 pods out of 5
  E0413 13:11:46.484175      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:47.485072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:48.485279      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:49.485370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:50.486314      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:51.079: INFO: Pod name wrapped-volume-race-ee52a573-3b64-468e-96a9-2b7688187d11: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/13/24 13:11:51.079
  STEP: Creating RC which spawns configmap-volume pods @ 04/13/24 13:11:51.101
  Apr 13 13:11:51.113: INFO: Pod name wrapped-volume-race-11d0adf2-95b1-4a07-97cc-3b2a95336373: Found 0 pods out of 5
  E0413 13:11:51.487382      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:52.487471      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:53.487655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:54.487759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:55.487869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:11:56.122: INFO: Pod name wrapped-volume-race-11d0adf2-95b1-4a07-97cc-3b2a95336373: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/13/24 13:11:56.122
  STEP: deleting ReplicationController wrapped-volume-race-11d0adf2-95b1-4a07-97cc-3b2a95336373 in namespace emptydir-wrapper-3751, will wait for the garbage collector to delete the pods @ 04/13/24 13:11:56.141
  Apr 13 13:11:56.206: INFO: Deleting ReplicationController wrapped-volume-race-11d0adf2-95b1-4a07-97cc-3b2a95336373 took: 8.378472ms
  Apr 13 13:11:56.306: INFO: Terminating ReplicationController wrapped-volume-race-11d0adf2-95b1-4a07-97cc-3b2a95336373 pods took: 100.405893ms
  E0413 13:11:56.487926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:11:57.488580      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-ee52a573-3b64-468e-96a9-2b7688187d11 in namespace emptydir-wrapper-3751, will wait for the garbage collector to delete the pods @ 04/13/24 13:11:57.707
  Apr 13 13:11:57.769: INFO: Deleting ReplicationController wrapped-volume-race-ee52a573-3b64-468e-96a9-2b7688187d11 took: 7.60688ms
  Apr 13 13:11:57.870: INFO: Terminating ReplicationController wrapped-volume-race-ee52a573-3b64-468e-96a9-2b7688187d11 pods took: 101.041297ms
  E0413 13:11:58.489044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-fc363ee2-5837-47cc-bff2-f1308afa9d86 in namespace emptydir-wrapper-3751, will wait for the garbage collector to delete the pods @ 04/13/24 13:11:59.071
  Apr 13 13:11:59.134: INFO: Deleting ReplicationController wrapped-volume-race-fc363ee2-5837-47cc-bff2-f1308afa9d86 took: 7.260803ms
  Apr 13 13:11:59.234: INFO: Terminating ReplicationController wrapped-volume-race-fc363ee2-5837-47cc-bff2-f1308afa9d86 pods took: 100.224154ms
  E0413 13:11:59.490479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 04/13/24 13:12:00.235
  E0413 13:12:00.491188      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:00.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-3751" for this suite. @ 04/13/24 13:12:00.54
• [19.890 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 04/13/24 13:12:00.546
  Apr 13 13:12:00.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 13:12:00.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:12:00.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:12:00.567
  STEP: Create a Replicaset @ 04/13/24 13:12:00.575
  STEP: Verify that the required pods have come up. @ 04/13/24 13:12:00.581
  Apr 13 13:12:00.585: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0413 13:12:01.491322      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:02.491556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:03.491759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:04.491990      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:05.492079      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:05.590: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 13:12:05.59
  STEP: Getting /status @ 04/13/24 13:12:05.59
  Apr 13 13:12:05.593: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/13/24 13:12:05.593
  Apr 13 13:12:05.604: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/13/24 13:12:05.604
  Apr 13 13:12:05.606: INFO: Observed &ReplicaSet event: ADDED
  Apr 13 13:12:05.606: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.607: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.607: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.607: INFO: Found replicaset test-rs in namespace replicaset-2260 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 13 13:12:05.607: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/13/24 13:12:05.607
  Apr 13 13:12:05.607: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 13 13:12:05.613: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/13/24 13:12:05.613
  Apr 13 13:12:05.615: INFO: Observed &ReplicaSet event: ADDED
  Apr 13 13:12:05.615: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.615: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.615: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.615: INFO: Observed replicaset test-rs in namespace replicaset-2260 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:12:05.615: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 13 13:12:05.615: INFO: Found replicaset test-rs in namespace replicaset-2260 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 13 13:12:05.615: INFO: Replicaset test-rs has a patched status
  Apr 13 13:12:05.615: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2260" for this suite. @ 04/13/24 13:12:05.619
• [5.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 04/13/24 13:12:05.626
  Apr 13 13:12:05.626: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename limitrange @ 04/13/24 13:12:05.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:12:05.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:12:05.646
  STEP: Creating a LimitRange @ 04/13/24 13:12:05.649
  STEP: Setting up watch @ 04/13/24 13:12:05.649
  STEP: Submitting a LimitRange @ 04/13/24 13:12:05.753
  STEP: Verifying LimitRange creation was observed @ 04/13/24 13:12:05.758
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/13/24 13:12:05.758
  Apr 13 13:12:05.761: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 13 13:12:05.761: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/13/24 13:12:05.761
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/13/24 13:12:05.768
  Apr 13 13:12:05.772: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 13 13:12:05.772: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/13/24 13:12:05.772
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/13/24 13:12:05.78
  Apr 13 13:12:05.787: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 13 13:12:05.787: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/13/24 13:12:05.787
  STEP: Failing to create a Pod with more than max resources @ 04/13/24 13:12:05.791
  STEP: Updating a LimitRange @ 04/13/24 13:12:05.793
  STEP: Verifying LimitRange updating is effective @ 04/13/24 13:12:05.799
  E0413 13:12:06.492513      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:07.492662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 04/13/24 13:12:07.803
  STEP: Failing to create a Pod with more than max resources @ 04/13/24 13:12:07.81
  STEP: Deleting a LimitRange @ 04/13/24 13:12:07.812
  STEP: Verifying the LimitRange was deleted @ 04/13/24 13:12:07.822
  E0413 13:12:08.493167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:09.493385      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:10.493630      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:11.494243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:12.494705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:12.827: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/13/24 13:12:12.827
  Apr 13 13:12:12.836: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7363" for this suite. @ 04/13/24 13:12:12.842
• [7.223 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/13/24 13:12:12.849
  Apr 13 13:12:12.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 13:12:12.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:12:12.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:12:12.869
  Apr 13 13:12:12.873: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:12:13.495158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/13/24 13:12:14.183
  Apr 13 13:12:14.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-7888 --namespace=crd-publish-openapi-7888 create -f -'
  Apr 13 13:12:14.263: INFO: stderr: ""
  Apr 13 13:12:14.263: INFO: stdout: "e2e-test-crd-publish-openapi-7908-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 13 13:12:14.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-7888 --namespace=crd-publish-openapi-7888 delete e2e-test-crd-publish-openapi-7908-crds test-cr'
  Apr 13 13:12:14.321: INFO: stderr: ""
  Apr 13 13:12:14.321: INFO: stdout: "e2e-test-crd-publish-openapi-7908-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 13 13:12:14.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-7888 --namespace=crd-publish-openapi-7888 apply -f -'
  Apr 13 13:12:14.371: INFO: stderr: ""
  Apr 13 13:12:14.371: INFO: stdout: "e2e-test-crd-publish-openapi-7908-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 13 13:12:14.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-7888 --namespace=crd-publish-openapi-7888 delete e2e-test-crd-publish-openapi-7908-crds test-cr'
  Apr 13 13:12:14.419: INFO: stderr: ""
  Apr 13 13:12:14.419: INFO: stdout: "e2e-test-crd-publish-openapi-7908-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/13/24 13:12:14.419
  Apr 13 13:12:14.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-7888 explain e2e-test-crd-publish-openapi-7908-crds'
  Apr 13 13:12:14.456: INFO: stderr: ""
  Apr 13 13:12:14.456: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-7908-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0413 13:12:14.495377      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:15.495756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:15.682: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7888" for this suite. @ 04/13/24 13:12:15.69
• [2.846 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 04/13/24 13:12:15.696
  Apr 13 13:12:15.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:12:15.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:12:15.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:12:15.713
  STEP: Creating service test in namespace statefulset-9523 @ 04/13/24 13:12:15.716
  STEP: Creating a new StatefulSet @ 04/13/24 13:12:15.721
  Apr 13 13:12:15.735: INFO: Found 0 stateful pods, waiting for 3
  E0413 13:12:16.496823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:17.496824      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:18.496921      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:19.497014      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:20.497201      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:21.497407      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:22.497809      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:23.497883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:24.497998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:25.498084      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:25.737: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:12:25.737: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:12:25.737: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:12:25.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-9523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 13:12:25.843: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:12:25.843: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:12:25.843: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0413 13:12:26.498933      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:27.499327      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:28.499524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:29.499929      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:30.500044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:31.500213      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:32.500856      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:33.500924      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:34.501026      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:35.501531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/13/24 13:12:35.852
  Apr 13 13:12:35.879: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/13/24 13:12:35.879
  E0413 13:12:36.502537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:37.502709      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:38.502791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:39.503533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:40.503626      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:41.503707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:42.503827      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:43.503926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:44.504133      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:45.504308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 04/13/24 13:12:45.888
  Apr 13 13:12:45.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-9523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:12:45.984: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:12:45.984: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:12:45.984: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0413 13:12:46.504494      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:47.504724      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:48.504841      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:49.504958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:50.505049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:51.505175      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:52.506161      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:53.506291      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:54.506486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:55.507556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:12:55.999: INFO: Waiting for StatefulSet statefulset-9523/ss2 to complete update
  E0413 13:12:56.508463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:57.508582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:58.508699      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:12:59.508773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:00.509104      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:01.509325      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:02.509722      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:03.509801      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:04.509902      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:05.510191      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 04/13/24 13:13:06.002
  Apr 13 13:13:06.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-9523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 13:13:06.090: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:13:06.090: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:13:06.090: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0413 13:13:06.510788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:07.511047      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:08.511139      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:09.511245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:10.511320      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:11.511420      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:12.511647      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:13.511741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:14.511852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:15.511942      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:16.121: INFO: Updating stateful set ss2
  E0413 13:13:16.512769      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:17.512927      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:18.513028      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:19.513220      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:20.513377      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:21.513484      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:22.513633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:23.513739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:24.513813      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:25.513911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 04/13/24 13:13:26.131
  Apr 13 13:13:26.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-9523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:13:26.227: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:13:26.227: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:13:26.227: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0413 13:13:26.514979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:27.515372      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:28.516330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:29.516790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:30.516886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:31.517050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:32.517202      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:33.517296      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:34.517470      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:35.517641      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:36.243: INFO: Deleting all statefulset in ns statefulset-9523
  Apr 13 13:13:36.246: INFO: Scaling statefulset ss2 to 0
  E0413 13:13:36.518388      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:37.518799      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:38.519590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:39.519671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:40.519770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:41.519910      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:42.519998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:43.520984      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:44.521993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:45.522180      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:46.260: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 13:13:46.263: INFO: Deleting statefulset ss2
  Apr 13 13:13:46.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9523" for this suite. @ 04/13/24 13:13:46.28
• [90.592 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 04/13/24 13:13:46.288
  Apr 13 13:13:46.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:13:46.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:13:46.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:13:46.307
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:13:46.31
  E0413 13:13:46.523015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:47.523685      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:48.524752      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:49.524942      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:13:50.33
  Apr 13 13:13:50.334: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-7d5ce6f2-15f7-4b76-b44c-0221e682af6d container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:13:50.348
  Apr 13 13:13:50.364: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9116" for this suite. @ 04/13/24 13:13:50.368
• [4.086 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 04/13/24 13:13:50.374
  Apr 13 13:13:50.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:13:50.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:13:50.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:13:50.392
  STEP: creating a collection of services @ 04/13/24 13:13:50.395
  Apr 13 13:13:50.395: INFO: Creating e2e-svc-a-fxvv4
  Apr 13 13:13:50.404: INFO: Creating e2e-svc-b-r2ws4
  Apr 13 13:13:50.414: INFO: Creating e2e-svc-c-dv5zt
  STEP: deleting service collection @ 04/13/24 13:13:50.427
  Apr 13 13:13:50.452: INFO: Collection of services has been deleted
  Apr 13 13:13:50.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6415" for this suite. @ 04/13/24 13:13:50.456
• [0.089 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 04/13/24 13:13:50.463
  Apr 13 13:13:50.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:13:50.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:13:50.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:13:50.478
  STEP: creating a replication controller @ 04/13/24 13:13:50.482
  Apr 13 13:13:50.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 create -f -'
  E0413 13:13:50.525450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:50.557: INFO: stderr: ""
  Apr 13 13:13:50.557: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/13/24 13:13:50.557
  Apr 13 13:13:50.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:13:50.599: INFO: stderr: ""
  Apr 13 13:13:50.599: INFO: stdout: "update-demo-nautilus-d9wwf update-demo-nautilus-tmv5b "
  Apr 13 13:13:50.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:13:50.642: INFO: stderr: ""
  Apr 13 13:13:50.642: INFO: stdout: ""
  Apr 13 13:13:50.642: INFO: update-demo-nautilus-d9wwf is created but not running
  E0413 13:13:51.525907      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:52.526753      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:53.526831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:54.526934      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:55.527031      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:55.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:13:55.685: INFO: stderr: ""
  Apr 13 13:13:55.685: INFO: stdout: "update-demo-nautilus-d9wwf update-demo-nautilus-tmv5b "
  Apr 13 13:13:55.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:13:55.725: INFO: stderr: ""
  Apr 13 13:13:55.725: INFO: stdout: "true"
  Apr 13 13:13:55.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:13:55.764: INFO: stderr: ""
  Apr 13 13:13:55.764: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:13:55.764: INFO: validating pod update-demo-nautilus-d9wwf
  Apr 13 13:13:55.769: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:13:55.769: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:13:55.769: INFO: update-demo-nautilus-d9wwf is verified up and running
  Apr 13 13:13:55.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-tmv5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:13:55.808: INFO: stderr: ""
  Apr 13 13:13:55.808: INFO: stdout: "true"
  Apr 13 13:13:55.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-tmv5b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:13:55.847: INFO: stderr: ""
  Apr 13 13:13:55.847: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:13:55.847: INFO: validating pod update-demo-nautilus-tmv5b
  Apr 13 13:13:55.852: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:13:55.853: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:13:55.853: INFO: update-demo-nautilus-tmv5b is verified up and running
  STEP: scaling down the replication controller @ 04/13/24 13:13:55.853
  Apr 13 13:13:55.853: INFO: scanned /root for discovery docs: <nil>
  Apr 13 13:13:55.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0413 13:13:56.527584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:13:56.915: INFO: stderr: ""
  Apr 13 13:13:56.915: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/13/24 13:13:56.915
  Apr 13 13:13:56.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:13:56.961: INFO: stderr: ""
  Apr 13 13:13:56.961: INFO: stdout: "update-demo-nautilus-d9wwf update-demo-nautilus-tmv5b "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 04/13/24 13:13:56.961
  E0413 13:13:57.527669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:58.527767      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:13:59.527985      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:00.528128      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:01.528852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:14:01.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:14:02.004: INFO: stderr: ""
  Apr 13 13:14:02.004: INFO: stdout: "update-demo-nautilus-d9wwf "
  Apr 13 13:14:02.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:14:02.044: INFO: stderr: ""
  Apr 13 13:14:02.044: INFO: stdout: "true"
  Apr 13 13:14:02.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:14:02.085: INFO: stderr: ""
  Apr 13 13:14:02.085: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:14:02.085: INFO: validating pod update-demo-nautilus-d9wwf
  Apr 13 13:14:02.089: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:14:02.089: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:14:02.089: INFO: update-demo-nautilus-d9wwf is verified up and running
  STEP: scaling up the replication controller @ 04/13/24 13:14:02.089
  Apr 13 13:14:02.089: INFO: scanned /root for discovery docs: <nil>
  Apr 13 13:14:02.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0413 13:14:02.529679      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:14:03.147: INFO: stderr: ""
  Apr 13 13:14:03.147: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/13/24 13:14:03.147
  Apr 13 13:14:03.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:14:03.192: INFO: stderr: ""
  Apr 13 13:14:03.192: INFO: stdout: "update-demo-nautilus-d9wwf update-demo-nautilus-pg8z7 "
  Apr 13 13:14:03.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:14:03.232: INFO: stderr: ""
  Apr 13 13:14:03.232: INFO: stdout: "true"
  Apr 13 13:14:03.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-d9wwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:14:03.271: INFO: stderr: ""
  Apr 13 13:14:03.271: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:14:03.271: INFO: validating pod update-demo-nautilus-d9wwf
  Apr 13 13:14:03.275: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:14:03.275: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:14:03.275: INFO: update-demo-nautilus-d9wwf is verified up and running
  Apr 13 13:14:03.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-pg8z7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:14:03.315: INFO: stderr: ""
  Apr 13 13:14:03.315: INFO: stdout: "true"
  Apr 13 13:14:03.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods update-demo-nautilus-pg8z7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:14:03.354: INFO: stderr: ""
  Apr 13 13:14:03.354: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:14:03.354: INFO: validating pod update-demo-nautilus-pg8z7
  Apr 13 13:14:03.360: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:14:03.360: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:14:03.360: INFO: update-demo-nautilus-pg8z7 is verified up and running
  STEP: using delete to clean up resources @ 04/13/24 13:14:03.36
  Apr 13 13:14:03.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 delete --grace-period=0 --force -f -'
  Apr 13 13:14:03.404: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:14:03.404: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 13 13:14:03.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get rc,svc -l name=update-demo --no-headers'
  Apr 13 13:14:03.448: INFO: stderr: "No resources found in kubectl-6055 namespace.\n"
  Apr 13 13:14:03.448: INFO: stdout: ""
  Apr 13 13:14:03.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6055 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 13 13:14:03.490: INFO: stderr: ""
  Apr 13 13:14:03.490: INFO: stdout: ""
  Apr 13 13:14:03.490: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6055" for this suite. @ 04/13/24 13:14:03.494
• [13.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 04/13/24 13:14:03.501
  Apr 13 13:14:03.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/13/24 13:14:03.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:14:03.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:14:03.519
  STEP: create the container to handle the HTTPGet hook request. @ 04/13/24 13:14:03.525
  E0413 13:14:03.530321      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:04.530576      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:05.530677      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/13/24 13:14:05.548
  E0413 13:14:06.531539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:07.531711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/13/24 13:14:07.568
  E0413 13:14:08.531821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:09.531896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:10.531993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:11.532082      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/13/24 13:14:11.589
  Apr 13 13:14:11.595: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-419" for this suite. @ 04/13/24 13:14:11.599
• [8.105 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/13/24 13:14:11.606
  Apr 13 13:14:11.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename cronjob @ 04/13/24 13:14:11.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:14:11.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:14:11.624
  STEP: Creating a cronjob @ 04/13/24 13:14:11.627
  STEP: Ensuring more than one job is running at a time @ 04/13/24 13:14:11.632
  E0413 13:14:12.532735      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:13.532827      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:14.532938      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:15.533981      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:16.534118      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:17.534703      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:18.534784      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:19.535668      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:20.536718      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:21.536818      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:22.537444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:23.537541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:24.538395      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:25.538575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:26.539541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:27.539627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:28.540241      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:29.540334      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:30.540442      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:31.540555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:32.541345      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:33.541429      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:34.542368      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:35.542467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:36.542499      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:37.542587      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:38.543552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:39.543639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:40.543951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:41.544125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:42.544273      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:43.544358      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:44.544443      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:45.544624      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:46.545094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:47.545505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:48.545964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:49.546068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:50.546151      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:51.546270      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:52.546759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:53.546858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:54.546952      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:55.547529      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:56.548008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:57.548441      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:58.548544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:14:59.549139      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:00.549253      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:01.549505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:02.550004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:03.550091      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:04.550666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:05.550751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:06.550830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:07.551883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:08.551975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:09.552376      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:10.552592      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:11.552764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:12.552865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:13.553052      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:14.554060      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:15.554415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:16.554498      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:17.554886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:18.555433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:19.555547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:20.556038      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:21.556226      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:22.557211      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:23.557434      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:24.557500      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:25.558210      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:26.558764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:27.558854      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:28.559437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:29.559494      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:30.559565      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:31.559667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:32.559971      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:33.560072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:34.560824      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:35.561836      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:36.561956      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:37.562978      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:38.563532      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:39.563704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:40.563876      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:41.564088      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:42.564611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:43.565122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:44.565630      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:45.565808      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:46.566268      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:47.566358      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:48.566631      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:49.566726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:50.567714      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:51.567811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:52.567848      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:53.568020      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:54.568306      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:55.568598      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:56.568683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:57.568778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:58.569441      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:15:59.569524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:00.570608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:01.570643      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/13/24 13:16:01.639
  STEP: Removing cronjob @ 04/13/24 13:16:01.642
  Apr 13 13:16:01.648: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1564" for this suite. @ 04/13/24 13:16:01.652
• [110.051 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/13/24 13:16:01.658
  Apr 13 13:16:01.658: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svc-latency @ 04/13/24 13:16:01.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:01.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:01.688
  Apr 13 13:16:01.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5696 @ 04/13/24 13:16:01.693
  I0413 13:16:01.699733      21 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5696, replica count: 1
  E0413 13:16:02.571193      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:16:02.750566      21 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0413 13:16:03.571936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:16:03.751300      21 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:16:03.865: INFO: Created: latency-svc-pqzdj
  Apr 13 13:16:03.873: INFO: Got endpoints: latency-svc-pqzdj [21.246733ms]
  Apr 13 13:16:03.885: INFO: Created: latency-svc-tkhd7
  Apr 13 13:16:03.893: INFO: Created: latency-svc-mslz6
  Apr 13 13:16:03.895: INFO: Got endpoints: latency-svc-tkhd7 [21.322594ms]
  Apr 13 13:16:03.901: INFO: Got endpoints: latency-svc-mslz6 [27.503625ms]
  Apr 13 13:16:03.903: INFO: Created: latency-svc-bc7bl
  Apr 13 13:16:03.905: INFO: Got endpoints: latency-svc-bc7bl [31.396653ms]
  Apr 13 13:16:03.909: INFO: Created: latency-svc-622jf
  Apr 13 13:16:03.915: INFO: Got endpoints: latency-svc-622jf [41.609941ms]
  Apr 13 13:16:03.919: INFO: Created: latency-svc-czb4v
  Apr 13 13:16:03.922: INFO: Got endpoints: latency-svc-czb4v [48.163612ms]
  Apr 13 13:16:03.927: INFO: Created: latency-svc-v5h55
  Apr 13 13:16:03.932: INFO: Created: latency-svc-2h7cz
  Apr 13 13:16:03.935: INFO: Got endpoints: latency-svc-v5h55 [61.335508ms]
  Apr 13 13:16:03.938: INFO: Got endpoints: latency-svc-2h7cz [64.077587ms]
  Apr 13 13:16:03.941: INFO: Created: latency-svc-fg2mk
  Apr 13 13:16:03.947: INFO: Got endpoints: latency-svc-fg2mk [73.340666ms]
  Apr 13 13:16:03.951: INFO: Created: latency-svc-59gng
  Apr 13 13:16:03.956: INFO: Got endpoints: latency-svc-59gng [82.23637ms]
  Apr 13 13:16:03.956: INFO: Created: latency-svc-ntfwx
  Apr 13 13:16:03.961: INFO: Got endpoints: latency-svc-ntfwx [86.898975ms]
  Apr 13 13:16:03.966: INFO: Created: latency-svc-5bcf8
  Apr 13 13:16:03.969: INFO: Got endpoints: latency-svc-5bcf8 [94.790603ms]
  Apr 13 13:16:03.978: INFO: Created: latency-svc-xf9kl
  Apr 13 13:16:03.978: INFO: Created: latency-svc-fglxn
  Apr 13 13:16:03.985: INFO: Created: latency-svc-rnf2x
  Apr 13 13:16:03.988: INFO: Got endpoints: latency-svc-fglxn [113.966031ms]
  Apr 13 13:16:03.988: INFO: Got endpoints: latency-svc-xf9kl [113.918712ms]
  Apr 13 13:16:03.992: INFO: Got endpoints: latency-svc-rnf2x [118.731032ms]
  Apr 13 13:16:03.995: INFO: Created: latency-svc-tngwr
  Apr 13 13:16:04.002: INFO: Got endpoints: latency-svc-tngwr [128.365099ms]
  Apr 13 13:16:04.003: INFO: Created: latency-svc-prt56
  Apr 13 13:16:04.009: INFO: Created: latency-svc-g2kgg
  Apr 13 13:16:04.010: INFO: Got endpoints: latency-svc-prt56 [115.50993ms]
  Apr 13 13:16:04.014: INFO: Got endpoints: latency-svc-g2kgg [112.847786ms]
  Apr 13 13:16:04.018: INFO: Created: latency-svc-g9z9p
  Apr 13 13:16:04.022: INFO: Got endpoints: latency-svc-g9z9p [117.484897ms]
  Apr 13 13:16:04.027: INFO: Created: latency-svc-4xwhf
  Apr 13 13:16:04.032: INFO: Got endpoints: latency-svc-4xwhf [116.919737ms]
  Apr 13 13:16:04.033: INFO: Created: latency-svc-w8b94
  Apr 13 13:16:04.039: INFO: Got endpoints: latency-svc-w8b94 [117.452493ms]
  Apr 13 13:16:04.041: INFO: Created: latency-svc-7gpcp
  Apr 13 13:16:04.045: INFO: Created: latency-svc-bn9cv
  Apr 13 13:16:04.046: INFO: Got endpoints: latency-svc-7gpcp [110.80208ms]
  Apr 13 13:16:04.051: INFO: Got endpoints: latency-svc-bn9cv [113.054518ms]
  Apr 13 13:16:04.054: INFO: Created: latency-svc-cfd2t
  Apr 13 13:16:04.060: INFO: Got endpoints: latency-svc-cfd2t [113.146269ms]
  Apr 13 13:16:04.065: INFO: Created: latency-svc-v68fr
  Apr 13 13:16:04.070: INFO: Got endpoints: latency-svc-v68fr [113.788677ms]
  Apr 13 13:16:04.073: INFO: Created: latency-svc-9whqr
  Apr 13 13:16:04.078: INFO: Got endpoints: latency-svc-9whqr [117.315116ms]
  Apr 13 13:16:04.079: INFO: Created: latency-svc-6qchl
  Apr 13 13:16:04.086: INFO: Got endpoints: latency-svc-6qchl [117.54412ms]
  Apr 13 13:16:04.089: INFO: Created: latency-svc-qmnmw
  Apr 13 13:16:04.093: INFO: Got endpoints: latency-svc-qmnmw [105.043493ms]
  Apr 13 13:16:04.093: INFO: Created: latency-svc-z5xmr
  Apr 13 13:16:04.102: INFO: Got endpoints: latency-svc-z5xmr [113.861645ms]
  Apr 13 13:16:04.104: INFO: Created: latency-svc-pjf7z
  Apr 13 13:16:04.110: INFO: Got endpoints: latency-svc-pjf7z [117.534239ms]
  Apr 13 13:16:04.112: INFO: Created: latency-svc-9597j
  Apr 13 13:16:04.121: INFO: Got endpoints: latency-svc-9597j [119.166183ms]
  Apr 13 13:16:04.124: INFO: Created: latency-svc-49t76
  Apr 13 13:16:04.128: INFO: Got endpoints: latency-svc-49t76 [117.929821ms]
  Apr 13 13:16:04.131: INFO: Created: latency-svc-x84x8
  Apr 13 13:16:04.142: INFO: Got endpoints: latency-svc-x84x8 [128.322112ms]
  Apr 13 13:16:04.148: INFO: Created: latency-svc-2tnjg
  Apr 13 13:16:04.151: INFO: Got endpoints: latency-svc-2tnjg [129.000615ms]
  Apr 13 13:16:04.156: INFO: Created: latency-svc-gzzqg
  Apr 13 13:16:04.160: INFO: Got endpoints: latency-svc-gzzqg [127.498599ms]
  Apr 13 13:16:04.167: INFO: Created: latency-svc-p962q
  Apr 13 13:16:04.175: INFO: Got endpoints: latency-svc-p962q [135.609268ms]
  Apr 13 13:16:04.236: INFO: Created: latency-svc-kbs4r
  Apr 13 13:16:04.238: INFO: Created: latency-svc-g924s
  Apr 13 13:16:04.239: INFO: Created: latency-svc-x8hxq
  Apr 13 13:16:04.241: INFO: Created: latency-svc-7vh8m
  Apr 13 13:16:04.241: INFO: Created: latency-svc-hvd4f
  Apr 13 13:16:04.241: INFO: Created: latency-svc-gzzc2
  Apr 13 13:16:04.241: INFO: Created: latency-svc-74h5r
  Apr 13 13:16:04.241: INFO: Created: latency-svc-g7d9v
  Apr 13 13:16:04.241: INFO: Created: latency-svc-8gzp4
  Apr 13 13:16:04.242: INFO: Created: latency-svc-wjrfr
  Apr 13 13:16:04.242: INFO: Created: latency-svc-tkhqc
  Apr 13 13:16:04.242: INFO: Created: latency-svc-2b46l
  Apr 13 13:16:04.243: INFO: Created: latency-svc-hxtwd
  Apr 13 13:16:04.247: INFO: Created: latency-svc-jv2df
  Apr 13 13:16:04.247: INFO: Created: latency-svc-r85nz
  Apr 13 13:16:04.251: INFO: Got endpoints: latency-svc-kbs4r [165.203194ms]
  Apr 13 13:16:04.262: INFO: Created: latency-svc-txzqr
  Apr 13 13:16:04.268: INFO: Got endpoints: latency-svc-wjrfr [190.316026ms]
  Apr 13 13:16:04.278: INFO: Created: latency-svc-n89q2
  Apr 13 13:16:04.320: INFO: Got endpoints: latency-svc-74h5r [191.888146ms]
  Apr 13 13:16:04.329: INFO: Created: latency-svc-n78sg
  Apr 13 13:16:04.369: INFO: Got endpoints: latency-svc-hxtwd [259.303338ms]
  Apr 13 13:16:04.380: INFO: Created: latency-svc-vm9b9
  Apr 13 13:16:04.419: INFO: Got endpoints: latency-svc-g7d9v [317.006052ms]
  Apr 13 13:16:04.430: INFO: Created: latency-svc-tp2gw
  Apr 13 13:16:04.468: INFO: Got endpoints: latency-svc-tkhqc [316.941612ms]
  Apr 13 13:16:04.483: INFO: Created: latency-svc-s4mq9
  Apr 13 13:16:04.520: INFO: Got endpoints: latency-svc-r85nz [345.077257ms]
  Apr 13 13:16:04.530: INFO: Created: latency-svc-wbsf8
  Apr 13 13:16:04.571: INFO: Got endpoints: latency-svc-8gzp4 [520.423478ms]
  E0413 13:16:04.571979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:04.581: INFO: Created: latency-svc-ct8nv
  Apr 13 13:16:04.618: INFO: Got endpoints: latency-svc-x8hxq [557.702196ms]
  Apr 13 13:16:04.630: INFO: Created: latency-svc-6n86g
  Apr 13 13:16:04.669: INFO: Got endpoints: latency-svc-jv2df [599.253688ms]
  Apr 13 13:16:04.680: INFO: Created: latency-svc-9bzf9
  Apr 13 13:16:04.719: INFO: Got endpoints: latency-svc-2b46l [625.873123ms]
  Apr 13 13:16:04.728: INFO: Created: latency-svc-4g6kp
  Apr 13 13:16:04.771: INFO: Got endpoints: latency-svc-7vh8m [648.956008ms]
  Apr 13 13:16:04.779: INFO: Created: latency-svc-q7csx
  Apr 13 13:16:04.821: INFO: Got endpoints: latency-svc-hvd4f [661.183289ms]
  Apr 13 13:16:04.830: INFO: Created: latency-svc-rwt5x
  Apr 13 13:16:04.870: INFO: Got endpoints: latency-svc-g924s [728.116283ms]
  Apr 13 13:16:04.886: INFO: Created: latency-svc-dvm5h
  Apr 13 13:16:04.919: INFO: Got endpoints: latency-svc-gzzc2 [873.179658ms]
  Apr 13 13:16:04.935: INFO: Created: latency-svc-r58gg
  Apr 13 13:16:04.972: INFO: Got endpoints: latency-svc-txzqr [720.179732ms]
  Apr 13 13:16:04.982: INFO: Created: latency-svc-2mj2l
  Apr 13 13:16:05.021: INFO: Got endpoints: latency-svc-n89q2 [752.643097ms]
  Apr 13 13:16:05.032: INFO: Created: latency-svc-zkdmj
  Apr 13 13:16:05.074: INFO: Got endpoints: latency-svc-n78sg [754.001597ms]
  Apr 13 13:16:05.084: INFO: Created: latency-svc-zbz95
  Apr 13 13:16:05.120: INFO: Got endpoints: latency-svc-vm9b9 [750.871276ms]
  Apr 13 13:16:05.134: INFO: Created: latency-svc-d58d5
  Apr 13 13:16:05.171: INFO: Got endpoints: latency-svc-tp2gw [752.202952ms]
  Apr 13 13:16:05.182: INFO: Created: latency-svc-2vxtf
  Apr 13 13:16:05.224: INFO: Got endpoints: latency-svc-s4mq9 [755.093541ms]
  Apr 13 13:16:05.234: INFO: Created: latency-svc-tzrn5
  Apr 13 13:16:05.272: INFO: Got endpoints: latency-svc-wbsf8 [751.771435ms]
  Apr 13 13:16:05.284: INFO: Created: latency-svc-msghz
  Apr 13 13:16:05.323: INFO: Got endpoints: latency-svc-ct8nv [751.435807ms]
  Apr 13 13:16:05.332: INFO: Created: latency-svc-t4jg6
  Apr 13 13:16:05.371: INFO: Got endpoints: latency-svc-6n86g [752.812841ms]
  Apr 13 13:16:05.381: INFO: Created: latency-svc-82n26
  Apr 13 13:16:05.419: INFO: Got endpoints: latency-svc-9bzf9 [749.530162ms]
  Apr 13 13:16:05.430: INFO: Created: latency-svc-zkxfx
  Apr 13 13:16:05.469: INFO: Got endpoints: latency-svc-4g6kp [749.711966ms]
  Apr 13 13:16:05.479: INFO: Created: latency-svc-n2bkn
  Apr 13 13:16:05.526: INFO: Got endpoints: latency-svc-q7csx [755.489437ms]
  Apr 13 13:16:05.535: INFO: Created: latency-svc-b7p6d
  Apr 13 13:16:05.570: INFO: Got endpoints: latency-svc-rwt5x [748.987998ms]
  E0413 13:16:05.572707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:05.585: INFO: Created: latency-svc-5xg6q
  Apr 13 13:16:05.619: INFO: Got endpoints: latency-svc-dvm5h [748.368867ms]
  Apr 13 13:16:05.634: INFO: Created: latency-svc-lphd7
  Apr 13 13:16:05.670: INFO: Got endpoints: latency-svc-r58gg [750.349324ms]
  Apr 13 13:16:05.680: INFO: Created: latency-svc-x277w
  Apr 13 13:16:05.719: INFO: Got endpoints: latency-svc-2mj2l [747.740551ms]
  Apr 13 13:16:05.730: INFO: Created: latency-svc-nh9h7
  Apr 13 13:16:05.771: INFO: Got endpoints: latency-svc-zkdmj [749.589375ms]
  Apr 13 13:16:05.784: INFO: Created: latency-svc-7v54l
  Apr 13 13:16:05.826: INFO: Got endpoints: latency-svc-zbz95 [751.748537ms]
  Apr 13 13:16:05.845: INFO: Created: latency-svc-xkftf
  Apr 13 13:16:05.868: INFO: Got endpoints: latency-svc-d58d5 [747.817203ms]
  Apr 13 13:16:05.879: INFO: Created: latency-svc-7z5zw
  Apr 13 13:16:05.919: INFO: Got endpoints: latency-svc-2vxtf [747.560443ms]
  Apr 13 13:16:05.928: INFO: Created: latency-svc-c2g7w
  Apr 13 13:16:05.971: INFO: Got endpoints: latency-svc-tzrn5 [746.947344ms]
  Apr 13 13:16:05.980: INFO: Created: latency-svc-jmd75
  Apr 13 13:16:06.021: INFO: Got endpoints: latency-svc-msghz [748.795603ms]
  Apr 13 13:16:06.032: INFO: Created: latency-svc-qbpcq
  Apr 13 13:16:06.071: INFO: Got endpoints: latency-svc-t4jg6 [748.030519ms]
  Apr 13 13:16:06.082: INFO: Created: latency-svc-8bllj
  Apr 13 13:16:06.119: INFO: Got endpoints: latency-svc-82n26 [748.64467ms]
  Apr 13 13:16:06.129: INFO: Created: latency-svc-mvp7f
  Apr 13 13:16:06.168: INFO: Got endpoints: latency-svc-zkxfx [749.386732ms]
  Apr 13 13:16:06.178: INFO: Created: latency-svc-cnvnj
  Apr 13 13:16:06.219: INFO: Got endpoints: latency-svc-n2bkn [749.980793ms]
  Apr 13 13:16:06.228: INFO: Created: latency-svc-lwj4g
  Apr 13 13:16:06.271: INFO: Got endpoints: latency-svc-b7p6d [744.222294ms]
  Apr 13 13:16:06.280: INFO: Created: latency-svc-qj9v5
  Apr 13 13:16:06.321: INFO: Got endpoints: latency-svc-5xg6q [750.549542ms]
  Apr 13 13:16:06.330: INFO: Created: latency-svc-hgv6j
  Apr 13 13:16:06.371: INFO: Got endpoints: latency-svc-lphd7 [752.124265ms]
  Apr 13 13:16:06.381: INFO: Created: latency-svc-t7kk6
  Apr 13 13:16:06.419: INFO: Got endpoints: latency-svc-x277w [749.088111ms]
  Apr 13 13:16:06.430: INFO: Created: latency-svc-6bc6l
  Apr 13 13:16:06.469: INFO: Got endpoints: latency-svc-nh9h7 [749.882327ms]
  Apr 13 13:16:06.480: INFO: Created: latency-svc-dv6n4
  Apr 13 13:16:06.521: INFO: Got endpoints: latency-svc-7v54l [750.262031ms]
  Apr 13 13:16:06.531: INFO: Created: latency-svc-pn4jr
  Apr 13 13:16:06.572: INFO: Got endpoints: latency-svc-xkftf [746.066364ms]
  E0413 13:16:06.572905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:06.581: INFO: Created: latency-svc-jhjkh
  Apr 13 13:16:06.619: INFO: Got endpoints: latency-svc-7z5zw [750.503767ms]
  Apr 13 13:16:06.630: INFO: Created: latency-svc-rl7n2
  Apr 13 13:16:06.674: INFO: Got endpoints: latency-svc-c2g7w [755.067576ms]
  Apr 13 13:16:06.685: INFO: Created: latency-svc-xncdz
  Apr 13 13:16:06.718: INFO: Got endpoints: latency-svc-jmd75 [747.299953ms]
  Apr 13 13:16:06.728: INFO: Created: latency-svc-nrtng
  Apr 13 13:16:06.770: INFO: Got endpoints: latency-svc-qbpcq [749.486909ms]
  Apr 13 13:16:06.780: INFO: Created: latency-svc-cclc9
  Apr 13 13:16:06.820: INFO: Got endpoints: latency-svc-8bllj [748.494729ms]
  Apr 13 13:16:06.830: INFO: Created: latency-svc-j6j5q
  Apr 13 13:16:06.868: INFO: Got endpoints: latency-svc-mvp7f [748.759969ms]
  Apr 13 13:16:06.881: INFO: Created: latency-svc-bfqb6
  Apr 13 13:16:06.920: INFO: Got endpoints: latency-svc-cnvnj [751.61793ms]
  Apr 13 13:16:06.937: INFO: Created: latency-svc-772kb
  Apr 13 13:16:06.970: INFO: Got endpoints: latency-svc-lwj4g [751.000938ms]
  Apr 13 13:16:06.979: INFO: Created: latency-svc-29grh
  Apr 13 13:16:07.020: INFO: Got endpoints: latency-svc-qj9v5 [749.13358ms]
  Apr 13 13:16:07.030: INFO: Created: latency-svc-8xkk6
  Apr 13 13:16:07.068: INFO: Got endpoints: latency-svc-hgv6j [747.741052ms]
  Apr 13 13:16:07.080: INFO: Created: latency-svc-gwf24
  Apr 13 13:16:07.119: INFO: Got endpoints: latency-svc-t7kk6 [747.372017ms]
  Apr 13 13:16:07.130: INFO: Created: latency-svc-v8x4g
  Apr 13 13:16:07.171: INFO: Got endpoints: latency-svc-6bc6l [751.680461ms]
  Apr 13 13:16:07.182: INFO: Created: latency-svc-tmhnj
  Apr 13 13:16:07.221: INFO: Got endpoints: latency-svc-dv6n4 [751.716088ms]
  Apr 13 13:16:07.231: INFO: Created: latency-svc-5sf7z
  Apr 13 13:16:07.270: INFO: Got endpoints: latency-svc-pn4jr [748.950672ms]
  Apr 13 13:16:07.280: INFO: Created: latency-svc-slhjq
  Apr 13 13:16:07.319: INFO: Got endpoints: latency-svc-jhjkh [746.939975ms]
  Apr 13 13:16:07.331: INFO: Created: latency-svc-sdtl2
  Apr 13 13:16:07.368: INFO: Got endpoints: latency-svc-rl7n2 [749.163083ms]
  Apr 13 13:16:07.379: INFO: Created: latency-svc-bmw6t
  Apr 13 13:16:07.420: INFO: Got endpoints: latency-svc-xncdz [745.775291ms]
  Apr 13 13:16:07.430: INFO: Created: latency-svc-bvvdp
  Apr 13 13:16:07.472: INFO: Got endpoints: latency-svc-nrtng [753.797699ms]
  Apr 13 13:16:07.482: INFO: Created: latency-svc-qqdtf
  Apr 13 13:16:07.520: INFO: Got endpoints: latency-svc-cclc9 [749.33834ms]
  Apr 13 13:16:07.529: INFO: Created: latency-svc-vd866
  Apr 13 13:16:07.571: INFO: Got endpoints: latency-svc-j6j5q [751.514653ms]
  E0413 13:16:07.572906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:07.582: INFO: Created: latency-svc-65dm5
  Apr 13 13:16:07.619: INFO: Got endpoints: latency-svc-bfqb6 [750.557561ms]
  Apr 13 13:16:07.630: INFO: Created: latency-svc-d8wzw
  Apr 13 13:16:07.669: INFO: Got endpoints: latency-svc-772kb [740.483914ms]
  Apr 13 13:16:07.679: INFO: Created: latency-svc-r4vt4
  Apr 13 13:16:07.720: INFO: Got endpoints: latency-svc-29grh [749.830081ms]
  Apr 13 13:16:07.730: INFO: Created: latency-svc-tl2ds
  Apr 13 13:16:07.772: INFO: Got endpoints: latency-svc-8xkk6 [752.631481ms]
  Apr 13 13:16:07.784: INFO: Created: latency-svc-wpsdz
  Apr 13 13:16:07.821: INFO: Got endpoints: latency-svc-gwf24 [752.342444ms]
  Apr 13 13:16:07.833: INFO: Created: latency-svc-zgxf4
  Apr 13 13:16:07.871: INFO: Got endpoints: latency-svc-v8x4g [752.087732ms]
  Apr 13 13:16:07.883: INFO: Created: latency-svc-w429d
  Apr 13 13:16:07.920: INFO: Got endpoints: latency-svc-tmhnj [749.328313ms]
  Apr 13 13:16:07.929: INFO: Created: latency-svc-744rn
  Apr 13 13:16:07.971: INFO: Got endpoints: latency-svc-5sf7z [749.330338ms]
  Apr 13 13:16:07.980: INFO: Created: latency-svc-5g9tb
  Apr 13 13:16:08.020: INFO: Got endpoints: latency-svc-slhjq [749.881501ms]
  Apr 13 13:16:08.030: INFO: Created: latency-svc-zg86n
  Apr 13 13:16:08.069: INFO: Got endpoints: latency-svc-sdtl2 [750.110633ms]
  Apr 13 13:16:08.082: INFO: Created: latency-svc-lkpzw
  Apr 13 13:16:08.121: INFO: Got endpoints: latency-svc-bmw6t [752.569435ms]
  Apr 13 13:16:08.130: INFO: Created: latency-svc-bsf79
  Apr 13 13:16:08.169: INFO: Got endpoints: latency-svc-bvvdp [749.417037ms]
  Apr 13 13:16:08.181: INFO: Created: latency-svc-s4jjk
  Apr 13 13:16:08.219: INFO: Got endpoints: latency-svc-qqdtf [747.209587ms]
  Apr 13 13:16:08.230: INFO: Created: latency-svc-xhvxc
  Apr 13 13:16:08.271: INFO: Got endpoints: latency-svc-vd866 [751.409744ms]
  Apr 13 13:16:08.281: INFO: Created: latency-svc-wdv85
  Apr 13 13:16:08.321: INFO: Got endpoints: latency-svc-65dm5 [749.625669ms]
  Apr 13 13:16:08.331: INFO: Created: latency-svc-k4rdt
  Apr 13 13:16:08.369: INFO: Got endpoints: latency-svc-d8wzw [750.268139ms]
  Apr 13 13:16:08.381: INFO: Created: latency-svc-xtsg4
  Apr 13 13:16:08.420: INFO: Got endpoints: latency-svc-r4vt4 [751.882868ms]
  Apr 13 13:16:08.430: INFO: Created: latency-svc-kxczl
  Apr 13 13:16:08.468: INFO: Got endpoints: latency-svc-tl2ds [748.009747ms]
  Apr 13 13:16:08.478: INFO: Created: latency-svc-wgh8q
  Apr 13 13:16:08.520: INFO: Got endpoints: latency-svc-wpsdz [747.557324ms]
  Apr 13 13:16:08.530: INFO: Created: latency-svc-tw924
  Apr 13 13:16:08.570: INFO: Got endpoints: latency-svc-zgxf4 [748.752681ms]
  E0413 13:16:08.573287      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:08.579: INFO: Created: latency-svc-zstmg
  Apr 13 13:16:08.619: INFO: Got endpoints: latency-svc-w429d [747.939929ms]
  Apr 13 13:16:08.630: INFO: Created: latency-svc-dvm4b
  Apr 13 13:16:08.669: INFO: Got endpoints: latency-svc-744rn [748.806266ms]
  Apr 13 13:16:08.680: INFO: Created: latency-svc-k2j6c
  Apr 13 13:16:08.718: INFO: Got endpoints: latency-svc-5g9tb [747.34799ms]
  Apr 13 13:16:08.727: INFO: Created: latency-svc-n9zqd
  Apr 13 13:16:08.770: INFO: Got endpoints: latency-svc-zg86n [749.457347ms]
  Apr 13 13:16:08.779: INFO: Created: latency-svc-hs4nt
  Apr 13 13:16:08.820: INFO: Got endpoints: latency-svc-lkpzw [750.362131ms]
  Apr 13 13:16:08.830: INFO: Created: latency-svc-6xmhw
  Apr 13 13:16:08.869: INFO: Got endpoints: latency-svc-bsf79 [748.180165ms]
  Apr 13 13:16:08.882: INFO: Created: latency-svc-pvlcz
  Apr 13 13:16:08.919: INFO: Got endpoints: latency-svc-s4jjk [749.395626ms]
  Apr 13 13:16:08.928: INFO: Created: latency-svc-c4nq5
  Apr 13 13:16:08.970: INFO: Got endpoints: latency-svc-xhvxc [750.395806ms]
  Apr 13 13:16:08.980: INFO: Created: latency-svc-lntzj
  Apr 13 13:16:09.020: INFO: Got endpoints: latency-svc-wdv85 [748.827026ms]
  Apr 13 13:16:09.029: INFO: Created: latency-svc-k9874
  Apr 13 13:16:09.071: INFO: Got endpoints: latency-svc-k4rdt [750.301961ms]
  Apr 13 13:16:09.080: INFO: Created: latency-svc-bh6zl
  Apr 13 13:16:09.120: INFO: Got endpoints: latency-svc-xtsg4 [750.522653ms]
  Apr 13 13:16:09.131: INFO: Created: latency-svc-4rrht
  Apr 13 13:16:09.168: INFO: Got endpoints: latency-svc-kxczl [748.003593ms]
  Apr 13 13:16:09.184: INFO: Created: latency-svc-mtdll
  Apr 13 13:16:09.219: INFO: Got endpoints: latency-svc-wgh8q [751.572785ms]
  Apr 13 13:16:09.229: INFO: Created: latency-svc-fhlvs
  Apr 13 13:16:09.272: INFO: Got endpoints: latency-svc-tw924 [751.623309ms]
  Apr 13 13:16:09.282: INFO: Created: latency-svc-7j47x
  Apr 13 13:16:09.320: INFO: Got endpoints: latency-svc-zstmg [749.816039ms]
  Apr 13 13:16:09.330: INFO: Created: latency-svc-czwxb
  Apr 13 13:16:09.369: INFO: Got endpoints: latency-svc-dvm4b [750.517235ms]
  Apr 13 13:16:09.386: INFO: Created: latency-svc-ss2zz
  Apr 13 13:16:09.419: INFO: Got endpoints: latency-svc-k2j6c [750.311797ms]
  Apr 13 13:16:09.429: INFO: Created: latency-svc-f6px9
  Apr 13 13:16:09.473: INFO: Got endpoints: latency-svc-n9zqd [754.877299ms]
  Apr 13 13:16:09.483: INFO: Created: latency-svc-dc8pm
  Apr 13 13:16:09.520: INFO: Got endpoints: latency-svc-hs4nt [750.394957ms]
  Apr 13 13:16:09.531: INFO: Created: latency-svc-lcz4d
  Apr 13 13:16:09.570: INFO: Got endpoints: latency-svc-6xmhw [749.972579ms]
  E0413 13:16:09.573346      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:09.580: INFO: Created: latency-svc-h5cjr
  Apr 13 13:16:09.620: INFO: Got endpoints: latency-svc-pvlcz [751.229436ms]
  Apr 13 13:16:09.629: INFO: Created: latency-svc-lgngk
  Apr 13 13:16:09.672: INFO: Got endpoints: latency-svc-c4nq5 [753.175774ms]
  Apr 13 13:16:09.681: INFO: Created: latency-svc-q75h2
  Apr 13 13:16:09.722: INFO: Got endpoints: latency-svc-lntzj [752.017611ms]
  Apr 13 13:16:09.734: INFO: Created: latency-svc-4jknd
  Apr 13 13:16:09.770: INFO: Got endpoints: latency-svc-k9874 [749.833685ms]
  Apr 13 13:16:09.779: INFO: Created: latency-svc-lwvfn
  Apr 13 13:16:09.819: INFO: Got endpoints: latency-svc-bh6zl [747.229169ms]
  Apr 13 13:16:09.830: INFO: Created: latency-svc-r6rwh
  Apr 13 13:16:09.869: INFO: Got endpoints: latency-svc-4rrht [748.92149ms]
  Apr 13 13:16:09.881: INFO: Created: latency-svc-q9tjp
  Apr 13 13:16:09.919: INFO: Got endpoints: latency-svc-mtdll [750.445045ms]
  Apr 13 13:16:09.930: INFO: Created: latency-svc-gxxnk
  Apr 13 13:16:09.971: INFO: Got endpoints: latency-svc-fhlvs [751.512404ms]
  Apr 13 13:16:09.980: INFO: Created: latency-svc-57kxn
  Apr 13 13:16:10.018: INFO: Got endpoints: latency-svc-7j47x [746.588119ms]
  Apr 13 13:16:10.030: INFO: Created: latency-svc-x58qv
  Apr 13 13:16:10.069: INFO: Got endpoints: latency-svc-czwxb [748.917577ms]
  Apr 13 13:16:10.081: INFO: Created: latency-svc-2vwk2
  Apr 13 13:16:10.120: INFO: Got endpoints: latency-svc-ss2zz [750.361283ms]
  Apr 13 13:16:10.131: INFO: Created: latency-svc-lck4v
  Apr 13 13:16:10.174: INFO: Got endpoints: latency-svc-f6px9 [754.364935ms]
  Apr 13 13:16:10.187: INFO: Created: latency-svc-pqrcf
  Apr 13 13:16:10.221: INFO: Got endpoints: latency-svc-dc8pm [747.915341ms]
  Apr 13 13:16:10.234: INFO: Created: latency-svc-f9gnp
  Apr 13 13:16:10.274: INFO: Got endpoints: latency-svc-lcz4d [753.452361ms]
  Apr 13 13:16:10.288: INFO: Created: latency-svc-nqlh2
  Apr 13 13:16:10.325: INFO: Got endpoints: latency-svc-h5cjr [754.771471ms]
  Apr 13 13:16:10.338: INFO: Created: latency-svc-dwxkg
  Apr 13 13:16:10.369: INFO: Got endpoints: latency-svc-lgngk [748.777294ms]
  Apr 13 13:16:10.380: INFO: Created: latency-svc-2sbjl
  Apr 13 13:16:10.427: INFO: Got endpoints: latency-svc-q75h2 [755.576693ms]
  Apr 13 13:16:10.442: INFO: Created: latency-svc-nxfp8
  Apr 13 13:16:10.472: INFO: Got endpoints: latency-svc-4jknd [750.015087ms]
  Apr 13 13:16:10.481: INFO: Created: latency-svc-rtpsf
  Apr 13 13:16:10.520: INFO: Got endpoints: latency-svc-lwvfn [749.922078ms]
  Apr 13 13:16:10.530: INFO: Created: latency-svc-7nqhq
  Apr 13 13:16:10.570: INFO: Got endpoints: latency-svc-r6rwh [751.472112ms]
  E0413 13:16:10.573733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:10.580: INFO: Created: latency-svc-ps8jv
  Apr 13 13:16:10.619: INFO: Got endpoints: latency-svc-q9tjp [750.388063ms]
  Apr 13 13:16:10.630: INFO: Created: latency-svc-djzpx
  Apr 13 13:16:10.669: INFO: Got endpoints: latency-svc-gxxnk [749.970439ms]
  Apr 13 13:16:10.678: INFO: Created: latency-svc-l65bn
  Apr 13 13:16:10.721: INFO: Got endpoints: latency-svc-57kxn [749.57713ms]
  Apr 13 13:16:10.731: INFO: Created: latency-svc-bw2hh
  Apr 13 13:16:10.772: INFO: Got endpoints: latency-svc-x58qv [753.010388ms]
  Apr 13 13:16:10.781: INFO: Created: latency-svc-gndhz
  Apr 13 13:16:10.820: INFO: Got endpoints: latency-svc-2vwk2 [750.832823ms]
  Apr 13 13:16:10.831: INFO: Created: latency-svc-ghfbw
  Apr 13 13:16:10.868: INFO: Got endpoints: latency-svc-lck4v [747.980217ms]
  Apr 13 13:16:10.879: INFO: Created: latency-svc-889v2
  Apr 13 13:16:10.918: INFO: Got endpoints: latency-svc-pqrcf [744.569268ms]
  Apr 13 13:16:10.928: INFO: Created: latency-svc-j5qhl
  Apr 13 13:16:10.971: INFO: Got endpoints: latency-svc-f9gnp [750.241169ms]
  Apr 13 13:16:10.980: INFO: Created: latency-svc-lfl7t
  Apr 13 13:16:11.021: INFO: Got endpoints: latency-svc-nqlh2 [747.718053ms]
  Apr 13 13:16:11.031: INFO: Created: latency-svc-ln6f4
  Apr 13 13:16:11.070: INFO: Got endpoints: latency-svc-dwxkg [745.630634ms]
  Apr 13 13:16:11.081: INFO: Created: latency-svc-bvnxp
  Apr 13 13:16:11.119: INFO: Got endpoints: latency-svc-2sbjl [749.745742ms]
  Apr 13 13:16:11.129: INFO: Created: latency-svc-lshrw
  Apr 13 13:16:11.171: INFO: Got endpoints: latency-svc-nxfp8 [743.786988ms]
  Apr 13 13:16:11.181: INFO: Created: latency-svc-qffwg
  Apr 13 13:16:11.221: INFO: Got endpoints: latency-svc-rtpsf [748.79085ms]
  Apr 13 13:16:11.231: INFO: Created: latency-svc-kg84q
  Apr 13 13:16:11.270: INFO: Got endpoints: latency-svc-7nqhq [749.787033ms]
  Apr 13 13:16:11.280: INFO: Created: latency-svc-2brht
  Apr 13 13:16:11.319: INFO: Got endpoints: latency-svc-ps8jv [748.431787ms]
  Apr 13 13:16:11.330: INFO: Created: latency-svc-l8xf8
  Apr 13 13:16:11.368: INFO: Got endpoints: latency-svc-djzpx [748.457672ms]
  Apr 13 13:16:11.380: INFO: Created: latency-svc-sbp2v
  Apr 13 13:16:11.419: INFO: Got endpoints: latency-svc-l65bn [750.129868ms]
  Apr 13 13:16:11.428: INFO: Created: latency-svc-w7pdc
  Apr 13 13:16:11.472: INFO: Got endpoints: latency-svc-bw2hh [751.254681ms]
  Apr 13 13:16:11.481: INFO: Created: latency-svc-9gwlt
  Apr 13 13:16:11.518: INFO: Got endpoints: latency-svc-gndhz [746.445368ms]
  Apr 13 13:16:11.529: INFO: Created: latency-svc-88g6r
  Apr 13 13:16:11.568: INFO: Got endpoints: latency-svc-ghfbw [748.072509ms]
  E0413 13:16:11.574174      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:11.579: INFO: Created: latency-svc-5w4lp
  Apr 13 13:16:11.621: INFO: Got endpoints: latency-svc-889v2 [752.89228ms]
  Apr 13 13:16:11.630: INFO: Created: latency-svc-n9wtq
  Apr 13 13:16:11.672: INFO: Got endpoints: latency-svc-j5qhl [753.292659ms]
  Apr 13 13:16:11.680: INFO: Created: latency-svc-bx6tp
  Apr 13 13:16:11.721: INFO: Got endpoints: latency-svc-lfl7t [749.420327ms]
  Apr 13 13:16:11.770: INFO: Got endpoints: latency-svc-ln6f4 [748.718804ms]
  Apr 13 13:16:11.820: INFO: Got endpoints: latency-svc-bvnxp [749.796732ms]
  Apr 13 13:16:11.869: INFO: Got endpoints: latency-svc-lshrw [750.149548ms]
  Apr 13 13:16:11.920: INFO: Got endpoints: latency-svc-qffwg [748.239587ms]
  Apr 13 13:16:11.970: INFO: Got endpoints: latency-svc-kg84q [749.158267ms]
  Apr 13 13:16:12.022: INFO: Got endpoints: latency-svc-2brht [751.398134ms]
  Apr 13 13:16:12.068: INFO: Got endpoints: latency-svc-l8xf8 [748.781108ms]
  Apr 13 13:16:12.120: INFO: Got endpoints: latency-svc-sbp2v [751.742157ms]
  Apr 13 13:16:12.170: INFO: Got endpoints: latency-svc-w7pdc [750.962588ms]
  Apr 13 13:16:12.219: INFO: Got endpoints: latency-svc-9gwlt [747.181688ms]
  Apr 13 13:16:12.270: INFO: Got endpoints: latency-svc-88g6r [752.136119ms]
  Apr 13 13:16:12.320: INFO: Got endpoints: latency-svc-5w4lp [752.349865ms]
  Apr 13 13:16:12.370: INFO: Got endpoints: latency-svc-n9wtq [749.179416ms]
  Apr 13 13:16:12.419: INFO: Got endpoints: latency-svc-bx6tp [747.350996ms]
  Apr 13 13:16:12.419: INFO: Latencies: [21.322594ms 27.503625ms 31.396653ms 41.609941ms 48.163612ms 61.335508ms 64.077587ms 73.340666ms 82.23637ms 86.898975ms 94.790603ms 105.043493ms 110.80208ms 112.847786ms 113.054518ms 113.146269ms 113.788677ms 113.861645ms 113.918712ms 113.966031ms 115.50993ms 116.919737ms 117.315116ms 117.452493ms 117.484897ms 117.534239ms 117.54412ms 117.929821ms 118.731032ms 119.166183ms 127.498599ms 128.322112ms 128.365099ms 129.000615ms 135.609268ms 165.203194ms 190.316026ms 191.888146ms 259.303338ms 316.941612ms 317.006052ms 345.077257ms 520.423478ms 557.702196ms 599.253688ms 625.873123ms 648.956008ms 661.183289ms 720.179732ms 728.116283ms 740.483914ms 743.786988ms 744.222294ms 744.569268ms 745.630634ms 745.775291ms 746.066364ms 746.445368ms 746.588119ms 746.939975ms 746.947344ms 747.181688ms 747.209587ms 747.229169ms 747.299953ms 747.34799ms 747.350996ms 747.372017ms 747.557324ms 747.560443ms 747.718053ms 747.740551ms 747.741052ms 747.817203ms 747.915341ms 747.939929ms 747.980217ms 748.003593ms 748.009747ms 748.030519ms 748.072509ms 748.180165ms 748.239587ms 748.368867ms 748.431787ms 748.457672ms 748.494729ms 748.64467ms 748.718804ms 748.752681ms 748.759969ms 748.777294ms 748.781108ms 748.79085ms 748.795603ms 748.806266ms 748.827026ms 748.917577ms 748.92149ms 748.950672ms 748.987998ms 749.088111ms 749.13358ms 749.158267ms 749.163083ms 749.179416ms 749.328313ms 749.330338ms 749.33834ms 749.386732ms 749.395626ms 749.417037ms 749.420327ms 749.457347ms 749.486909ms 749.530162ms 749.57713ms 749.589375ms 749.625669ms 749.711966ms 749.745742ms 749.787033ms 749.796732ms 749.816039ms 749.830081ms 749.833685ms 749.881501ms 749.882327ms 749.922078ms 749.970439ms 749.972579ms 749.980793ms 750.015087ms 750.110633ms 750.129868ms 750.149548ms 750.241169ms 750.262031ms 750.268139ms 750.301961ms 750.311797ms 750.349324ms 750.361283ms 750.362131ms 750.388063ms 750.394957ms 750.395806ms 750.445045ms 750.503767ms 750.517235ms 750.522653ms 750.549542ms 750.557561ms 750.832823ms 750.871276ms 750.962588ms 751.000938ms 751.229436ms 751.254681ms 751.398134ms 751.409744ms 751.435807ms 751.472112ms 751.512404ms 751.514653ms 751.572785ms 751.61793ms 751.623309ms 751.680461ms 751.716088ms 751.742157ms 751.748537ms 751.771435ms 751.882868ms 752.017611ms 752.087732ms 752.124265ms 752.136119ms 752.202952ms 752.342444ms 752.349865ms 752.569435ms 752.631481ms 752.643097ms 752.812841ms 752.89228ms 753.010388ms 753.175774ms 753.292659ms 753.452361ms 753.797699ms 754.001597ms 754.364935ms 754.771471ms 754.877299ms 755.067576ms 755.093541ms 755.489437ms 755.576693ms 873.179658ms]
  Apr 13 13:16:12.419: INFO: 50 %ile: 748.987998ms
  Apr 13 13:16:12.419: INFO: 90 %ile: 752.349865ms
  Apr 13 13:16:12.419: INFO: 99 %ile: 755.576693ms
  Apr 13 13:16:12.419: INFO: Total sample count: 200
  Apr 13 13:16:12.420: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5696" for this suite. @ 04/13/24 13:16:12.424
• [10.771 seconds]
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 04/13/24 13:16:12.429
  Apr 13 13:16:12.429: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 13:16:12.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:12.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:12.446
  STEP: create the rc @ 04/13/24 13:16:12.453
  W0413 13:16:12.458494      21 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0413 13:16:12.574715      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:13.575511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:14.578004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:15.582659      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:16.587868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:17.592872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/13/24 13:16:18.463
  STEP: wait for the rc to be deleted @ 04/13/24 13:16:18.475
  E0413 13:16:18.592869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:19.492: INFO: 100 pods remaining
  Apr 13 13:16:19.492: INFO: 100 pods has nil DeletionTimestamp
  Apr 13 13:16:19.492: INFO: 
  E0413 13:16:19.592987      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:20.490: INFO: 91 pods remaining
  Apr 13 13:16:20.490: INFO: 91 pods has nil DeletionTimestamp
  Apr 13 13:16:20.490: INFO: 
  E0413 13:16:20.593760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:21.492: INFO: 77 pods remaining
  Apr 13 13:16:21.492: INFO: 76 pods has nil DeletionTimestamp
  Apr 13 13:16:21.492: INFO: 
  E0413 13:16:21.594865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:22.490: INFO: 60 pods remaining
  Apr 13 13:16:22.490: INFO: 60 pods has nil DeletionTimestamp
  Apr 13 13:16:22.490: INFO: 
  E0413 13:16:22.595142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:23.484: INFO: 51 pods remaining
  Apr 13 13:16:23.484: INFO: 51 pods has nil DeletionTimestamp
  Apr 13 13:16:23.484: INFO: 
  E0413 13:16:23.595887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:24.487: INFO: 37 pods remaining
  Apr 13 13:16:24.487: INFO: 36 pods has nil DeletionTimestamp
  Apr 13 13:16:24.487: INFO: 
  E0413 13:16:24.597163      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:25.483: INFO: 20 pods remaining
  Apr 13 13:16:25.483: INFO: 20 pods has nil DeletionTimestamp
  Apr 13 13:16:25.483: INFO: 
  E0413 13:16:25.597972      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:26.482: INFO: 11 pods remaining
  Apr 13 13:16:26.482: INFO: 11 pods has nil DeletionTimestamp
  Apr 13 13:16:26.482: INFO: 
  E0413 13:16:26.598984      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:27.483: INFO: 0 pods remaining
  Apr 13 13:16:27.483: INFO: 0 pods has nil DeletionTimestamp
  Apr 13 13:16:27.483: INFO: 
  E0413 13:16:27.599236      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:28.483: INFO: 0 pods remaining
  Apr 13 13:16:28.483: INFO: 0 pods has nil DeletionTimestamp
  Apr 13 13:16:28.483: INFO: 
  E0413 13:16:28.599479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:29.482: INFO: 0 pods remaining
  Apr 13 13:16:29.482: INFO: 0 pods has nil DeletionTimestamp
  Apr 13 13:16:29.482: INFO: 
  E0413 13:16:29.599538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:30.483: INFO: 0 pods remaining
  Apr 13 13:16:30.483: INFO: 0 pods has nil DeletionTimestamp
  Apr 13 13:16:30.483: INFO: 
  E0413 13:16:30.600116      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/13/24 13:16:31.483
  W0413 13:16:31.489061      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 13:16:31.489: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 13:16:31.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2727" for this suite. @ 04/13/24 13:16:31.492
• [19.069 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 04/13/24 13:16:31.498
  Apr 13 13:16:31.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:16:31.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:31.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:31.515
  STEP: Creating configMap with name projected-configmap-test-volume-92a4ef8e-fd6a-44eb-8012-ba596d488d2f @ 04/13/24 13:16:31.518
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:16:31.524
  E0413 13:16:31.600935      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:32.601124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:33.601230      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:34.601440      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:16:35.547
  Apr 13 13:16:35.551: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-13ca6223-4de7-43ed-aa4b-f06d5889303e container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:16:35.561
  Apr 13 13:16:35.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6521" for this suite. @ 04/13/24 13:16:35.581
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 04/13/24 13:16:35.589
  Apr 13 13:16:35.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:16:35.59
  E0413 13:16:35.601448      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:35.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:35.606
  STEP: Setting up server cert @ 04/13/24 13:16:35.627
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:16:36.081
  STEP: Deploying the webhook pod @ 04/13/24 13:16:36.088
  STEP: Wait for the deployment to be ready @ 04/13/24 13:16:36.099
  Apr 13 13:16:36.117: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:16:36.602008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:37.602717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:16:38.128
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:16:38.141
  E0413 13:16:38.603578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:39.141: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/13/24 13:16:39.247
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/13/24 13:16:39.273
  STEP: Deleting the collection of validation webhooks @ 04/13/24 13:16:39.297
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/13/24 13:16:39.353
  Apr 13 13:16:39.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9231" for this suite. @ 04/13/24 13:16:39.405
  STEP: Destroying namespace "webhook-markers-8260" for this suite. @ 04/13/24 13:16:39.413
• [3.832 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/13/24 13:16:39.421
  Apr 13 13:16:39.421: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:16:39.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:39.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:39.438
  E0413 13:16:39.604519      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:40.604819      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:41.460: INFO: Deleting pod "var-expansion-7412e3a4-aeb6-4e12-934c-282e61da4005" in namespace "var-expansion-8242"
  Apr 13 13:16:41.468: INFO: Wait up to 5m0s for pod "var-expansion-7412e3a4-aeb6-4e12-934c-282e61da4005" to be fully deleted
  E0413 13:16:41.605055      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:42.605198      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:43.476: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8242" for this suite. @ 04/13/24 13:16:43.48
• [4.066 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 04/13/24 13:16:43.487
  Apr 13 13:16:43.487: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename runtimeclass @ 04/13/24 13:16:43.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:43.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:43.505
  E0413 13:16:43.605957      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:44.606080      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:16:45.538: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4649" for this suite. @ 04/13/24 13:16:45.542
• [2.060 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 04/13/24 13:16:45.548
  Apr 13 13:16:45.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:16:45.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:16:45.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:16:45.565
  STEP: Creating configMap with name cm-test-opt-del-5198a75d-365c-476a-b831-073fcce2c275 @ 04/13/24 13:16:45.572
  STEP: Creating configMap with name cm-test-opt-upd-50f6425c-d0d4-43dc-8bca-73190a2173b8 @ 04/13/24 13:16:45.576
  STEP: Creating the pod @ 04/13/24 13:16:45.58
  E0413 13:16:45.606413      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:46.607163      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:47.607460      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-5198a75d-365c-476a-b831-073fcce2c275 @ 04/13/24 13:16:47.622
  STEP: Updating configmap cm-test-opt-upd-50f6425c-d0d4-43dc-8bca-73190a2173b8 @ 04/13/24 13:16:47.632
  STEP: Creating configMap with name cm-test-opt-create-a2bc2046-7590-49f7-b491-a24b2ec2f18d @ 04/13/24 13:16:47.637
  STEP: waiting to observe update in volume @ 04/13/24 13:16:47.642
  E0413 13:16:48.607607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:49.608118      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:50.608835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:51.609436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:52.609781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:53.610006      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:54.610506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:55.610652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:56.610959      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:57.611057      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:58.611211      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:16:59.611269      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:00.612214      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:01.612304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:02.613206      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:03.613326      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:04.614411      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:05.614520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:06.615565      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:07.615929      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:08.616059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:09.616124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:10.616223      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:11.616336      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:12.616551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:13.617168      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:14.617269      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:15.617308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:16.617418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:17.617767      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:18.617899      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:19.617993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:20.618509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:21.618546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:22.618619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:23.618741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:24.619734      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:25.619907      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:26.620493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:27.620956      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:28.621043      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:29.621141      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:30.621277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:31.621366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:32.622055      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:33.623005      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:34.623100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:35.623667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:36.626304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:37.626492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:38.626589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:39.626701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:40.626781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:41.626880      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:42.627543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:43.627639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:44.628350      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:45.628547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:46.629000      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:47.629998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:48.630259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:49.630362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:50.630500      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:51.630583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:52.630681      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:53.631551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:54.631654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:55.631742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:56.631827      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:57.632187      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:58.632547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:17:59.632650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:17:59.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9085" for this suite. @ 04/13/24 13:17:59.952
• [74.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 04/13/24 13:17:59.959
  Apr 13 13:17:59.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:17:59.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:17:59.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:17:59.98
  STEP: creating all guestbook components @ 04/13/24 13:17:59.982
  Apr 13 13:17:59.982: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 13 13:17:59.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.067: INFO: stderr: ""
  Apr 13 13:18:00.068: INFO: stdout: "service/agnhost-replica created\n"
  Apr 13 13:18:00.068: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 13 13:18:00.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.158: INFO: stderr: ""
  Apr 13 13:18:00.158: INFO: stdout: "service/agnhost-primary created\n"
  Apr 13 13:18:00.158: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 13 13:18:00.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.242: INFO: stderr: ""
  Apr 13 13:18:00.242: INFO: stdout: "service/frontend created\n"
  Apr 13 13:18:00.242: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 13 13:18:00.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.304: INFO: stderr: ""
  Apr 13 13:18:00.304: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 13 13:18:00.304: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 13 13:18:00.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.372: INFO: stderr: ""
  Apr 13 13:18:00.372: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 13 13:18:00.372: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 13 13:18:00.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 create -f -'
  Apr 13 13:18:00.438: INFO: stderr: ""
  Apr 13 13:18:00.438: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/13/24 13:18:00.438
  Apr 13 13:18:00.438: INFO: Waiting for all frontend pods to be Running.
  E0413 13:18:00.633818      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:01.633915      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:02.633998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:03.634770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:04.634859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:05.489: INFO: Waiting for frontend to serve content.
  Apr 13 13:18:05.498: INFO: Trying to add a new entry to the guestbook.
  Apr 13 13:18:05.511: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.52
  Apr 13 13:18:05.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.576: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.576: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.576
  Apr 13 13:18:05.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.634: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.634: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  E0413 13:18:05.634842      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.634
  Apr 13 13:18:05.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.687: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.687: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.687
  Apr 13 13:18:05.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.732: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.732: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.732
  Apr 13 13:18:05.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.794: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.794: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/13/24 13:18:05.795
  Apr 13 13:18:05.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4521 delete --grace-period=0 --force -f -'
  Apr 13 13:18:05.858: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:18:05.858: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 13 13:18:05.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4521" for this suite. @ 04/13/24 13:18:05.863
• [5.913 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 04/13/24 13:18:05.872
  Apr 13 13:18:05.872: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename runtimeclass @ 04/13/24 13:18:05.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:18:05.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:18:05.895
  STEP: getting /apis @ 04/13/24 13:18:05.898
  STEP: getting /apis/node.k8s.io @ 04/13/24 13:18:05.902
  STEP: getting /apis/node.k8s.io/v1 @ 04/13/24 13:18:05.904
  STEP: creating @ 04/13/24 13:18:05.905
  STEP: watching @ 04/13/24 13:18:05.923
  Apr 13 13:18:05.923: INFO: starting watch
  STEP: getting @ 04/13/24 13:18:05.93
  STEP: listing @ 04/13/24 13:18:05.933
  STEP: patching @ 04/13/24 13:18:05.936
  STEP: updating @ 04/13/24 13:18:05.943
  Apr 13 13:18:05.948: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/13/24 13:18:05.948
  STEP: deleting a collection @ 04/13/24 13:18:05.968
  Apr 13 13:18:05.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5769" for this suite. @ 04/13/24 13:18:05.992
• [0.126 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 04/13/24 13:18:05.998
  Apr 13 13:18:05.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 13:18:05.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:18:06.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:18:06.025
  Apr 13 13:18:06.051: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/13/24 13:18:06.057
  Apr 13 13:18:06.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:06.067: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/13/24 13:18:06.067
  Apr 13 13:18:06.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:06.096: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:18:06.635604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:07.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:07.095: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:18:07.635869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:08.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 13 13:18:08.096: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/13/24 13:18:08.1
  Apr 13 13:18:08.116: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 13 13:18:08.116: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0413 13:18:08.636923      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:09.117: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:09.117: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/13/24 13:18:09.117
  Apr 13 13:18:09.128: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:09.128: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:18:09.637612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:10.127: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:10.127: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:18:10.638576      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:11.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 13 13:18:11.129: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 13:18:11.139
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8502, will wait for the garbage collector to delete the pods @ 04/13/24 13:18:11.139
  Apr 13 13:18:11.202: INFO: Deleting DaemonSet.extensions daemon-set took: 9.399281ms
  Apr 13 13:18:11.303: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.28498ms
  E0413 13:18:11.638612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:18:12.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:18:12.408: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 13:18:12.411: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33155"},"items":null}

  Apr 13 13:18:12.415: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33155"},"items":null}

  Apr 13 13:18:12.437: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8502" for this suite. @ 04/13/24 13:18:12.441
• [6.450 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/13/24 13:18:12.449
  Apr 13 13:18:12.449: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:18:12.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:18:12.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:18:12.467
  STEP: Creating projection with secret that has name projected-secret-test-cf1d8b95-dcad-47dc-bba3-acbce3565796 @ 04/13/24 13:18:12.47
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:18:12.474
  E0413 13:18:12.639531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:13.639652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:14.640252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:15.640349      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:18:16.494
  Apr 13 13:18:16.498: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-f6313733-812f-494a-ae40-6262aeffba3d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:18:16.505
  Apr 13 13:18:16.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5198" for this suite. @ 04/13/24 13:18:16.523
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/13/24 13:18:16.53
  Apr 13 13:18:16.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-preemption @ 04/13/24 13:18:16.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:18:16.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:18:16.547
  Apr 13 13:18:16.564: INFO: Waiting up to 1m0s for all nodes to be ready
  E0413 13:18:16.640608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:17.640763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:18.641130      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:19.641384      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:20.642257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:21.642468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:22.643397      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:23.643756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:24.644037      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:25.644144      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:26.644872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:27.644981      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:28.645650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:29.645766      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:30.646728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:31.646850      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:32.647177      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:33.647309      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:34.648146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:35.648330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:36.649260      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:37.649507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:38.649520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:39.650496      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:40.651259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:41.652028      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:42.652240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:43.652361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:44.652693      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:45.653328      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:46.654111      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:47.654305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:48.654412      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:49.654492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:50.654831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:51.655526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:52.656367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:53.656508      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:54.656707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:55.656838      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:56.657412      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:57.657523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:58.657885      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:18:59.658139      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:00.658449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:01.658553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:02.658891      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:03.659111      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:04.660162      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:05.661202      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:06.661267      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:07.661349      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:08.661716      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:09.661841      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:10.662446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:11.662531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:12.663391      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:13.663511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:14.663575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:15.663812      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:19:16.569: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/13/24 13:19:16.573
  Apr 13 13:19:16.589: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 13 13:19:16.597: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 13 13:19:16.613: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 13 13:19:16.620: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 13 13:19:16.634: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 13 13:19:16.643: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/13/24 13:19:16.643
  E0413 13:19:16.663995      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:17.664998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:18.665745      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/13/24 13:19:18.673
  E0413 13:19:19.665906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:20.666011      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:21.666122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:22.666235      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:19:22.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9020" for this suite. @ 04/13/24 13:19:22.782
• [66.259 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 04/13/24 13:19:22.789
  Apr 13 13:19:22.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subpath @ 04/13/24 13:19:22.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:19:22.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:19:22.806
  STEP: Setting up data @ 04/13/24 13:19:22.81
  STEP: Creating pod pod-subpath-test-secret-t2ts @ 04/13/24 13:19:22.819
  STEP: Creating a pod to test atomic-volume-subpath @ 04/13/24 13:19:22.819
  E0413 13:19:23.666479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:24.666593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:25.667554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:26.667670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:27.667743      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:28.667846      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:29.667908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:30.668009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:31.668106      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:32.668875      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:33.669798      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:34.670010      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:35.670241      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:36.670367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:37.670910      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:38.671001      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:39.671094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:40.671560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:41.671654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:42.672623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:43.672753      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:44.672958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:45.673071      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:46.673160      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:19:46.893
  Apr 13 13:19:46.896: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-subpath-test-secret-t2ts container test-container-subpath-secret-t2ts: <nil>
  STEP: delete the pod @ 04/13/24 13:19:46.916
  STEP: Deleting pod pod-subpath-test-secret-t2ts @ 04/13/24 13:19:46.933
  Apr 13 13:19:46.933: INFO: Deleting pod "pod-subpath-test-secret-t2ts" in namespace "subpath-60"
  Apr 13 13:19:46.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-60" for this suite. @ 04/13/24 13:19:46.939
• [24.158 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/13/24 13:19:46.947
  Apr 13 13:19:46.947: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption @ 04/13/24 13:19:46.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:19:46.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:19:46.967
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/13/24 13:19:46.97
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:19:46.975
  E0413 13:19:47.673872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:48.673995      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/13/24 13:19:48.986
  STEP: Waiting for all pods to be running @ 04/13/24 13:19:48.986
  Apr 13 13:19:48.990: INFO: pods: 0 < 3
  E0413 13:19:49.674390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:50.674499      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/13/24 13:19:50.991
  STEP: Updating the pdb to allow a pod to be evicted @ 04/13/24 13:19:51
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:19:51.009
  E0413 13:19:51.675549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:52.676312      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/13/24 13:19:53.014
  STEP: Waiting for all pods to be running @ 04/13/24 13:19:53.014
  STEP: Waiting for the pdb to observed all healthy pods @ 04/13/24 13:19:53.018
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/13/24 13:19:53.043
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:19:53.07
  STEP: Waiting for all pods to be running @ 04/13/24 13:19:53.077
  Apr 13 13:19:53.082: INFO: running pods: 2 < 3
  E0413 13:19:53.676896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:54.676979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/13/24 13:19:55.082
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/13/24 13:19:55.091
  STEP: Waiting for the pdb to be deleted @ 04/13/24 13:19:55.097
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/13/24 13:19:55.102
  STEP: Waiting for all pods to be running @ 04/13/24 13:19:55.102
  Apr 13 13:19:55.120: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9466" for this suite. @ 04/13/24 13:19:55.124
• [8.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/13/24 13:19:55.132
  Apr 13 13:19:55.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 13:19:55.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:19:55.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:19:55.156
  STEP: set up a multi version CRD @ 04/13/24 13:19:55.16
  Apr 13 13:19:55.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:19:55.677946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:56.678587      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:19:57.679601      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 04/13/24 13:19:58.354
  STEP: check the new version name is served @ 04/13/24 13:19:58.367
  E0413 13:19:58.680556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 04/13/24 13:19:59.076
  E0413 13:19:59.680722      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/13/24 13:19:59.701
  E0413 13:20:00.681295      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:01.682297      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:02.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8053" for this suite. @ 04/13/24 13:20:02.255
• [7.131 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 04/13/24 13:20:02.263
  Apr 13 13:20:02.263: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename limitrange @ 04/13/24 13:20:02.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:02.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:02.285
  STEP: Creating LimitRange "e2e-limitrange-8vpgw" in namespace "limitrange-6104" @ 04/13/24 13:20:02.288
  STEP: Creating another limitRange in another namespace @ 04/13/24 13:20:02.294
  Apr 13 13:20:02.308: INFO: Namespace "e2e-limitrange-8vpgw-4106" created
  Apr 13 13:20:02.308: INFO: Creating LimitRange "e2e-limitrange-8vpgw" in namespace "e2e-limitrange-8vpgw-4106"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-8vpgw" @ 04/13/24 13:20:02.313
  Apr 13 13:20:02.316: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-8vpgw" in "limitrange-6104" namespace @ 04/13/24 13:20:02.316
  Apr 13 13:20:02.322: INFO: LimitRange "e2e-limitrange-8vpgw" has been patched
  STEP: Delete LimitRange "e2e-limitrange-8vpgw" by Collection with labelSelector: "e2e-limitrange-8vpgw=patched" @ 04/13/24 13:20:02.322
  STEP: Confirm that the limitRange "e2e-limitrange-8vpgw" has been deleted @ 04/13/24 13:20:02.329
  Apr 13 13:20:02.329: INFO: Requesting list of LimitRange to confirm quantity
  Apr 13 13:20:02.332: INFO: Found 0 LimitRange with label "e2e-limitrange-8vpgw=patched"
  Apr 13 13:20:02.332: INFO: LimitRange "e2e-limitrange-8vpgw" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-8vpgw" @ 04/13/24 13:20:02.332
  Apr 13 13:20:02.336: INFO: Found 1 limitRange
  Apr 13 13:20:02.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-6104" for this suite. @ 04/13/24 13:20:02.339
  STEP: Destroying namespace "e2e-limitrange-8vpgw-4106" for this suite. @ 04/13/24 13:20:02.347
• [0.092 seconds]
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/13/24 13:20:02.355
  Apr 13 13:20:02.355: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 13:20:02.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:02.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:02.373
  STEP: Creating a test headless service @ 04/13/24 13:20:02.377
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8083.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8083.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/13/24 13:20:02.383
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8083.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8083.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/13/24 13:20:02.383
  STEP: creating a pod to probe DNS @ 04/13/24 13:20:02.383
  STEP: submitting the pod to kubernetes @ 04/13/24 13:20:02.383
  E0413 13:20:02.682459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:03.682840      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 13:20:04.405
  STEP: looking for the results for each expected name from probers @ 04/13/24 13:20:04.409
  Apr 13 13:20:04.426: INFO: DNS probes using dns-8083/dns-test-35f73687-a676-460d-ae8f-3229f0b86c5c succeeded

  STEP: deleting the pod @ 04/13/24 13:20:04.426
  STEP: deleting the test headless service @ 04/13/24 13:20:04.438
  Apr 13 13:20:04.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8083" for this suite. @ 04/13/24 13:20:04.454
• [2.107 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 04/13/24 13:20:04.462
  Apr 13 13:20:04.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:20:04.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:04.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:04.483
  STEP: Setting up server cert @ 04/13/24 13:20:04.506
  E0413 13:20:04.682921      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:20:04.739
  STEP: Deploying the webhook pod @ 04/13/24 13:20:04.749
  STEP: Wait for the deployment to be ready @ 04/13/24 13:20:04.762
  Apr 13 13:20:04.768: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:20:05.683142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:06.683217      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:20:06.781
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:20:06.793
  E0413 13:20:07.683542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:07.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/13/24 13:20:07.803
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/13/24 13:20:07.804
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/13/24 13:20:07.804
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/13/24 13:20:07.804
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/13/24 13:20:07.806
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/13/24 13:20:07.806
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/13/24 13:20:07.807
  Apr 13 13:20:07.841: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9188" for this suite. @ 04/13/24 13:20:07.847
  STEP: Destroying namespace "webhook-markers-3334" for this suite. @ 04/13/24 13:20:07.854
• [3.399 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 04/13/24 13:20:07.861
  Apr 13 13:20:07.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:20:07.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:07.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:07.883
  Apr 13 13:20:07.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8536" for this suite. @ 04/13/24 13:20:07.933
• [0.080 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/13/24 13:20:07.941
  Apr 13 13:20:07.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 13:20:07.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:07.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:07.964
  Apr 13 13:20:07.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:20:08.684122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/13/24 13:20:09.173
  Apr 13 13:20:09.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-4039 --namespace=crd-publish-openapi-4039 create -f -'
  Apr 13 13:20:09.239: INFO: stderr: ""
  Apr 13 13:20:09.239: INFO: stdout: "e2e-test-crd-publish-openapi-8461-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 13 13:20:09.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-4039 --namespace=crd-publish-openapi-4039 delete e2e-test-crd-publish-openapi-8461-crds test-cr'
  Apr 13 13:20:09.284: INFO: stderr: ""
  Apr 13 13:20:09.284: INFO: stdout: "e2e-test-crd-publish-openapi-8461-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 13 13:20:09.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-4039 --namespace=crd-publish-openapi-4039 apply -f -'
  Apr 13 13:20:09.346: INFO: stderr: ""
  Apr 13 13:20:09.346: INFO: stdout: "e2e-test-crd-publish-openapi-8461-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 13 13:20:09.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-4039 --namespace=crd-publish-openapi-4039 delete e2e-test-crd-publish-openapi-8461-crds test-cr'
  Apr 13 13:20:09.392: INFO: stderr: ""
  Apr 13 13:20:09.392: INFO: stdout: "e2e-test-crd-publish-openapi-8461-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/13/24 13:20:09.392
  Apr 13 13:20:09.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=crd-publish-openapi-4039 explain e2e-test-crd-publish-openapi-8461-crds'
  Apr 13 13:20:09.429: INFO: stderr: ""
  Apr 13 13:20:09.429: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-8461-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0413 13:20:09.684646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:10.685419      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:10.721: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4039" for this suite. @ 04/13/24 13:20:10.729
• [2.796 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 04/13/24 13:20:10.738
  Apr 13 13:20:10.738: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:20:10.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:10.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:10.756
  STEP: creating service in namespace services-9525 @ 04/13/24 13:20:10.759
  STEP: creating service affinity-nodeport in namespace services-9525 @ 04/13/24 13:20:10.759
  STEP: creating replication controller affinity-nodeport in namespace services-9525 @ 04/13/24 13:20:10.774
  I0413 13:20:10.781136      21 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-9525, replica count: 3
  E0413 13:20:11.685820      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:12.686154      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:13.686369      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:20:13.831633      21 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:20:13.843: INFO: Creating new exec pod
  E0413 13:20:14.686483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:15.686912      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:16.687619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:16.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-9525 exec execpod-affinity2c49w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 13 13:20:16.966: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 13 13:20:16.966: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:20:16.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-9525 exec execpod-affinity2c49w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.57 80'
  Apr 13 13:20:17.053: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.57 80\nConnection to 10.152.183.57 80 port [tcp/http] succeeded!\n"
  Apr 13 13:20:17.053: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:20:17.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-9525 exec execpod-affinity2c49w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.82.63 32694'
  Apr 13 13:20:17.141: INFO: stderr: "+ nc -v -t -w 2 172.31.82.63 32694\n+ echo hostName\nConnection to 172.31.82.63 32694 port [tcp/*] succeeded!\n"
  Apr 13 13:20:17.141: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:20:17.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-9525 exec execpod-affinity2c49w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.229 32694'
  Apr 13 13:20:17.234: INFO: stderr: "+ nc -v -t -w 2 172.31.35.229 32694\n+ echo hostName\nConnection to 172.31.35.229 32694 port [tcp/*] succeeded!\n"
  Apr 13 13:20:17.234: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:20:17.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-9525 exec execpod-affinity2c49w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.35.229:32694/ ; done'
  Apr 13 13:20:17.417: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:32694/\n"
  Apr 13 13:20:17.417: INFO: stdout: "\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n\naffinity-nodeport-gxh8n"
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Received response from host: affinity-nodeport-gxh8n
  Apr 13 13:20:17.417: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-9525, will wait for the garbage collector to delete the pods @ 04/13/24 13:20:17.434
  Apr 13 13:20:17.496: INFO: Deleting ReplicationController affinity-nodeport took: 7.833418ms
  Apr 13 13:20:17.596: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.214076ms
  E0413 13:20:17.688598      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:18.688950      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:19.689095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:20.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9525" for this suite. @ 04/13/24 13:20:20.625
• [9.893 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 04/13/24 13:20:20.631
  Apr 13 13:20:20.631: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 13:20:20.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:20.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:20.654
  STEP: create the rc @ 04/13/24 13:20:20.657
  W0413 13:20:20.664430      21 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0413 13:20:20.690157      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:21.690262      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:22.691147      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:23.691240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:24.691322      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/13/24 13:20:25.668
  STEP: wait for all pods to be garbage collected @ 04/13/24 13:20:25.674
  E0413 13:20:25.692798      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:26.693439      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:27.693782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:28.693961      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:29.694041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/13/24 13:20:30.683
  W0413 13:20:30.688973      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 13:20:30.688: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 13:20:30.689: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2094" for this suite. @ 04/13/24 13:20:30.692
  E0413 13:20:30.694614      21 retrywatcher.go:129] "Watch failed" err="context canceled"
• [10.067 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 04/13/24 13:20:30.698
  Apr 13 13:20:30.698: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:20:30.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:30.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:30.715
  STEP: Creating a pod to test downward api env vars @ 04/13/24 13:20:30.718
  E0413 13:20:31.695435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:32.695890      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:33.696002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:34.696101      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:20:34.742
  Apr 13 13:20:34.745: INFO: Trying to get logs from node ip-172-31-82-63 pod downward-api-5e26d2ed-f6fb-460d-b14c-53a2e4e9a57a container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 13:20:34.763
  Apr 13 13:20:34.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4200" for this suite. @ 04/13/24 13:20:34.782
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 04/13/24 13:20:34.789
  Apr 13 13:20:34.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:20:34.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:34.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:34.808
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:20:34.811
  E0413 13:20:35.696242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:36.696497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:37.696578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:38.696684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:20:38.837
  Apr 13 13:20:38.840: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-e2bc0870-3110-4e44-b8fe-ac823a31b06f container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:20:38.846
  Apr 13 13:20:38.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6964" for this suite. @ 04/13/24 13:20:38.866
• [4.083 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 04/13/24 13:20:38.872
  Apr 13 13:20:38.872: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 13:20:38.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:38.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:38.889
  Apr 13 13:20:38.892: INFO: Creating ReplicaSet my-hostname-basic-932f0b12-710f-4e4f-9d6e-d9550f3bdff2
  Apr 13 13:20:38.900: INFO: Pod name my-hostname-basic-932f0b12-710f-4e4f-9d6e-d9550f3bdff2: Found 0 pods out of 1
  E0413 13:20:39.697355      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:40.697483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:41.697654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:42.697767      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:43.697857      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:20:43.904: INFO: Pod name my-hostname-basic-932f0b12-710f-4e4f-9d6e-d9550f3bdff2: Found 1 pods out of 1
  Apr 13 13:20:43.904: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-932f0b12-710f-4e4f-9d6e-d9550f3bdff2" is running
  Apr 13 13:20:43.908: INFO: Pod "my-hostname-basic-932f0b12-710f-4e4f-9d6e-d9550f3bdff2-7d2br" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:20:40 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:20:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:20:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:20:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:20:38 +0000 UTC Reason: Message:}])
  Apr 13 13:20:43.908: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/13/24 13:20:43.908
  Apr 13 13:20:43.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4237" for this suite. @ 04/13/24 13:20:43.922
• [5.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 04/13/24 13:20:43.929
  Apr 13 13:20:43.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subpath @ 04/13/24 13:20:43.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:20:43.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:20:43.947
  STEP: Setting up data @ 04/13/24 13:20:43.951
  STEP: Creating pod pod-subpath-test-configmap-8hhv @ 04/13/24 13:20:43.961
  STEP: Creating a pod to test atomic-volume-subpath @ 04/13/24 13:20:43.961
  E0413 13:20:44.698444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:45.698530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:46.699572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:47.700041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:48.700168      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:49.700272      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:50.700523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:51.700627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:52.701578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:53.701662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:54.702705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:55.702825      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:56.702908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:57.703667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:58.703785      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:20:59.703874      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:00.703974      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:01.704084      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:02.705084      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:03.705192      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:04.705288      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:05.705386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:06.705476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:07.705586      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:21:08.034
  Apr 13 13:21:08.038: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-subpath-test-configmap-8hhv container test-container-subpath-configmap-8hhv: <nil>
  STEP: delete the pod @ 04/13/24 13:21:08.045
  STEP: Deleting pod pod-subpath-test-configmap-8hhv @ 04/13/24 13:21:08.061
  Apr 13 13:21:08.061: INFO: Deleting pod "pod-subpath-test-configmap-8hhv" in namespace "subpath-3334"
  Apr 13 13:21:08.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3334" for this suite. @ 04/13/24 13:21:08.068
• [24.145 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/13/24 13:21:08.074
  Apr 13 13:21:08.074: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:21:08.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:08.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:08.091
  STEP: creating service nodeport-test with type=NodePort in namespace services-7521 @ 04/13/24 13:21:08.094
  STEP: creating replication controller nodeport-test in namespace services-7521 @ 04/13/24 13:21:08.106
  I0413 13:21:08.114831      21 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-7521, replica count: 2
  E0413 13:21:08.705648      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:09.705814      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:10.705922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:21:11.165321      21 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:21:11.165: INFO: Creating new exec pod
  E0413 13:21:11.706848      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:12.707523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:13.708143      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:14.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7521 exec execpod44tkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 13 13:21:14.294: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 13 13:21:14.294: INFO: stdout: "nodeport-test-s62rv"
  Apr 13 13:21:14.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7521 exec execpod44tkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.172 80'
  Apr 13 13:21:14.383: INFO: stderr: "+ nc -v -t -w 2 10.152.183.172 80\nConnection to 10.152.183.172 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 13 13:21:14.383: INFO: stdout: ""
  E0413 13:21:14.708225      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:15.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7521 exec execpod44tkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.172 80'
  Apr 13 13:21:15.371: INFO: stderr: "+ nc -v -t -w 2 10.152.183.172 80\nConnection to 10.152.183.172 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 13 13:21:15.371: INFO: stdout: "nodeport-test-8t47d"
  Apr 13 13:21:15.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7521 exec execpod44tkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.229 32759'
  Apr 13 13:21:15.467: INFO: stderr: "+ nc -v -t -w 2 172.31.35.229 32759\n+ echo hostName\nConnection to 172.31.35.229 32759 port [tcp/*] succeeded!\n"
  Apr 13 13:21:15.467: INFO: stdout: "nodeport-test-8t47d"
  Apr 13 13:21:15.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7521 exec execpod44tkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.65.227 32759'
  Apr 13 13:21:15.561: INFO: stderr: "+ nc -v -t -w 2 172.31.65.227 32759\n+ echo hostName\nConnection to 172.31.65.227 32759 port [tcp/*] succeeded!\n"
  Apr 13 13:21:15.561: INFO: stdout: "nodeport-test-8t47d"
  Apr 13 13:21:15.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7521" for this suite. @ 04/13/24 13:21:15.566
• [7.499 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 04/13/24 13:21:15.573
  Apr 13 13:21:15.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-webhook @ 04/13/24 13:21:15.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:15.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:15.592
  STEP: Setting up server cert @ 04/13/24 13:21:15.596
  E0413 13:21:15.709122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/13/24 13:21:15.807
  STEP: Deploying the custom resource conversion webhook pod @ 04/13/24 13:21:15.814
  STEP: Wait for the deployment to be ready @ 04/13/24 13:21:15.825
  Apr 13 13:21:15.834: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0413 13:21:16.709619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:17.709724      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:21:17.846
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:21:17.856
  E0413 13:21:18.710061      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:18.856: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 13 13:21:18.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:21:19.710603      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:20.711661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/13/24 13:21:21.419
  STEP: v2 custom resource should be converted @ 04/13/24 13:21:21.423
  E0413 13:21:21.711702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:21.980: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6220" for this suite. @ 04/13/24 13:21:21.983
• [6.417 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/13/24 13:21:21.99
  Apr 13 13:21:21.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 13:21:21.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:22.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:22.007
  STEP: Creating pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997 @ 04/13/24 13:21:22.01
  E0413 13:21:22.711798      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:23.711907      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 13:21:24.026
  Apr 13 13:21:24.029: INFO: Initial restart count of pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 is 0
  Apr 13 13:21:24.032: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:24.712482      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:25.712662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:26.037: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:26.713183      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:27.713285      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:28.042: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:28.713409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:29.713575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:30.047: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:30.713790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:31.713960      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:32.051: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:32.714444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:33.714558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:34.056: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:34.715608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:35.715695      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:36.061: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:36.716611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:37.716745      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:38.066: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:38.717656      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:39.717879      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:40.072: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:40.718869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:41.718895      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:42.076: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  E0413 13:21:42.719552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:43.720547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:44.081: INFO: Get pod liveness-10447fea-e40c-4409-9c87-268e27c446e0 in namespace container-probe-3997
  Apr 13 13:21:44.081: INFO: Restart count of pod container-probe-3997/liveness-10447fea-e40c-4409-9c87-268e27c446e0 is now 1 (20.05247706s elapsed)
  STEP: deleting the pod @ 04/13/24 13:21:44.081
  Apr 13 13:21:44.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3997" for this suite. @ 04/13/24 13:21:44.097
• [22.112 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 04/13/24 13:21:44.103
  Apr 13 13:21:44.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:21:44.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:44.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:44.119
  STEP: Creating projection with secret that has name secret-emptykey-test-f01c7137-4e71-4456-b897-3e371261e434 @ 04/13/24 13:21:44.122
  Apr 13 13:21:44.124: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9471" for this suite. @ 04/13/24 13:21:44.128
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 04/13/24 13:21:44.134
  Apr 13 13:21:44.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/13/24 13:21:44.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:44.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:44.153
  Apr 13 13:21:44.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:21:44.720898      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:45.182: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4668" for this suite. @ 04/13/24 13:21:45.187
• [1.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 04/13/24 13:21:45.195
  Apr 13 13:21:45.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:21:45.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:45.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:45.218
  STEP: creating service in namespace services-7131 @ 04/13/24 13:21:45.221
  STEP: creating service affinity-nodeport-transition in namespace services-7131 @ 04/13/24 13:21:45.221
  STEP: creating replication controller affinity-nodeport-transition in namespace services-7131 @ 04/13/24 13:21:45.236
  I0413 13:21:45.245104      21 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-7131, replica count: 3
  E0413 13:21:45.721165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:46.721948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:47.722483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:21:48.295778      21 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:21:48.307: INFO: Creating new exec pod
  E0413 13:21:48.723468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:49.723558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:50.723649      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:51.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Apr 13 13:21:51.422: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 13 13:21:51.422: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:21:51.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.84 80'
  Apr 13 13:21:51.509: INFO: stderr: "+ nc -v -t -w 2 10.152.183.84 80\n+ echo hostName\nConnection to 10.152.183.84 80 port [tcp/http] succeeded!\n"
  Apr 13 13:21:51.509: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:21:51.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.229 30707'
  Apr 13 13:21:51.598: INFO: stderr: "+ nc -v -t -w 2 172.31.35.229 30707\n+ echo hostName\nConnection to 172.31.35.229 30707 port [tcp/*] succeeded!\n"
  Apr 13 13:21:51.599: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:21:51.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.82.63 30707'
  Apr 13 13:21:51.685: INFO: stderr: "+ nc -v -t -w 2 172.31.82.63 30707\n+ echo hostName\nConnection to 172.31.82.63 30707 port [tcp/*] succeeded!\n"
  Apr 13 13:21:51.685: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:21:51.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.35.229:30707/ ; done'
  E0413 13:21:51.724217      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:51.862: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n"
  Apr 13 13:21:51.862: INFO: stdout: "\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-57f96\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-57f96\naffinity-nodeport-transition-57f96\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-57f96\naffinity-nodeport-transition-q98jg\naffinity-nodeport-transition-57f96\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-57f96"
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-q98jg
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:51.862: INFO: Received response from host: affinity-nodeport-transition-57f96
  Apr 13 13:21:51.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-7131 exec execpod-affinitycqh8m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.35.229:30707/ ; done'
  Apr 13 13:21:52.098: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.35.229:30707/\n"
  Apr 13 13:21:52.098: INFO: stdout: "\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9\naffinity-nodeport-transition-qrxk9"
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Received response from host: affinity-nodeport-transition-qrxk9
  Apr 13 13:21:52.098: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7131, will wait for the garbage collector to delete the pods @ 04/13/24 13:21:52.113
  Apr 13 13:21:52.173: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.906163ms
  Apr 13 13:21:52.274: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.410725ms
  E0413 13:21:52.724449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:53.727222      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:54.727666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:21:55.399: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7131" for this suite. @ 04/13/24 13:21:55.402
• [10.213 seconds]
------------------------------
S
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/13/24 13:21:55.408
  Apr 13 13:21:55.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:21:55.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:21:55.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:21:55.425
  STEP: creating service endpoint-test2 in namespace services-2479 @ 04/13/24 13:21:55.428
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2479 to expose endpoints map[] @ 04/13/24 13:21:55.439
  Apr 13 13:21:55.447: INFO: successfully validated that service endpoint-test2 in namespace services-2479 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2479 @ 04/13/24 13:21:55.447
  E0413 13:21:55.728366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:56.728589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2479 to expose endpoints map[pod1:[80]] @ 04/13/24 13:21:57.466
  Apr 13 13:21:57.478: INFO: successfully validated that service endpoint-test2 in namespace services-2479 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/13/24 13:21:57.478
  Apr 13 13:21:57.478: INFO: Creating new exec pod
  E0413 13:21:57.729390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:58.729513      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:21:59.730047      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:00.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 13 13:22:00.585: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:00.585: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:22:00.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.101 80'
  Apr 13 13:22:00.675: INFO: stderr: "+ nc -v -t -w 2 10.152.183.101 80\n+ echo hostName\nConnection to 10.152.183.101 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:00.675: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-2479 @ 04/13/24 13:22:00.675
  E0413 13:22:00.730763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:01.730866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2479 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/13/24 13:22:02.696
  Apr 13 13:22:02.709: INFO: successfully validated that service endpoint-test2 in namespace services-2479 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/13/24 13:22:02.709
  E0413 13:22:02.731476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:03.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0413 13:22:03.731977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:03.801: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:03.801: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:22:03.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.101 80'
  Apr 13 13:22:03.893: INFO: stderr: "+ nc -v -t -w 2 10.152.183.101 80\n+ echo hostName\nConnection to 10.152.183.101 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:03.893: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2479 @ 04/13/24 13:22:03.893
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2479 to expose endpoints map[pod2:[80]] @ 04/13/24 13:22:03.906
  E0413 13:22:04.732708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:04.929: INFO: successfully validated that service endpoint-test2 in namespace services-2479 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/13/24 13:22:04.929
  E0413 13:22:05.732771      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:05.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 13 13:22:06.022: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:06.022: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:22:06.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-2479 exec execpodbtz8s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.101 80'
  Apr 13 13:22:06.114: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.101 80\nConnection to 10.152.183.101 80 port [tcp/http] succeeded!\n"
  Apr 13 13:22:06.114: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-2479 @ 04/13/24 13:22:06.114
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2479 to expose endpoints map[] @ 04/13/24 13:22:06.13
  E0413 13:22:06.732896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:07.149: INFO: successfully validated that service endpoint-test2 in namespace services-2479 exposes endpoints map[]
  Apr 13 13:22:07.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2479" for this suite. @ 04/13/24 13:22:07.17
• [11.768 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 04/13/24 13:22:07.176
  Apr 13 13:22:07.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:22:07.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:07.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:07.194
  STEP: Creating configMap with name projected-configmap-test-volume-map-cb87741b-2b6e-4e7b-9463-0ab1da1b8dcc @ 04/13/24 13:22:07.197
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:22:07.201
  E0413 13:22:07.733672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:08.733778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:09.733895      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:10.734148      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:22:11.225
  Apr 13 13:22:11.228: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-23e4dbed-7f35-49fb-93f3-0f4fa7b66950 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:22:11.239
  Apr 13 13:22:11.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6315" for this suite. @ 04/13/24 13:22:11.26
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 04/13/24 13:22:11.268
  Apr 13 13:22:11.268: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/13/24 13:22:11.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:11.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:11.287
  STEP: creating a target pod @ 04/13/24 13:22:11.29
  E0413 13:22:11.734549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:12.734582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/13/24 13:22:13.31
  E0413 13:22:13.735539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:14.735628      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/13/24 13:22:15.329
  Apr 13 13:22:15.329: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-415 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:22:15.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:22:15.329: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:22:15.330: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-415/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 13 13:22:15.382: INFO: Exec stderr: ""
  Apr 13 13:22:15.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-415" for this suite. @ 04/13/24 13:22:15.395
• [4.134 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/13/24 13:22:15.402
  Apr 13 13:22:15.402: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename hostport @ 04/13/24 13:22:15.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:15.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:15.42
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/13/24 13:22:15.428
  E0413 13:22:15.736567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:16.736648      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.82.63 on the node which pod1 resides and expect scheduled @ 04/13/24 13:22:17.443
  E0413 13:22:17.737094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:18.737281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.82.63 but use UDP protocol on the node which pod2 resides @ 04/13/24 13:22:19.457
  E0413 13:22:19.737740      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:20.737847      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:21.738846      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:22.739529      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:23.739921      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:24.740035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:25.740910      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:26.741016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:27.741442      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:28.741551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:29.741604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:30.741809      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:31.742717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:32.743595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/13/24 13:22:33.515
  Apr 13 13:22:33.515: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.82.63 http://127.0.0.1:54323/hostname] Namespace:hostport-4100 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:22:33.515: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:22:33.516: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:22:33.516: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4100/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.82.63+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.82.63, port: 54323 @ 04/13/24 13:22:33.569
  Apr 13 13:22:33.569: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.82.63:54323/hostname] Namespace:hostport-4100 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:22:33.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:22:33.569: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:22:33.569: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4100/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.82.63%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.82.63, port: 54323 UDP @ 04/13/24 13:22:33.629
  Apr 13 13:22:33.629: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.82.63 54323] Namespace:hostport-4100 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:22:33.629: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:22:33.629: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:22:33.629: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4100/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.82.63+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0413 13:22:33.743950      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:34.744192      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:35.744464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:36.744603      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:37.744713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:38.676: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-4100" for this suite. @ 04/13/24 13:22:38.68
• [23.284 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/13/24 13:22:38.686
  Apr 13 13:22:38.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 13:22:38.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:38.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:38.705
  Apr 13 13:22:38.708: INFO: Creating simple deployment test-new-deployment
  Apr 13 13:22:38.721: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0413 13:22:38.745688      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:39.745862      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 04/13/24 13:22:40.74
  STEP: updating a scale subresource @ 04/13/24 13:22:40.743
  E0413 13:22:40.746699      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the deployment Spec.Replicas was modified @ 04/13/24 13:22:40.75
  STEP: Patch a scale subresource @ 04/13/24 13:22:40.756
  Apr 13 13:22:40.779: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d3463e83-d5ad-4d85-b332-687bd94b0436",
      ResourceVersion: (string) (len=5) "35339",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611358,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611358,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611358,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 13:22:40.784: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "90a2bcba-0229-4752-87d4-161d4ac7283d",
      ResourceVersion: (string) (len=5) "35343",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611358,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "d3463e83-d5ad-4d85-b332-687bd94b0436",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611360,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 33 34 36 33 65  38 33 2d 64 35 61 64 2d  |\"d3463e83-d5ad-|
              00000120  34 64 38 35 2d 62 33 33  32 2d 36 38 37 62 64 39  |4d85-b332-687bd9|
              00000130  34 62 30 34 33 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |4b0436\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611360,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:22:40.791: INFO: Pod "test-new-deployment-557759b7c7-gx6wp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-gx6wp",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "786b5ac2-896e-4ca6-9b47-524ed477961c",
      ResourceVersion: (string) (len=5) "35341",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611360,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "90a2bcba-0229-4752-87d4-161d4ac7283d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611360,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 30  61 32 62 63 62 61 2d 30  |d\":\"90a2bcba-0|
              00000090  32 32 39 2d 34 37 35 32  2d 38 37 64 34 2d 31 36  |229-4752-87d4-16|
              000000a0  31 64 34 61 63 37 32 38  33 64 5c 22 7d 22 3a 7b  |1d4ac7283d\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rmslh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rmslh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611360,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 13:22:40.792: INFO: Pod "test-new-deployment-557759b7c7-wjrts" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-wjrts",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3038",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b1e101c1-3a87-4683-b837-7b74623ba4cf",
      ResourceVersion: (string) (len=5) "35329",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611358,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "90a2bcba-0229-4752-87d4-161d4ac7283d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611358,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 30  61 32 62 63 62 61 2d 30  |d\":\"90a2bcba-0|
              00000090  32 32 39 2d 34 37 35 32  2d 38 37 64 34 2d 31 36  |229-4752-87d4-16|
              000000a0  31 64 34 61 63 37 32 38  33 64 5c 22 7d 22 3a 7b  |1d4ac7283d\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 35 37  2e 32 31 30 5c 22 7d 22  |2.168.57.210\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vmrpl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vmrpl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-229",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611358,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611359,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611358,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.229",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.229"
        }
      },
      PodIP: (string) (len=14) "192.168.57.210",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.57.210"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611358,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848611359,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://81ba0213ea7982dedffb72c5e8c5f17d5d2e9b4866f6e4c835ef06830ddfc42a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 13:22:40.793: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3038" for this suite. @ 04/13/24 13:22:40.799
• [2.129 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/13/24 13:22:40.816
  Apr 13 13:22:40.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 13:22:40.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:40.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:40.845
  Apr 13 13:22:40.848: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: creating the pod @ 04/13/24 13:22:40.848
  STEP: submitting the pod to kubernetes @ 04/13/24 13:22:40.848
  E0413 13:22:41.747505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:42.747626      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:42.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2785" for this suite. @ 04/13/24 13:22:42.89
• [2.080 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/13/24 13:22:42.895
  Apr 13 13:22:42.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 13:22:42.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:42.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:42.914
  STEP: apply creating a deployment @ 04/13/24 13:22:42.917
  Apr 13 13:22:42.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3949" for this suite. @ 04/13/24 13:22:42.933
• [0.045 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 04/13/24 13:22:42.941
  Apr 13 13:22:42.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 13:22:42.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:42.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:42.961
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/13/24 13:22:42.964
  Apr 13 13:22:42.972: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0413 13:22:43.747701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:44.747874      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:45.748170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:46.748348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:47.748475      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:22:47.976: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 13:22:47.976
  STEP: getting scale subresource @ 04/13/24 13:22:47.976
  STEP: updating a scale subresource @ 04/13/24 13:22:47.98
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/13/24 13:22:47.987
  STEP: Patch a scale subresource @ 04/13/24 13:22:47.99
  Apr 13 13:22:48.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2962" for this suite. @ 04/13/24 13:22:48.021
• [5.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/13/24 13:22:48.04
  Apr 13 13:22:48.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:22:48.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:48.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:48.071
  STEP: Creating projection with secret that has name projected-secret-test-51d90123-5dc5-48b6-95c3-260801b0de09 @ 04/13/24 13:22:48.075
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:22:48.083
  E0413 13:22:48.748595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:49.748690      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:50.749663      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:51.750471      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:22:52.107
  Apr 13 13:22:52.111: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-3e36c3cd-1943-4a28-bdb3-7135ada6be28 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:22:52.117
  Apr 13 13:22:52.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1516" for this suite. @ 04/13/24 13:22:52.136
• [4.102 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 04/13/24 13:22:52.142
  Apr 13 13:22:52.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:22:52.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:22:52.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:22:52.162
  STEP: Counting existing ResourceQuota @ 04/13/24 13:22:52.165
  E0413 13:22:52.751533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:53.751634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:54.751935      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:55.752197      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:56.753041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/13/24 13:22:57.169
  STEP: Ensuring resource quota status is calculated @ 04/13/24 13:22:57.175
  E0413 13:22:57.753092      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:22:58.753388      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 04/13/24 13:22:59.18
  STEP: Ensuring resource quota status captures replication controller creation @ 04/13/24 13:22:59.192
  E0413 13:22:59.754401      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:00.754481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 04/13/24 13:23:01.197
  STEP: Ensuring resource quota status released usage @ 04/13/24 13:23:01.203
  E0413 13:23:01.754777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:02.754890      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:03.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8593" for this suite. @ 04/13/24 13:23:03.212
• [11.077 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/13/24 13:23:03.219
  Apr 13 13:23:03.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 13:23:03.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:03.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:03.237
  Apr 13 13:23:03.253: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0413 13:23:03.755219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:04.755536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:05.755644      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:06.755826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:07.755928      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:08.258: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 13:23:08.258
  Apr 13 13:23:08.258: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/13/24 13:23:08.269
  E0413 13:23:08.756816      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:09.757469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:10.290: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9776",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e1b60150-1173-4c8d-9c0d-c39defae4c9d",
      ResourceVersion: (string) (len=5) "35719",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611388,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-7bc75bbdf6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 13:23:10.294: INFO: New ReplicaSet "test-cleanup-deployment-7bc75bbdf6" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9776",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7b0cbcc6-23b4-496c-8269-ce48f162d5bc",
      ResourceVersion: (string) (len=5) "35709",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611388,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "e1b60150-1173-4c8d-9c0d-c39defae4c9d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 31 62 36 30 31  35 30 2d 31 31 37 33 2d  |\"e1b60150-1173-|
              00000120  34 63 38 64 2d 39 63 30  64 2d 63 33 39 64 65 66  |4c8d-9c0d-c39def|
              00000130  61 65 34 63 39 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ae4c9d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:23:10.299: INFO: Pod "test-cleanup-deployment-7bc75bbdf6-sccz6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7bc75bbdf6-sccz6",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7bc75bbdf6-",
      Namespace: (string) (len=15) "deployment-9776",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95fd0f3d-274d-4ae4-a639-338fea4d1a04",
      ResourceVersion: (string) (len=5) "35708",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611388,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
          UID: (types.UID) (len=36) "7b0cbcc6-23b4-496c-8269-ce48f162d5bc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 62  30 63 62 63 63 36 2d 32  |d\":\"7b0cbcc6-2|
              00000090  33 62 34 2d 34 39 36 63  2d 38 32 36 39 2d 63 65  |3b4-496c-8269-ce|
              000000a0  34 38 66 31 36 32 64 35  62 63 5c 22 7d 22 3a 7b  |48f162d5bc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 37  32 2e 32 31 31 5c 22 7d  |2.168.172.211\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xlvjs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xlvjs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611389,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848611388,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.211",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.211"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848611388,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848611388,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://15a493b49da0719a1436ab36a5faa494d7705fe919d93b7463fbef98d538f2f8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 13:23:10.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9776" for this suite. @ 04/13/24 13:23:10.303
• [7.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 04/13/24 13:23:10.31
  Apr 13 13:23:10.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:23:10.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:10.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:10.328
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/13/24 13:23:10.33
  Apr 13 13:23:10.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6947 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 13 13:23:10.377: INFO: stderr: ""
  Apr 13 13:23:10.377: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/13/24 13:23:10.377
  E0413 13:23:10.757527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:11.757615      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:12.757642      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:13.758658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:14.759538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/13/24 13:23:15.429
  Apr 13 13:23:15.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6947 get pod e2e-test-httpd-pod -o json'
  Apr 13 13:23:15.470: INFO: stderr: ""
  Apr 13 13:23:15.470: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-04-13T13:23:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6947\",\n        \"resourceVersion\": \"35744\",\n        \"uid\": \"941d6d0f-1a1c-433c-aff7-a66f0e16ddfd\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jcvhv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-82-63\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-jcvhv\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-13T13:23:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-13T13:23:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-13T13:23:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-13T13:23:11Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-13T13:23:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://55a1b9960fc236e427f2f46e796d60306b286aed790863381b2ef40416051d9a\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-13T13:23:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.82.63\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.82.63\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.172.220\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.172.220\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-13T13:23:10Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/13/24 13:23:15.47
  Apr 13 13:23:15.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6947 replace -f -'
  Apr 13 13:23:15.547: INFO: stderr: ""
  Apr 13 13:23:15.547: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 04/13/24 13:23:15.547
  Apr 13 13:23:15.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6947 delete pods e2e-test-httpd-pod'
  E0413 13:23:15.759842      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:16.759946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:17.533: INFO: stderr: ""
  Apr 13 13:23:17.533: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 13 13:23:17.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6947" for this suite. @ 04/13/24 13:23:17.538
• [7.234 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 04/13/24 13:23:17.544
  Apr 13 13:23:17.544: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/13/24 13:23:17.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:17.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:17.561
  STEP: Creating two CSIDrivers @ 04/13/24 13:23:17.564
  STEP: Getting "inline-driver-106e1cd4-28fb-4d55-b6d2-938ff7895323" & "inline-driver-4a4e32a8-760a-46d8-90f4-65eebe30d515" @ 04/13/24 13:23:17.58
  STEP: Patching the CSIDriver "inline-driver-4a4e32a8-760a-46d8-90f4-65eebe30d515" @ 04/13/24 13:23:17.586
  STEP: Updating the CSIDriver "inline-driver-4a4e32a8-760a-46d8-90f4-65eebe30d515" @ 04/13/24 13:23:17.591
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-4410" @ 04/13/24 13:23:17.598
  STEP: Deleting CSIDriver "inline-driver-106e1cd4-28fb-4d55-b6d2-938ff7895323" @ 04/13/24 13:23:17.601
  STEP: Confirm deletion of CSIDriver "inline-driver-106e1cd4-28fb-4d55-b6d2-938ff7895323" @ 04/13/24 13:23:17.606
  STEP: Deleting CSIDriver "inline-driver-4a4e32a8-760a-46d8-90f4-65eebe30d515" via DeleteCollection @ 04/13/24 13:23:17.609
  STEP: Confirm deletion of CSIDriver "inline-driver-4a4e32a8-760a-46d8-90f4-65eebe30d515" @ 04/13/24 13:23:17.618
  Apr 13 13:23:17.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4410" for this suite. @ 04/13/24 13:23:17.63
• [0.096 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/13/24 13:23:17.64
  Apr 13 13:23:17.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:23:17.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:17.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:17.665
  STEP: Creating secret with name secret-test-aa1061d7-9f22-4349-92ad-82dfcf208282 @ 04/13/24 13:23:17.672
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:23:17.682
  E0413 13:23:17.760450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:18.761377      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:23:19.711
  Apr 13 13:23:19.715: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-9ac44d6d-3f9e-429e-8b77-7ebfb31390f7 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:23:19.72
  Apr 13 13:23:19.736: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9162" for this suite. @ 04/13/24 13:23:19.74
• [2.106 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 04/13/24 13:23:19.746
  Apr 13 13:23:19.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:23:19.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:19.76
  E0413 13:23:19.762306      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:19.764
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/13/24 13:23:19.767
  E0413 13:23:20.762490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:21.762585      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:23:21.785
  Apr 13 13:23:21.789: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-afbaebb0-235a-4d3a-a7c7-336fc4d26707 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:23:21.795
  Apr 13 13:23:21.810: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8667" for this suite. @ 04/13/24 13:23:21.814
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 04/13/24 13:23:21.821
  Apr 13 13:23:21.821: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:23:21.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:21.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:21.84
  STEP: Creating configMap with name projected-configmap-test-volume-dd437bc3-ea01-49db-b7fb-a4af90cc13c7 @ 04/13/24 13:23:21.843
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:23:21.847
  E0413 13:23:22.763570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:23.763763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:24.763867      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:25.763952      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:23:25.867
  Apr 13 13:23:25.870: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-5aac7317-7b4d-41ca-98d0-34d4d1ea5710 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:23:25.877
  Apr 13 13:23:25.892: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9388" for this suite. @ 04/13/24 13:23:25.896
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/13/24 13:23:25.906
  Apr 13 13:23:25.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:23:25.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:25.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:25.924
  STEP: Creating secret with name secret-test-90b5122c-8517-4405-9a5e-483a2157f8b0 @ 04/13/24 13:23:25.929
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:23:25.932
  E0413 13:23:26.764042      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:27.765108      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:28.765215      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:29.765338      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:23:29.958
  Apr 13 13:23:29.961: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-7b1b3070-d8d6-468d-8549-d795934b335f container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:23:29.967
  Apr 13 13:23:29.984: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5400" for this suite. @ 04/13/24 13:23:29.99
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 04/13/24 13:23:30
  Apr 13 13:23:30.000: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 13:23:30.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:30.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:30.021
  STEP: Given a ReplicationController is created @ 04/13/24 13:23:30.024
  STEP: When the matched label of one of its pods change @ 04/13/24 13:23:30.028
  Apr 13 13:23:30.031: INFO: Pod name pod-release: Found 0 pods out of 1
  E0413 13:23:30.765431      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:31.765521      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:32.766528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:33.766613      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:34.766706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:35.037: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/13/24 13:23:35.054
  E0413 13:23:35.767551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:36.063: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7807" for this suite. @ 04/13/24 13:23:36.067
• [6.074 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/13/24 13:23:36.074
  Apr 13 13:23:36.074: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:23:36.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:36.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:36.091
  STEP: Creating secret with name secret-test-map-889d506d-aba1-4a90-8ff3-d5bc321d75c7 @ 04/13/24 13:23:36.094
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:23:36.098
  E0413 13:23:36.767670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:37.767770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:38.767867      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:39.768914      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:23:40.122
  Apr 13 13:23:40.126: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-secrets-1fda76eb-1d1e-48dc-94ba-99b911165272 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:23:40.132
  Apr 13 13:23:40.151: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4902" for this suite. @ 04/13/24 13:23:40.155
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 04/13/24 13:23:40.163
  Apr 13 13:23:40.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:23:40.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:40.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:40.184
  STEP: Creating the pod @ 04/13/24 13:23:40.188
  E0413 13:23:40.769244      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:41.769352      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:42.735: INFO: Successfully updated pod "labelsupdate8dcc0def-2648-4627-8b52-771a358ef4d8"
  E0413 13:23:42.769712      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:43.769845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:44.770647      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:45.771546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:23:46.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4694" for this suite. @ 04/13/24 13:23:46.763
• [6.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 04/13/24 13:23:46.77
  Apr 13 13:23:46.770: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:23:46.771
  E0413 13:23:46.771497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:23:46.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:23:46.789
  STEP: Creating configMap with name cm-test-opt-del-0bf92394-c797-4196-89eb-edb0cf026d6f @ 04/13/24 13:23:46.795
  STEP: Creating configMap with name cm-test-opt-upd-6da9a1e0-0c1f-453b-aa96-b6c3c2bb1f71 @ 04/13/24 13:23:46.801
  STEP: Creating the pod @ 04/13/24 13:23:46.805
  E0413 13:23:47.771670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:48.771759      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-0bf92394-c797-4196-89eb-edb0cf026d6f @ 04/13/24 13:23:48.846
  STEP: Updating configmap cm-test-opt-upd-6da9a1e0-0c1f-453b-aa96-b6c3c2bb1f71 @ 04/13/24 13:23:48.852
  STEP: Creating configMap with name cm-test-opt-create-2159671d-87c4-42dd-bf2a-c772b0db7659 @ 04/13/24 13:23:48.857
  STEP: waiting to observe update in volume @ 04/13/24 13:23:48.862
  E0413 13:23:49.771850      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:50.771961      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:51.772056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:52.772998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:53.773170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:54.773758      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:55.773982      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:56.774073      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:57.774701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:58.775560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:23:59.776003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:00.776090      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:01.776218      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:02.777187      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:03.777294      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:04.777491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:05.777583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:06.777782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:07.777967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:08.778049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:09.778523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:10.778843      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:11.778745      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:12.779100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:13.779530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:14.779625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:15.780457      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:16.780707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:17.781716      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:18.782224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:19.782448      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:20.782545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:21.783538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:22.783635      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:23.784019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:24.784198      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:25.784331      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:26.784595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:27.784783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:28.784953      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:29.786027      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:30.786191      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:31.786352      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:32.786459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:33.787524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:34.787717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:35.788236      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:36.788425      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:37.788875      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:38.788984      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:39.789094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:40.789288      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:41.789737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:42.789936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:43.790033      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:44.790119      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:45.790455      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:46.790553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:47.791517      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:48.791626      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:49.792510      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:50.792654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:51.793641      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:52.793740      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:53.794820      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:54.794922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:55.795397      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:56.795597      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:57.795685      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:58.795764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:24:59.796723      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:00.797172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:01.797334      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:02.798265      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:03.799145      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:04.799271      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:05.799300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:06.799415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:07.799495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:08.799591      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:09.800435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:10.800536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:11.801285      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:12.801371      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:25:13.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-493" for this suite. @ 04/13/24 13:25:13.232
• [86.467 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/13/24 13:25:13.238
  Apr 13 13:25:13.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename certificates @ 04/13/24 13:25:13.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:25:13.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:25:13.257
  STEP: getting /apis @ 04/13/24 13:25:13.518
  STEP: getting /apis/certificates.k8s.io @ 04/13/24 13:25:13.521
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/13/24 13:25:13.523
  STEP: creating @ 04/13/24 13:25:13.524
  STEP: getting @ 04/13/24 13:25:13.542
  STEP: listing @ 04/13/24 13:25:13.546
  STEP: watching @ 04/13/24 13:25:13.549
  Apr 13 13:25:13.549: INFO: starting watch
  STEP: patching @ 04/13/24 13:25:13.55
  STEP: updating @ 04/13/24 13:25:13.555
  Apr 13 13:25:13.561: INFO: waiting for watch events with expected annotations
  Apr 13 13:25:13.562: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/13/24 13:25:13.562
  STEP: patching /approval @ 04/13/24 13:25:13.564
  STEP: updating /approval @ 04/13/24 13:25:13.57
  STEP: getting /status @ 04/13/24 13:25:13.577
  STEP: patching /status @ 04/13/24 13:25:13.58
  STEP: updating /status @ 04/13/24 13:25:13.588
  STEP: deleting @ 04/13/24 13:25:13.594
  STEP: deleting a collection @ 04/13/24 13:25:13.606
  Apr 13 13:25:13.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-9101" for this suite. @ 04/13/24 13:25:13.623
• [0.393 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 04/13/24 13:25:13.631
  Apr 13 13:25:13.631: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubelet-test @ 04/13/24 13:25:13.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:25:13.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:25:13.645
  E0413 13:25:13.801418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:14.802141      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:25:15.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6378" for this suite. @ 04/13/24 13:25:15.688
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/13/24 13:25:15.695
  Apr 13 13:25:15.695: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename cronjob @ 04/13/24 13:25:15.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:25:15.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:25:15.715
  STEP: Creating a suspended cronjob @ 04/13/24 13:25:15.718
  STEP: Ensuring no jobs are scheduled @ 04/13/24 13:25:15.724
  E0413 13:25:15.802415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:16.802507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:17.803465      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:18.803664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:19.804156      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:20.804322      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:21.805348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:22.805489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:23.805682      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:24.805906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:25.806687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:26.807564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:27.808187      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:28.808305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:29.808685      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:30.809493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:31.810359      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:32.810506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:33.811248      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:34.811872      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:35.812408      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:36.812672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:37.813415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:38.813533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:39.813633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:40.813744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:41.814437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:42.814520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:43.815093      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:44.815486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:45.815804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:46.816550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:47.817123      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:48.817317      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:49.818131      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:50.818355      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:51.818849      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:52.818982      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:53.819409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:54.819514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:55.819608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:56.820549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:57.820948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:58.821869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:25:59.822581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:00.822663      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:01.823435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:02.823537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:03.824232      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:04.824335      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:05.824807      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:06.825705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:07.826692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:08.827571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:09.828004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:10.828368      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:11.829313      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:12.829408      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:13.829875      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:14.829996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:15.830939      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:16.831981      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:17.832868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:18.832978      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:19.833307      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:20.833555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:21.834364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:22.834454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:23.834522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:24.834629      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:25.835682      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:26.836153      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:27.836705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:28.836852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:29.837534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:30.837640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:31.838530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:32.838650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:33.839080      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:34.839554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:35.840634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:36.840965      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:37.842015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:38.842194      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:39.842284      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:40.842464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:41.843364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:42.843770      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:43.844399      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:44.844606      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:45.845659      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:46.845999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:47.846544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:48.847527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:49.848125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:50.848304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:51.848626      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:52.848779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:53.849708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:54.849895      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:55.850240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:56.850543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:57.850684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:58.851676      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:26:59.852398      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:00.852619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:01.853362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:02.853430      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:03.854297      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:04.854461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:05.855466      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:06.855765      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:07.856070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:08.856192      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:09.857223      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:10.857417      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:11.858402      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:12.858478      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:13.858830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:14.858935      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:15.859520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:16.859791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:17.860575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:18.860691      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:19.861490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:20.861608      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:21.862550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:22.862636      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:23.863500      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:24.863609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:25.864092      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:26.864468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:27.865531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:28.865711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:29.865767      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:30.865883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:31.866645      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:32.866747      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:33.867632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:34.867741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:35.867819      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:36.868531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:37.868839      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:38.868998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:39.870018      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:40.870591      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:41.871811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:42.871642      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:43.872008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:44.872167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:45.872715      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:46.873046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:47.873581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:48.874142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:49.874606      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:50.875528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:51.875605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:52.875696      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:53.876438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:54.876584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:55.877617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:56.877845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:57.878572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:58.879545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:27:59.880319      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:00.880474      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:01.880622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:02.881361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:03.881448      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:04.881826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:05.882507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:06.883510      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:07.884463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:08.884572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:09.885330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:10.885575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:11.886635      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:12.887001      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:13.888052      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:14.889046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:15.889097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:16.889555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:17.890179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:18.890304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:19.890749      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:20.890853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:21.891806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:22.892008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:23.892431      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:24.892590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:25.893625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:26.894009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:27.894703      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:28.894799      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:29.895534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:30.895700      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:31.896018      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:32.896290      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:33.896808      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:34.896933      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:35.897892      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:36.898425      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:37.899016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:38.899550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:39.900141      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:40.900260      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:41.902068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:42.902460      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:43.903396      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:44.903542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:45.903866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:46.904350      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:47.904435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:48.904709      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:49.905676      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:50.905766      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:51.910202      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:52.910788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:53.911643      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:54.911799      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:55.912733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:56.913678      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:57.914298      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:58.914462      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:28:59.915136      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:00.915515      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:01.918617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:02.919533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:03.920429      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:04.920496      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:05.921219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:06.921476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:07.922438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:08.922485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:09.922911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:10.923008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:11.925858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:12.926710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:13.927170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:14.927390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:15.927823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:16.928689      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:17.928793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:18.928829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:19.929789      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:20.930021      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:21.930133      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:22.930245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:23.931256      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:24.931353      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:25.932133      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:26.932510      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:27.933548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:28.933706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:29.934769      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:30.935535      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:31.935932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:32.935999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:33.936473      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:34.936660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:35.937706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:36.938040      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:37.938599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:38.939532      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:39.939974      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:40.940095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:41.941571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:42.941660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:43.942228      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:44.942321      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:45.942630      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:46.943542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:47.943582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:48.943791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:49.944259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:50.944457      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:51.945453      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:52.945522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:53.946450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:54.946540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:55.947199      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:56.947530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:57.947887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:58.948290      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:29:59.948453      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:00.948551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:01.949785      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:02.949867      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:03.950480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:04.951527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:05.951999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:06.952291      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:07.952371      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:08.952576      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:09.953467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:10.953817      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:11.953671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:12.953945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:13.954128      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:14.954444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/13/24 13:30:15.732
  STEP: Removing cronjob @ 04/13/24 13:30:15.735
  Apr 13 13:30:15.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5814" for this suite. @ 04/13/24 13:30:15.745
• [300.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 04/13/24 13:30:15.754
  Apr 13 13:30:15.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:30:15.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:30:15.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:30:15.772
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/13/24 13:30:15.775
  E0413 13:30:15.955002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:16.955564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:17.955958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:18.956150      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:30:19.795
  Apr 13 13:30:19.801: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-99af792f-445c-4688-b549-4079ef1a847b container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:30:19.82
  Apr 13 13:30:19.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7957" for this suite. @ 04/13/24 13:30:19.84
• [4.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 04/13/24 13:30:19.848
  Apr 13 13:30:19.848: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubelet-test @ 04/13/24 13:30:19.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:30:19.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:30:19.862
  Apr 13 13:30:19.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-415" for this suite. @ 04/13/24 13:30:19.895
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 04/13/24 13:30:19.9
  Apr 13 13:30:19.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:30:19.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:30:19.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:30:19.918
  STEP: validating cluster-info @ 04/13/24 13:30:19.921
  Apr 13 13:30:19.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-4238 cluster-info'
  E0413 13:30:19.956828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:19.962: INFO: stderr: ""
  Apr 13 13:30:19.962: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 13 13:30:19.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4238" for this suite. @ 04/13/24 13:30:19.966
• [0.074 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 04/13/24 13:30:19.974
  Apr 13 13:30:19.974: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 13:30:19.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:30:19.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:30:19.989
  STEP: Creating pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139 @ 04/13/24 13:30:19.992
  E0413 13:30:20.956948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:21.957139      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 13:30:22.009
  Apr 13 13:30:22.013: INFO: Initial restart count of pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 is 0
  Apr 13 13:30:22.016: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:22.957235      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:23.957348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:24.022: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:24.958163      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:25.958273      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:26.026: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:26.958555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:27.958646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:28.031: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:28.959436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:29.959518      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:30.036: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:30.959633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:31.959804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:32.041: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:32.960149      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:33.960330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:34.045: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:34.960594      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:35.960692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:36.050: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:36.961511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:37.961629      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:38.055: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:38.961727      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:39.961936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:40.061: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:40.962156      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:41.962236      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:42.065: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:42.962485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:43.963548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:44.070: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:44.964427      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:45.964522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:46.074: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:46.964672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:47.964737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:48.079: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:48.965555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:49.965707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:50.084: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:50.966237      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:51.966530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:52.090: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:52.967164      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:53.967552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:54.095: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:54.968107      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:55.968201      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:56.098: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:56.968669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:57.968763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:30:58.104: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:30:58.968858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:30:59.968971      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:00.110: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:00.969087      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:01.969169      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:02.114: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:02.969277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:03.969470      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:04.119: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:04.969607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:05.969719      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:06.124: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:06.970654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:07.970742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:08.129: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:08.970917      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:09.971016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:10.135: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:10.971579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:11.971666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:12.140: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:12.971720      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:13.972446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:14.145: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:14.972571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:15.972751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:16.150: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:16.973240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:17.973746      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:18.156: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:18.973936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:19.974049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:20.160: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:20.974144      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:21.974255      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:22.164: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:22.974376      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:23.974509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:24.169: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:24.975569      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:25.975760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:26.174: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  E0413 13:31:26.976584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:27.976672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:31:28.179: INFO: Get pod test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 in namespace container-probe-2139
  Apr 13 13:31:28.179: INFO: Restart count of pod container-probe-2139/test-grpc-dedb1b62-c2c1-4372-a5e7-2c735316f1b0 is now 1 (1m6.165722957s elapsed)
  STEP: deleting the pod @ 04/13/24 13:31:28.179
  Apr 13 13:31:28.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2139" for this suite. @ 04/13/24 13:31:28.197
• [68.230 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/13/24 13:31:28.205
  Apr 13 13:31:28.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:31:28.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:31:28.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:31:28.224
  STEP: creating the pod @ 04/13/24 13:31:28.227
  STEP: waiting for pod running @ 04/13/24 13:31:28.234
  E0413 13:31:28.977578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:29.977795      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/13/24 13:31:30.244
  Apr 13 13:31:30.248: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9624 PodName:var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:31:30.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:31:30.248: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:31:30.248: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-9624/pods/var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/13/24 13:31:30.299
  Apr 13 13:31:30.303: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9624 PodName:var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:31:30.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:31:30.303: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:31:30.303: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-9624/pods/var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/13/24 13:31:30.35
  Apr 13 13:31:30.862: INFO: Successfully updated pod "var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78"
  STEP: waiting for annotated pod running @ 04/13/24 13:31:30.862
  STEP: deleting the pod gracefully @ 04/13/24 13:31:30.866
  Apr 13 13:31:30.866: INFO: Deleting pod "var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78" in namespace "var-expansion-9624"
  Apr 13 13:31:30.874: INFO: Wait up to 5m0s for pod "var-expansion-21c8892a-b6b7-4420-b044-df6cefaf2a78" to be fully deleted
  E0413 13:31:30.977951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:31.978046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:32.978556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:33.978699      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:34.979708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:35.979909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:36.980667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:37.980778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:38.981119      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:39.981822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:40.982697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:41.983609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:42.984047      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:43.984277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:44.984852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:45.985053      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:46.985702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:47.985798      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:48.986052      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:49.986852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:50.987529      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:51.987622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:52.988254      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:53.988330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:54.988504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:55.988623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:56.989146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:57.989252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:58.989542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:31:59.989769      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:00.990733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:01.990839      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:02.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9624" for this suite. @ 04/13/24 13:32:02.954
• [34.757 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/13/24 13:32:02.962
  Apr 13 13:32:02.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename var-expansion @ 04/13/24 13:32:02.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:02.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:02.978
  STEP: Creating a pod to test substitution in container's command @ 04/13/24 13:32:02.982
  E0413 13:32:02.990885      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:03.991061      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:04.991148      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:05.991238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:06.991532      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:32:07.005
  Apr 13 13:32:07.008: INFO: Trying to get logs from node ip-172-31-82-63 pod var-expansion-75642d0f-ee42-4cc5-9b0b-7d90be3b8494 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 13:32:07.018
  Apr 13 13:32:07.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1423" for this suite. @ 04/13/24 13:32:07.037
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 04/13/24 13:32:07.044
  Apr 13 13:32:07.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename aggregator @ 04/13/24 13:32:07.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:07.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:07.061
  Apr 13 13:32:07.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Registering the sample API server. @ 04/13/24 13:32:07.064
  Apr 13 13:32:07.296: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 13 13:32:07.323: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0413 13:32:07.991943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:08.992152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:09.362: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:09.992593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:10.992945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:11.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:11.993686      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:12.993744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:13.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:13.993849      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:14.994094      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:15.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:15.995044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:16.996006      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:17.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:17.997053      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:18.998133      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:19.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:19.999162      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:20.999280      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:21.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:21.999525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:22.999637      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:23.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:23.999834      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:24.999939      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:25.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:26.000431      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:27.000640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:27.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:28.000864      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:29.000959      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:29.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:30.001437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:31.002364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:31.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0413 13:32:32.003187      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:33.003422      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:33.487: INFO: Waited 111.874922ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/13/24 13:32:33.517
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/13/24 13:32:33.521
  STEP: List APIServices @ 04/13/24 13:32:33.528
  Apr 13 13:32:33.533: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/13/24 13:32:33.533
  Apr 13 13:32:33.545: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/13/24 13:32:33.545
  Apr 13 13:32:33.557: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.April, 13, 13, 32, 33, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/13/24 13:32:33.557
  Apr 13 13:32:33.560: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-04-13 13:32:33 +0000 UTC Passed all checks passed}
  Apr 13 13:32:33.560: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:32:33.560: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/13/24 13:32:33.56
  Apr 13 13:32:33.571: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-2011269446" @ 04/13/24 13:32:33.571
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/13/24 13:32:33.578
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/13/24 13:32:33.584
  STEP: Patch APIService Status @ 04/13/24 13:32:33.587
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/13/24 13:32:33.595
  Apr 13 13:32:33.598: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-04-13 13:32:33 +0000 UTC Passed all checks passed}
  Apr 13 13:32:33.598: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:32:33.598: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 13 13:32:33.598: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 04/13/24 13:32:33.599
  STEP: Confirm that the generated APIService has been deleted @ 04/13/24 13:32:33.608
  Apr 13 13:32:33.608: INFO: Requesting list of APIServices to confirm quantity
  Apr 13 13:32:33.611: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Apr 13 13:32:33.611: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 13 13:32:33.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-8574" for this suite. @ 04/13/24 13:32:33.714
• [26.676 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/13/24 13:32:33.72
  Apr 13 13:32:33.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:32:33.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:33.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:33.738
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5576 @ 04/13/24 13:32:33.742
  STEP: changing the ExternalName service to type=NodePort @ 04/13/24 13:32:33.748
  STEP: creating replication controller externalname-service in namespace services-5576 @ 04/13/24 13:32:33.764
  I0413 13:32:33.772371      21 runners.go:197] Created replication controller with name: externalname-service, namespace: services-5576, replica count: 2
  E0413 13:32:34.004140      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:35.004281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:36.005255      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:32:36.823403      21 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:32:36.823: INFO: Creating new exec pod
  E0413 13:32:37.005655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:38.005835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:39.006552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:39.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5576 exec execpodskjlh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 13 13:32:39.939: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 13 13:32:39.939: INFO: stdout: "externalname-service-c49dn"
  Apr 13 13:32:39.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5576 exec execpodskjlh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.188 80'
  E0413 13:32:40.007182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:40.031: INFO: stderr: "+ nc -v -t -w 2 10.152.183.188 80\nConnection to 10.152.183.188 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 13 13:32:40.031: INFO: stdout: ""
  Apr 13 13:32:40.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5576 exec execpodskjlh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.188 80'
  E0413 13:32:41.007277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:32:41.029: INFO: stderr: "+ nc -v -t -w 2 10.152.183.188 80\n+ echo hostName\nConnection to 10.152.183.188 80 port [tcp/http] succeeded!\n"
  Apr 13 13:32:41.029: INFO: stdout: "externalname-service-c49dn"
  Apr 13 13:32:41.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5576 exec execpodskjlh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.229 31185'
  Apr 13 13:32:41.126: INFO: stderr: "+ nc -v -t -w 2 172.31.35.229 31185\n+ echo hostName\nConnection to 172.31.35.229 31185 port [tcp/*] succeeded!\n"
  Apr 13 13:32:41.126: INFO: stdout: "externalname-service-vhr2g"
  Apr 13 13:32:41.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-5576 exec execpodskjlh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.65.227 31185'
  Apr 13 13:32:41.213: INFO: stderr: "+ nc -v -t -w 2 172.31.65.227 31185\n+ echo hostName\nConnection to 172.31.65.227 31185 port [tcp/*] succeeded!\n"
  Apr 13 13:32:41.213: INFO: stdout: "externalname-service-vhr2g"
  Apr 13 13:32:41.214: INFO: Cleaning up the ExternalName to NodePort test service
  Apr 13 13:32:41.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5576" for this suite. @ 04/13/24 13:32:41.238
• [7.525 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 04/13/24 13:32:41.245
  Apr 13 13:32:41.245: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 13:32:41.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:41.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:41.26
  STEP: Creating a test namespace @ 04/13/24 13:32:41.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:41.279
  STEP: Creating a service in the namespace @ 04/13/24 13:32:41.282
  STEP: Deleting the namespace @ 04/13/24 13:32:41.291
  STEP: Waiting for the namespace to be removed. @ 04/13/24 13:32:41.298
  E0413 13:32:42.007399      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:43.007515      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:44.007604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:45.008571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:46.009564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:47.009717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/13/24 13:32:47.302
  STEP: Verifying there is no service in the namespace @ 04/13/24 13:32:47.314
  Apr 13 13:32:47.320: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5157" for this suite. @ 04/13/24 13:32:47.323
  STEP: Destroying namespace "nsdeletetest-6555" for this suite. @ 04/13/24 13:32:47.329
  Apr 13 13:32:47.332: INFO: Namespace nsdeletetest-6555 was already deleted
  STEP: Destroying namespace "nsdeletetest-9131" for this suite. @ 04/13/24 13:32:47.332
• [6.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/13/24 13:32:47.339
  Apr 13 13:32:47.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 13:32:47.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:47.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:47.356
  STEP: apply creating a deployment @ 04/13/24 13:32:47.359
  Apr 13 13:32:47.373: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7888" for this suite. @ 04/13/24 13:32:47.376
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 04/13/24 13:32:47.383
  Apr 13 13:32:47.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:32:47.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:47.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:47.398
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:32:47.406
  E0413 13:32:48.010640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:49.010725      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:50.011571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:51.011655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:32:51.43
  Apr 13 13:32:51.434: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-2c7673b6-ada2-4bb1-bf5e-bd9ea953dda8 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:32:51.441
  Apr 13 13:32:51.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8948" for this suite. @ 04/13/24 13:32:51.462
• [4.088 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/13/24 13:32:51.471
  Apr 13 13:32:51.471: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:32:51.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:32:51.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:32:51.488
  STEP: Creating secret with name s-test-opt-del-1e453c77-37cd-4bac-8b0f-14c4085f4be4 @ 04/13/24 13:32:51.495
  STEP: Creating secret with name s-test-opt-upd-777764ee-01e8-47e3-9e0b-f10b303fbf98 @ 04/13/24 13:32:51.5
  STEP: Creating the pod @ 04/13/24 13:32:51.505
  E0413 13:32:52.012308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:53.012406      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-1e453c77-37cd-4bac-8b0f-14c4085f4be4 @ 04/13/24 13:32:53.548
  STEP: Updating secret s-test-opt-upd-777764ee-01e8-47e3-9e0b-f10b303fbf98 @ 04/13/24 13:32:53.553
  STEP: Creating secret with name s-test-opt-create-84e82d15-f879-4034-babf-a888d139450d @ 04/13/24 13:32:53.558
  STEP: waiting to observe update in volume @ 04/13/24 13:32:53.562
  E0413 13:32:54.012817      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:55.013034      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:56.014097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:57.014488      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:58.015172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:32:59.015262      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:00.015367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:01.015527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:02.015620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:03.015766      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:04.015847      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:05.015945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:06.016618      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:07.017502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:08.017582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:09.017711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:10.017829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:11.017915      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:12.018295      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:13.018581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:14.019428      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:15.019596      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:16.019692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:17.020689      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:18.020776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:19.021157      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:20.022206      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:21.022490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:22.023145      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:23.023227      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:24.023364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:25.023452      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:26.023547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:27.023632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:28.024177      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:29.024462      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:30.025208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:31.025914      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:32.026540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:33.026644      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:34.026736      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:35.027574      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:36.027615      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:37.027921      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:38.028424      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:39.028615      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:40.028706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:41.028884      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:42.029505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:43.029599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:44.030160      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:45.030254      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:46.030864      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:47.031545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:48.031640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:49.031737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:50.032124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:51.032314      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:52.032365      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:53.032474      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:54.033156      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:55.033271      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:56.033350      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:57.033610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:58.033633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:33:59.033789      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:00.034610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:01.034707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:02.035558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:03.035631      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:04.036618      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:05.036793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:06.037362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:07.037779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:08.037944      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:09.038063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:10.039045      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:11.039466      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:12.039829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:13.039920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:14.040419      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:15.040521      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:16.041447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:17.041705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:18.042286      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:19.042459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:20.043258      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:21.043344      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:21.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9936" for this suite. @ 04/13/24 13:34:21.929
• [90.465 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 04/13/24 13:34:21.937
  Apr 13 13:34:21.937: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-webhook @ 04/13/24 13:34:21.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:21.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:21.956
  STEP: Setting up server cert @ 04/13/24 13:34:21.959
  E0413 13:34:22.043396      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/13/24 13:34:22.13
  STEP: Deploying the custom resource conversion webhook pod @ 04/13/24 13:34:22.137
  STEP: Wait for the deployment to be ready @ 04/13/24 13:34:22.149
  Apr 13 13:34:22.156: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0413 13:34:23.043554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:24.043812      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:34:24.168
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:34:24.176
  E0413 13:34:25.044027      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:25.177: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 13 13:34:25.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:34:26.044701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:27.044987      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/13/24 13:34:27.74
  STEP: Create a v2 custom resource @ 04/13/24 13:34:27.756
  STEP: List CRs in v1 @ 04/13/24 13:34:27.786
  STEP: List CRs in v2 @ 04/13/24 13:34:27.791
  E0413 13:34:28.045328      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:28.355: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-4492" for this suite. @ 04/13/24 13:34:28.359
• [6.431 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 04/13/24 13:34:28.368
  Apr 13 13:34:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:34:28.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:28.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:28.388
  STEP: creating Agnhost RC @ 04/13/24 13:34:28.391
  Apr 13 13:34:28.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8044 create -f -'
  Apr 13 13:34:28.484: INFO: stderr: ""
  Apr 13 13:34:28.484: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/13/24 13:34:28.484
  E0413 13:34:29.046016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:29.488: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:34:29.488: INFO: Found 0 / 1
  E0413 13:34:30.046845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:30.490: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:34:30.490: INFO: Found 1 / 1
  Apr 13 13:34:30.490: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/13/24 13:34:30.49
  Apr 13 13:34:30.493: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:34:30.493: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 13 13:34:30.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-8044 patch pod agnhost-primary-j22jm -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 13 13:34:30.544: INFO: stderr: ""
  Apr 13 13:34:30.544: INFO: stdout: "pod/agnhost-primary-j22jm patched\n"
  STEP: checking annotations @ 04/13/24 13:34:30.544
  Apr 13 13:34:30.547: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 13 13:34:30.547: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 13 13:34:30.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8044" for this suite. @ 04/13/24 13:34:30.551
• [2.188 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 04/13/24 13:34:30.556
  Apr 13 13:34:30.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context-test @ 04/13/24 13:34:30.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:30.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:30.578
  E0413 13:34:31.047560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:32.047829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:33.048673      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:34.048757      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:34.608: INFO: Got logs for pod "busybox-privileged-false-6c6da169-c2dd-43d7-89aa-854b41d3b317": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 13 13:34:34.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2227" for this suite. @ 04/13/24 13:34:34.612
• [4.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 04/13/24 13:34:34.62
  Apr 13 13:34:34.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:34:34.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:34.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:34.637
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/13/24 13:34:34.64
  E0413 13:34:35.049134      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:36.049250      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:37.050303      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:38.050493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:34:38.662
  Apr 13 13:34:38.666: INFO: Trying to get logs from node ip-172-31-35-229 pod pod-24c0fadd-0b99-4485-982c-dcb06a4f46f7 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:34:38.682
  Apr 13 13:34:38.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1620" for this suite. @ 04/13/24 13:34:38.701
• [4.088 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/13/24 13:34:38.708
  Apr 13 13:34:38.708: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 13:34:38.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:38.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:38.726
  Apr 13 13:34:38.730: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:34:39.051026      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:40.051135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:41.051243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0413 13:34:41.266716      21 warnings.go:70] unknown field "alpha"
  W0413 13:34:41.266733      21 warnings.go:70] unknown field "beta"
  W0413 13:34:41.266736      21 warnings.go:70] unknown field "delta"
  W0413 13:34:41.266739      21 warnings.go:70] unknown field "epsilon"
  W0413 13:34:41.266742      21 warnings.go:70] unknown field "gamma"
  Apr 13 13:34:41.810: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-775" for this suite. @ 04/13/24 13:34:41.813
• [3.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 04/13/24 13:34:41.82
  Apr 13 13:34:41.820: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename ingressclass @ 04/13/24 13:34:41.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:41.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:41.836
  STEP: getting /apis @ 04/13/24 13:34:41.84
  STEP: getting /apis/networking.k8s.io @ 04/13/24 13:34:41.843
  STEP: getting /apis/networking.k8s.iov1 @ 04/13/24 13:34:41.844
  STEP: creating @ 04/13/24 13:34:41.845
  STEP: getting @ 04/13/24 13:34:41.86
  STEP: listing @ 04/13/24 13:34:41.863
  STEP: watching @ 04/13/24 13:34:41.866
  Apr 13 13:34:41.866: INFO: starting watch
  STEP: patching @ 04/13/24 13:34:41.867
  STEP: updating @ 04/13/24 13:34:41.873
  Apr 13 13:34:41.878: INFO: waiting for watch events with expected annotations
  Apr 13 13:34:41.878: INFO: saw patched and updated annotations
  STEP: deleting @ 04/13/24 13:34:41.878
  STEP: deleting a collection @ 04/13/24 13:34:41.888
  Apr 13 13:34:41.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-3064" for this suite. @ 04/13/24 13:34:41.906
• [0.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 04/13/24 13:34:41.915
  Apr 13 13:34:41.915: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:34:41.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:41.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:41.942
  STEP: creating secret secrets-872/secret-test-a6212721-2b24-4513-8bfd-2dfa5386b916 @ 04/13/24 13:34:41.95
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:34:41.956
  E0413 13:34:42.051920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:43.052077      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:34:43.971
  Apr 13 13:34:43.974: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-c12d626a-0dce-4b73-b4ad-a4b341903528 container env-test: <nil>
  STEP: delete the pod @ 04/13/24 13:34:43.981
  Apr 13 13:34:43.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-872" for this suite. @ 04/13/24 13:34:43.999
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 04/13/24 13:34:44.005
  Apr 13 13:34:44.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:34:44.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:34:44.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:34:44.023
  STEP: Creating service test in namespace statefulset-1203 @ 04/13/24 13:34:44.026
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/13/24 13:34:44.031
  STEP: Creating stateful set ss in namespace statefulset-1203 @ 04/13/24 13:34:44.037
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1203 @ 04/13/24 13:34:44.042
  Apr 13 13:34:44.045: INFO: Found 0 stateful pods, waiting for 1
  E0413 13:34:44.052038      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:45.052962      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:46.053158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:47.054199      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:48.054292      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:49.054469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:50.054605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:51.055548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:52.055716      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:53.055805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:54.047: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/13/24 13:34:54.047
  Apr 13 13:34:54.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0413 13:34:54.056631      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:34:54.146: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:34:54.146: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:34:54.146: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 13:34:54.149: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0413 13:34:55.056784      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:56.056893      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:57.057811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:58.057901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:34:59.058015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:00.058126      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:01.058279      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:02.058461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:03.058558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:04.059522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:04.151: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 13:35:04.151: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 13 13:35:04.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999741s
  E0413 13:35:05.060425      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:05.173: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996630752s
  E0413 13:35:06.060646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:06.178: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991450875s
  E0413 13:35:07.061526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:07.184: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98553836s
  E0413 13:35:08.061946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:08.188: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980212218s
  E0413 13:35:09.062483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:09.193: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97667385s
  E0413 13:35:10.062585      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:10.199: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970491501s
  E0413 13:35:11.062693      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:11.204: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.965354684s
  E0413 13:35:12.062706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:12.209: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.960438743s
  E0413 13:35:13.062797      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:13.214: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.24894ms
  E0413 13:35:14.062884      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1203 @ 04/13/24 13:35:14.215
  Apr 13 13:35:14.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:35:14.308: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:35:14.308: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:35:14.308: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 13:35:14.312: INFO: Found 1 stateful pods, waiting for 3
  E0413 13:35:15.063542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:16.064178      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:17.064548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:18.064655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:19.064835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:20.064968      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:21.065085      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:22.065263      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:23.065370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:24.065530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:24.314: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:35:24.314: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:35:24.314: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/13/24 13:35:24.314
  STEP: Scale down will halt with unhealthy stateful pod @ 04/13/24 13:35:24.314
  Apr 13 13:35:24.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 13:35:24.411: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:35:24.411: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:35:24.411: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 13:35:24.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 13:35:24.511: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:35:24.511: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:35:24.511: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 13:35:24.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 13 13:35:24.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 13 13:35:24.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 13 13:35:24.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 13 13:35:24.610: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 13 13:35:24.613: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0413 13:35:25.066508      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:26.067547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:27.067674      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:28.067831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:29.068038      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:30.068136      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:31.068228      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:32.068343      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:33.068439      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:34.068622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:34.618: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 13:35:34.618: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 13:35:34.618: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 13 13:35:34.633: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999761s
  E0413 13:35:35.069173      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:35.638: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996551162s
  E0413 13:35:36.069805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:36.642: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991883302s
  E0413 13:35:37.070568      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:37.647: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986893298s
  E0413 13:35:38.071265      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:38.652: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982448376s
  E0413 13:35:39.071976      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:39.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977644232s
  E0413 13:35:40.072170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:40.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973442298s
  E0413 13:35:41.072852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:41.667: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967730623s
  E0413 13:35:42.072948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:42.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962601197s
  E0413 13:35:43.073025      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:43.676: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.588819ms
  E0413 13:35:44.073798      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1203 @ 04/13/24 13:35:44.677
  Apr 13 13:35:44.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:35:44.772: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:35:44.772: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:35:44.772: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 13:35:44.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:35:44.872: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:35:44.872: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:35:44.872: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 13:35:44.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=statefulset-1203 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 13 13:35:44.959: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 13 13:35:44.959: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 13 13:35:44.959: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 13 13:35:44.959: INFO: Scaling statefulset ss to 0
  E0413 13:35:45.074226      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:46.075219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:47.076075      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:48.076437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:49.076897      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:50.076948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:51.077050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:52.077241      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:53.077335      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:54.077465      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/13/24 13:35:54.972
  Apr 13 13:35:54.972: INFO: Deleting all statefulset in ns statefulset-1203
  Apr 13 13:35:54.976: INFO: Scaling statefulset ss to 0
  Apr 13 13:35:54.988: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 13:35:54.991: INFO: Deleting statefulset ss
  Apr 13 13:35:55.003: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1203" for this suite. @ 04/13/24 13:35:55.01
• [71.011 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 04/13/24 13:35:55.016
  Apr 13 13:35:55.016: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 13:35:55.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:35:55.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:35:55.036
  Apr 13 13:35:55.039: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:35:55.077948      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:56.078224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:57.078483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:35:58.079324      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:35:58.119: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2452" for this suite. @ 04/13/24 13:35:58.123
• [3.114 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 04/13/24 13:35:58.131
  Apr 13 13:35:58.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:35:58.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:35:58.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:35:58.15
  STEP: Setting up server cert @ 04/13/24 13:35:58.171
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:35:58.305
  STEP: Deploying the webhook pod @ 04/13/24 13:35:58.314
  STEP: Wait for the deployment to be ready @ 04/13/24 13:35:58.326
  Apr 13 13:35:58.338: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:35:59.079973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:00.080160      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:36:00.348
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:36:00.358
  E0413 13:36:01.080366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:01.359: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/13/24 13:36:01.367
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/13/24 13:36:01.38
  Apr 13 13:36:01.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:36:01.429: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1671" for this suite. @ 04/13/24 13:36:01.433
  STEP: Destroying namespace "webhook-markers-4186" for this suite. @ 04/13/24 13:36:01.439
• [3.313 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 04/13/24 13:36:01.444
  Apr 13 13:36:01.444: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:36:01.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:01.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:01.46
  STEP: fetching services @ 04/13/24 13:36:01.464
  Apr 13 13:36:01.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3811" for this suite. @ 04/13/24 13:36:01.472
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/13/24 13:36:01.477
  Apr 13 13:36:01.478: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/13/24 13:36:01.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:01.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:01.494
  STEP: mirroring a new custom Endpoint @ 04/13/24 13:36:01.506
  Apr 13 13:36:01.514: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0413 13:36:02.080455      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:03.080901      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/13/24 13:36:03.519
  Apr 13 13:36:03.527: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0413 13:36:04.081514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:05.081737      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 04/13/24 13:36:05.532
  Apr 13 13:36:05.542: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0413 13:36:06.081827      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:07.081883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:07.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-8145" for this suite. @ 04/13/24 13:36:07.551
• [6.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/13/24 13:36:07.557
  Apr 13 13:36:07.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 13:36:07.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:07.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:07.575
  STEP: Create set of pods @ 04/13/24 13:36:07.578
  Apr 13 13:36:07.586: INFO: created test-pod-1
  Apr 13 13:36:07.593: INFO: created test-pod-2
  Apr 13 13:36:07.598: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/13/24 13:36:07.598
  E0413 13:36:08.082303      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:09.082495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/13/24 13:36:09.644
  Apr 13 13:36:09.648: INFO: Pod quantity 3 is different from expected quantity 0
  E0413 13:36:10.082584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:10.649: INFO: Pod quantity 3 is different from expected quantity 0
  E0413 13:36:11.083208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:11.648: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4767" for this suite. @ 04/13/24 13:36:11.652
• [4.103 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 04/13/24 13:36:11.661
  Apr 13 13:36:11.661: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:36:11.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:11.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:11.678
  STEP: Creating configMap with name projected-configmap-test-volume-39598091-1ad5-44e5-a13b-a04d7a4dc51b @ 04/13/24 13:36:11.681
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:36:11.685
  E0413 13:36:12.083962      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:13.084314      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:14.084866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:15.085054      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:36:15.708
  Apr 13 13:36:15.712: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-4bf32506-15b9-4487-a1a6-39617f295b1b container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:36:15.726
  Apr 13 13:36:15.745: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2081" for this suite. @ 04/13/24 13:36:15.748
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 04/13/24 13:36:15.754
  Apr 13 13:36:15.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:36:15.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:15.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:15.771
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/13/24 13:36:15.774
  Apr 13 13:36:15.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1560 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 13 13:36:15.819: INFO: stderr: ""
  Apr 13 13:36:15.819: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/13/24 13:36:15.819
  Apr 13 13:36:15.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1560 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Apr 13 13:36:15.865: INFO: stderr: ""
  Apr 13 13:36:15.865: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/13/24 13:36:15.865
  Apr 13 13:36:15.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-1560 delete pods e2e-test-httpd-pod'
  E0413 13:36:16.085426      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:17.085703      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:17.862: INFO: stderr: ""
  Apr 13 13:36:17.862: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 13 13:36:17.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1560" for this suite. @ 04/13/24 13:36:17.866
• [2.117 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 04/13/24 13:36:17.871
  Apr 13 13:36:17.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename csi-storageclass @ 04/13/24 13:36:17.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:17.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:17.89
  STEP: Creating a StorageClass @ 04/13/24 13:36:17.893
  STEP: Get StorageClass "e2e-qhzr8" @ 04/13/24 13:36:17.898
  STEP: Patching the StorageClass "e2e-qhzr8" @ 04/13/24 13:36:17.901
  STEP: Delete StorageClass "e2e-qhzr8" @ 04/13/24 13:36:17.907
  STEP: Confirm deletion of StorageClass "e2e-qhzr8" @ 04/13/24 13:36:17.913
  STEP: Create a replacement StorageClass @ 04/13/24 13:36:17.916
  STEP: Updating StorageClass "e2e-v2-8tnx9" @ 04/13/24 13:36:17.919
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-8tnx9=updated" @ 04/13/24 13:36:17.928
  STEP: Deleting StorageClass "e2e-v2-8tnx9" via DeleteCollection @ 04/13/24 13:36:17.931
  STEP: Confirm deletion of StorageClass "e2e-v2-8tnx9" @ 04/13/24 13:36:17.938
  Apr 13 13:36:17.941: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-9310" for this suite. @ 04/13/24 13:36:17.945
• [0.079 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 04/13/24 13:36:17.951
  Apr 13 13:36:17.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/13/24 13:36:17.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:17.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:17.966
  STEP: create the container to handle the HTTPGet hook request. @ 04/13/24 13:36:17.973
  E0413 13:36:18.086158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:19.086490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/13/24 13:36:19.994
  E0413 13:36:20.086495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:21.086595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/13/24 13:36:22.013
  STEP: delete the pod with lifecycle hook @ 04/13/24 13:36:22.024
  E0413 13:36:22.087447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:23.087575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:24.088281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:25.088445      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:26.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4164" for this suite. @ 04/13/24 13:36:26.048
• [8.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 04/13/24 13:36:26.055
  Apr 13 13:36:26.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:36:26.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:26.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:26.071
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/13/24 13:36:26.074
  E0413 13:36:26.088443      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:27.088925      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:28.089173      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:36:28.091
  Apr 13 13:36:28.094: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-f2ba82e0-7d33-48c0-9be6-34695817b667 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:36:28.1
  Apr 13 13:36:28.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1668" for this suite. @ 04/13/24 13:36:28.117
• [2.068 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/13/24 13:36:28.123
  Apr 13 13:36:28.123: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 13:36:28.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:28.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:28.14
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/13/24 13:36:28.143
  Apr 13 13:36:28.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:36:29.089932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:29.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:36:30.089973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:31.090146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:32.090579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:33.090927      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:34.091419      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:34.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5847" for this suite. @ 04/13/24 13:36:34.592
• [6.476 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 04/13/24 13:36:34.598
  Apr 13 13:36:34.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename gc @ 04/13/24 13:36:34.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:34.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:34.618
  STEP: create the deployment @ 04/13/24 13:36:34.626
  W0413 13:36:34.632967      21 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/13/24 13:36:34.633
  E0413 13:36:35.091979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 04/13/24 13:36:35.137
  STEP: wait for all rs to be garbage collected @ 04/13/24 13:36:35.143
  STEP: expected 0 pods, got 2 pods @ 04/13/24 13:36:35.146
  STEP: expected 0 rs, got 1 rs @ 04/13/24 13:36:35.153
  STEP: Gathering metrics @ 04/13/24 13:36:35.654
  W0413 13:36:35.660316      21 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 13 13:36:35.660: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 13 13:36:35.660: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2841" for this suite. @ 04/13/24 13:36:35.664
• [1.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/13/24 13:36:35.671
  Apr 13 13:36:35.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 13:36:35.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:35.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:35.691
  STEP: creating pod @ 04/13/24 13:36:35.694
  E0413 13:36:36.092444      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:37.092505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:37.716: INFO: Pod pod-hostip-e05ac364-c504-4a10-94bb-430285a6fe60 has hostIP: 172.31.82.63
  Apr 13 13:36:37.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5158" for this suite. @ 04/13/24 13:36:37.72
• [2.056 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 04/13/24 13:36:37.728
  Apr 13 13:36:37.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:36:37.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:37.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:37.746
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/13/24 13:36:37.75
  E0413 13:36:38.092601      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:39.092698      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:40.093466      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:41.094043      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:36:41.771
  Apr 13 13:36:41.776: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-01c151dc-c126-4fe5-a153-c0ab97d5d0e4 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:36:41.787
  Apr 13 13:36:41.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6573" for this suite. @ 04/13/24 13:36:41.805
• [4.085 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 04/13/24 13:36:41.812
  Apr 13 13:36:41.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:36:41.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:41.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:41.832
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:36:41.837
  E0413 13:36:42.094612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:43.094664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:44.095570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:45.095647      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:36:45.861
  Apr 13 13:36:45.864: INFO: Trying to get logs from node ip-172-31-35-229 pod downwardapi-volume-3855b197-43f1-487e-a4e2-17e88a69c580 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:36:45.878
  Apr 13 13:36:45.894: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2194" for this suite. @ 04/13/24 13:36:45.898
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 04/13/24 13:36:45.907
  Apr 13 13:36:45.907: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 13:36:45.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:45.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:45.938
  STEP: Creating replication controller my-hostname-basic-7349c597-aebb-49cc-92ba-56ae0a3fa280 @ 04/13/24 13:36:45.944
  Apr 13 13:36:45.958: INFO: Pod name my-hostname-basic-7349c597-aebb-49cc-92ba-56ae0a3fa280: Found 0 pods out of 1
  E0413 13:36:46.096612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:47.096733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:48.096807      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:49.097050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:50.097240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:50.962: INFO: Pod name my-hostname-basic-7349c597-aebb-49cc-92ba-56ae0a3fa280: Found 1 pods out of 1
  Apr 13 13:36:50.962: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7349c597-aebb-49cc-92ba-56ae0a3fa280" are running
  Apr 13 13:36:50.966: INFO: Pod "my-hostname-basic-7349c597-aebb-49cc-92ba-56ae0a3fa280-w4sk2" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:36:46 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:36:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:36:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:36:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-13 13:36:45 +0000 UTC Reason: Message:}])
  Apr 13 13:36:50.966: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/13/24 13:36:50.966
  Apr 13 13:36:50.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-349" for this suite. @ 04/13/24 13:36:50.983
• [5.082 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 04/13/24 13:36:50.99
  Apr 13 13:36:50.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:36:50.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:51.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:51.009
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/13/24 13:36:51.012
  Apr 13 13:36:51.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6227 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 13 13:36:51.065: INFO: stderr: ""
  Apr 13 13:36:51.065: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/13/24 13:36:51.065
  Apr 13 13:36:51.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-6227 delete pods e2e-test-httpd-pod'
  E0413 13:36:51.097502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:52.097614      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:36:52.935: INFO: stderr: ""
  Apr 13 13:36:52.935: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 13 13:36:52.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6227" for this suite. @ 04/13/24 13:36:52.939
• [1.958 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 04/13/24 13:36:52.948
  Apr 13 13:36:52.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:36:52.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:52.965
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:52.969
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/13/24 13:36:52.973
  E0413 13:36:53.098148      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:54.098259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:55.098999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:56.099563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:36:56.997
  Apr 13 13:36:57.000: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-dafc3093-f100-468e-b85f-484fbe53b266 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:36:57.007
  Apr 13 13:36:57.024: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-594" for this suite. @ 04/13/24 13:36:57.027
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 04/13/24 13:36:57.034
  Apr 13 13:36:57.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:36:57.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:36:57.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:36:57.052
  STEP: Creating secret with name secret-test-bb40cafb-9d5d-4595-b422-4464c4489542 @ 04/13/24 13:36:57.055
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:36:57.06
  E0413 13:36:57.100263      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:58.101311      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:36:59.101934      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:00.102039      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:37:01.082
  Apr 13 13:37:01.086: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-secrets-b85dcd4b-e979-46dd-bcf2-468e94135370 container secret-env-test: <nil>
  STEP: delete the pod @ 04/13/24 13:37:01.093
  E0413 13:37:01.102424      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:01.108: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7184" for this suite. @ 04/13/24 13:37:01.112
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 04/13/24 13:37:01.119
  Apr 13 13:37:01.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename init-container @ 04/13/24 13:37:01.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:01.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:01.136
  STEP: creating the pod @ 04/13/24 13:37:01.139
  Apr 13 13:37:01.139: INFO: PodSpec: initContainers in spec.initContainers
  E0413 13:37:02.102788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:03.103098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:03.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9434" for this suite. @ 04/13/24 13:37:03.949
• [2.837 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 04/13/24 13:37:03.956
  Apr 13 13:37:03.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubelet-test @ 04/13/24 13:37:03.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:03.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:03.975
  E0413 13:37:04.103786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:05.103936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:06.104439      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:07.104522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:07.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-549" for this suite. @ 04/13/24 13:37:08.002
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 04/13/24 13:37:08.009
  Apr 13 13:37:08.009: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 13:37:08.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:08.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:08.031
  Apr 13 13:37:08.034: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/13/24 13:37:08.043
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/13/24 13:37:08.048
  E0413 13:37:08.104843      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/13/24 13:37:09.055
  Apr 13 13:37:09.064: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/13/24 13:37:09.064
  Apr 13 13:37:09.070: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4829" for this suite. @ 04/13/24 13:37:09.073
• [1.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 04/13/24 13:37:09.08
  Apr 13 13:37:09.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename secrets @ 04/13/24 13:37:09.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:09.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:09.099
  STEP: creating a secret @ 04/13/24 13:37:09.102
  E0413 13:37:09.105652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/13/24 13:37:09.108
  STEP: patching the secret @ 04/13/24 13:37:09.111
  STEP: deleting the secret using a LabelSelector @ 04/13/24 13:37:09.123
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/13/24 13:37:09.13
  Apr 13 13:37:09.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-83" for this suite. @ 04/13/24 13:37:09.137
• [0.063 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 04/13/24 13:37:09.143
  Apr 13 13:37:09.143: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pv @ 04/13/24 13:37:09.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:09.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:09.163
  STEP: Creating initial PV and PVC @ 04/13/24 13:37:09.167
  Apr 13 13:37:09.167: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9049" @ 04/13/24 13:37:09.18
  STEP: Listing PVCs in namespace "pv-9049" @ 04/13/24 13:37:09.191
  STEP: Patching the PV "pv-9049-89vsp" @ 04/13/24 13:37:09.194
  STEP: Patching the PVC "pvc-wl9sf" @ 04/13/24 13:37:09.204
  STEP: Getting PV "pv-9049-89vsp" @ 04/13/24 13:37:09.213
  STEP: Getting PVC "pvc-wl9sf" @ 04/13/24 13:37:09.216
  STEP: Deleting PVC "pvc-wl9sf" @ 04/13/24 13:37:09.22
  STEP: Confirm deletion of PVC "pvc-wl9sf" @ 04/13/24 13:37:09.227
  E0413 13:37:10.106800      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:11.106886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-9049-89vsp" @ 04/13/24 13:37:11.235
  STEP: Confirm deletion of PV "pv-9049-89vsp" @ 04/13/24 13:37:11.242
  E0413 13:37:12.106975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:13.107060      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 04/13/24 13:37:13.25
  Apr 13 13:37:13.250: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-9049-x89tx" @ 04/13/24 13:37:13.262
  STEP: Updating the PVC "pvc-84tfr" @ 04/13/24 13:37:13.292
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-84tfr=updated" @ 04/13/24 13:37:13.301
  STEP: Deleting PVC "pvc-84tfr" via DeleteCollection @ 04/13/24 13:37:13.305
  STEP: Confirm deletion of PVC "pvc-84tfr" @ 04/13/24 13:37:13.314
  E0413 13:37:14.107176      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:15.107336      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-9049-x89tx" via DeleteCollection @ 04/13/24 13:37:15.322
  STEP: Confirm deletion of PV "pv-9049-x89tx" @ 04/13/24 13:37:15.334
  E0413 13:37:16.107451      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:17.107621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:17.344: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Apr 13 13:37:17.344: INFO: Deleting PersistentVolumeClaim "pvc-84tfr"
  Apr 13 13:37:17.348: INFO: Deleting PersistentVolume "pv-9049-x89tx"
  Apr 13 13:37:17.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9049" for this suite. @ 04/13/24 13:37:17.355
• [8.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 04/13/24 13:37:17.363
  Apr 13 13:37:17.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 13:37:17.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:17.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:17.383
  STEP: creating a Namespace @ 04/13/24 13:37:17.386
  STEP: patching the Namespace @ 04/13/24 13:37:17.401
  STEP: get the Namespace and ensuring it has the label @ 04/13/24 13:37:17.408
  Apr 13 13:37:17.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5136" for this suite. @ 04/13/24 13:37:17.416
  STEP: Destroying namespace "nspatchtest-c495335d-fcf0-40d1-a5f2-47853917bd1d-3452" for this suite. @ 04/13/24 13:37:17.423
• [0.065 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 04/13/24 13:37:17.429
  Apr 13 13:37:17.429: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename podtemplate @ 04/13/24 13:37:17.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:17.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:17.449
  Apr 13 13:37:17.483: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7019" for this suite. @ 04/13/24 13:37:17.487
• [0.064 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 04/13/24 13:37:17.493
  Apr 13 13:37:17.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:37:17.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:17.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:17.513
  STEP: Creating service test in namespace statefulset-4378 @ 04/13/24 13:37:17.517
  STEP: Creating statefulset ss in namespace statefulset-4378 @ 04/13/24 13:37:17.527
  Apr 13 13:37:17.538: INFO: Found 0 stateful pods, waiting for 1
  E0413 13:37:18.108453      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:19.108543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:20.108646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:21.108777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:22.108877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:23.108977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:24.109157      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:25.109390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:26.109507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:27.109605      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:27.539: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/13/24 13:37:27.547
  STEP: Getting /status @ 04/13/24 13:37:27.557
  Apr 13 13:37:27.561: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/13/24 13:37:27.561
  Apr 13 13:37:27.571: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/13/24 13:37:27.571
  Apr 13 13:37:27.573: INFO: Observed &StatefulSet event: ADDED
  Apr 13 13:37:27.573: INFO: Found Statefulset ss in namespace statefulset-4378 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:37:27.573: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/13/24 13:37:27.573
  Apr 13 13:37:27.573: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 13 13:37:27.580: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/13/24 13:37:27.58
  Apr 13 13:37:27.581: INFO: Observed &StatefulSet event: ADDED
  Apr 13 13:37:27.582: INFO: Observed Statefulset ss in namespace statefulset-4378 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:37:27.582: INFO: Observed &StatefulSet event: MODIFIED
  Apr 13 13:37:27.582: INFO: Deleting all statefulset in ns statefulset-4378
  Apr 13 13:37:27.585: INFO: Scaling statefulset ss to 0
  E0413 13:37:28.110370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:29.110506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:30.110598      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:31.110681      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:32.110774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:33.111546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:34.111667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:35.111845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:36.112014      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:37.112891      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:37.599: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 13:37:37.603: INFO: Deleting statefulset ss
  Apr 13 13:37:37.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4378" for this suite. @ 04/13/24 13:37:37.62
• [20.133 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 04/13/24 13:37:37.626
  Apr 13 13:37:37.626: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename runtimeclass @ 04/13/24 13:37:37.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:37.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:37.645
  Apr 13 13:37:37.673: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2023" for this suite. @ 04/13/24 13:37:37.676
• [0.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 04/13/24 13:37:37.683
  Apr 13 13:37:37.683: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 13:37:37.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:37.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:37.703
  STEP: Creating service test in namespace statefulset-8683 @ 04/13/24 13:37:37.707
  Apr 13 13:37:37.726: INFO: Found 0 stateful pods, waiting for 1
  E0413 13:37:38.113812      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:39.113994      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:40.114301      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:41.114482      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:42.114512      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:43.114563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:44.115381      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:45.115518      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:46.115621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:47.115841      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:47.727: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/13/24 13:37:47.734
  W0413 13:37:47.742373      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 13 13:37:47.748: INFO: Found 1 stateful pods, waiting for 2
  E0413 13:37:48.116418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:49.116821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:50.117038      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:51.117185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:52.117479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:53.117593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:54.117776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:55.117859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:56.117963      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:57.118866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:37:57.751: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 13:37:57.751: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/13/24 13:37:57.758
  STEP: Delete all of the StatefulSets @ 04/13/24 13:37:57.761
  STEP: Verify that StatefulSets have been deleted @ 04/13/24 13:37:57.769
  Apr 13 13:37:57.772: INFO: Deleting all statefulset in ns statefulset-8683
  Apr 13 13:37:57.790: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8683" for this suite. @ 04/13/24 13:37:57.793
• [20.119 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 04/13/24 13:37:57.803
  Apr 13 13:37:57.803: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/13/24 13:37:57.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:37:57.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:37:57.822
  Apr 13 13:37:57.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:37:58.119566      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:37:59.119621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:00.120540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:01.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-65" for this suite. @ 04/13/24 13:38:01.023
• [3.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 04/13/24 13:38:01.032
  Apr 13 13:38:01.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 13:38:01.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:01.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:01.055
  STEP: Creating simple DaemonSet "daemon-set" @ 04/13/24 13:38:01.08
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 13:38:01.086
  Apr 13 13:38:01.094: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:01.094: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:01.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:38:01.097: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:38:01.121360      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:02.090: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:02.090: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:02.093: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:38:02.093: INFO: Node ip-172-31-65-227 is running 0 daemon pod, expected 1
  E0413 13:38:02.122033      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:03.090: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:03.090: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:38:03.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:38:03.095: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 04/13/24 13:38:03.098
  Apr 13 13:38:03.101: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/13/24 13:38:03.101
  Apr 13 13:38:03.112: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/13/24 13:38:03.112
  Apr 13 13:38:03.114: INFO: Observed &DaemonSet event: ADDED
  Apr 13 13:38:03.114: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.114: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.114: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.114: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.114: INFO: Found daemon set daemon-set in namespace daemonsets-6019 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 13 13:38:03.114: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/13/24 13:38:03.114
  STEP: watching for the daemon set status to be patched @ 04/13/24 13:38:03.12
  E0413 13:38:03.122054      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: ADDED
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.122: INFO: Observed daemon set daemon-set in namespace daemonsets-6019 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 13 13:38:03.122: INFO: Observed &DaemonSet event: MODIFIED
  Apr 13 13:38:03.122: INFO: Found daemon set daemon-set in namespace daemonsets-6019 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 13 13:38:03.122: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 13:38:03.128
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6019, will wait for the garbage collector to delete the pods @ 04/13/24 13:38:03.128
  Apr 13 13:38:03.188: INFO: Deleting DaemonSet.extensions daemon-set took: 6.186751ms
  Apr 13 13:38:03.289: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.70089ms
  E0413 13:38:04.122939      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:04.293: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:38:04.293: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 13:38:04.296: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40332"},"items":null}

  Apr 13 13:38:04.300: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40332"},"items":null}

  Apr 13 13:38:04.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6019" for this suite. @ 04/13/24 13:38:04.317
• [3.294 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 04/13/24 13:38:04.326
  Apr 13 13:38:04.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 13:38:04.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:04.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:04.347
  Apr 13 13:38:04.366: INFO: created pod
  E0413 13:38:05.123407      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:06.123639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:38:06.375
  E0413 13:38:07.123744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:08.123955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:09.124098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:10.124192      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:11.124303      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:12.124403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:13.124763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:14.124903      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:15.125013      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:16.125086      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:17.125308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:18.125621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:19.125831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:20.125909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:21.126070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:22.126166      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:23.126450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:24.126506      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:25.127525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:26.127725      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:27.127839      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:28.128126      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:29.128327      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:30.128595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:31.128793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:32.128965      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:33.129251      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:34.129356      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:35.129573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:36.129741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:36.376: INFO: polling logs
  Apr 13 13:38:36.388: INFO: Pod logs: 
  I0413 13:38:04.928146       1 log.go:245] OK: Got token
  I0413 13:38:04.928183       1 log.go:245] validating with in-cluster discovery
  I0413 13:38:04.928412       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I0413 13:38:04.928446       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-6012:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000013af0), NotBefore:(*jwt.NumericDate)(0xc000013bd8), IssuedAt:(*jwt.NumericDate)(0xc000013b00), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6012", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2c291fd1-9c68-4bf8-be80-898d33f81cfa"}}}
  I0413 13:38:04.934276       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0413 13:38:04.937447       1 log.go:245] OK: Validated signature on JWT
  I0413 13:38:04.937535       1 log.go:245] OK: Got valid claims from token!
  I0413 13:38:04.937575       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-6012:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000247240), NotBefore:(*jwt.NumericDate)(0xc000247278), IssuedAt:(*jwt.NumericDate)(0xc000247248), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6012", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2c291fd1-9c68-4bf8-be80-898d33f81cfa"}}}

  Apr 13 13:38:36.388: INFO: completed pod
  Apr 13 13:38:36.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6012" for this suite. @ 04/13/24 13:38:36.398
• [32.079 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 04/13/24 13:38:36.405
  Apr 13 13:38:36.405: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename init-container @ 04/13/24 13:38:36.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:36.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:36.426
  STEP: creating the pod @ 04/13/24 13:38:36.429
  Apr 13 13:38:36.429: INFO: PodSpec: initContainers in spec.initContainers
  E0413 13:38:37.130480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:38.131050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:39.131163      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:39.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2601" for this suite. @ 04/13/24 13:38:39.287
• [2.888 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 04/13/24 13:38:39.298
  Apr 13 13:38:39.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context @ 04/13/24 13:38:39.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:39.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:39.316
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/13/24 13:38:39.319
  E0413 13:38:40.131326      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:41.131480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:38:41.342
  Apr 13 13:38:41.345: INFO: Trying to get logs from node ip-172-31-82-63 pod security-context-07562d62-8665-4591-b738-0ed36176883f container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:38:41.353
  Apr 13 13:38:41.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-116" for this suite. @ 04/13/24 13:38:41.372
• [2.081 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/13/24 13:38:41.378
  Apr 13 13:38:41.378: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:38:41.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:41.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:41.4
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-3894 @ 04/13/24 13:38:41.41
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/13/24 13:38:41.424
  STEP: creating service externalsvc in namespace services-3894 @ 04/13/24 13:38:41.424
  STEP: creating replication controller externalsvc in namespace services-3894 @ 04/13/24 13:38:41.434
  I0413 13:38:41.441547      21 runners.go:197] Created replication controller with name: externalsvc, namespace: services-3894, replica count: 2
  E0413 13:38:42.132386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:43.132440      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:44.132814      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:38:44.493369      21 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/13/24 13:38:44.499
  Apr 13 13:38:44.517: INFO: Creating new exec pod
  E0413 13:38:45.132916      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:46.133180      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:46.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-3894 exec execpodj6kgz -- /bin/sh -x -c nslookup nodeport-service.services-3894.svc.cluster.local'
  Apr 13 13:38:46.654: INFO: stderr: "+ nslookup nodeport-service.services-3894.svc.cluster.local\n"
  Apr 13 13:38:46.655: INFO: stdout: "Server:\t\t10.152.183.177\nAddress:\t10.152.183.177#53\n\nnodeport-service.services-3894.svc.cluster.local\tcanonical name = externalsvc.services-3894.svc.cluster.local.\nName:\texternalsvc.services-3894.svc.cluster.local\nAddress: 10.152.183.253\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-3894, will wait for the garbage collector to delete the pods @ 04/13/24 13:38:46.655
  Apr 13 13:38:46.717: INFO: Deleting ReplicationController externalsvc took: 7.210625ms
  Apr 13 13:38:46.818: INFO: Terminating ReplicationController externalsvc pods took: 100.494148ms
  E0413 13:38:47.134165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:48.134523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:49.134633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:49.234: INFO: Cleaning up the NodePort to ExternalName test service
  Apr 13 13:38:49.244: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3894" for this suite. @ 04/13/24 13:38:49.25
• [7.879 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 04/13/24 13:38:49.257
  Apr 13 13:38:49.257: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replication-controller @ 04/13/24 13:38:49.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:49.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:49.275
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/13/24 13:38:49.28
  E0413 13:38:50.135591      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:51.135903      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 04/13/24 13:38:51.302
  STEP: Then the orphan pod is adopted @ 04/13/24 13:38:51.309
  E0413 13:38:52.135993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:52.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8368" for this suite. @ 04/13/24 13:38:52.322
• [3.072 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 04/13/24 13:38:52.329
  Apr 13 13:38:52.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:38:52.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:52.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:52.35
  STEP: Setting up server cert @ 04/13/24 13:38:52.375
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:38:52.548
  STEP: Deploying the webhook pod @ 04/13/24 13:38:52.557
  STEP: Wait for the deployment to be ready @ 04/13/24 13:38:52.575
  Apr 13 13:38:52.582: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 13:38:53.136692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:54.136793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:38:54.595
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:38:54.605
  E0413 13:38:55.136851      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:38:55.606: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/13/24 13:38:55.615
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/13/24 13:38:55.63
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/13/24 13:38:55.637
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/13/24 13:38:55.648
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/13/24 13:38:55.659
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/13/24 13:38:55.667
  Apr 13 13:38:55.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-368" for this suite. @ 04/13/24 13:38:55.715
  STEP: Destroying namespace "webhook-markers-4176" for this suite. @ 04/13/24 13:38:55.727
• [3.404 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 04/13/24 13:38:55.734
  Apr 13 13:38:55.734: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 13:38:55.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:55.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:55.753
  STEP: Updating Namespace "namespaces-5766" @ 04/13/24 13:38:55.756
  Apr 13 13:38:55.765: INFO: Namespace "namespaces-5766" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"0a2af82a-977a-4467-bc2e-9d348b0a2115", "kubernetes.io/metadata.name":"namespaces-5766", "namespaces-5766":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Apr 13 13:38:55.765: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5766" for this suite. @ 04/13/24 13:38:55.772
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 04/13/24 13:38:55.78
  Apr 13 13:38:55.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 13:38:55.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:55.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:55.799
  STEP: Creating a job @ 04/13/24 13:38:55.802
  STEP: Ensuring active pods == parallelism @ 04/13/24 13:38:55.807
  E0413 13:38:56.137793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:57.137863      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 04/13/24 13:38:57.812
  STEP: deleting Job.batch foo in namespace job-1475, will wait for the garbage collector to delete the pods @ 04/13/24 13:38:57.812
  Apr 13 13:38:57.874: INFO: Deleting Job.batch foo took: 7.373874ms
  Apr 13 13:38:57.975: INFO: Terminating Job.batch foo pods took: 100.973155ms
  E0413 13:38:58.138906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:38:59.139835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 04/13/24 13:38:59.275
  Apr 13 13:38:59.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1475" for this suite. @ 04/13/24 13:38:59.284
• [3.511 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 04/13/24 13:38:59.291
  Apr 13 13:38:59.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:38:59.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:38:59.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:38:59.309
  STEP: Setting up server cert @ 04/13/24 13:38:59.335
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:38:59.455
  STEP: Deploying the webhook pod @ 04/13/24 13:38:59.46
  STEP: Wait for the deployment to be ready @ 04/13/24 13:38:59.47
  Apr 13 13:38:59.477: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0413 13:39:00.140835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:01.140912      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:39:01.493
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:39:01.501
  E0413 13:39:02.141751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:39:02.502: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/13/24 13:39:02.509
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/13/24 13:39:02.522
  STEP: Creating a dummy validating-webhook-configuration object @ 04/13/24 13:39:02.535
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/13/24 13:39:02.544
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/13/24 13:39:02.55
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/13/24 13:39:02.559
  Apr 13 13:39:02.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5730" for this suite. @ 04/13/24 13:39:02.626
  STEP: Destroying namespace "webhook-markers-4406" for this suite. @ 04/13/24 13:39:02.633
• [3.348 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 04/13/24 13:39:02.64
  Apr 13 13:39:02.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 13:39:02.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:39:02.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:39:02.658
  STEP: creating a replication controller @ 04/13/24 13:39:02.661
  Apr 13 13:39:02.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 create -f -'
  Apr 13 13:39:02.736: INFO: stderr: ""
  Apr 13 13:39:02.736: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/13/24 13:39:02.736
  Apr 13 13:39:02.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:39:02.787: INFO: stderr: ""
  Apr 13 13:39:02.787: INFO: stdout: "update-demo-nautilus-4lb5g update-demo-nautilus-5qtnb "
  Apr 13 13:39:02.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods update-demo-nautilus-4lb5g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:39:02.826: INFO: stderr: ""
  Apr 13 13:39:02.826: INFO: stdout: ""
  Apr 13 13:39:02.826: INFO: update-demo-nautilus-4lb5g is created but not running
  E0413 13:39:03.142362      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:04.142492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:05.142620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:06.142723      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:07.143699      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:39:07.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 13 13:39:07.871: INFO: stderr: ""
  Apr 13 13:39:07.871: INFO: stdout: "update-demo-nautilus-4lb5g update-demo-nautilus-5qtnb "
  Apr 13 13:39:07.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods update-demo-nautilus-4lb5g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:39:07.911: INFO: stderr: ""
  Apr 13 13:39:07.911: INFO: stdout: "true"
  Apr 13 13:39:07.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods update-demo-nautilus-4lb5g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:39:07.950: INFO: stderr: ""
  Apr 13 13:39:07.950: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:39:07.950: INFO: validating pod update-demo-nautilus-4lb5g
  Apr 13 13:39:07.955: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:39:07.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:39:07.955: INFO: update-demo-nautilus-4lb5g is verified up and running
  Apr 13 13:39:07.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods update-demo-nautilus-5qtnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 13 13:39:07.996: INFO: stderr: ""
  Apr 13 13:39:07.996: INFO: stdout: "true"
  Apr 13 13:39:07.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods update-demo-nautilus-5qtnb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 13 13:39:08.039: INFO: stderr: ""
  Apr 13 13:39:08.039: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 13 13:39:08.039: INFO: validating pod update-demo-nautilus-5qtnb
  Apr 13 13:39:08.045: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 13 13:39:08.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 13 13:39:08.045: INFO: update-demo-nautilus-5qtnb is verified up and running
  STEP: using delete to clean up resources @ 04/13/24 13:39:08.045
  Apr 13 13:39:08.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 delete --grace-period=0 --force -f -'
  Apr 13 13:39:08.092: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 13:39:08.092: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 13 13:39:08.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get rc,svc -l name=update-demo --no-headers'
  E0413 13:39:08.144072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:39:08.151: INFO: stderr: "No resources found in kubectl-5696 namespace.\n"
  Apr 13 13:39:08.151: INFO: stdout: ""
  Apr 13 13:39:08.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5696 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 13 13:39:08.212: INFO: stderr: ""
  Apr 13 13:39:08.212: INFO: stdout: ""
  Apr 13 13:39:08.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5696" for this suite. @ 04/13/24 13:39:08.217
• [5.585 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 04/13/24 13:39:08.225
  Apr 13 13:39:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename init-container @ 04/13/24 13:39:08.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:39:08.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:39:08.247
  STEP: creating the pod @ 04/13/24 13:39:08.251
  Apr 13 13:39:08.251: INFO: PodSpec: initContainers in spec.initContainers
  E0413 13:39:09.144182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:10.145229      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:11.145373      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:12.145523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:13.145611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:14.145713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:15.145955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:16.146011      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:17.146269      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:18.146388      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:19.146469      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:20.147534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:21.147733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:22.148010      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:23.148303      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:24.148409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:25.148584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:26.148764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:27.148920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:28.149671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:29.149776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:30.149877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:31.149991      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:32.150064      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:33.150172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:34.150275      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:35.150467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:36.151528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:37.151782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:38.152065      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:39.152147      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:40.152254      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:41.152448      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:42.152814      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:43.153025      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:44.153134      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:45.153667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:46.154590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:47.154690      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:48.154786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:49.155575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:50.155774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:51.156270      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:52.156391      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:39:52.280: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d97175b3-72b5-4176-8dce-645527af8b96", GenerateName:"", Namespace:"init-container-9091", SelfLink:"", UID:"25532750-0017-4b3b-ab55-d08d5ca76d4c", ResourceVersion:"41194", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"251163770"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0011fedf8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 39, 52, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0011fee28), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-7gxt9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004354fe0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-7gxt9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-7gxt9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-7gxt9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00172a848), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-82-63", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0000497a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00172a8d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00172a8f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00172a8f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00172a8fc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003e40450), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 13, 13, 39, 9, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.82.63", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.82.63"}}, PodIP:"192.168.172.208", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.172.208"}}, StartTime:time.Date(2024, time.April, 13, 13, 39, 8, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000049880)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000498f0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://56501a93d7a89a7f6079655e770deab8f9cdda3a9c216e19ba6798d47d4facb0", Started:(*bool)(0xc00172a99a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004355040), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00172a9af), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004355020), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc00172a97f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Apr 13 13:39:52.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9091" for this suite. @ 04/13/24 13:39:52.285
• [44.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 04/13/24 13:39:52.293
  Apr 13 13:39:52.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename runtimeclass @ 04/13/24 13:39:52.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:39:52.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:39:52.314
  STEP: Deleting RuntimeClass runtimeclass-6004-delete-me @ 04/13/24 13:39:52.321
  STEP: Waiting for the RuntimeClass to disappear @ 04/13/24 13:39:52.326
  Apr 13 13:39:52.335: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6004" for this suite. @ 04/13/24 13:39:52.339
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 04/13/24 13:39:52.347
  Apr 13 13:39:52.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/13/24 13:39:52.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:39:52.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:39:52.367
  STEP: create the container to handle the HTTPGet hook request. @ 04/13/24 13:39:52.375
  E0413 13:39:53.157211      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:54.157340      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/13/24 13:39:54.399
  E0413 13:39:55.158434      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:56.158504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/13/24 13:39:56.423
  E0413 13:39:57.158928      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:39:58.159025      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/13/24 13:39:58.437
  Apr 13 13:39:58.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5343" for this suite. @ 04/13/24 13:39:58.448
• [6.107 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 04/13/24 13:39:58.455
  Apr 13 13:39:58.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:39:58.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:39:58.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:39:58.474
  STEP: creating service in namespace services-289 @ 04/13/24 13:39:58.477
  STEP: creating service affinity-clusterip-transition in namespace services-289 @ 04/13/24 13:39:58.477
  STEP: creating replication controller affinity-clusterip-transition in namespace services-289 @ 04/13/24 13:39:58.486
  I0413 13:39:58.494406      21 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-289, replica count: 3
  E0413 13:39:59.159467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:00.159794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:01.160765      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:40:01.545350      21 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:40:01.553: INFO: Creating new exec pod
  E0413 13:40:02.161104      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:03.161225      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:04.161290      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:04.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-289 exec execpod-affinityfccrl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 13 13:40:04.664: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 13 13:40:04.664: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:40:04.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-289 exec execpod-affinityfccrl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.171 80'
  Apr 13 13:40:04.766: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.171 80\nConnection to 10.152.183.171 80 port [tcp/http] succeeded!\n"
  Apr 13 13:40:04.766: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:40:04.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-289 exec execpod-affinityfccrl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.171:80/ ; done'
  Apr 13 13:40:04.931: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n"
  Apr 13 13:40:04.931: INFO: stdout: "\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-26h29\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-26h29\naffinity-clusterip-transition-26h29\naffinity-clusterip-transition-2rvqp\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2"
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-26h29
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-26h29
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-26h29
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-2rvqp
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.931: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:04.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-289 exec execpod-affinityfccrl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.171:80/ ; done'
  Apr 13 13:40:05.080: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.171:80/\n"
  Apr 13 13:40:05.081: INFO: stdout: "\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2\naffinity-clusterip-transition-wxjd2"
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Received response from host: affinity-clusterip-transition-wxjd2
  Apr 13 13:40:05.081: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-289, will wait for the garbage collector to delete the pods @ 04/13/24 13:40:05.096
  Apr 13 13:40:05.161: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.44845ms
  E0413 13:40:05.162182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:05.261: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.626655ms
  E0413 13:40:06.162750      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:07.163226      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:08.164087      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:08.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-289" for this suite. @ 04/13/24 13:40:08.383
• [9.934 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/13/24 13:40:08.389
  Apr 13 13:40:08.389: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-runtime @ 04/13/24 13:40:08.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:08.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:08.408
  STEP: create the container @ 04/13/24 13:40:08.412
  W0413 13:40:08.421492      21 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/13/24 13:40:08.421
  E0413 13:40:09.165006      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:10.165151      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:11.166097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/13/24 13:40:11.443
  STEP: the container should be terminated @ 04/13/24 13:40:11.449
  STEP: the termination message should be set @ 04/13/24 13:40:11.449
  Apr 13 13:40:11.449: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/13/24 13:40:11.449
  Apr 13 13:40:11.466: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7997" for this suite. @ 04/13/24 13:40:11.469
• [3.087 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/13/24 13:40:11.476
  Apr 13 13:40:11.476: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 13:40:11.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:11.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:11.503
  STEP: Creating a test headless service @ 04/13/24 13:40:11.506
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4627 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4627;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4627 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4627;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4627.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4627.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4627.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4627.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4627.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4627.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4627.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4627.svc;check="$$(dig +notcp +noall +answer +search 22.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.22_udp@PTR;check="$$(dig +tcp +noall +answer +search 22.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.22_tcp@PTR;sleep 1; done
   @ 04/13/24 13:40:11.53
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4627 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4627;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4627 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4627;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4627.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4627.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4627.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4627.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4627.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4627.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4627.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4627.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4627.svc;check="$$(dig +notcp +noall +answer +search 22.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.22_udp@PTR;check="$$(dig +tcp +noall +answer +search 22.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.22_tcp@PTR;sleep 1; done
   @ 04/13/24 13:40:11.53
  STEP: creating a pod to probe DNS @ 04/13/24 13:40:11.53
  STEP: submitting the pod to kubernetes @ 04/13/24 13:40:11.531
  E0413 13:40:12.166248      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:13.166478      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 13:40:13.555
  STEP: looking for the results for each expected name from probers @ 04/13/24 13:40:13.558
  Apr 13 13:40:13.563: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.567: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.572: INFO: Unable to read wheezy_udp@dns-test-service.dns-4627 from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4627 from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.579: INFO: Unable to read wheezy_udp@dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.583: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.587: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.591: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.608: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.612: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.615: INFO: Unable to read jessie_udp@dns-test-service.dns-4627 from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.618: INFO: Unable to read jessie_tcp@dns-test-service.dns-4627 from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.622: INFO: Unable to read jessie_udp@dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.625: INFO: Unable to read jessie_tcp@dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.629: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.632: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4627.svc from pod dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298: the server could not find the requested resource (get pods dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298)
  Apr 13 13:40:13.648: INFO: Lookups using dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4627 wheezy_tcp@dns-test-service.dns-4627 wheezy_udp@dns-test-service.dns-4627.svc wheezy_tcp@dns-test-service.dns-4627.svc wheezy_udp@_http._tcp.dns-test-service.dns-4627.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4627.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4627 jessie_tcp@dns-test-service.dns-4627 jessie_udp@dns-test-service.dns-4627.svc jessie_tcp@dns-test-service.dns-4627.svc jessie_udp@_http._tcp.dns-test-service.dns-4627.svc jessie_tcp@_http._tcp.dns-test-service.dns-4627.svc]

  Apr 13 13:40:13.654: INFO: Pod client logs for webserver: 
  Apr 13 13:40:13.661: INFO: Pod client logs for querier: 
  Apr 13 13:40:13.666: INFO: Pod client logs for jessie-querier: 
  E0413 13:40:14.167485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:15.167689      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:16.167788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:17.167794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:18.168043      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:18.652: INFO: DNS probes using dns-4627/dns-test-96a408f4-7e6d-4324-95b7-d93cb6896298 succeeded

  STEP: deleting the pod @ 04/13/24 13:40:18.653
  STEP: deleting the test service @ 04/13/24 13:40:18.676
  STEP: deleting the test headless service @ 04/13/24 13:40:18.699
  Apr 13 13:40:18.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4627" for this suite. @ 04/13/24 13:40:18.713
• [7.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/13/24 13:40:18.721
  Apr 13 13:40:18.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 13:40:18.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:18.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:18.742
  STEP: creating the pod @ 04/13/24 13:40:18.746
  STEP: submitting the pod to kubernetes @ 04/13/24 13:40:18.746
  E0413 13:40:19.168844      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:20.169387      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/13/24 13:40:20.766
  STEP: updating the pod @ 04/13/24 13:40:20.77
  E0413 13:40:21.170313      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:21.283: INFO: Successfully updated pod "pod-update-a07b12ea-a72e-49cd-9ca2-a1b0fb0c30b5"
  STEP: verifying the updated pod is in kubernetes @ 04/13/24 13:40:21.288
  Apr 13 13:40:21.291: INFO: Pod update OK
  Apr 13 13:40:21.291: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2248" for this suite. @ 04/13/24 13:40:21.294
• [2.581 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/13/24 13:40:21.302
  Apr 13 13:40:21.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename containers @ 04/13/24 13:40:21.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:21.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:21.322
  E0413 13:40:22.170415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:23.170495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:23.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9405" for this suite. @ 04/13/24 13:40:23.357
• [2.062 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 04/13/24 13:40:23.364
  Apr 13 13:40:23.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/13/24 13:40:23.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:23.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:23.383
  STEP: creating a target pod @ 04/13/24 13:40:23.387
  E0413 13:40:24.171055      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:25.171502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/13/24 13:40:25.407
  E0413 13:40:26.171633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:27.171965      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/13/24 13:40:27.423
  Apr 13 13:40:27.423: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5581 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:40:27.423: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:40:27.423: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:40:27.423: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-5581/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 13 13:40:27.478: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 04/13/24 13:40:27.498
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 04/13/24 13:40:27.503
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 04/13/24 13:40:27.513
  Apr 13 13:40:27.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5581" for this suite. @ 04/13/24 13:40:27.523
• [4.165 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 04/13/24 13:40:27.529
  Apr 13 13:40:27.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:40:27.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:27.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:27.553
  STEP: Creating configMap with name configmap-test-volume-map-25340d35-8901-4748-bafb-96f57523d26b @ 04/13/24 13:40:27.557
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:40:27.564
  E0413 13:40:28.172131      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:29.172348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:40:29.584
  Apr 13 13:40:29.587: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-f8cb2d10-1d66-4ddb-995f-92724c60c788 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:40:29.593
  Apr 13 13:40:29.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2674" for this suite. @ 04/13/24 13:40:29.613
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 04/13/24 13:40:29.62
  Apr 13 13:40:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 13:40:29.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:29.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:29.639
  STEP: Creating ServiceAccount "e2e-sa-9bck4"  @ 04/13/24 13:40:29.643
  Apr 13 13:40:29.648: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-9bck4"  @ 04/13/24 13:40:29.648
  Apr 13 13:40:29.656: INFO: AutomountServiceAccountToken: true
  Apr 13 13:40:29.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9657" for this suite. @ 04/13/24 13:40:29.66
• [0.046 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 04/13/24 13:40:29.666
  Apr 13 13:40:29.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:40:29.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:40:29.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:40:29.684
  STEP: Creating resourceQuota "e2e-rq-status-r4p65" @ 04/13/24 13:40:29.691
  Apr 13 13:40:29.702: INFO: Resource quota "e2e-rq-status-r4p65" reports spec: hard cpu limit of 500m
  Apr 13 13:40:29.702: INFO: Resource quota "e2e-rq-status-r4p65" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-r4p65" /status @ 04/13/24 13:40:29.702
  STEP: Confirm /status for "e2e-rq-status-r4p65" resourceQuota via watch @ 04/13/24 13:40:29.709
  Apr 13 13:40:29.711: INFO: observed resourceQuota "e2e-rq-status-r4p65" in namespace "resourcequota-6476" with hard status: v1.ResourceList(nil)
  Apr 13 13:40:29.711: INFO: Found resourceQuota "e2e-rq-status-r4p65" in namespace "resourcequota-6476" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 13 13:40:29.711: INFO: ResourceQuota "e2e-rq-status-r4p65" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/13/24 13:40:29.714
  Apr 13 13:40:29.720: INFO: Resource quota "e2e-rq-status-r4p65" reports spec: hard cpu limit of 1
  Apr 13 13:40:29.720: INFO: Resource quota "e2e-rq-status-r4p65" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-r4p65" /status @ 04/13/24 13:40:29.72
  STEP: Confirm /status for "e2e-rq-status-r4p65" resourceQuota via watch @ 04/13/24 13:40:29.729
  Apr 13 13:40:29.731: INFO: observed resourceQuota "e2e-rq-status-r4p65" in namespace "resourcequota-6476" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 13 13:40:29.731: INFO: Found resourceQuota "e2e-rq-status-r4p65" in namespace "resourcequota-6476" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 13 13:40:29.731: INFO: ResourceQuota "e2e-rq-status-r4p65" /status was patched
  STEP: Get "e2e-rq-status-r4p65" /status @ 04/13/24 13:40:29.731
  Apr 13 13:40:29.734: INFO: Resourcequota "e2e-rq-status-r4p65" reports status: hard cpu of 1
  Apr 13 13:40:29.734: INFO: Resourcequota "e2e-rq-status-r4p65" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-r4p65" /status before checking Spec is unchanged @ 04/13/24 13:40:29.737
  Apr 13 13:40:29.742: INFO: Resourcequota "e2e-rq-status-r4p65" reports status: hard cpu of 2
  Apr 13 13:40:29.742: INFO: Resourcequota "e2e-rq-status-r4p65" reports status: hard memory of 2Gi
  Apr 13 13:40:29.743: INFO: Found resourceQuota "e2e-rq-status-r4p65" in namespace "resourcequota-6476" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Apr 13 13:40:29.747: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005193e30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005193e90), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005193ed8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:30.172446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:31.172544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:32.172625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:33.172730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:34.172828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:34.747: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e150), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e1b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e1e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:35.172858      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:36.172961      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:37.173866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:38.173980      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:39.174105      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:39.749: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9158), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9188), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f91d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:40.175113      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:41.175208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:42.175412      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:43.175507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:44.175612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:44.749: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f93c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f93f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9440), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:45.175732      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:46.175806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:47.176840      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:48.176964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:49.177070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:49.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e8a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e918), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496e960), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:50.178079      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:51.178177      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:52.178364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:53.178511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:54.178610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:54.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496ec90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496ecd8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496ed08), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:40:55.179438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:56.180464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:57.181423      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:58.181970      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:40:59.182040      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:40:59.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f080), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f0c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f0f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:00.182377      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:01.182483      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:02.182552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:03.183522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:04.184175      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:04.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9920), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9950), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9980), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:05.184843      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:06.184979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:07.186002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:08.186107      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:09.186296      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:09.747: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f4e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f548), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496f578), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:10.186455      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:11.186595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:12.186694      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:13.187550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:14.188459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:14.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9c98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9cc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051f9cf8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:15.189276      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:16.189474      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:17.189581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:18.190291      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:19.190485      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:19.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496fa88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496fad0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00496fb18), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:20.190952      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:21.191615      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:22.191710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:23.191796      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:24.191886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:24.749: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b620d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62120), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:25.192832      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:26.193882      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:27.194869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:28.195578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:29.195669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:29.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62438), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b624e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62540), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:30.196315      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:31.196414      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:32.196638      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:33.196730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:34.196945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:34.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044f4318), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044f43c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044f4408), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:35.198111      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:36.198351      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:37.198473      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:38.198497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:39.198528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:39.749: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62bd0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62c00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b62c30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:40.199420      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:41.199602      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:42.199909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:43.200234      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:44.200646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:44.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b63080), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b630b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b63110), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:45.200923      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:46.201257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:47.201348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:48.201438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:49.202448      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:49.749: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-r4p65", GenerateName:"", Namespace:"resourcequota-6476", SelfLink:"", UID:"74cb6ff8-408d-4a54-a686-920788b630ab", ResourceVersion:"41757", Generation:0, CreationTimestamp:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-r4p65"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b633f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b63470), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 13, 13, 40, 29, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b634a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0413 13:41:50.202537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:51.203457      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:52.203610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:53.203727      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:54.203905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:41:54.748: INFO: ResourceQuota "e2e-rq-status-r4p65" Spec was unchanged and /status reset
  Apr 13 13:41:54.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6476" for this suite. @ 04/13/24 13:41:54.753
• [85.094 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 04/13/24 13:41:54.761
  Apr 13 13:41:54.761: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:41:54.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:41:54.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:41:54.781
  STEP: Counting existing ResourceQuota @ 04/13/24 13:41:54.784
  E0413 13:41:55.203975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:56.204059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:57.204857      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:58.205760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:41:59.205830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/13/24 13:41:59.787
  STEP: Ensuring resource quota status is calculated @ 04/13/24 13:41:59.792
  E0413 13:42:00.205967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:01.206152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 04/13/24 13:42:01.796
  STEP: Ensuring resource quota status captures replicaset creation @ 04/13/24 13:42:01.808
  E0413 13:42:02.206704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:03.206821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 04/13/24 13:42:03.813
  STEP: Ensuring resource quota status released usage @ 04/13/24 13:42:03.821
  E0413 13:42:04.207853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:05.208235      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:05.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6291" for this suite. @ 04/13/24 13:42:05.83
• [11.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/13/24 13:42:05.84
  Apr 13 13:42:05.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:42:05.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:42:05.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:42:05.858
  STEP: creating service multi-endpoint-test in namespace services-871 @ 04/13/24 13:42:05.861
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-871 to expose endpoints map[] @ 04/13/24 13:42:05.871
  Apr 13 13:42:05.882: INFO: successfully validated that service multi-endpoint-test in namespace services-871 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-871 @ 04/13/24 13:42:05.882
  E0413 13:42:06.208390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:07.208734      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-871 to expose endpoints map[pod1:[100]] @ 04/13/24 13:42:07.908
  Apr 13 13:42:07.921: INFO: successfully validated that service multi-endpoint-test in namespace services-871 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-871 @ 04/13/24 13:42:07.921
  E0413 13:42:08.208833      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:09.208932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-871 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/13/24 13:42:09.939
  Apr 13 13:42:09.954: INFO: successfully validated that service multi-endpoint-test in namespace services-871 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/13/24 13:42:09.954
  Apr 13 13:42:09.954: INFO: Creating new exec pod
  E0413 13:42:10.209419      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:11.209679      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:12.209742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:12.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-871 exec execpodtf2qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 13 13:42:13.057: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 13 13:42:13.057: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:42:13.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-871 exec execpodtf2qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.214 80'
  Apr 13 13:42:13.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.214 80\nConnection to 10.152.183.214 80 port [tcp/http] succeeded!\n"
  Apr 13 13:42:13.148: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:42:13.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-871 exec execpodtf2qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  E0413 13:42:13.210016      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:13.242: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 13 13:42:13.242: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:42:13.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-871 exec execpodtf2qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.214 81'
  Apr 13 13:42:13.337: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.214 81\nConnection to 10.152.183.214 81 port [tcp/*] succeeded!\n"
  Apr 13 13:42:13.337: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-871 @ 04/13/24 13:42:13.338
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-871 to expose endpoints map[pod2:[101]] @ 04/13/24 13:42:13.348
  E0413 13:42:14.210259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:14.376: INFO: successfully validated that service multi-endpoint-test in namespace services-871 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-871 @ 04/13/24 13:42:14.376
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-871 to expose endpoints map[] @ 04/13/24 13:42:14.393
  Apr 13 13:42:14.401: INFO: successfully validated that service multi-endpoint-test in namespace services-871 exposes endpoints map[]
  Apr 13 13:42:14.417: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-871" for this suite. @ 04/13/24 13:42:14.421
• [8.587 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 04/13/24 13:42:14.427
  Apr 13 13:42:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename replicaset @ 04/13/24 13:42:14.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:42:14.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:42:14.445
  Apr 13 13:42:14.461: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0413 13:42:15.210543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:16.211550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:17.211742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:18.211862      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:19.212762      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:19.467: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/13/24 13:42:19.467
  STEP: Scaling up "test-rs" replicaset @ 04/13/24 13:42:19.467
  Apr 13 13:42:19.477: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/13/24 13:42:19.477
  Apr 13 13:42:19.489: INFO: observed ReplicaSet test-rs in namespace replicaset-7631 with ReadyReplicas 1, AvailableReplicas 1
  Apr 13 13:42:19.497: INFO: observed ReplicaSet test-rs in namespace replicaset-7631 with ReadyReplicas 1, AvailableReplicas 1
  Apr 13 13:42:19.517: INFO: observed ReplicaSet test-rs in namespace replicaset-7631 with ReadyReplicas 1, AvailableReplicas 1
  Apr 13 13:42:19.522: INFO: observed ReplicaSet test-rs in namespace replicaset-7631 with ReadyReplicas 1, AvailableReplicas 1
  E0413 13:42:20.213022      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:42:20.534: INFO: observed ReplicaSet test-rs in namespace replicaset-7631 with ReadyReplicas 2, AvailableReplicas 2
  Apr 13 13:42:20.663: INFO: observed Replicaset test-rs in namespace replicaset-7631 with ReadyReplicas 3 found true
  Apr 13 13:42:20.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7631" for this suite. @ 04/13/24 13:42:20.667
• [6.247 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/13/24 13:42:20.674
  Apr 13 13:42:20.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename containers @ 04/13/24 13:42:20.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:42:20.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:42:20.692
  STEP: Creating a pod to test override all @ 04/13/24 13:42:20.695
  E0413 13:42:21.213520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:22.213629      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:23.214634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:24.214791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:42:24.716
  Apr 13 13:42:24.719: INFO: Trying to get logs from node ip-172-31-82-63 pod client-containers-54230a6b-cb74-4545-aedc-090efa2032cc container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 13:42:24.735
  Apr 13 13:42:24.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2101" for this suite. @ 04/13/24 13:42:24.756
• [4.089 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/13/24 13:42:24.764
  Apr 13 13:42:24.764: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename subjectreview @ 04/13/24 13:42:24.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:42:24.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:42:24.781
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-0" @ 04/13/24 13:42:24.785
  Apr 13 13:42:24.789: INFO: saUsername: "system:serviceaccount:subjectreview-0:e2e"
  Apr 13 13:42:24.789: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-0"}
  Apr 13 13:42:24.789: INFO: saUID: "c368d13e-15fe-4ad7-87c8-f96d362784b4"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-0:e2e" @ 04/13/24 13:42:24.789
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-0:e2e" @ 04/13/24 13:42:24.79
  Apr 13 13:42:24.791: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-0:e2e" api 'list' configmaps in "subjectreview-0" namespace @ 04/13/24 13:42:24.792
  Apr 13 13:42:24.793: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-0:e2e" @ 04/13/24 13:42:24.793
  Apr 13 13:42:24.796: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 13 13:42:24.796: INFO: LocalSubjectAccessReview has been verified
  Apr 13 13:42:24.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-0" for this suite. @ 04/13/24 13:42:24.799
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 04/13/24 13:42:24.807
  Apr 13 13:42:24.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sched-pred @ 04/13/24 13:42:24.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:42:24.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:42:24.827
  Apr 13 13:42:24.830: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 13 13:42:24.838: INFO: Waiting for terminating namespaces to be deleted...
  Apr 13 13:42:24.841: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-35-229 before test
  Apr 13 13:42:24.847: INFO: nginx-ingress-controller-kubernetes-worker-tchsj from ingress-nginx-kubernetes-worker started at 2024-04-13 12:16:24 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.847: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: calico-node-mrwfw from kube-system started at 2024-04-13 12:19:51 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.847: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: test-rs-hhr8v from replicaset-7631 started at 2024-04-13 13:42:19 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.847: INFO: 	Container httpd ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: sonobuoy-e2e-job-e3618131f41d4cd5 from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.847: INFO: 	Container e2e ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-2fnld from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.847: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:42:24.847: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-65-227 before test
  Apr 13 13:42:24.852: INFO: nginx-ingress-controller-kubernetes-worker-fr5bd from ingress-nginx-kubernetes-worker started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: calico-node-lfv4l from kube-system started at 2024-04-13 12:20:12 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: coredns-bddfd76d7-xzr8q from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container coredns ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: kube-state-metrics-78c475f58b-tmplf from kube-system started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: metrics-server-v0.6.3-69d7fbfdf8-c2gtp from kube-system started at 2024-04-13 12:12:03 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: dashboard-metrics-scraper-5dd7cb5fc-fljfb from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: kubernetes-dashboard-7b899cb9d9-ss9wp from kubernetes-dashboard started at 2024-04-13 12:12:03 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: test-rs-sr64w from replicaset-7631 started at 2024-04-13 13:42:19 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container httpd ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: 	Container test-rs ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-qn24t from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.852: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 13 13:42:24.852: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-63 before test
  Apr 13 13:42:24.857: INFO: nginx-ingress-controller-kubernetes-worker-x6l7w from ingress-nginx-kubernetes-worker started at 2024-04-13 12:47:31 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.857: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 13 13:42:24.857: INFO: calico-node-9p4gt from kube-system started at 2024-04-13 12:20:01 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.857: INFO: 	Container calico-node ready: true, restart count 0
  Apr 13 13:42:24.857: INFO: test-rs-dnds7 from replicaset-7631 started at 2024-04-13 13:42:14 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.857: INFO: 	Container httpd ready: true, restart count 0
  Apr 13 13:42:24.857: INFO: sonobuoy from sonobuoy started at 2024-04-13 12:20:25 +0000 UTC (1 container statuses recorded)
  Apr 13 13:42:24.857: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 13 13:42:24.857: INFO: sonobuoy-systemd-logs-daemon-set-ffe0b930d1754fc8-sbrvb from sonobuoy started at 2024-04-13 12:20:26 +0000 UTC (2 container statuses recorded)
  Apr 13 13:42:24.857: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 13 13:42:24.857: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/13/24 13:42:24.857
  E0413 13:42:25.215367      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:26.215459      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/13/24 13:42:26.881
  STEP: Trying to apply a random label on the found node. @ 04/13/24 13:42:26.898
  STEP: verifying the node has the label kubernetes.io/e2e-f1df7d31-c2ba-4d59-a1fe-b00e93552cd6 95 @ 04/13/24 13:42:26.906
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/13/24 13:42:26.909
  E0413 13:42:27.216066      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:28.216307      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.82.63 on the node which pod4 resides and expect not scheduled @ 04/13/24 13:42:28.925
  E0413 13:42:29.216625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:30.216710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:31.217666      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:32.217777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:33.217908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:34.217963      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:35.218080      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:36.218180      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:37.218628      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:38.219612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:39.220095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:40.220197      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:41.220826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:42.220977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:43.221566      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:44.221953      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:45.222420      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:46.222623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:47.223382      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:48.223672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:49.223804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:50.223936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:51.224553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:52.224637      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:53.225570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:54.225772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:55.225897      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:56.225977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:57.226069      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:58.226178      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:42:59.227159      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:00.227260      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:01.228109      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:02.228203      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:03.228366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:04.228560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:05.229474      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:06.229588      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:07.229622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:08.229782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:09.229776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:10.230518      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:11.230582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:12.230670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:13.231539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:14.231988      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:15.232932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:16.233045      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:17.233481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:18.233775      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:19.234806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:20.235652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:21.236643      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:22.236742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:23.237243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:24.237375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:25.238399      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:26.238509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:27.239229      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:28.239567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:29.240110      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:30.240277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:31.241071      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:32.241249      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:33.241283      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:34.241411      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:35.242310      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:36.242479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:37.243206      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:38.243522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:39.243602      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:40.243801      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:41.244683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:42.244943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:43.246020      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:44.246237      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:45.246420      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:46.246495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:47.246543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:48.246684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:49.247070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:50.247169      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:51.248044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:52.248149      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:53.248196      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:54.248347      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:55.248806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:56.248941      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:57.249277      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:58.249386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:43:59.249634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:00.249815      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:01.250105      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:02.250194      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:03.250788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:04.250905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:05.251461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:06.251673      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:07.252087      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:08.252450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:09.253307      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:10.253436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:11.253969      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:12.254076      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:13.254792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:14.255551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:15.256091      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:16.256400      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:17.257119      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:18.257320      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:19.258158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:20.258366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:21.258438      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:22.258553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:23.259484      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:24.259557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:25.260220      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:26.260363      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:27.260782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:28.261153      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:29.260932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:30.261046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:31.261639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:32.261822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:33.262593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:34.263552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:35.263954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:36.264892      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:37.265627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:38.265802      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:39.266262      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:40.266449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:41.266534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:42.266655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:43.266739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:44.267531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:45.268620      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:46.268763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:47.268894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:48.269476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:49.269674      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:50.269772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:51.269909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:52.270503      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:53.271561      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:54.271673      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:55.272060      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:56.272182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:57.272451      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:58.273331      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:44:59.273526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:00.273641      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:01.273732      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:02.274112      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:03.274199      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:04.274527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:05.274634      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:06.274739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:07.275006      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:08.275713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:09.275979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:10.276216      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:11.276411      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:12.276481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:13.276704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:14.276779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:15.276904      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:16.277000      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:17.277230      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:18.277486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:19.278318      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:20.278497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:21.278591      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:22.279510      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:23.279606      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:24.280599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:25.281504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:26.281612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:27.281627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:28.282064      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:29.282135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:30.282502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:31.282593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:32.283539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:33.283683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:34.283771      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:35.283873      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:36.284109      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:37.284129      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:38.284237      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:39.284447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:40.284545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:41.284640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:42.285524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:43.285614      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:44.285732      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:45.285808      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:46.285954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:47.286699      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:48.287556      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:49.287660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:50.288244      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:51.288332      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:52.288802      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:53.288832      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:54.288964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:55.289071      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:56.289185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:57.289475      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:58.289596      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:45:59.289794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:00.289919      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:01.290035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:02.290523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:03.290555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:04.291450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:05.291531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:06.292451      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:07.292481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:08.293533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:09.293612      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:10.293742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:11.293821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:12.294538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:13.294566      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:14.294662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:15.294751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:16.294849      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:17.294920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:18.295007      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:19.295095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:20.295198      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:21.295295      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:22.295828      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:23.295990      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:24.296208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:25.296306      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:26.297317      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:27.297559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:28.297996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:29.298100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:30.298455      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:31.299527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:32.300513      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:33.301481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:34.301528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:35.301616      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:36.302682      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:37.303774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:38.304731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:39.304907      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:40.305207      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:41.305294      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:42.305405      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:43.305449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:44.306379      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:45.306463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:46.307365      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:47.307446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:48.308021      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:49.308171      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:50.309304      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:51.309379      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:52.309456      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:53.309891      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:54.310056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:55.310368      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:56.310653      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:57.311135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:58.311555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:46:59.311702      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:00.311795      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:01.311964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:02.312502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:03.312657      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:04.313300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:05.313379      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:06.314278      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:07.314538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:08.314575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:09.315537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:10.316172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:11.316288      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:12.317056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:13.317225      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:14.318283      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:15.318457      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:16.318588      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:17.318610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:18.319547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:19.319654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:20.320097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:21.320225      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:22.320394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:23.320503      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:24.320665      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:25.320868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:26.320845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:27.321084      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:28.321260      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-f1df7d31-c2ba-4d59-a1fe-b00e93552cd6 off the node ip-172-31-82-63 @ 04/13/24 13:47:28.934
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-f1df7d31-c2ba-4d59-a1fe-b00e93552cd6 @ 04/13/24 13:47:28.948
  Apr 13 13:47:28.957: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1005" for this suite. @ 04/13/24 13:47:28.961
• [304.160 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 04/13/24 13:47:28.967
  Apr 13 13:47:28.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename namespaces @ 04/13/24 13:47:28.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:28.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:28.987
  STEP: Creating a test namespace @ 04/13/24 13:47:28.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:29.004
  STEP: Creating a pod in the namespace @ 04/13/24 13:47:29.009
  STEP: Waiting for the pod to have running status @ 04/13/24 13:47:29.017
  E0413 13:47:29.321995      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:30.322059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 04/13/24 13:47:31.026
  STEP: Waiting for the namespace to be removed. @ 04/13/24 13:47:31.032
  E0413 13:47:31.322196      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:32.323198      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:33.323281      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:34.323308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:35.323593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:36.328613      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:37.329290      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:38.329395      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:39.329502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:40.330036      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:41.330924      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/13/24 13:47:42.037
  STEP: Verifying there are no pods in the namespace @ 04/13/24 13:47:42.054
  Apr 13 13:47:42.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8557" for this suite. @ 04/13/24 13:47:42.062
  STEP: Destroying namespace "nsdeletetest-3298" for this suite. @ 04/13/24 13:47:42.068
  Apr 13 13:47:42.071: INFO: Namespace nsdeletetest-3298 was already deleted
  STEP: Destroying namespace "nsdeletetest-452" for this suite. @ 04/13/24 13:47:42.071
• [13.110 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 04/13/24 13:47:42.077
  Apr 13 13:47:42.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:47:42.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:42.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:42.097
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:47:42.1
  E0413 13:47:42.331364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:43.331502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:44.332145      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:45.332352      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:47:46.125
  Apr 13 13:47:46.128: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-3f29e03f-d9ee-4d79-9f17-f681fee13a17 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:47:46.149
  Apr 13 13:47:46.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7682" for this suite. @ 04/13/24 13:47:46.167
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 04/13/24 13:47:46.174
  Apr 13 13:47:46.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:47:46.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:46.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:46.193
  STEP: Counting existing ResourceQuota @ 04/13/24 13:47:46.197
  E0413 13:47:46.333357      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:47.333528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:48.333773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:49.334037      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:50.334664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/13/24 13:47:51.201
  STEP: Ensuring resource quota status is calculated @ 04/13/24 13:47:51.206
  E0413 13:47:51.335457      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:52.335553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 04/13/24 13:47:53.21
  STEP: Creating a NodePort Service @ 04/13/24 13:47:53.227
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/13/24 13:47:53.249
  STEP: Ensuring resource quota status captures service creation @ 04/13/24 13:47:53.271
  E0413 13:47:53.336507      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:54.336623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 04/13/24 13:47:55.276
  STEP: Ensuring resource quota status released usage @ 04/13/24 13:47:55.309
  E0413 13:47:55.336889      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:56.337095      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:47:57.315: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3172" for this suite. @ 04/13/24 13:47:57.319
• [11.152 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 04/13/24 13:47:57.326
  Apr 13 13:47:57.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 13:47:57.327
  E0413 13:47:57.337693      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:57.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:57.345
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/13/24 13:47:57.349
  E0413 13:47:58.337865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:47:59.337973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:47:59.366
  Apr 13 13:47:59.371: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-1528ed68-64b9-4098-9220-dfdd24804e44 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 13:47:59.378
  Apr 13 13:47:59.392: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7203" for this suite. @ 04/13/24 13:47:59.395
• [2.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 04/13/24 13:47:59.403
  Apr 13 13:47:59.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename svcaccounts @ 04/13/24 13:47:59.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:59.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:59.421
  STEP: creating a ServiceAccount @ 04/13/24 13:47:59.425
  STEP: watching for the ServiceAccount to be added @ 04/13/24 13:47:59.434
  STEP: patching the ServiceAccount @ 04/13/24 13:47:59.437
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/13/24 13:47:59.442
  STEP: deleting the ServiceAccount @ 04/13/24 13:47:59.446
  Apr 13 13:47:59.460: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3385" for this suite. @ 04/13/24 13:47:59.465
• [0.067 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 04/13/24 13:47:59.471
  Apr 13 13:47:59.471: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 13:47:59.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:47:59.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:47:59.49
  STEP: Creating a suspended job @ 04/13/24 13:47:59.497
  STEP: Patching the Job @ 04/13/24 13:47:59.505
  STEP: Watching for Job to be patched @ 04/13/24 13:47:59.518
  Apr 13 13:47:59.520: INFO: Event ADDED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx] and annotations: map[]
  Apr 13 13:47:59.520: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx] and annotations: map[]
  Apr 13 13:47:59.520: INFO: Event MODIFIED found for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[]
  STEP: Updating the job @ 04/13/24 13:47:59.52
  STEP: Watching for Job to be updated @ 04/13/24 13:47:59.536
  Apr 13 13:47:59.538: INFO: Event MODIFIED found for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:47:59.538: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/13/24 13:47:59.538
  Apr 13 13:47:59.541: INFO: Job: e2e-xmmjx as labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched]
  STEP: Waiting for job to complete @ 04/13/24 13:47:59.541
  E0413 13:48:00.338524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:01.338600      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:02.338857      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:03.338932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:04.339348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:05.339578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:06.340530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:07.341501      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 04/13/24 13:48:07.547
  STEP: Watching for Job to be deleted @ 04/13/24 13:48:07.556
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event MODIFIED observed for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  Apr 13 13:48:07.558: INFO: Event DELETED found for Job e2e-xmmjx in namespace job-4133 with labels: map[e2e-job-label:e2e-xmmjx e2e-xmmjx:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 04/13/24 13:48:07.558
  Apr 13 13:48:07.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4133" for this suite. @ 04/13/24 13:48:07.565
• [8.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 04/13/24 13:48:07.579
  Apr 13 13:48:07.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:48:07.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:48:07.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:48:07.598
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:48:07.602
  E0413 13:48:08.341662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:09.341774      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:10.341789      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:11.341883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:48:11.624
  Apr 13 13:48:11.629: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-238689a6-90e8-4ddb-937f-18c32464571c container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:48:11.635
  Apr 13 13:48:11.649: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2853" for this suite. @ 04/13/24 13:48:11.653
• [4.081 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 04/13/24 13:48:11.66
  Apr 13 13:48:11.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:48:11.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:48:11.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:48:11.677
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-675a1a35-1b04-4548-8e48-aa8c1b9f074a @ 04/13/24 13:48:11.684
  STEP: Creating the pod @ 04/13/24 13:48:11.689
  E0413 13:48:12.342541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:13.342641      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-675a1a35-1b04-4548-8e48-aa8c1b9f074a @ 04/13/24 13:48:13.719
  STEP: waiting to observe update in volume @ 04/13/24 13:48:13.724
  E0413 13:48:14.343251      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:15.343357      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:16.343557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:17.343630      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:18.344554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:19.344660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:20.344848      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:21.344955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:22.345572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:23.345651      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:24.345756      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:25.345886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:26.345999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:27.346660      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:28.347019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:29.346870      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:30.347257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:31.347586      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:32.348101      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:33.348269      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:34.348495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:35.348684      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:36.348983      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:37.349505      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:38.349632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:39.349761      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:40.349957      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:41.350125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:42.350527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:43.350607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:44.350842      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:45.351531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:46.351922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:47.352755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:48.352853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:49.353028      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:50.353128      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:51.353242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:52.353320      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:53.353451      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:54.354508      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:55.354598      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:56.355429      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:57.358428      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:58.356943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:48:59.357121      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:00.357881      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:01.358012      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:02.358714      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:03.359570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:04.360065      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:05.360119      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:06.360181      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:07.360251      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:08.360569      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:09.360659      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:10.360747      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:11.361424      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:12.361834      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:13.362217      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:14.363237      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:15.363326      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:16.363995      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:17.364356      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:18.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8024" for this suite. @ 04/13/24 13:49:18.005
• [66.353 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/13/24 13:49:18.013
  Apr 13 13:49:18.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 13:49:18.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:49:18.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:49:18.032
  STEP: Creating pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355 @ 04/13/24 13:49:18.035
  E0413 13:49:18.364479      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:19.364740      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 13:49:20.052
  Apr 13 13:49:20.056: INFO: Initial restart count of pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is 0
  Apr 13 13:49:20.059: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:20.365328      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:21.365475      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:22.065: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:22.365714      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:23.365924      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:24.070: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:24.366366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:25.366488      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:26.075: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:26.367527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:27.368578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:28.080: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:28.369249      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:29.369470      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:30.085: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:30.370462      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:31.370523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:32.091: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:32.371526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:33.371672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:34.095: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:34.371964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:35.372166      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:36.099: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:36.372336      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:37.372600      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:38.105: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:38.373544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:39.373764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:40.109: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  Apr 13 13:49:40.109: INFO: Restart count of pod container-probe-8355/liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is now 1 (20.053271768s elapsed)
  E0413 13:49:40.374293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:41.374509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:42.115: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:42.375537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:43.375729      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:44.120: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:44.375785      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:45.375977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:46.124: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:46.376224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:47.376588      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:48.130: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:48.377611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:49.377714      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:50.134: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:50.378700      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:51.378810      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:52.139: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:52.379050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:53.379571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:54.144: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:54.379990      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:55.380067      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:56.150: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:56.380712      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:57.381705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:49:58.155: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:49:58.382299      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:49:59.382477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:00.161: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  Apr 13 13:50:00.161: INFO: Restart count of pod container-probe-8355/liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is now 2 (40.104782165s elapsed)
  E0413 13:50:00.382584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:01.383574      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:02.166: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:02.383964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:03.384032      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:04.171: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:04.384908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:05.385009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:06.175: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:06.385103      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:07.385409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:08.181: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:08.385555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:09.385646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:10.186: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:10.385697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:11.385813      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:12.191: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:12.386197      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:13.386497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:14.195: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:14.387098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:15.387661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:16.201: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:16.388679      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:17.388821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:18.205: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:18.389869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:19.389972      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:20.210: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  Apr 13 13:50:20.210: INFO: Restart count of pod container-probe-8355/liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is now 3 (1m0.153519456s elapsed)
  E0413 13:50:20.390532      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:21.391539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:22.214: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:22.392004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:23.392093      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:24.219: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:24.392721      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:25.392826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:26.224: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:26.393376      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:27.393583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:28.230: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:28.393806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:29.393923      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:30.236: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:30.394283      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:31.394461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:32.240: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:32.395310      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:33.395419      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:34.246: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:34.396401      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:35.396498      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:36.250: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:36.397124      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:37.397744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:38.255: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:38.397954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:39.398025      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:40.260: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  Apr 13 13:50:40.260: INFO: Restart count of pod container-probe-8355/liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is now 4 (1m20.203862582s elapsed)
  E0413 13:50:40.398966      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:41.399064      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:42.266: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:42.399964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:43.400070      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:44.271: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:44.401063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:45.401178      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:46.277: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:46.401805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:47.402211      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:48.283: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:48.402851      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:49.403519      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:50.289: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:50.404581      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:51.404801      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:52.294: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:52.405386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:53.405489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:54.298: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:54.405930      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:55.406114      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:56.303: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:56.407082      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:57.407533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:50:58.309: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:50:58.408445      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:50:59.408648      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:00.314: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:00.408850      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:01.408946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:02.319: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:02.409125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:03.409241      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:04.325: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:04.409332      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:05.410391      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:06.329: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:06.411009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:07.411370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:08.336: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:08.412305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:09.412558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:10.341: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:10.413552      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:11.413678      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:12.346: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:12.413908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:13.414366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:14.351: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:14.415100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:15.416117      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:16.357: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:16.416318      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:17.416584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:18.362: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:18.417489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:19.417625      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:20.368: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:20.418664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:21.418738      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:22.374: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:22.419599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:23.419726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:24.379: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:24.420433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:25.420553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:26.385: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:26.421305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:27.421495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:28.390: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:28.421721      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:29.421835      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:30.395: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:30.422779      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:31.423534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:32.400: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:32.423998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:33.424167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:34.405: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:34.425003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:35.425125      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:36.410: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:36.425617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:37.426258      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:38.416: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:38.427256      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:39.428034      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:40.420: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:40.428533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:41.428669      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:42.426: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:42.429644      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:43.429772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:44.430609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:44.432: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:45.430874      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:46.431527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:46.437: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  E0413 13:51:47.431557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:48.431641      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:51:48.443: INFO: Get pod liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 in namespace container-probe-8355
  Apr 13 13:51:48.443: INFO: Restart count of pod container-probe-8355/liveness-d25c55ee-85fb-4987-8304-3abdb67d28c5 is now 5 (2m28.387138158s elapsed)
  STEP: deleting the pod @ 04/13/24 13:51:48.443
  Apr 13 13:51:48.459: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8355" for this suite. @ 04/13/24 13:51:48.462
• [150.456 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/13/24 13:51:48.469
  Apr 13 13:51:48.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename watch @ 04/13/24 13:51:48.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:51:48.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:51:48.489
  STEP: creating a watch on configmaps with a certain label @ 04/13/24 13:51:48.493
  STEP: creating a new configmap @ 04/13/24 13:51:48.494
  STEP: modifying the configmap once @ 04/13/24 13:51:48.499
  STEP: changing the label value of the configmap @ 04/13/24 13:51:48.506
  STEP: Expecting to observe a delete notification for the watched object @ 04/13/24 13:51:48.516
  Apr 13 13:51:48.516: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43877 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:51:48.517: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43878 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:51:48.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43879 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/13/24 13:51:48.517
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/13/24 13:51:48.525
  E0413 13:51:49.431776      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:50.431871      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:51.431998      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:52.432600      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:53.432697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:54.432892      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:55.433107      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:56.433339      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:57.433662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:51:58.433861      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 04/13/24 13:51:58.526
  STEP: modifying the configmap a third time @ 04/13/24 13:51:58.538
  STEP: deleting the configmap @ 04/13/24 13:51:58.547
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/13/24 13:51:58.552
  Apr 13 13:51:58.552: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43915 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:51:58.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43916 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:51:58.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6892  0f4ef99b-f0dc-45da-a7be-87375acb74b1 43917 0 2024-04-13 13:51:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-13 13:51:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 13:51:58.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6892" for this suite. @ 04/13/24 13:51:58.556
• [10.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 04/13/24 13:51:58.563
  Apr 13 13:51:58.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename discovery @ 04/13/24 13:51:58.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:51:58.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:51:58.583
  STEP: Setting up server cert @ 04/13/24 13:51:58.588
  Apr 13 13:51:58.759: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 13 13:51:58.761: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 13 13:51:58.761: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 13 13:51:58.761: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 13 13:51:58.761: INFO: Checking APIGroup: apps
  Apr 13 13:51:58.762: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 13 13:51:58.762: INFO: Versions found [{apps/v1 v1}]
  Apr 13 13:51:58.762: INFO: apps/v1 matches apps/v1
  Apr 13 13:51:58.762: INFO: Checking APIGroup: events.k8s.io
  Apr 13 13:51:58.764: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 13 13:51:58.764: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 13 13:51:58.764: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 13 13:51:58.764: INFO: Checking APIGroup: authentication.k8s.io
  Apr 13 13:51:58.765: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 13 13:51:58.765: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 13 13:51:58.765: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 13 13:51:58.765: INFO: Checking APIGroup: authorization.k8s.io
  Apr 13 13:51:58.767: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 13 13:51:58.767: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 13 13:51:58.767: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 13 13:51:58.767: INFO: Checking APIGroup: autoscaling
  Apr 13 13:51:58.768: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 13 13:51:58.768: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 13 13:51:58.768: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 13 13:51:58.768: INFO: Checking APIGroup: batch
  Apr 13 13:51:58.770: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 13 13:51:58.770: INFO: Versions found [{batch/v1 v1}]
  Apr 13 13:51:58.770: INFO: batch/v1 matches batch/v1
  Apr 13 13:51:58.770: INFO: Checking APIGroup: certificates.k8s.io
  Apr 13 13:51:58.771: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 13 13:51:58.771: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 13 13:51:58.771: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 13 13:51:58.771: INFO: Checking APIGroup: networking.k8s.io
  Apr 13 13:51:58.773: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 13 13:51:58.773: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 13 13:51:58.773: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 13 13:51:58.773: INFO: Checking APIGroup: policy
  Apr 13 13:51:58.774: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 13 13:51:58.774: INFO: Versions found [{policy/v1 v1}]
  Apr 13 13:51:58.774: INFO: policy/v1 matches policy/v1
  Apr 13 13:51:58.774: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 13 13:51:58.776: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 13 13:51:58.776: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 13 13:51:58.776: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 13 13:51:58.776: INFO: Checking APIGroup: storage.k8s.io
  Apr 13 13:51:58.777: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 13 13:51:58.777: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 13 13:51:58.777: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 13 13:51:58.777: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 13 13:51:58.778: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 13 13:51:58.778: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 13 13:51:58.778: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 13 13:51:58.778: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 13 13:51:58.780: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 13 13:51:58.780: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 13 13:51:58.780: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 13 13:51:58.780: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 13 13:51:58.781: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 13 13:51:58.781: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 13 13:51:58.781: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 13 13:51:58.781: INFO: Checking APIGroup: coordination.k8s.io
  Apr 13 13:51:58.783: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 13 13:51:58.783: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 13 13:51:58.783: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 13 13:51:58.783: INFO: Checking APIGroup: node.k8s.io
  Apr 13 13:51:58.785: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 13 13:51:58.785: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 13 13:51:58.785: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 13 13:51:58.785: INFO: Checking APIGroup: discovery.k8s.io
  Apr 13 13:51:58.786: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 13 13:51:58.786: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 13 13:51:58.786: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 13 13:51:58.786: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 13 13:51:58.787: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Apr 13 13:51:58.787: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Apr 13 13:51:58.787: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Apr 13 13:51:58.787: INFO: Checking APIGroup: metrics.k8s.io
  Apr 13 13:51:58.789: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Apr 13 13:51:58.789: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Apr 13 13:51:58.789: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Apr 13 13:51:58.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1551" for this suite. @ 04/13/24 13:51:58.793
• [0.237 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 04/13/24 13:51:58.8
  Apr 13 13:51:58.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pod-network-test @ 04/13/24 13:51:58.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:51:58.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:51:58.817
  STEP: Performing setup for networking test in namespace pod-network-test-4846 @ 04/13/24 13:51:58.82
  STEP: creating a selector @ 04/13/24 13:51:58.82
  STEP: Creating the service pods in kubernetes @ 04/13/24 13:51:58.82
  Apr 13 13:51:58.820: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0413 13:51:59.434800      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:00.434894      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:01.435664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:02.436500      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:03.436704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:04.436829      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:05.436943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:06.437048      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:07.437650      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:08.437859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:09.438086      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:10.438135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/13/24 13:52:10.901
  E0413 13:52:11.438227      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:12.438280      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:12.919: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 13 13:52:12.919: INFO: Breadth first check of 192.168.57.219 on host 172.31.35.229...
  Apr 13 13:52:12.922: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.196:9080/dial?request=hostname&protocol=http&host=192.168.57.219&port=8083&tries=1'] Namespace:pod-network-test-4846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:52:12.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:52:12.923: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:52:12.923: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.196%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.57.219%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 13:52:12.983: INFO: Waiting for responses: map[]
  Apr 13 13:52:12.983: INFO: reached 192.168.57.219 after 0/1 tries
  Apr 13 13:52:12.984: INFO: Breadth first check of 192.168.254.237 on host 172.31.65.227...
  Apr 13 13:52:12.988: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.196:9080/dial?request=hostname&protocol=http&host=192.168.254.237&port=8083&tries=1'] Namespace:pod-network-test-4846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:52:12.988: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:52:12.988: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:52:12.988: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.196%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.254.237%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 13:52:13.042: INFO: Waiting for responses: map[]
  Apr 13 13:52:13.042: INFO: reached 192.168.254.237 after 0/1 tries
  Apr 13 13:52:13.042: INFO: Breadth first check of 192.168.172.234 on host 172.31.82.63...
  Apr 13 13:52:13.046: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.196:9080/dial?request=hostname&protocol=http&host=192.168.172.234&port=8083&tries=1'] Namespace:pod-network-test-4846 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 13 13:52:13.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:52:13.047: INFO: ExecWithOptions: Clientset creation
  Apr 13 13:52:13.047: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4846/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.196%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.172.234%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 13 13:52:13.093: INFO: Waiting for responses: map[]
  Apr 13 13:52:13.093: INFO: reached 192.168.172.234 after 0/1 tries
  Apr 13 13:52:13.093: INFO: Going to retry 0 out of 3 pods....
  Apr 13 13:52:13.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4846" for this suite. @ 04/13/24 13:52:13.097
• [14.304 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 04/13/24 13:52:13.104
  Apr 13 13:52:13.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 13:52:13.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:13.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:13.124
  STEP: Setting up server cert @ 04/13/24 13:52:13.148
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 13:52:13.416
  STEP: Deploying the webhook pod @ 04/13/24 13:52:13.425
  STEP: Wait for the deployment to be ready @ 04/13/24 13:52:13.437
  E0413 13:52:13.438609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:13.444: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0413 13:52:14.439302      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:15.439426      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 13:52:15.458
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 13:52:15.471
  E0413 13:52:16.439967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:16.472: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/13/24 13:52:16.48
  STEP: create a namespace for the webhook @ 04/13/24 13:52:16.493
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/13/24 13:52:16.508
  Apr 13 13:52:16.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3871" for this suite. @ 04/13/24 13:52:16.558
  STEP: Destroying namespace "webhook-markers-8574" for this suite. @ 04/13/24 13:52:16.565
  STEP: Destroying namespace "fail-closed-namespace-259" for this suite. @ 04/13/24 13:52:16.572
• [3.474 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/13/24 13:52:16.579
  Apr 13 13:52:16.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 13:52:16.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:16.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:16.596
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7440.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7440.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/13/24 13:52:16.6
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7440.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7440.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/13/24 13:52:16.6
  STEP: creating a pod to probe /etc/hosts @ 04/13/24 13:52:16.6
  STEP: submitting the pod to kubernetes @ 04/13/24 13:52:16.6
  E0413 13:52:17.440595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:18.440661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 13:52:18.62
  STEP: looking for the results for each expected name from probers @ 04/13/24 13:52:18.623
  Apr 13 13:52:18.648: INFO: DNS probes using dns-7440/dns-test-d18090ac-f402-4c61-9a5a-b16600fd6243 succeeded

  STEP: deleting the pod @ 04/13/24 13:52:18.648
  Apr 13 13:52:18.658: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7440" for this suite. @ 04/13/24 13:52:18.662
• [2.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 04/13/24 13:52:18.669
  Apr 13 13:52:18.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/13/24 13:52:18.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:18.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:18.686
  Apr 13 13:52:18.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  Apr 13 13:52:19.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4053" for this suite. @ 04/13/24 13:52:19.238
• [0.577 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 04/13/24 13:52:19.247
  Apr 13 13:52:19.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:52:19.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:19.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:19.265
  STEP: Creating a pod to test downward api env vars @ 04/13/24 13:52:19.268
  E0413 13:52:19.441361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:20.441446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:21.441967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:22.442601      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:52:23.291
  Apr 13 13:52:23.295: INFO: Trying to get logs from node ip-172-31-82-63 pod downward-api-2cd0cea2-7da2-4aed-a9ca-61fb01a08301 container dapi-container: <nil>
  STEP: delete the pod @ 04/13/24 13:52:23.306
  Apr 13 13:52:23.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-865" for this suite. @ 04/13/24 13:52:23.328
• [4.088 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 04/13/24 13:52:23.334
  Apr 13 13:52:23.334: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/13/24 13:52:23.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:23.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:23.354
  STEP: creating @ 04/13/24 13:52:23.358
  STEP: getting @ 04/13/24 13:52:23.377
  STEP: listing in namespace @ 04/13/24 13:52:23.381
  STEP: patching @ 04/13/24 13:52:23.384
  STEP: deleting @ 04/13/24 13:52:23.39
  Apr 13 13:52:23.407: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7564" for this suite. @ 04/13/24 13:52:23.411
• [0.084 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/13/24 13:52:23.418
  Apr 13 13:52:23.418: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:52:23.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:23.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:23.44
  E0413 13:52:23.442697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6212 @ 04/13/24 13:52:23.444
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/13/24 13:52:23.454
  STEP: creating service externalsvc in namespace services-6212 @ 04/13/24 13:52:23.454
  STEP: creating replication controller externalsvc in namespace services-6212 @ 04/13/24 13:52:23.468
  I0413 13:52:23.473577      21 runners.go:197] Created replication controller with name: externalsvc, namespace: services-6212, replica count: 2
  E0413 13:52:24.443590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:25.444503      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:26.444708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:52:26.524973      21 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/13/24 13:52:26.529
  Apr 13 13:52:26.543: INFO: Creating new exec pod
  E0413 13:52:27.444850      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:28.445068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:28.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6212 exec execpodckpq4 -- /bin/sh -x -c nslookup clusterip-service.services-6212.svc.cluster.local'
  Apr 13 13:52:28.662: INFO: stderr: "+ nslookup clusterip-service.services-6212.svc.cluster.local\n"
  Apr 13 13:52:28.662: INFO: stdout: "Server:\t\t10.152.183.177\nAddress:\t10.152.183.177#53\n\nclusterip-service.services-6212.svc.cluster.local\tcanonical name = externalsvc.services-6212.svc.cluster.local.\nName:\texternalsvc.services-6212.svc.cluster.local\nAddress: 10.152.183.119\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6212, will wait for the garbage collector to delete the pods @ 04/13/24 13:52:28.662
  Apr 13 13:52:28.724: INFO: Deleting ReplicationController externalsvc took: 7.541776ms
  Apr 13 13:52:28.824: INFO: Terminating ReplicationController externalsvc pods took: 100.448994ms
  E0413 13:52:29.445570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:30.445991      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:31.446681      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:31.742: INFO: Cleaning up the ClusterIP to ExternalName test service
  Apr 13 13:52:31.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6212" for this suite. @ 04/13/24 13:52:31.755
• [8.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/13/24 13:52:31.763
  Apr 13 13:52:31.763: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:52:31.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:31.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:31.783
  STEP: Creating secret with name s-test-opt-del-eea4cdb4-cbeb-4ad7-88d5-f6587ce77873 @ 04/13/24 13:52:31.791
  STEP: Creating secret with name s-test-opt-upd-fa5d5919-bf31-48f8-938b-8a2a1b3d10e0 @ 04/13/24 13:52:31.795
  STEP: Creating the pod @ 04/13/24 13:52:31.8
  E0413 13:52:32.447545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:33.447644      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-eea4cdb4-cbeb-4ad7-88d5-f6587ce77873 @ 04/13/24 13:52:33.854
  STEP: Updating secret s-test-opt-upd-fa5d5919-bf31-48f8-938b-8a2a1b3d10e0 @ 04/13/24 13:52:33.86
  STEP: Creating secret with name s-test-opt-create-86e660a5-86ce-48ba-8470-ad615823d512 @ 04/13/24 13:52:33.866
  STEP: waiting to observe update in volume @ 04/13/24 13:52:33.871
  E0413 13:52:34.447921      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:35.448200      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:36.449259      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:37.449717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:37.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7983" for this suite. @ 04/13/24 13:52:37.91
• [6.154 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 04/13/24 13:52:37.917
  Apr 13 13:52:37.917: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:52:37.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:37.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:37.935
  STEP: Creating configMap with name configmap-test-volume-6cfff45e-1c48-44da-9c16-3cc45ae93961 @ 04/13/24 13:52:37.939
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:52:37.946
  E0413 13:52:38.450409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:39.450492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:52:39.965
  Apr 13 13:52:39.969: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-9bea1b7d-181f-4fbc-b6b6-702dfbdaff28 container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:52:39.976
  Apr 13 13:52:39.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5344" for this suite. @ 04/13/24 13:52:39.993
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 04/13/24 13:52:40.001
  Apr 13 13:52:40.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename job @ 04/13/24 13:52:40.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:40.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:40.023
  STEP: Creating Indexed job @ 04/13/24 13:52:40.027
  STEP: Ensuring job reaches completions @ 04/13/24 13:52:40.034
  E0413 13:52:40.451063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:41.451165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:42.451245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:43.452276      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:44.453196      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:45.453403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:46.453866      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:47.453930      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/13/24 13:52:48.039
  Apr 13 13:52:48.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6280" for this suite. @ 04/13/24 13:52:48.048
• [8.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 04/13/24 13:52:48.056
  Apr 13 13:52:48.056: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename deployment @ 04/13/24 13:52:48.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:48.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:48.078
  STEP: creating a Deployment @ 04/13/24 13:52:48.087
  Apr 13 13:52:48.087: INFO: Creating simple deployment test-deployment-clvdc
  Apr 13 13:52:48.099: INFO: deployment "test-deployment-clvdc" doesn't have the required revision set
  E0413 13:52:48.454044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:49.454137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 04/13/24 13:52:50.115
  Apr 13 13:52:50.119: INFO: Deployment test-deployment-clvdc has Conditions: [{Available True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-clvdc-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/13/24 13:52:50.119
  Apr 13 13:52:50.129: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 13, 13, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 13, 13, 52, 48, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-clvdc-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/13/24 13:52:50.129
  Apr 13 13:52:50.131: INFO: Observed &Deployment event: ADDED
  Apr 13 13:52:50.131: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-clvdc-5d576bd769"}
  Apr 13 13:52:50.131: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.131: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-clvdc-5d576bd769"}
  Apr 13 13:52:50.131: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 13 13:52:50.131: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.131: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 13 13:52:50.131: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-clvdc-5d576bd769" is progressing.}
  Apr 13 13:52:50.132: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.132: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 13 13:52:50.132: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-clvdc-5d576bd769" has successfully progressed.}
  Apr 13 13:52:50.132: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.132: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 13 13:52:50.132: INFO: Observed Deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-clvdc-5d576bd769" has successfully progressed.}
  Apr 13 13:52:50.132: INFO: Found Deployment test-deployment-clvdc in namespace deployment-5988 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:52:50.132: INFO: Deployment test-deployment-clvdc has an updated status
  STEP: patching the Statefulset Status @ 04/13/24 13:52:50.132
  Apr 13 13:52:50.132: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 13 13:52:50.138: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/13/24 13:52:50.138
  Apr 13 13:52:50.140: INFO: Observed &Deployment event: ADDED
  Apr 13 13:52:50.140: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-clvdc-5d576bd769"}
  Apr 13 13:52:50.140: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.140: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-clvdc-5d576bd769"}
  Apr 13 13:52:50.140: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 13 13:52:50.141: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:48 +0000 UTC 2024-04-13 13:52:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-clvdc-5d576bd769" is progressing.}
  Apr 13 13:52:50.141: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-clvdc-5d576bd769" has successfully progressed.}
  Apr 13 13:52:50.141: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-13 13:52:49 +0000 UTC 2024-04-13 13:52:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-clvdc-5d576bd769" has successfully progressed.}
  Apr 13 13:52:50.141: INFO: Observed deployment test-deployment-clvdc in namespace deployment-5988 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 13 13:52:50.141: INFO: Observed &Deployment event: MODIFIED
  Apr 13 13:52:50.141: INFO: Found deployment test-deployment-clvdc in namespace deployment-5988 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 13 13:52:50.141: INFO: Deployment test-deployment-clvdc has a patched status
  Apr 13 13:52:50.146: INFO: Deployment "test-deployment-clvdc":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-clvdc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5988",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "755fc352-f3ba-4c9c-96b5-f2b91ff81273",
      ResourceVersion: (string) (len=5) "44676",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848613168,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613168,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613170,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613170,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613170,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613170,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-clvdc-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 13 13:52:50.150: INFO: New ReplicaSet "test-deployment-clvdc-5d576bd769" of Deployment "test-deployment-clvdc":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-clvdc-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5988",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "699d9166-0026-4136-9df0-eec081ae8fa8",
      ResourceVersion: (string) (len=5) "44672",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848613168,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-clvdc",
          UID: (types.UID) (len=36) "755fc352-f3ba-4c9c-96b5-f2b91ff81273",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613168,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 37 35 35  |k:{\"uid\":\"755|
              00000120  66 63 33 35 32 2d 66 33  62 61 2d 34 63 39 63 2d  |fc352-f3ba-4c9c-|
              00000130  39 36 62 35 2d 66 32 62  39 31 66 66 38 31 32 37  |96b5-f2b91ff8127|
              00000140  33 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |3\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613169,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 13 13:52:50.154: INFO: Pod "test-deployment-clvdc-5d576bd769-mlm7h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-clvdc-5d576bd769-mlm7h",
      GenerateName: (string) (len=33) "test-deployment-clvdc-5d576bd769-",
      Namespace: (string) (len=15) "deployment-5988",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a22dc688-ca5b-4ff9-b9a1-9be5e9ba1be4",
      ResourceVersion: (string) (len=5) "44671",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848613168,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-clvdc-5d576bd769",
          UID: (types.UID) (len=36) "699d9166-0026-4136-9df0-eec081ae8fa8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613168,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 36 39 39 64 39 31 36  36 2d 30 30 32 36 2d 34  |"699d9166-0026-4|
              000000a0  31 33 36 2d 39 64 66 30  2d 65 65 63 30 38 31 61  |136-9df0-eec081a|
              000000b0  65 38 66 61 38 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |e8fa8\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613169,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 37  32 2e 32 34 37 5c 22 7d  |2.168.172.247\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9cl9l",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9cl9l",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-82-63",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613169,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613168,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613169,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613169,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848613168,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.82.63",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.82.63"
        }
      },
      PodIP: (string) (len=15) "192.168.172.247",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.172.247"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848613168,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848613168,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://70f59c96bad4b66946d45be5849611ad238c78084aaf394d161a1d6461b429d0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 13 13:52:50.156: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5988" for this suite. @ 04/13/24 13:52:50.16
• [2.111 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 04/13/24 13:52:50.167
  Apr 13 13:52:50.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename daemonsets @ 04/13/24 13:52:50.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:50.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:50.187
  Apr 13 13:52:50.210: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/13/24 13:52:50.215
  Apr 13 13:52:50.219: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:50.219: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:50.222: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:52:50.222: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:52:50.454394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:51.221: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:51.221: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:51.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:52:51.225: INFO: Node ip-172-31-35-229 is running 0 daemon pod, expected 1
  E0413 13:52:51.455072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:52.219: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:52.220: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:52.223: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:52:52.223: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/13/24 13:52:52.238
  STEP: Check that daemon pods images are updated. @ 04/13/24 13:52:52.249
  Apr 13 13:52:52.253: INFO: Wrong image for pod: daemon-set-4hr4r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:52.253: INFO: Wrong image for pod: daemon-set-cpn5m. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:52.253: INFO: Wrong image for pod: daemon-set-ztwbn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:52.257: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:52.257: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0413 13:52:52.455611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:53.254: INFO: Wrong image for pod: daemon-set-4hr4r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:53.254: INFO: Wrong image for pod: daemon-set-cpn5m. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:53.254: INFO: Pod daemon-set-qdsrh is not available
  Apr 13 13:52:53.257: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:53.257: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0413 13:52:53.456009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:54.255: INFO: Wrong image for pod: daemon-set-4hr4r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:54.255: INFO: Pod daemon-set-dgfwf is not available
  Apr 13 13:52:54.259: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:54.259: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0413 13:52:54.461104      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:55.253: INFO: Wrong image for pod: daemon-set-4hr4r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 13 13:52:55.253: INFO: Pod daemon-set-dgfwf is not available
  Apr 13 13:52:55.257: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:55.257: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0413 13:52:55.461564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:56.254: INFO: Pod daemon-set-5crz8 is not available
  Apr 13 13:52:56.257: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:56.257: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/13/24 13:52:56.257
  Apr 13 13:52:56.261: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:56.261: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:56.265: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 13 13:52:56.265: INFO: Node ip-172-31-82-63 is running 0 daemon pod, expected 1
  E0413 13:52:56.462409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:57.263: INFO: DaemonSet pods can't tolerate node ip-172-31-28-251 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:57.263: INFO: DaemonSet pods can't tolerate node ip-172-31-84-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 13 13:52:57.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 13 13:52:57.267: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/13/24 13:52:57.284
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1545, will wait for the garbage collector to delete the pods @ 04/13/24 13:52:57.284
  Apr 13 13:52:57.345: INFO: Deleting DaemonSet.extensions daemon-set took: 7.241728ms
  Apr 13 13:52:57.445: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.212504ms
  E0413 13:52:57.462847      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:52:58.462893      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:52:58.750: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 13 13:52:58.750: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 13 13:52:58.753: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44903"},"items":null}

  Apr 13 13:52:58.757: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44903"},"items":null}

  Apr 13 13:52:58.770: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1545" for this suite. @ 04/13/24 13:52:58.774
• [8.612 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 04/13/24 13:52:58.78
  Apr 13 13:52:58.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename endpointslice @ 04/13/24 13:52:58.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:52:58.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:52:58.799
  E0413 13:52:59.463661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:00.463838      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:01.463949      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:02.464661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:03.464833      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 04/13/24 13:53:03.864
  E0413 13:53:04.464955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:05.465103      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:06.465433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:07.465850      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:08.466199      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 04/13/24 13:53:08.873
  E0413 13:53:09.466708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:10.467569      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:11.467619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:12.467708      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:13.467926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/13/24 13:53:13.882
  E0413 13:53:14.468772      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:15.468879      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:16.469784      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:17.470877      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:18.471528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 04/13/24 13:53:18.892
  Apr 13 13:53:18.912: INFO: EndpointSlice for Service endpointslice-2982/example-named-port not found
  E0413 13:53:19.472632      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:20.472739      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:21.472940      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:22.473853      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:23.473973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:24.474032      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:25.474136      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:26.474563      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:27.475560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:28.475640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:28.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2982" for this suite. @ 04/13/24 13:53:28.923
• [30.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 04/13/24 13:53:28.931
  Apr 13 13:53:28.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename resourcequota @ 04/13/24 13:53:28.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:28.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:28.951
  STEP: Creating a ResourceQuota @ 04/13/24 13:53:28.955
  STEP: Getting a ResourceQuota @ 04/13/24 13:53:28.959
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/13/24 13:53:28.963
  STEP: Patching the ResourceQuota @ 04/13/24 13:53:28.966
  STEP: Deleting a Collection of ResourceQuotas @ 04/13/24 13:53:28.972
  STEP: Verifying the deleted ResourceQuota @ 04/13/24 13:53:28.981
  Apr 13 13:53:28.984: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3806" for this suite. @ 04/13/24 13:53:28.987
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 04/13/24 13:53:28.994
  Apr 13 13:53:28.994: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:53:28.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:29.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:29.013
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:53:29.017
  E0413 13:53:29.475692      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:30.475889      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:53:31.035
  Apr 13 13:53:31.038: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-5f85ac68-f617-4343-a900-59a8891203b4 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:53:31.053
  Apr 13 13:53:31.070: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4133" for this suite. @ 04/13/24 13:53:31.074
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 04/13/24 13:53:31.083
  Apr 13 13:53:31.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename downward-api @ 04/13/24 13:53:31.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:31.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:31.104
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 13:53:31.108
  E0413 13:53:31.476672      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:32.477744      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:33.478460      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:34.478538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:53:35.131
  Apr 13 13:53:35.135: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-b0b67d3a-de34-4df7-b2c0-fa4c7be86113 container client-container: <nil>
  STEP: delete the pod @ 04/13/24 13:53:35.141
  Apr 13 13:53:35.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4013" for this suite. @ 04/13/24 13:53:35.158
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 04/13/24 13:53:35.165
  Apr 13 13:53:35.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 13:53:35.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:35.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:35.184
  STEP: Creating configMap configmap-2224/configmap-test-0b4c0030-aaf3-4a44-bf1e-51ce43e7fa50 @ 04/13/24 13:53:35.188
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:53:35.192
  E0413 13:53:35.479429      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:36.479652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:37.480430      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:38.480536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:53:39.216
  Apr 13 13:53:39.220: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-cec3cb56-611a-4d37-a0da-fb90a5b8ba4f container env-test: <nil>
  STEP: delete the pod @ 04/13/24 13:53:39.227
  Apr 13 13:53:39.242: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2224" for this suite. @ 04/13/24 13:53:39.246
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/13/24 13:53:39.252
  Apr 13 13:53:39.252: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 13:53:39.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:39.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:39.272
  STEP: creating a Pod with a static label @ 04/13/24 13:53:39.28
  STEP: watching for Pod to be ready @ 04/13/24 13:53:39.289
  Apr 13 13:53:39.290: INFO: observed Pod pod-test in namespace pods-1923 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 13 13:53:39.293: INFO: observed Pod pod-test in namespace pods-1923 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  }]
  Apr 13 13:53:39.317: INFO: observed Pod pod-test in namespace pods-1923 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  }]
  E0413 13:53:39.481280      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:40.481331      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:40.780: INFO: Found Pod pod-test in namespace pods-1923 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:40 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-13 13:53:39 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/13/24 13:53:40.785
  STEP: getting the Pod and ensuring that it's patched @ 04/13/24 13:53:40.794
  STEP: replacing the Pod's status Ready condition to False @ 04/13/24 13:53:40.798
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/13/24 13:53:40.809
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/13/24 13:53:40.809
  STEP: watching for the Pod to be deleted @ 04/13/24 13:53:40.818
  Apr 13 13:53:40.820: INFO: observed event type MODIFIED
  E0413 13:53:41.481885      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:42.481984      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:42.788: INFO: observed event type MODIFIED
  Apr 13 13:53:43.018: INFO: observed event type MODIFIED
  E0413 13:53:43.483065      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:43.793: INFO: observed event type MODIFIED
  Apr 13 13:53:43.811: INFO: observed event type MODIFIED
  Apr 13 13:53:43.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1923" for this suite. @ 04/13/24 13:53:43.825
• [4.579 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 04/13/24 13:53:43.832
  Apr 13 13:53:43.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename services @ 04/13/24 13:53:43.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:43.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:43.851
  STEP: creating service in namespace services-6949 @ 04/13/24 13:53:43.854
  STEP: creating service affinity-clusterip in namespace services-6949 @ 04/13/24 13:53:43.854
  STEP: creating replication controller affinity-clusterip in namespace services-6949 @ 04/13/24 13:53:43.865
  I0413 13:53:43.873705      21 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-6949, replica count: 3
  E0413 13:53:44.484028      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:45.484122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:46.484305      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 13:53:46.924063      21 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 13:53:46.932: INFO: Creating new exec pod
  E0413 13:53:47.484730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:48.484926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:49.485790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:49.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6949 exec execpod-affinityjgcch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 13 13:53:50.033: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 13 13:53:50.033: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:53:50.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6949 exec execpod-affinityjgcch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.244 80'
  Apr 13 13:53:50.124: INFO: stderr: "+ nc -v -t -w 2 10.152.183.244 80\n+ echo hostName\nConnection to 10.152.183.244 80 port [tcp/http] succeeded!\n"
  Apr 13 13:53:50.124: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 13 13:53:50.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=services-6949 exec execpod-affinityjgcch -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.244:80/ ; done'
  Apr 13 13:53:50.264: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.244:80/\n"
  Apr 13 13:53:50.264: INFO: stdout: "\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647\naffinity-clusterip-qk647"
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.264: INFO: Received response from host: affinity-clusterip-qk647
  Apr 13 13:53:50.265: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-6949, will wait for the garbage collector to delete the pods @ 04/13/24 13:53:50.28
  Apr 13 13:53:50.341: INFO: Deleting ReplicationController affinity-clusterip took: 6.656038ms
  Apr 13 13:53:50.441: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.576109ms
  E0413 13:53:50.485859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:51.486864      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:52.487031      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:53.487201      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:53:53.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6949" for this suite. @ 04/13/24 13:53:53.762
• [9.937 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/13/24 13:53:53.769
  Apr 13 13:53:53.769: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:53:53.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:53.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:53.787
  STEP: Creating secret with name projected-secret-test-84c2cf6f-78a7-422e-8dd6-f3a4542e053a @ 04/13/24 13:53:53.791
  STEP: Creating a pod to test consume secrets @ 04/13/24 13:53:53.797
  E0413 13:53:54.487331      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:55.487547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:56.488536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:57.488996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:53:57.823
  Apr 13 13:53:57.827: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-0a4856cc-8bc0-499b-8cca-689fc73cc2a1 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:53:57.833
  Apr 13 13:53:57.850: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-927" for this suite. @ 04/13/24 13:53:57.854
• [4.091 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 04/13/24 13:53:57.861
  Apr 13 13:53:57.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context-test @ 04/13/24 13:53:57.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:53:57.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:53:57.88
  E0413 13:53:58.489845      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:53:59.490033      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:00.490481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:01.490653      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:54:01.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-725" for this suite. @ 04/13/24 13:54:01.917
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 04/13/24 13:54:01.932
  Apr 13 13:54:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 13:54:01.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:54:01.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:54:01.955
  STEP: Creating configMap with name projected-configmap-test-volume-f00931cb-8f07-43b4-b063-9f8882732765 @ 04/13/24 13:54:01.959
  STEP: Creating a pod to test consume configMaps @ 04/13/24 13:54:01.966
  E0413 13:54:02.490764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:03.490952      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 13:54:03.984
  Apr 13 13:54:03.987: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-3147ce17-f1d2-4d4d-bace-c1b464be1f3b container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 13:54:03.993
  Apr 13 13:54:04.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1461" for this suite. @ 04/13/24 13:54:04.01
• [2.085 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 04/13/24 13:54:04.017
  Apr 13 13:54:04.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename field-validation @ 04/13/24 13:54:04.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:54:04.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:54:04.037
  Apr 13 13:54:04.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 13:54:04.492059      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:05.493110      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:06.493181      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0413 13:54:06.576888      21 warnings.go:70] unknown field "alpha"
  W0413 13:54:06.576902      21 warnings.go:70] unknown field "beta"
  W0413 13:54:06.576905      21 warnings.go:70] unknown field "delta"
  W0413 13:54:06.576908      21 warnings.go:70] unknown field "epsilon"
  W0413 13:54:06.576910      21 warnings.go:70] unknown field "gamma"
  Apr 13 13:54:07.121: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5658" for this suite. @ 04/13/24 13:54:07.125
• [3.115 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/13/24 13:54:07.132
  Apr 13 13:54:07.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename disruption @ 04/13/24 13:54:07.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:54:07.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:54:07.154
  STEP: creating the pdb @ 04/13/24 13:54:07.158
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:54:07.162
  E0413 13:54:07.493855      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:08.493993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 04/13/24 13:54:09.167
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:54:09.175
  E0413 13:54:09.494088      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:10.494191      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 04/13/24 13:54:11.18
  STEP: Waiting for the pdb to be processed @ 04/13/24 13:54:11.19
  STEP: Waiting for the pdb to be deleted @ 04/13/24 13:54:11.202
  Apr 13 13:54:11.206: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1671" for this suite. @ 04/13/24 13:54:11.209
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 04/13/24 13:54:11.216
  Apr 13 13:54:11.216: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pv @ 04/13/24 13:54:11.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:54:11.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:54:11.239
  STEP: Creating initial PV and PVC @ 04/13/24 13:54:11.242
  Apr 13 13:54:11.242: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9475" @ 04/13/24 13:54:11.257
  STEP: Listing PVCs in namespace "pv-9475" @ 04/13/24 13:54:11.26
  STEP: Reading "pvc-dlgkz" Status @ 04/13/24 13:54:11.264
  STEP: Reading "pv-9475-4xqcg" Status @ 04/13/24 13:54:11.268
  STEP: Patching "pvc-dlgkz" Status @ 04/13/24 13:54:11.275
  STEP: Patching "pv-9475-4xqcg" Status @ 04/13/24 13:54:11.28
  STEP: Updating "pvc-dlgkz" Status @ 04/13/24 13:54:11.287
  STEP: Updating "pv-9475-4xqcg" Status @ 04/13/24 13:54:11.296
  Apr 13 13:54:11.306: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Apr 13 13:54:11.306: INFO: Deleting PersistentVolumeClaim "pvc-dlgkz"
  Apr 13 13:54:11.313: INFO: Deleting PersistentVolume "pv-9475-4xqcg"
  Apr 13 13:54:11.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9475" for this suite. @ 04/13/24 13:54:11.322
• [0.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 04/13/24 13:54:11.331
  Apr 13 13:54:11.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename chunking @ 04/13/24 13:54:11.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 13:54:11.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 13:54:11.349
  STEP: creating a large number of resources @ 04/13/24 13:54:11.353
  E0413 13:54:11.495097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:12.495679      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:13.496663      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:14.496713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:15.496781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:16.497433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:17.498372      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:18.499188      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:19.499818      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:20.500709      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:21.501559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:22.502454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:23.502746      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:24.503524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:25.503978      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:26.504219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:27.504426      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:28.504619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 04/13/24 13:54:29.038
  Apr 13 13:54:29.087: INFO: Retrieved 40/40 results with rv 46111 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 04/13/24 13:54:29.087
  E0413 13:54:29.504667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:30.504936      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:31.505068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:32.505755      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:33.506661      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:34.507670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:35.507754      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:36.507972      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:37.508019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:38.508922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:39.509152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:40.509300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:41.510033      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:42.510712      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:43.511557      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:44.511825      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:45.512046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:46.512159      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:47.512713      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:48.512928      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:54:49.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:54:49.513035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:50.513190      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:51.513335      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:52.513478      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:53.514511      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:54.514604      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:55.515546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:56.515824      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:57.516848      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:58.517022      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:54:59.517416      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:00.517492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:01.517707      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:02.518745      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:03.518836      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:04.518959      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:05.519539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:06.519663      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:07.520046      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:08.520179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:55:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:55:09.520734      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:10.521615      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:11.521748      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:12.522122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:13.522414      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:14.522491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:15.523515      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:16.523627      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:17.523667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:18.523838      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:19.524019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:20.524108      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:21.524289      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:22.524574      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:23.524745      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:24.524941      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:25.525127      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:26.525227      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:27.525812      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:28.526436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:55:29.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:55:29.527193      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:30.527330      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:31.527495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:32.528136      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:33.528301      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:34.528495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:35.528683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:36.528885      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:37.528975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:38.529161      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:39.529980      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:40.530154      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:41.530322      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:42.531311      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:43.531394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:44.531497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:45.531656      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:46.531830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:47.531941      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:48.532243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:55:49.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:55:49.533034      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:50.533115      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:51.533231      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:52.533919      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:53.534908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:54.535558      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:55.536132      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:56.536252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:57.536705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:58.536906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:55:59.537093      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:00.537359      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:01.537463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:02.537580      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:03.537758      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:04.537896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:05.538000      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:06.538105      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:07.539138      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:08.539245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:56:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:56:09.539662      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:10.539762      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:11.539947      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:12.540785      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:13.540880      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:14.541657      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:15.541763      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:16.542261      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:17.542695      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:18.543541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:19.543636      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:20.543813      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:21.544161      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:22.544916      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:23.544988      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:24.545172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:25.545266      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:26.545436      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:27.545664      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:28.545917      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:56:29.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:56:29.546224      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:30.546463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:31.546637      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:32.547526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:33.547622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:34.548112      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:35.548325      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:36.548453      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:37.549480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:38.549814      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:39.549916      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:40.550154      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:41.550323      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:42.551052      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:43.552058      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:44.552239      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:45.552435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:46.553309      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:47.553726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:48.553855      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:56:49.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:56:49.554179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:50.554288      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:51.554464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:52.554553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:53.555539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:54.555723      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:55.555909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:56.556089      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:57.556553      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:58.556826      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:56:59.556975      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:00.557219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:01.557410      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:02.557525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:03.557618      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:04.557954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:05.558450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:06.558539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:07.559005      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:08.559544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:57:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:57:09.560551      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:10.560639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:11.561720      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:12.561781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:13.562773      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:14.563521      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:15.563697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:16.563871      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:17.564904      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:18.565075      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:19.566126      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:20.566323      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:21.566470      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:22.566559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:23.566668      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:24.567534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:25.567718      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:26.568585      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:27.569658      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:28.570003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:57:29.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:57:29.571072      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:30.571179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:31.571270      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:32.571535      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:33.571794      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:34.571973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:35.572579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:36.572839      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:37.573719      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:38.573819      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:39.574020      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:40.574117      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:41.574299      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:42.574460      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:43.574536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:44.575546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:45.575731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:46.575925      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:47.576922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:48.577047      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:57:49.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:57:49.577541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:50.577590      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:51.577791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:52.578790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:53.578868      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:54.579533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:55.580464      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:56.580554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:57.581498      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:58.582267      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:57:59.582449      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:00.582623      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:01.583516      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:02.583618      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:03.583728      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:04.583800      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:05.583909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:06.584049      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:07.585008      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:08.585102      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:58:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:58:09.585922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:10.586165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:11.586435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:12.586525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:13.587554      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:14.588208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:15.588343      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:16.588569      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:17.588880      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:18.589075      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:19.589245      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:20.589418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:21.589922      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:22.590796      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:23.591544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:24.592137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:25.592237      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:26.592409      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:27.592741      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:28.592945      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:58:29.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:58:29.593003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:30.593795      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:31.593905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:32.594782      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:33.594883      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:34.595523      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:35.595582      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:36.595687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:37.595793      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:38.595958      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:39.596196      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:40.596384      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:41.596570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:42.597238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:43.597342      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:44.597530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:45.597691      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:46.598097      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:47.598368      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:48.598454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:58:49.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:58:49.598555      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:50.599532      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:51.599718      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:52.599775      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:53.599869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:54.600851      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:55.600943      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:56.601170      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:57.601606      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:58.602599      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:58:59.603520      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:00.603704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:01.603898      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:02.604009      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:03.604950      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:04.605182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:05.605287      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:06.605392      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:07.605706      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:08.605926      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:59:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:59:09.606711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:10.607534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:11.607633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:12.607721      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:13.608013      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:14.608201      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:15.608386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:16.608493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:17.608589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:18.609454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:19.609559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:20.609778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:21.610584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:22.610823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:23.610908      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:24.611017      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:25.611542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:26.611701      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:27.611976      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:28.612137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:59:29.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:59:29.612226      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:30.612329      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:31.612491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:32.613252      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:33.613413      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:34.614492      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:35.614594      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:36.615521      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:37.615589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:38.615792      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:39.615980      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:40.616148      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:41.616578      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:42.616675      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:43.616807      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:44.616912      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:45.617110      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:46.617201      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:47.617655      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:48.617769      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 13:59:49.094: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 13:59:49.617898      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:50.618122      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:51.618294      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:52.618477      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:53.618577      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:54.618687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:55.618816      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:56.619548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:57.619893      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:58.620920      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 13:59:59.621704      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:00.621818      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:01.621909      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:02.622123      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:03.622214      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:04.622460      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:05.622519      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:06.623504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:07.623585      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:08.623687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:00:09.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 14:00:09.624683      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:10.624830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:11.624931      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:12.625940      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:13.626044      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:14.626236      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:15.626308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:16.626454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:17.626542      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:18.626640      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:19.627564      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:20.628185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:21.628354      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:22.628447      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:23.628687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:24.628790      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:25.628946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:26.629002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:27.630015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:28.630458      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:00:29.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 14:00:29.630219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:30.630403      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:31.630491      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:32.631550      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:33.632182      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:34.632257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:35.633037      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:36.633146      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:37.633733      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:38.633862      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:39.634050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:40.634317      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:41.634467      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:42.634572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:43.635544      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:44.635717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:45.635896      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:46.636000      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:47.636190      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:48.636378      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:00:49.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 14:00:49.637312      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:50.638234      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:51.638434      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:52.638534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:53.638621      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:54.639536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:55.639727      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:56.639814      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:57.640164      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:58.640340      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:00:59.640476      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:00.640576      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:01.640688      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:02.640786      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:03.641015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:04.641098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:05.641196      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:06.641296      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:07.641375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:08.641561      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:01:09.092: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 14:01:09.641638      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:10.642260      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:11.642456      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:12.642533      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:13.643540      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:14.643727      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:15.644137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:16.644243      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:17.644732      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:18.644821      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:19.645751      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:20.645954      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:21.646142      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:22.646238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:23.646465      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:24.647547      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:25.647736      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:26.647932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:27.648025      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:28.648205      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:01:29.093: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDYxMTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0413 14:01:29.649021      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:30.649208      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:31.649319      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:32.649414      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:33.649654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:34.649843      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:35.650056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:36.650264      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:37.650852      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:38.650947      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:39.651527      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:40.651646      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:41.651809      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:42.651887      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:43.652027      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:44.652115      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:45.652994      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:46.653100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:47.653440      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:48.653561      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:01:49.092: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Apr 13 14:01:49.092: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 04/13/24 14:01:49.092
  STEP: retrieving all remaining pages @ 04/13/24 14:01:49.096
  Apr 13 14:01:49.101: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Apr 13 14:01:49.105: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Apr 13 14:01:49.109: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Apr 13 14:01:49.116: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Apr 13 14:01:49.119: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Apr 13 14:01:49.124: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Apr 13 14:01:49.128: INFO: Retrieved 40/40 results with rv 46946 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY5NDYsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Apr 13 14:01:49.132: INFO: Retrieved 40/40 results with rv 46946 and continue 
  Apr 13 14:01:49.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-8905" for this suite. @ 04/13/24 14:01:49.136
• [457.810 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/13/24 14:01:49.142
  Apr 13 14:01:49.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename watch @ 04/13/24 14:01:49.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:01:49.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:01:49.168
  STEP: creating a watch on configmaps @ 04/13/24 14:01:49.172
  STEP: creating a new configmap @ 04/13/24 14:01:49.174
  STEP: modifying the configmap once @ 04/13/24 14:01:49.178
  STEP: closing the watch once it receives two notifications @ 04/13/24 14:01:49.187
  Apr 13 14:01:49.187: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8317  81c5a47a-f608-4bc9-8567-79e9984274f0 46956 0 2024-04-13 14:01:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-13 14:01:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 14:01:49.187: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8317  81c5a47a-f608-4bc9-8567-79e9984274f0 46957 0 2024-04-13 14:01:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-13 14:01:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/13/24 14:01:49.187
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/13/24 14:01:49.196
  STEP: deleting the configmap @ 04/13/24 14:01:49.197
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/13/24 14:01:49.202
  Apr 13 14:01:49.202: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8317  81c5a47a-f608-4bc9-8567-79e9984274f0 46958 0 2024-04-13 14:01:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-13 14:01:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 14:01:49.203: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8317  81c5a47a-f608-4bc9-8567-79e9984274f0 46959 0 2024-04-13 14:01:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-13 14:01:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 13 14:01:49.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8317" for this suite. @ 04/13/24 14:01:49.206
• [0.070 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 04/13/24 14:01:49.212
  Apr 13 14:01:49.212: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 14:01:49.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:01:49.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:01:49.23
  STEP: Creating configMap with name configmap-test-volume-59505dc4-b187-4281-a453-45d76bec87b3 @ 04/13/24 14:01:49.233
  STEP: Creating a pod to test consume configMaps @ 04/13/24 14:01:49.24
  E0413 14:01:49.653636      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:50.653865      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:51.654861      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:52.655560      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:01:53.265
  Apr 13 14:01:53.269: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-344cdc7c-c02a-404d-a574-b4a1704e25d0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 14:01:53.288
  Apr 13 14:01:53.301: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2984" for this suite. @ 04/13/24 14:01:53.305
• [4.099 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 04/13/24 14:01:53.312
  Apr 13 14:01:53.312: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context @ 04/13/24 14:01:53.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:01:53.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:01:53.33
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/13/24 14:01:53.334
  E0413 14:01:53.655938      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:54.656218      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:55.657100      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:56.657320      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:01:57.354
  Apr 13 14:01:57.358: INFO: Trying to get logs from node ip-172-31-82-63 pod security-context-6ed6bb05-08af-4a5f-8ee9-4503b87634f4 container test-container: <nil>
  STEP: delete the pod @ 04/13/24 14:01:57.364
  Apr 13 14:01:57.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2530" for this suite. @ 04/13/24 14:01:57.382
• [4.078 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 04/13/24 14:01:57.389
  Apr 13 14:01:57.389: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 14:01:57.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:01:57.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:01:57.41
  STEP: Creating the pod @ 04/13/24 14:01:57.413
  E0413 14:01:57.658238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:58.658493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:01:59.659188      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:01:59.954: INFO: Successfully updated pod "annotationupdatee7b0b823-2481-44a9-b71f-a92ac29bf6f4"
  E0413 14:02:00.659203      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:01.659573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:02.659671      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:03.659788      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:02:03.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8658" for this suite. @ 04/13/24 14:02:03.982
• [6.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/13/24 14:02:03.99
  Apr 13 14:02:03.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename containers @ 04/13/24 14:02:03.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:02:04.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:02:04.01
  STEP: Creating a pod to test override arguments @ 04/13/24 14:02:04.014
  E0413 14:02:04.660710      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:05.660778      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:06.660905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:07.661589      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:02:08.035
  Apr 13 14:02:08.040: INFO: Trying to get logs from node ip-172-31-82-63 pod client-containers-f3ea64e3-c4a1-4fc1-846b-c841af743804 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 14:02:08.046
  Apr 13 14:02:08.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5003" for this suite. @ 04/13/24 14:02:08.066
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/13/24 14:02:08.073
  Apr 13 14:02:08.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename dns @ 04/13/24 14:02:08.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:02:08.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:02:08.091
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/13/24 14:02:08.095
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/13/24 14:02:08.095
  STEP: creating a pod to probe DNS @ 04/13/24 14:02:08.095
  STEP: submitting the pod to kubernetes @ 04/13/24 14:02:08.095
  E0413 14:02:08.661691      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:09.661807      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/13/24 14:02:10.115
  STEP: looking for the results for each expected name from probers @ 04/13/24 14:02:10.119
  Apr 13 14:02:10.138: INFO: DNS probes using dns-1834/dns-test-fbac5969-d3cf-44c3-9244-65649f275727 succeeded

  STEP: deleting the pod @ 04/13/24 14:02:10.138
  Apr 13 14:02:10.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1834" for this suite. @ 04/13/24 14:02:10.153
• [2.086 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 04/13/24 14:02:10.159
  Apr 13 14:02:10.159: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 14:02:10.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:02:10.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:02:10.178
  STEP: Creating configMap with name projected-configmap-test-volume-map-b8c20b4c-85fa-4137-b803-d556a38ff673 @ 04/13/24 14:02:10.182
  STEP: Creating a pod to test consume configMaps @ 04/13/24 14:02:10.187
  E0413 14:02:10.661900      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:11.662063      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:12.662861      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:13.662960      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:02:14.208
  Apr 13 14:02:14.211: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-configmaps-656c6a92-0637-444b-af73-e04749ef06a9 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 14:02:14.217
  Apr 13 14:02:14.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3477" for this suite. @ 04/13/24 14:02:14.234
• [4.081 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 04/13/24 14:02:14.24
  Apr 13 14:02:14.240: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename emptydir @ 04/13/24 14:02:14.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:02:14.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:02:14.264
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/13/24 14:02:14.268
  E0413 14:02:14.663649      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:15.663742      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:16.664493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:17.664579      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:02:18.291
  Apr 13 14:02:18.294: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-b2c81736-0b19-4828-b579-355fa8bc32bb container test-container: <nil>
  STEP: delete the pod @ 04/13/24 14:02:18.301
  Apr 13 14:02:18.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4233" for this suite. @ 04/13/24 14:02:18.322
• [4.088 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 04/13/24 14:02:18.328
  Apr 13 14:02:18.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename statefulset @ 04/13/24 14:02:18.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:02:18.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:02:18.348
  STEP: Creating service test in namespace statefulset-2084 @ 04/13/24 14:02:18.351
  STEP: Creating a new StatefulSet @ 04/13/24 14:02:18.356
  Apr 13 14:02:18.366: INFO: Found 0 stateful pods, waiting for 3
  E0413 14:02:18.664870      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:19.664965      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:20.665056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:21.665226      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:22.665861      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:23.665955      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:24.666041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:25.666234      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:26.666484      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:27.666571      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:02:28.368: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 14:02:28.368: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 14:02:28.368: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/13/24 14:02:28.379
  Apr 13 14:02:28.400: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/13/24 14:02:28.4
  E0413 14:02:28.666796      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:29.666810      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:30.666869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:31.667566      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:32.667804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:33.667906      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:34.668004      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:35.668200      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:36.668977      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:37.669078      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/13/24 14:02:38.409
  STEP: Performing a canary update @ 04/13/24 14:02:38.409
  Apr 13 14:02:38.428: INFO: Updating stateful set ss2
  Apr 13 14:02:38.437: INFO: Waiting for Pod statefulset-2084/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0413 14:02:38.670168      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:39.670263      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:40.670454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:41.671530      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:42.671611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:43.671859      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:44.671991      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:45.672164      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:46.672345      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:47.672441      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/13/24 14:02:48.438
  Apr 13 14:02:48.470: INFO: Found 1 stateful pods, waiting for 3
  E0413 14:02:48.672944      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:49.673967      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:50.674151      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:51.675029      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:52.675548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:53.675721      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:54.675874      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:55.676056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:56.676152      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:57.676206      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:02:58.471: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 14:02:58.471: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 13 14:02:58.471: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/13/24 14:02:58.478
  Apr 13 14:02:58.498: INFO: Updating stateful set ss2
  Apr 13 14:02:58.507: INFO: Waiting for Pod statefulset-2084/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0413 14:02:58.677308      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:02:59.677418      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:00.677619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:01.677726      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:02.677841      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:03.677953      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:04.678076      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:05.678180      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:06.678402      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:07.678508      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:08.529: INFO: Updating stateful set ss2
  Apr 13 14:03:08.537: INFO: Waiting for StatefulSet statefulset-2084/ss2 to complete update
  Apr 13 14:03:08.537: INFO: Waiting for Pod statefulset-2084/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0413 14:03:08.678946      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:09.679050      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:10.679148      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:11.679317      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:12.680080      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:13.680300      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:14.680394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:15.680691      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:16.680791      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:17.681777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:18.538: INFO: Deleting all statefulset in ns statefulset-2084
  Apr 13 14:03:18.541: INFO: Scaling statefulset ss2 to 0
  E0413 14:03:18.681863      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:19.682065      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:20.682172      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:21.682407      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:22.682512      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:23.682584      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:24.682705      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:25.682781      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:26.682973      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:27.683055      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:28.555: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 13 14:03:28.559: INFO: Deleting statefulset ss2
  Apr 13 14:03:28.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2084" for this suite. @ 04/13/24 14:03:28.58
• [70.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 04/13/24 14:03:28.588
  Apr 13 14:03:28.588: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename events @ 04/13/24 14:03:28.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:28.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:28.608
  STEP: creating a test event @ 04/13/24 14:03:28.611
  STEP: listing all events in all namespaces @ 04/13/24 14:03:28.616
  STEP: patching the test event @ 04/13/24 14:03:28.619
  STEP: fetching the test event @ 04/13/24 14:03:28.626
  STEP: updating the test event @ 04/13/24 14:03:28.629
  STEP: getting the test event @ 04/13/24 14:03:28.64
  STEP: deleting the test event @ 04/13/24 14:03:28.644
  STEP: listing all events in all namespaces @ 04/13/24 14:03:28.651
  Apr 13 14:03:28.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-684" for this suite. @ 04/13/24 14:03:28.659
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 04/13/24 14:03:28.666
  Apr 13 14:03:28.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename configmap @ 04/13/24 14:03:28.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:28.682
  E0413 14:03:28.683481      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:28.685
  STEP: Creating configMap with name configmap-test-volume-map-fdb12957-d67a-4109-8425-9462a1ad667b @ 04/13/24 14:03:28.688
  STEP: Creating a pod to test consume configMaps @ 04/13/24 14:03:28.693
  E0413 14:03:29.683633      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:30.683730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:31.683823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:32.683831      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:03:32.718
  Apr 13 14:03:32.722: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-configmaps-25f880d0-5605-4be9-b02f-d0ed6d078973 container agnhost-container: <nil>
  STEP: delete the pod @ 04/13/24 14:03:32.729
  Apr 13 14:03:32.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6291" for this suite. @ 04/13/24 14:03:32.748
• [4.089 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 04/13/24 14:03:32.756
  Apr 13 14:03:32.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename security-context-test @ 04/13/24 14:03:32.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:32.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:32.775
  E0413 14:03:33.683963      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:34.684149      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:35.684265      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:36.684386      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:36.810: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7027" for this suite. @ 04/13/24 14:03:36.814
• [4.065 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 04/13/24 14:03:36.821
  Apr 13 14:03:36.821: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename webhook @ 04/13/24 14:03:36.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:36.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:36.842
  STEP: Setting up server cert @ 04/13/24 14:03:36.866
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/13/24 14:03:37.043
  STEP: Deploying the webhook pod @ 04/13/24 14:03:37.052
  STEP: Wait for the deployment to be ready @ 04/13/24 14:03:37.066
  Apr 13 14:03:37.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0413 14:03:37.684498      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:38.684587      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/13/24 14:03:39.089
  STEP: Verifying the service has paired with the endpoint @ 04/13/24 14:03:39.1
  E0413 14:03:39.685286      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:40.100: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/13/24 14:03:40.109
  STEP: create a pod @ 04/13/24 14:03:40.122
  E0413 14:03:40.686110      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:41.686310      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/13/24 14:03:42.14
  Apr 13 14:03:42.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=webhook-883 attach --namespace=webhook-883 to-be-attached-pod -i -c=container1'
  Apr 13 14:03:42.192: INFO: rc: 1
  Apr 13 14:03:42.237: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-883" for this suite. @ 04/13/24 14:03:42.242
  STEP: Destroying namespace "webhook-markers-9811" for this suite. @ 04/13/24 14:03:42.25
• [5.436 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 04/13/24 14:03:42.257
  Apr 13 14:03:42.257: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename ingress @ 04/13/24 14:03:42.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:42.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:42.275
  STEP: getting /apis @ 04/13/24 14:03:42.279
  STEP: getting /apis/networking.k8s.io @ 04/13/24 14:03:42.282
  STEP: getting /apis/networking.k8s.iov1 @ 04/13/24 14:03:42.284
  STEP: creating @ 04/13/24 14:03:42.285
  STEP: getting @ 04/13/24 14:03:42.305
  STEP: listing @ 04/13/24 14:03:42.31
  STEP: watching @ 04/13/24 14:03:42.313
  Apr 13 14:03:42.313: INFO: starting watch
  STEP: cluster-wide listing @ 04/13/24 14:03:42.315
  STEP: cluster-wide watching @ 04/13/24 14:03:42.318
  Apr 13 14:03:42.318: INFO: starting watch
  STEP: patching @ 04/13/24 14:03:42.319
  STEP: updating @ 04/13/24 14:03:42.326
  Apr 13 14:03:42.335: INFO: waiting for watch events with expected annotations
  Apr 13 14:03:42.335: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/13/24 14:03:42.335
  STEP: updating /status @ 04/13/24 14:03:42.343
  STEP: get /status @ 04/13/24 14:03:42.355
  STEP: deleting @ 04/13/24 14:03:42.358
  STEP: deleting a collection @ 04/13/24 14:03:42.373
  Apr 13 14:03:42.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7653" for this suite. @ 04/13/24 14:03:42.392
• [0.142 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 04/13/24 14:03:42.4
  Apr 13 14:03:42.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename kubectl @ 04/13/24 14:03:42.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:42.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:42.421
  STEP: creating the pod @ 04/13/24 14:03:42.425
  Apr 13 14:03:42.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 create -f -'
  Apr 13 14:03:42.505: INFO: stderr: ""
  Apr 13 14:03:42.505: INFO: stdout: "pod/pause created\n"
  E0413 14:03:42.686421      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:43.686509      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/13/24 14:03:44.514
  Apr 13 14:03:44.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 label pods pause testing-label=testing-label-value'
  Apr 13 14:03:44.565: INFO: stderr: ""
  Apr 13 14:03:44.565: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/13/24 14:03:44.565
  Apr 13 14:03:44.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 get pod pause -L testing-label'
  Apr 13 14:03:44.607: INFO: stderr: ""
  Apr 13 14:03:44.607: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/13/24 14:03:44.607
  Apr 13 14:03:44.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 label pods pause testing-label-'
  Apr 13 14:03:44.658: INFO: stderr: ""
  Apr 13 14:03:44.658: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/13/24 14:03:44.658
  Apr 13 14:03:44.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 get pod pause -L testing-label'
  E0413 14:03:44.687117      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:44.697: INFO: stderr: ""
  Apr 13 14:03:44.697: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 04/13/24 14:03:44.697
  Apr 13 14:03:44.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 delete --grace-period=0 --force -f -'
  Apr 13 14:03:44.750: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 13 14:03:44.750: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 13 14:03:44.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 get rc,svc -l name=pause --no-headers'
  Apr 13 14:03:44.794: INFO: stderr: "No resources found in kubectl-5921 namespace.\n"
  Apr 13 14:03:44.794: INFO: stdout: ""
  Apr 13 14:03:44.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1897221845 --namespace=kubectl-5921 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 13 14:03:44.832: INFO: stderr: ""
  Apr 13 14:03:44.832: INFO: stdout: ""
  Apr 13 14:03:44.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5921" for this suite. @ 04/13/24 14:03:44.837
• [2.444 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/13/24 14:03:44.849
  Apr 13 14:03:44.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename proxy @ 04/13/24 14:03:44.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:44.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:44.868
  STEP: starting an echo server on multiple ports @ 04/13/24 14:03:44.883
  STEP: creating replication controller proxy-service-pxjmx in namespace proxy-2738 @ 04/13/24 14:03:44.883
  I0413 14:03:44.891585      21 runners.go:197] Created replication controller with name: proxy-service-pxjmx, namespace: proxy-2738, replica count: 1
  E0413 14:03:45.687567      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:45.942629      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:46.688117      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:46.943588      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:47.688275      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:47.944712      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:48.688363      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:48.945844      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:49.688408      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:49.946909      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:50.688762      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:50.947165      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:51.688864      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:51.949310      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:52.688951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:52.950388      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:53.689071      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:53.950534      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:54.689279      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:54.950666      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0413 14:03:55.690320      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0413 14:03:55.951610      21 runners.go:197] proxy-service-pxjmx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 13 14:03:55.956: INFO: setup took 11.083821508s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/13/24 14:03:55.956
  Apr 13 14:03:55.960: INFO: (0) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.485591ms)
  Apr 13 14:03:55.961: INFO: (0) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 4.773477ms)
  Apr 13 14:03:55.961: INFO: (0) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.958382ms)
  Apr 13 14:03:55.963: INFO: (0) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.903085ms)
  Apr 13 14:03:55.963: INFO: (0) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.343519ms)
  Apr 13 14:03:55.965: INFO: (0) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 8.503254ms)
  Apr 13 14:03:55.967: INFO: (0) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 11.025132ms)
  Apr 13 14:03:55.967: INFO: (0) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 11.088111ms)
  Apr 13 14:03:55.967: INFO: (0) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 11.573268ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 11.730114ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 11.892473ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 12.039876ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 11.934297ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 12.013111ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 11.884298ms)
  Apr 13 14:03:55.968: INFO: (0) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 12.101542ms)
  Apr 13 14:03:55.972: INFO: (1) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 3.988236ms)
  Apr 13 14:03:55.973: INFO: (1) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.029428ms)
  Apr 13 14:03:55.973: INFO: (1) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 5.116317ms)
  Apr 13 14:03:55.974: INFO: (1) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.396859ms)
  Apr 13 14:03:55.974: INFO: (1) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.444304ms)
  Apr 13 14:03:55.974: INFO: (1) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.696521ms)
  Apr 13 14:03:55.974: INFO: (1) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.15427ms)
  Apr 13 14:03:55.974: INFO: (1) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.180286ms)
  Apr 13 14:03:55.975: INFO: (1) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 6.573803ms)
  Apr 13 14:03:55.975: INFO: (1) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.006152ms)
  Apr 13 14:03:55.975: INFO: (1) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 7.061025ms)
  Apr 13 14:03:55.975: INFO: (1) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.278637ms)
  Apr 13 14:03:55.976: INFO: (1) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.677323ms)
  Apr 13 14:03:55.976: INFO: (1) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 8.258631ms)
  Apr 13 14:03:55.977: INFO: (1) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 8.385821ms)
  Apr 13 14:03:55.977: INFO: (1) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 8.739387ms)
  Apr 13 14:03:55.982: INFO: (2) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 4.813668ms)
  Apr 13 14:03:55.983: INFO: (2) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 5.228511ms)
  Apr 13 14:03:55.983: INFO: (2) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.343726ms)
  Apr 13 14:03:55.983: INFO: (2) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.15463ms)
  Apr 13 14:03:55.983: INFO: (2) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 6.296427ms)
  Apr 13 14:03:55.984: INFO: (2) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 6.969014ms)
  Apr 13 14:03:55.984: INFO: (2) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.060048ms)
  Apr 13 14:03:55.984: INFO: (2) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 7.151273ms)
  Apr 13 14:03:55.984: INFO: (2) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 7.016326ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 7.732888ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 7.75145ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.760468ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 8.012461ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.993329ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 8.209149ms)
  Apr 13 14:03:55.985: INFO: (2) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 8.139986ms)
  Apr 13 14:03:55.989: INFO: (3) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 3.339424ms)
  Apr 13 14:03:55.992: INFO: (3) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.430514ms)
  Apr 13 14:03:55.999: INFO: (3) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 12.960893ms)
  Apr 13 14:03:56.005: INFO: (3) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 19.244765ms)
  Apr 13 14:03:56.005: INFO: (3) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 19.209704ms)
  Apr 13 14:03:56.010: INFO: (3) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 24.072772ms)
  Apr 13 14:03:56.016: INFO: (3) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 30.568802ms)
  Apr 13 14:03:56.016: INFO: (3) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 30.84409ms)
  Apr 13 14:03:56.016: INFO: (3) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 30.917666ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 30.75922ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 30.830273ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 30.915703ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 30.893225ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 30.971205ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 31.22982ms)
  Apr 13 14:03:56.017: INFO: (3) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 31.783657ms)
  Apr 13 14:03:56.035: INFO: (4) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 17.110639ms)
  Apr 13 14:03:56.036: INFO: (4) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 17.975784ms)
  Apr 13 14:03:56.036: INFO: (4) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 17.994995ms)
  Apr 13 14:03:56.040: INFO: (4) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 22.228331ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 32.153732ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 32.016ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 32.173178ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 32.260626ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 32.389869ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 32.492038ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 32.708596ms)
  Apr 13 14:03:56.050: INFO: (4) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 32.858014ms)
  Apr 13 14:03:56.051: INFO: (4) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 32.82625ms)
  Apr 13 14:03:56.051: INFO: (4) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 32.854213ms)
  Apr 13 14:03:56.051: INFO: (4) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 32.976984ms)
  Apr 13 14:03:56.051: INFO: (4) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 32.972693ms)
  Apr 13 14:03:56.067: INFO: (5) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 16.371105ms)
  Apr 13 14:03:56.067: INFO: (5) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 16.602049ms)
  Apr 13 14:03:56.068: INFO: (5) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 16.851108ms)
  Apr 13 14:03:56.068: INFO: (5) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 16.607586ms)
  Apr 13 14:03:56.069: INFO: (5) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 18.047251ms)
  Apr 13 14:03:56.069: INFO: (5) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 18.108346ms)
  Apr 13 14:03:56.070: INFO: (5) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 18.676538ms)
  Apr 13 14:03:56.070: INFO: (5) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 19.201958ms)
  Apr 13 14:03:56.071: INFO: (5) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 19.838485ms)
  Apr 13 14:03:56.071: INFO: (5) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 20.058765ms)
  Apr 13 14:03:56.071: INFO: (5) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 20.266391ms)
  Apr 13 14:03:56.071: INFO: (5) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 20.115046ms)
  Apr 13 14:03:56.071: INFO: (5) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 20.604592ms)
  Apr 13 14:03:56.072: INFO: (5) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 20.698084ms)
  Apr 13 14:03:56.072: INFO: (5) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 20.718815ms)
  Apr 13 14:03:56.072: INFO: (5) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 20.975992ms)
  Apr 13 14:03:56.076: INFO: (6) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.242809ms)
  Apr 13 14:03:56.077: INFO: (6) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.602934ms)
  Apr 13 14:03:56.077: INFO: (6) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 5.164784ms)
  Apr 13 14:03:56.077: INFO: (6) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.314728ms)
  Apr 13 14:03:56.077: INFO: (6) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 5.226992ms)
  Apr 13 14:03:56.078: INFO: (6) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 5.585034ms)
  Apr 13 14:03:56.078: INFO: (6) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.823164ms)
  Apr 13 14:03:56.078: INFO: (6) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.864289ms)
  Apr 13 14:03:56.078: INFO: (6) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.257882ms)
  Apr 13 14:03:56.079: INFO: (6) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 6.740965ms)
  Apr 13 14:03:56.079: INFO: (6) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.183059ms)
  Apr 13 14:03:56.079: INFO: (6) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.296857ms)
  Apr 13 14:03:56.080: INFO: (6) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.377802ms)
  Apr 13 14:03:56.080: INFO: (6) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.583657ms)
  Apr 13 14:03:56.080: INFO: (6) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 8.071988ms)
  Apr 13 14:03:56.080: INFO: (6) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 8.056579ms)
  Apr 13 14:03:56.085: INFO: (7) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 4.371298ms)
  Apr 13 14:03:56.085: INFO: (7) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.550917ms)
  Apr 13 14:03:56.085: INFO: (7) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 4.923717ms)
  Apr 13 14:03:56.086: INFO: (7) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.127844ms)
  Apr 13 14:03:56.086: INFO: (7) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.881634ms)
  Apr 13 14:03:56.086: INFO: (7) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 5.914512ms)
  Apr 13 14:03:56.086: INFO: (7) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.140931ms)
  Apr 13 14:03:56.086: INFO: (7) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.971136ms)
  Apr 13 14:03:56.087: INFO: (7) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.366761ms)
  Apr 13 14:03:56.087: INFO: (7) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.540567ms)
  Apr 13 14:03:56.087: INFO: (7) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.833876ms)
  Apr 13 14:03:56.088: INFO: (7) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.088435ms)
  Apr 13 14:03:56.088: INFO: (7) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 7.230074ms)
  Apr 13 14:03:56.088: INFO: (7) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.162079ms)
  Apr 13 14:03:56.088: INFO: (7) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.335881ms)
  Apr 13 14:03:56.089: INFO: (7) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 8.025995ms)
  Apr 13 14:03:56.092: INFO: (8) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 3.755524ms)
  Apr 13 14:03:56.094: INFO: (8) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.114018ms)
  Apr 13 14:03:56.094: INFO: (8) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.962475ms)
  Apr 13 14:03:56.094: INFO: (8) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 5.165623ms)
  Apr 13 14:03:56.094: INFO: (8) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.378809ms)
  Apr 13 14:03:56.095: INFO: (8) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 5.870371ms)
  Apr 13 14:03:56.095: INFO: (8) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.587747ms)
  Apr 13 14:03:56.095: INFO: (8) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.719032ms)
  Apr 13 14:03:56.095: INFO: (8) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 6.576462ms)
  Apr 13 14:03:56.095: INFO: (8) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.659448ms)
  Apr 13 14:03:56.096: INFO: (8) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.907855ms)
  Apr 13 14:03:56.096: INFO: (8) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 6.915059ms)
  Apr 13 14:03:56.096: INFO: (8) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.113117ms)
  Apr 13 14:03:56.096: INFO: (8) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.189194ms)
  Apr 13 14:03:56.096: INFO: (8) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.775031ms)
  Apr 13 14:03:56.097: INFO: (8) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.78288ms)
  Apr 13 14:03:56.100: INFO: (9) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 3.082373ms)
  Apr 13 14:03:56.100: INFO: (9) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 3.447817ms)
  Apr 13 14:03:56.101: INFO: (9) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.265686ms)
  Apr 13 14:03:56.101: INFO: (9) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 4.486797ms)
  Apr 13 14:03:56.102: INFO: (9) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.770304ms)
  Apr 13 14:03:56.102: INFO: (9) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.325618ms)
  Apr 13 14:03:56.102: INFO: (9) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.466237ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.6175ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 6.093896ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.167841ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 6.261907ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.437863ms)
  Apr 13 14:03:56.103: INFO: (9) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.518354ms)
  Apr 13 14:03:56.104: INFO: (9) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 6.80504ms)
  Apr 13 14:03:56.104: INFO: (9) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 6.916719ms)
  Apr 13 14:03:56.105: INFO: (9) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 8.170592ms)
  Apr 13 14:03:56.108: INFO: (10) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 3.169928ms)
  Apr 13 14:03:56.108: INFO: (10) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 3.421291ms)
  Apr 13 14:03:56.109: INFO: (10) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 3.589502ms)
  Apr 13 14:03:56.109: INFO: (10) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.333523ms)
  Apr 13 14:03:56.110: INFO: (10) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.466266ms)
  Apr 13 14:03:56.110: INFO: (10) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.088819ms)
  Apr 13 14:03:56.110: INFO: (10) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.13265ms)
  Apr 13 14:03:56.110: INFO: (10) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.322636ms)
  Apr 13 14:03:56.111: INFO: (10) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.732655ms)
  Apr 13 14:03:56.111: INFO: (10) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 5.771797ms)
  Apr 13 14:03:56.111: INFO: (10) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 5.766323ms)
  Apr 13 14:03:56.112: INFO: (10) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.461862ms)
  Apr 13 14:03:56.112: INFO: (10) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.907274ms)
  Apr 13 14:03:56.112: INFO: (10) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.17611ms)
  Apr 13 14:03:56.112: INFO: (10) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.118465ms)
  Apr 13 14:03:56.113: INFO: (10) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.52849ms)
  Apr 13 14:03:56.116: INFO: (11) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 3.347156ms)
  Apr 13 14:03:56.117: INFO: (11) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 4.186893ms)
  Apr 13 14:03:56.117: INFO: (11) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.469332ms)
  Apr 13 14:03:56.117: INFO: (11) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.660429ms)
  Apr 13 14:03:56.118: INFO: (11) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 4.944669ms)
  Apr 13 14:03:56.118: INFO: (11) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 5.305562ms)
  Apr 13 14:03:56.118: INFO: (11) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.218784ms)
  Apr 13 14:03:56.118: INFO: (11) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.460064ms)
  Apr 13 14:03:56.119: INFO: (11) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.592141ms)
  Apr 13 14:03:56.119: INFO: (11) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.907849ms)
  Apr 13 14:03:56.119: INFO: (11) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.542913ms)
  Apr 13 14:03:56.120: INFO: (11) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 6.906704ms)
  Apr 13 14:03:56.120: INFO: (11) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 6.998212ms)
  Apr 13 14:03:56.120: INFO: (11) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.006492ms)
  Apr 13 14:03:56.120: INFO: (11) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.053474ms)
  Apr 13 14:03:56.120: INFO: (11) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.307697ms)
  Apr 13 14:03:56.123: INFO: (12) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 2.995573ms)
  Apr 13 14:03:56.125: INFO: (12) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.202888ms)
  Apr 13 14:03:56.125: INFO: (12) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.33984ms)
  Apr 13 14:03:56.125: INFO: (12) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.405458ms)
  Apr 13 14:03:56.125: INFO: (12) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.835153ms)
  Apr 13 14:03:56.126: INFO: (12) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.588129ms)
  Apr 13 14:03:56.126: INFO: (12) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 5.789168ms)
  Apr 13 14:03:56.126: INFO: (12) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.122183ms)
  Apr 13 14:03:56.126: INFO: (12) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.921498ms)
  Apr 13 14:03:56.126: INFO: (12) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 6.092092ms)
  Apr 13 14:03:56.127: INFO: (12) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.938049ms)
  Apr 13 14:03:56.127: INFO: (12) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.909961ms)
  Apr 13 14:03:56.127: INFO: (12) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.141308ms)
  Apr 13 14:03:56.128: INFO: (12) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.339061ms)
  Apr 13 14:03:56.128: INFO: (12) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.24072ms)
  Apr 13 14:03:56.128: INFO: (12) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.345569ms)
  Apr 13 14:03:56.132: INFO: (13) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 4.551074ms)
  Apr 13 14:03:56.133: INFO: (13) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.911121ms)
  Apr 13 14:03:56.133: INFO: (13) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.489568ms)
  Apr 13 14:03:56.134: INFO: (13) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 5.901104ms)
  Apr 13 14:03:56.134: INFO: (13) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.516907ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.927505ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 7.260774ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 7.238961ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 7.376633ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 7.498607ms)
  Apr 13 14:03:56.135: INFO: (13) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 7.380939ms)
  Apr 13 14:03:56.136: INFO: (13) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 7.839999ms)
  Apr 13 14:03:56.136: INFO: (13) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.673576ms)
  Apr 13 14:03:56.136: INFO: (13) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.771615ms)
  Apr 13 14:03:56.136: INFO: (13) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.837345ms)
  Apr 13 14:03:56.136: INFO: (13) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 8.123383ms)
  Apr 13 14:03:56.140: INFO: (14) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 3.672649ms)
  Apr 13 14:03:56.140: INFO: (14) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.378754ms)
  Apr 13 14:03:56.141: INFO: (14) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.794161ms)
  Apr 13 14:03:56.141: INFO: (14) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 4.884844ms)
  Apr 13 14:03:56.141: INFO: (14) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 5.216692ms)
  Apr 13 14:03:56.141: INFO: (14) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 5.111223ms)
  Apr 13 14:03:56.142: INFO: (14) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.545491ms)
  Apr 13 14:03:56.142: INFO: (14) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 6.075073ms)
  Apr 13 14:03:56.142: INFO: (14) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 6.353681ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.53852ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 6.548673ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 6.628807ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.876514ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.296195ms)
  Apr 13 14:03:56.143: INFO: (14) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.234745ms)
  Apr 13 14:03:56.144: INFO: (14) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.259046ms)
  Apr 13 14:03:56.147: INFO: (15) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 3.156438ms)
  Apr 13 14:03:56.148: INFO: (15) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.626509ms)
  Apr 13 14:03:56.149: INFO: (15) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 4.995073ms)
  Apr 13 14:03:56.149: INFO: (15) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.012603ms)
  Apr 13 14:03:56.150: INFO: (15) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.913033ms)
  Apr 13 14:03:56.150: INFO: (15) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.944989ms)
  Apr 13 14:03:56.150: INFO: (15) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.936653ms)
  Apr 13 14:03:56.150: INFO: (15) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.061907ms)
  Apr 13 14:03:56.150: INFO: (15) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 6.331027ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.020627ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 7.117452ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 7.208205ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.047033ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.236198ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.282139ms)
  Apr 13 14:03:56.151: INFO: (15) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.41702ms)
  Apr 13 14:03:56.156: INFO: (16) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 4.344181ms)
  Apr 13 14:03:56.156: INFO: (16) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.729682ms)
  Apr 13 14:03:56.157: INFO: (16) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.428741ms)
  Apr 13 14:03:56.157: INFO: (16) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 5.555257ms)
  Apr 13 14:03:56.157: INFO: (16) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.698963ms)
  Apr 13 14:03:56.157: INFO: (16) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 5.557706ms)
  Apr 13 14:03:56.157: INFO: (16) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.151023ms)
  Apr 13 14:03:56.158: INFO: (16) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 6.167443ms)
  Apr 13 14:03:56.158: INFO: (16) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.766756ms)
  Apr 13 14:03:56.158: INFO: (16) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 6.725265ms)
  Apr 13 14:03:56.158: INFO: (16) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 6.87365ms)
  Apr 13 14:03:56.159: INFO: (16) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 7.183079ms)
  Apr 13 14:03:56.159: INFO: (16) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.2659ms)
  Apr 13 14:03:56.159: INFO: (16) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.14706ms)
  Apr 13 14:03:56.159: INFO: (16) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.124944ms)
  Apr 13 14:03:56.159: INFO: (16) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.950395ms)
  Apr 13 14:03:56.163: INFO: (17) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 3.375603ms)
  Apr 13 14:03:56.163: INFO: (17) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 3.737289ms)
  Apr 13 14:03:56.164: INFO: (17) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 4.431699ms)
  Apr 13 14:03:56.164: INFO: (17) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.678373ms)
  Apr 13 14:03:56.164: INFO: (17) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.769864ms)
  Apr 13 14:03:56.165: INFO: (17) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 5.460564ms)
  Apr 13 14:03:56.165: INFO: (17) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.654455ms)
  Apr 13 14:03:56.165: INFO: (17) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 5.697365ms)
  Apr 13 14:03:56.165: INFO: (17) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 5.785418ms)
  Apr 13 14:03:56.166: INFO: (17) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.281738ms)
  Apr 13 14:03:56.166: INFO: (17) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 6.395493ms)
  Apr 13 14:03:56.166: INFO: (17) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.71809ms)
  Apr 13 14:03:56.166: INFO: (17) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 6.935907ms)
  Apr 13 14:03:56.167: INFO: (17) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 7.081553ms)
  Apr 13 14:03:56.167: INFO: (17) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.15091ms)
  Apr 13 14:03:56.167: INFO: (17) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.466007ms)
  Apr 13 14:03:56.172: INFO: (18) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 4.23908ms)
  Apr 13 14:03:56.172: INFO: (18) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 4.761934ms)
  Apr 13 14:03:56.172: INFO: (18) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 4.798089ms)
  Apr 13 14:03:56.173: INFO: (18) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.01408ms)
  Apr 13 14:03:56.173: INFO: (18) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 5.797989ms)
  Apr 13 14:03:56.173: INFO: (18) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 5.928006ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.408073ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 6.353574ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 6.595858ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.843953ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 6.652757ms)
  Apr 13 14:03:56.174: INFO: (18) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.956019ms)
  Apr 13 14:03:56.175: INFO: (18) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.15244ms)
  Apr 13 14:03:56.175: INFO: (18) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 7.35535ms)
  Apr 13 14:03:56.175: INFO: (18) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 7.474489ms)
  Apr 13 14:03:56.175: INFO: (18) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 8.026876ms)
  Apr 13 14:03:56.179: INFO: (19) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:443/proxy/tlsrewritem... (200; 3.395918ms)
  Apr 13 14:03:56.179: INFO: (19) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 3.807322ms)
  Apr 13 14:03:56.180: INFO: (19) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv/proxy/rewriteme">test</a> (200; 4.105812ms)
  Apr 13 14:03:56.180: INFO: (19) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 4.444232ms)
  Apr 13 14:03:56.181: INFO: (19) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:462/proxy/: tls qux (200; 5.342542ms)
  Apr 13 14:03:56.181: INFO: (19) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:160/proxy/: foo (200; 5.397981ms)
  Apr 13 14:03:56.181: INFO: (19) /api/v1/namespaces/proxy-2738/pods/https:proxy-service-pxjmx-lhdtv:460/proxy/: tls baz (200; 5.399313ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">test<... (200; 6.250297ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2738/pods/http:proxy-service-pxjmx-lhdtv:1080/proxy/rewriteme">... (200; 6.412647ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/pods/proxy-service-pxjmx-lhdtv:162/proxy/: bar (200; 6.494397ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname1/proxy/: foo (200; 6.804323ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname2/proxy/: bar (200; 6.773619ms)
  Apr 13 14:03:56.182: INFO: (19) /api/v1/namespaces/proxy-2738/services/http:proxy-service-pxjmx:portname2/proxy/: bar (200; 6.763966ms)
  Apr 13 14:03:56.183: INFO: (19) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname1/proxy/: tls baz (200; 7.20828ms)
  Apr 13 14:03:56.183: INFO: (19) /api/v1/namespaces/proxy-2738/services/proxy-service-pxjmx:portname1/proxy/: foo (200; 7.301032ms)
  Apr 13 14:03:56.183: INFO: (19) /api/v1/namespaces/proxy-2738/services/https:proxy-service-pxjmx:tlsportname2/proxy/: tls qux (200; 7.523302ms)
  STEP: deleting ReplicationController proxy-service-pxjmx in namespace proxy-2738, will wait for the garbage collector to delete the pods @ 04/13/24 14:03:56.183
  Apr 13 14:03:56.244: INFO: Deleting ReplicationController proxy-service-pxjmx took: 7.444269ms
  Apr 13 14:03:56.345: INFO: Terminating ReplicationController proxy-service-pxjmx pods took: 100.789289ms
  E0413 14:03:56.690400      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:57.691093      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:03:57.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2738" for this suite. @ 04/13/24 14:03:57.953
• [13.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/13/24 14:03:57.96
  Apr 13 14:03:57.960: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename container-probe @ 04/13/24 14:03:57.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:03:57.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:03:57.981
  STEP: Creating pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144 @ 04/13/24 14:03:57.984
  E0413 14:03:58.691576      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:03:59.691767      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/13/24 14:04:00.002
  Apr 13 14:04:00.006: INFO: Initial restart count of pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 is 0
  Apr 13 14:04:00.009: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:00.691886      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:01.692002      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:02.015: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:02.692302      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:03.692490      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:04.020: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:04.693056      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:05.693261      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:06.025: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:06.693415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:07.693486      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:08.031: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:08.693622      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:09.693905      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:10.036: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:10.694019      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:11.694213      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:12.040: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:12.694932      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:13.695013      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:14.046: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:14.695293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:15.695446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:16.051: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:16.695717      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:17.695869      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:18.056: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:18.696549      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:19.696670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:20.061: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:20.697141      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:21.697375      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:22.066: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:22.697478      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:23.698041      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:24.072: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:24.698722      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:25.698804      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:26.077: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:26.699611      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:27.699689      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:28.082: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:28.700082      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:29.699911      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:30.088: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:30.700861      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:31.700951      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:32.092: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:32.701573      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:33.701892      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:34.097: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:34.702454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:35.702536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:36.102: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:36.702652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:37.702731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:38.107: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:38.703035      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:39.703545      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:40.112: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:40.704435      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:41.704617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:42.117: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:42.705366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:43.705488      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:44.122: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:44.705538      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:45.705711      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:46.128: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:46.706777      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:47.706873      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:48.133: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:48.707537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:49.708617      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:50.138: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:50.709652      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:51.709753      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:52.143: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:52.710502      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:53.710531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:54.148: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:54.711472      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:55.711648      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:56.154: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:56.712098      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:57.712185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:04:58.159: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:04:58.712390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:04:59.712504      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:00.164: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:00.712572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:01.712653      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:02.170: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:02.712806      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:03.712900      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:04.175: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:04.713219      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:05.713358      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:06.180: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:06.713723      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:07.713838      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:08.185: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:08.713915      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:09.714092      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:10.190: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:10.714167      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:11.714441      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:12.195: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:12.714531      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:13.719537      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:14.200: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:14.719570      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:15.719675      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:16.205: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:16.719760      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:17.719837      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:18.211: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:18.720619      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:19.720811      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:20.216: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:20.720862      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:21.721730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:22.222: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:22.721823      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:23.721950      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:24.228: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:24.722942      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:25.723131      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:26.233: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:26.724185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:27.724394      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:28.237: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:28.725160      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:29.725355      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:30.243: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:30.726446      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:31.726526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:32.248: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:32.727103      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:33.727559      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:34.254: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:34.728247      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:35.728461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:36.260: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:36.728572      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:37.728730      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:38.265: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:38.728839      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:39.729045      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:40.270: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:40.730018      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:41.730135      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:42.275: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:42.730230      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:43.730437      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:44.281: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:44.730494      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:45.730588      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:46.286: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:46.730697      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:47.730783      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:48.291: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:48.731280      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:49.731379      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:50.296: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:50.732371      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:51.732454      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:52.306: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:52.733384      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:53.733595      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:54.312: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:54.734178      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:55.734365      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:56.317: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:56.734493      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:57.734593      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:05:58.321: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:05:58.735322      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:05:59.735425      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:00.327: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:00.735546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:01.736089      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:02.331: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:02.736168      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:03.736364      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:04.336: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:04.737432      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:05.737548      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:06.341: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:06.738361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:07.738524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:08.346: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:08.739583      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:09.739687      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:10.351: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:10.740380      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:11.740470      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:12.356: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:12.741120      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:13.741461      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:14.362: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:14.741575      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:15.741961      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:16.366: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:16.743006      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:17.743103      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:18.370: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:18.744087      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:19.744185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:20.375: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:20.745106      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:21.745301      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:22.380: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:22.745979      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:23.746165      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:24.385: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:24.746242      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:25.746370      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:26.391: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:26.746480      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:27.747158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:28.396: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:28.747344      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:29.747942      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:30.400: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:30.748822      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:31.749017      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:32.406: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:32.749990      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:33.750145      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:34.412: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:34.750656      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:35.750764      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:36.417: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:36.750964      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:37.751067      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:38.422: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:38.751534      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:39.752216      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:40.428: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:40.752290      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:41.752372      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:42.433: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:42.752525      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:43.753495      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:44.438: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:44.753805      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:45.753980      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:46.442: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:46.754296      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:47.754468      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:48.447: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:48.755514      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:49.755600      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:50.452: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:50.756497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:51.757251      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:52.457: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:52.757291      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:53.757607      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:54.463: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:54.758390      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:55.758512      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:56.468: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:56.758609      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:57.759118      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:06:58.473: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:06:58.760185      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:06:59.760297      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:00.478: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:00.760769      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:01.760863      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:02.484: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:02.761879      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:03.762238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:04.490: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:04.762415      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:05.762463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:06.496: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:06.762541      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:07.762639      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:08.501: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:08.763497      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:09.763679      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:10.504: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:10.764179      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:11.764293      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:12.510: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:12.764366      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:13.764546      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:14.515: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:14.765144      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:15.765254      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:16.521: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:16.765830      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:17.766147      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:18.527: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:18.766407      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:19.766463      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:20.531: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:20.766585      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:21.766670      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:22.536: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:22.767137      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:23.767524      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:24.541: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:24.768106      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:25.768371      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:26.547: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:26.769433      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:27.769528      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:28.551: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:28.770248      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:29.770450      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:30.556: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:30.771240      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:31.771331      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:32.562: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:32.771787      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:33.772676      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:34.568: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:34.773162      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:35.773339      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:36.574: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:36.773610      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:37.773841      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:38.579: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:38.774361      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:39.774475      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:40.583: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:40.774562      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:41.775526      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:42.588: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:42.776257      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:43.776348      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:44.593: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:44.777024      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:45.777203      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:46.597: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:46.778068      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:47.779129      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:48.602: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:48.779934      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:49.779999      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:50.608: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:50.780487      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:51.781536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:52.613: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:52.782543      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:53.782654      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:54.617: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:54.783218      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:55.783536      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:56.623: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:56.784209      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:57.784333      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:07:58.628: INFO: Get pod test-webserver-01d8b59c-e5c5-49c9-baf9-6da0d758f6e3 in namespace container-probe-2144
  E0413 14:07:58.784489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:07:59.784834      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/13/24 14:08:00.628
  Apr 13 14:08:00.642: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2144" for this suite. @ 04/13/24 14:08:00.646
• [242.694 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 04/13/24 14:08:00.654
  Apr 13 14:08:00.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 14:08:00.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:08:00.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:08:00.674
  STEP: Creating a pod to test downward API volume plugin @ 04/13/24 14:08:00.68
  E0413 14:08:00.785893      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:01.785993      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:02.786796      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:03.787539      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:08:04.704
  Apr 13 14:08:04.708: INFO: Trying to get logs from node ip-172-31-82-63 pod downwardapi-volume-c22fa157-9826-443d-8eba-d749326d981f container client-container: <nil>
  STEP: delete the pod @ 04/13/24 14:08:04.724
  Apr 13 14:08:04.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4202" for this suite. @ 04/13/24 14:08:04.744
• [4.096 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/13/24 14:08:04.75
  Apr 13 14:08:04.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename pods @ 04/13/24 14:08:04.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:08:04.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:08:04.77
  Apr 13 14:08:04.773: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: creating the pod @ 04/13/24 14:08:04.774
  STEP: submitting the pod to kubernetes @ 04/13/24 14:08:04.774
  E0413 14:08:04.787996      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:05.788158      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:06.788250      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:08:06.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-199" for this suite. @ 04/13/24 14:08:06.858
• [2.114 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/13/24 14:08:06.865
  Apr 13 14:08:06.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename projected @ 04/13/24 14:08:06.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:08:06.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:08:06.886
  STEP: Creating projection with secret that has name projected-secret-test-map-21e31ac3-6103-4b42-9a89-1ad10446994a @ 04/13/24 14:08:06.889
  STEP: Creating a pod to test consume secrets @ 04/13/24 14:08:06.894
  E0413 14:08:07.789003      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:08.789150      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:09.789275      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:10.789522      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/13/24 14:08:10.92
  Apr 13 14:08:10.923: INFO: Trying to get logs from node ip-172-31-82-63 pod pod-projected-secrets-02cf935d-d40b-4147-95d5-b4a976d6fd73 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/13/24 14:08:10.93
  Apr 13 14:08:10.947: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6404" for this suite. @ 04/13/24 14:08:10.951
• [4.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 04/13/24 14:08:10.958
  Apr 13 14:08:10.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename sysctl @ 04/13/24 14:08:10.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:08:10.976
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:08:10.979
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/13/24 14:08:10.983
  STEP: Watching for error events or started pod @ 04/13/24 14:08:10.991
  E0413 14:08:11.789667      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:12.789983      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/13/24 14:08:12.996
  E0413 14:08:13.790489      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:14.790569      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/13/24 14:08:15.009
  STEP: Getting logs from the pod @ 04/13/24 14:08:15.009
  STEP: Checking that the sysctl is actually updated @ 04/13/24 14:08:15.016
  Apr 13 14:08:15.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9799" for this suite. @ 04/13/24 14:08:15.019
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/13/24 14:08:15.027
  Apr 13 14:08:15.027: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/13/24 14:08:15.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/13/24 14:08:15.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/13/24 14:08:15.046
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/13/24 14:08:15.049
  Apr 13 14:08:15.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 14:08:15.791238      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:16.791746      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:17.792731      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:18.792984      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:19.793251      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/13/24 14:08:20.017
  Apr 13 14:08:20.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 14:08:20.793346      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:08:21.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1897221845
  E0413 14:08:21.793847      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:22.793930      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:23.794431      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:24.795475      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0413 14:08:25.796015      21 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 13 14:08:26.244: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-782" for this suite. @ 04/13/24 14:08:26.252
• [11.232 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 13 14:08:26.260: INFO: Running AfterSuite actions on node 1
  Apr 13 14:08:26.260: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.026 seconds]
------------------------------

Ran 388 of 7407 Specs in 6468.765 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h47m49.499623118s
Test Suite Passed
