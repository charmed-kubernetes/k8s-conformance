I1203 11:56:34.362524      19 e2e.go:116] Starting e2e run "50475f68-cfa2-4212-99a4-1120f9bc223d" on Ginkgo node 1
Dec  3 11:56:34.375: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1670068594 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Dec  3 11:56:34.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 11:56:34.517: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 11:56:34.537: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 11:56:34.571: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 11:56:34.571: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Dec  3 11:56:34.571: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 11:56:34.579: INFO: e2e test version: v1.25.4
Dec  3 11:56:34.582: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Dec  3 11:56:34.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 11:56:34.593: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.077 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec  3 11:56:34.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 11:56:34.517: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Dec  3 11:56:34.537: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Dec  3 11:56:34.571: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Dec  3 11:56:34.571: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Dec  3 11:56:34.571: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Dec  3 11:56:34.579: INFO: e2e test version: v1.25.4
    Dec  3 11:56:34.582: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec  3 11:56:34.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 11:56:34.593: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:56:34.615
Dec  3 11:56:34.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 11:56:34.616
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:56:34.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:56:34.65
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-91bd1084-17a2-4c3b-92d7-309b9847eb33 12/03/22 11:56:34.662
STEP: Creating a pod to test consume configMaps 12/03/22 11:56:34.683
Dec  3 11:56:34.712: INFO: Waiting up to 5m0s for pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497" in namespace "configmap-7635" to be "Succeeded or Failed"
Dec  3 11:56:34.718: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 5.434459ms
Dec  3 11:56:36.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010795765s
Dec  3 11:56:38.726: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013423058s
Dec  3 11:56:40.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010823505s
Dec  3 11:56:42.724: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012296357s
Dec  3 11:56:44.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010793941s
Dec  3 11:56:46.724: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 12.012017832s
Dec  3 11:56:48.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010185959s
Dec  3 11:56:50.725: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012414648s
Dec  3 11:56:52.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.009799961s
STEP: Saw pod success 12/03/22 11:56:52.722
Dec  3 11:56:52.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497" satisfied condition "Succeeded or Failed"
Dec  3 11:56:52.726: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 11:56:52.747
Dec  3 11:56:52.764: INFO: Waiting for pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 to disappear
Dec  3 11:56:52.768: INFO: Pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 11:56:52.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7635" for this suite. 12/03/22 11:56:52.773
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":1,"skipped":4,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.165 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:56:34.615
    Dec  3 11:56:34.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 11:56:34.616
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:56:34.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:56:34.65
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-91bd1084-17a2-4c3b-92d7-309b9847eb33 12/03/22 11:56:34.662
    STEP: Creating a pod to test consume configMaps 12/03/22 11:56:34.683
    Dec  3 11:56:34.712: INFO: Waiting up to 5m0s for pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497" in namespace "configmap-7635" to be "Succeeded or Failed"
    Dec  3 11:56:34.718: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 5.434459ms
    Dec  3 11:56:36.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010795765s
    Dec  3 11:56:38.726: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013423058s
    Dec  3 11:56:40.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010823505s
    Dec  3 11:56:42.724: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012296357s
    Dec  3 11:56:44.723: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010793941s
    Dec  3 11:56:46.724: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 12.012017832s
    Dec  3 11:56:48.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010185959s
    Dec  3 11:56:50.725: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012414648s
    Dec  3 11:56:52.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.009799961s
    STEP: Saw pod success 12/03/22 11:56:52.722
    Dec  3 11:56:52.722: INFO: Pod "pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497" satisfied condition "Succeeded or Failed"
    Dec  3 11:56:52.726: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 11:56:52.747
    Dec  3 11:56:52.764: INFO: Waiting for pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 to disappear
    Dec  3 11:56:52.768: INFO: Pod pod-configmaps-f8739f85-7227-4386-99cc-c41afc9df497 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 11:56:52.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7635" for this suite. 12/03/22 11:56:52.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:56:52.781
Dec  3 11:56:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 11:56:52.783
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:56:52.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:56:52.81
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-2580 12/03/22 11:56:52.815
Dec  3 11:56:52.830: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2580" to be "running and ready"
Dec  3 11:56:52.833: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.326441ms
Dec  3 11:56:52.833: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec  3 11:56:54.839: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.008975876s
Dec  3 11:56:54.839: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec  3 11:56:54.839: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec  3 11:56:54.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec  3 11:56:55.076: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec  3 11:56:55.076: INFO: stdout: "iptables"
Dec  3 11:56:55.076: INFO: proxyMode: iptables
Dec  3 11:56:55.088: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec  3 11:56:55.091: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2580 12/03/22 11:56:55.091
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2580 12/03/22 11:56:55.103
I1203 11:56:55.114477      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2580, replica count: 3
I1203 11:56:58.165523      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 11:57:01.166032      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 11:57:04.166225      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 11:57:04.175: INFO: Creating new exec pod
Dec  3 11:57:04.183: INFO: Waiting up to 5m0s for pod "execpod-affinitynqklh" in namespace "services-2580" to be "running"
Dec  3 11:57:04.187: INFO: Pod "execpod-affinitynqklh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799996ms
Dec  3 11:57:06.192: INFO: Pod "execpod-affinitynqklh": Phase="Running", Reason="", readiness=true. Elapsed: 2.008667845s
Dec  3 11:57:06.192: INFO: Pod "execpod-affinitynqklh" satisfied condition "running"
Dec  3 11:57:07.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Dec  3 11:57:07.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Dec  3 11:57:07.368: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 11:57:07.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.181 80'
Dec  3 11:57:07.509: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.181 80\nConnection to 10.152.183.181 80 port [tcp/http] succeeded!\n"
Dec  3 11:57:07.509: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 11:57:07.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.181:80/ ; done'
Dec  3 11:57:07.734: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
Dec  3 11:57:07.734: INFO: stdout: "\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf"
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
Dec  3 11:57:07.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.181:80/'
Dec  3 11:57:07.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
Dec  3 11:57:07.886: INFO: stdout: "affinity-clusterip-timeout-qcqhf"
Dec  3 11:57:27.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.181:80/'
Dec  3 11:57:28.052: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
Dec  3 11:57:28.052: INFO: stdout: "affinity-clusterip-timeout-j5xlb"
Dec  3 11:57:28.052: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2580, will wait for the garbage collector to delete the pods 12/03/22 11:57:28.066
Dec  3 11:57:28.131: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 8.368208ms
Dec  3 11:57:28.232: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.325893ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 11:57:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2580" for this suite. 12/03/22 11:57:30.267
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":2,"skipped":17,"failed":0}
------------------------------
â€¢ [SLOW TEST] [37.495 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:56:52.781
    Dec  3 11:56:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 11:56:52.783
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:56:52.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:56:52.81
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-2580 12/03/22 11:56:52.815
    Dec  3 11:56:52.830: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2580" to be "running and ready"
    Dec  3 11:56:52.833: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.326441ms
    Dec  3 11:56:52.833: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 11:56:54.839: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.008975876s
    Dec  3 11:56:54.839: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec  3 11:56:54.839: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec  3 11:56:54.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec  3 11:56:55.076: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec  3 11:56:55.076: INFO: stdout: "iptables"
    Dec  3 11:56:55.076: INFO: proxyMode: iptables
    Dec  3 11:56:55.088: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec  3 11:56:55.091: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-2580 12/03/22 11:56:55.091
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-2580 12/03/22 11:56:55.103
    I1203 11:56:55.114477      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2580, replica count: 3
    I1203 11:56:58.165523      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 11:57:01.166032      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 11:57:04.166225      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 11:57:04.175: INFO: Creating new exec pod
    Dec  3 11:57:04.183: INFO: Waiting up to 5m0s for pod "execpod-affinitynqklh" in namespace "services-2580" to be "running"
    Dec  3 11:57:04.187: INFO: Pod "execpod-affinitynqklh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799996ms
    Dec  3 11:57:06.192: INFO: Pod "execpod-affinitynqklh": Phase="Running", Reason="", readiness=true. Elapsed: 2.008667845s
    Dec  3 11:57:06.192: INFO: Pod "execpod-affinitynqklh" satisfied condition "running"
    Dec  3 11:57:07.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Dec  3 11:57:07.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Dec  3 11:57:07.368: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 11:57:07.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.181 80'
    Dec  3 11:57:07.509: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.181 80\nConnection to 10.152.183.181 80 port [tcp/http] succeeded!\n"
    Dec  3 11:57:07.509: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 11:57:07.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.181:80/ ; done'
    Dec  3 11:57:07.734: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
    Dec  3 11:57:07.734: INFO: stdout: "\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf\naffinity-clusterip-timeout-qcqhf"
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.734: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.735: INFO: Received response from host: affinity-clusterip-timeout-qcqhf
    Dec  3 11:57:07.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.181:80/'
    Dec  3 11:57:07.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
    Dec  3 11:57:07.886: INFO: stdout: "affinity-clusterip-timeout-qcqhf"
    Dec  3 11:57:27.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2580 exec execpod-affinitynqklh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.181:80/'
    Dec  3 11:57:28.052: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.181:80/\n"
    Dec  3 11:57:28.052: INFO: stdout: "affinity-clusterip-timeout-j5xlb"
    Dec  3 11:57:28.052: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2580, will wait for the garbage collector to delete the pods 12/03/22 11:57:28.066
    Dec  3 11:57:28.131: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 8.368208ms
    Dec  3 11:57:28.232: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.325893ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 11:57:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2580" for this suite. 12/03/22 11:57:30.267
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:57:30.278
Dec  3 11:57:30.279: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename namespaces 12/03/22 11:57:30.28
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:30.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:30.311
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 12/03/22 11:57:30.314
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:30.334
STEP: Creating a service in the namespace 12/03/22 11:57:30.338
STEP: Deleting the namespace 12/03/22 11:57:30.349
STEP: Waiting for the namespace to be removed. 12/03/22 11:57:30.357
STEP: Recreating the namespace 12/03/22 11:57:36.361
STEP: Verifying there is no service in the namespace 12/03/22 11:57:36.381
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec  3 11:57:36.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-668" for this suite. 12/03/22 11:57:36.389
STEP: Destroying namespace "nsdeletetest-899" for this suite. 12/03/22 11:57:36.397
Dec  3 11:57:36.403: INFO: Namespace nsdeletetest-899 was already deleted
STEP: Destroying namespace "nsdeletetest-4081" for this suite. 12/03/22 11:57:36.403
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":3,"skipped":47,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.132 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:57:30.278
    Dec  3 11:57:30.279: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename namespaces 12/03/22 11:57:30.28
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:30.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:30.311
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 12/03/22 11:57:30.314
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:30.334
    STEP: Creating a service in the namespace 12/03/22 11:57:30.338
    STEP: Deleting the namespace 12/03/22 11:57:30.349
    STEP: Waiting for the namespace to be removed. 12/03/22 11:57:30.357
    STEP: Recreating the namespace 12/03/22 11:57:36.361
    STEP: Verifying there is no service in the namespace 12/03/22 11:57:36.381
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 11:57:36.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-668" for this suite. 12/03/22 11:57:36.389
    STEP: Destroying namespace "nsdeletetest-899" for this suite. 12/03/22 11:57:36.397
    Dec  3 11:57:36.403: INFO: Namespace nsdeletetest-899 was already deleted
    STEP: Destroying namespace "nsdeletetest-4081" for this suite. 12/03/22 11:57:36.403
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:57:36.413
Dec  3 11:57:36.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 11:57:36.414
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:36.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:36.437
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 12/03/22 11:57:36.439
Dec  3 11:57:36.453: INFO: Waiting up to 5m0s for pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5" in namespace "emptydir-2562" to be "Succeeded or Failed"
Dec  3 11:57:36.459: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122749ms
Dec  3 11:57:38.464: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010776059s
Dec  3 11:57:40.467: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013456641s
STEP: Saw pod success 12/03/22 11:57:40.467
Dec  3 11:57:40.467: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5" satisfied condition "Succeeded or Failed"
Dec  3 11:57:40.470: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 container test-container: <nil>
STEP: delete the pod 12/03/22 11:57:40.477
Dec  3 11:57:40.490: INFO: Waiting for pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 to disappear
Dec  3 11:57:40.513: INFO: Pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 11:57:40.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2562" for this suite. 12/03/22 11:57:40.518
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":4,"skipped":49,"failed":0}
------------------------------
â€¢ [4.113 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:57:36.413
    Dec  3 11:57:36.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 11:57:36.414
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:36.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:36.437
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/03/22 11:57:36.439
    Dec  3 11:57:36.453: INFO: Waiting up to 5m0s for pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5" in namespace "emptydir-2562" to be "Succeeded or Failed"
    Dec  3 11:57:36.459: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122749ms
    Dec  3 11:57:38.464: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010776059s
    Dec  3 11:57:40.467: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013456641s
    STEP: Saw pod success 12/03/22 11:57:40.467
    Dec  3 11:57:40.467: INFO: Pod "pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5" satisfied condition "Succeeded or Failed"
    Dec  3 11:57:40.470: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 container test-container: <nil>
    STEP: delete the pod 12/03/22 11:57:40.477
    Dec  3 11:57:40.490: INFO: Waiting for pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 to disappear
    Dec  3 11:57:40.513: INFO: Pod pod-a3e02ffd-2919-4c73-b0b6-aa17589c51a5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 11:57:40.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2562" for this suite. 12/03/22 11:57:40.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:57:40.529
Dec  3 11:57:40.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 11:57:40.53
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:40.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:40.554
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-6c02cfe5-afff-4665-a732-1f87d3a149ca 12/03/22 11:57:40.557
STEP: Creating a pod to test consume secrets 12/03/22 11:57:40.564
Dec  3 11:57:40.573: INFO: Waiting up to 5m0s for pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd" in namespace "secrets-3849" to be "Succeeded or Failed"
Dec  3 11:57:40.576: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772171ms
Dec  3 11:57:42.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007406891s
Dec  3 11:57:44.582: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008204809s
Dec  3 11:57:46.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007461298s
STEP: Saw pod success 12/03/22 11:57:46.581
Dec  3 11:57:46.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd" satisfied condition "Succeeded or Failed"
Dec  3 11:57:46.584: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 11:57:46.593
Dec  3 11:57:46.607: INFO: Waiting for pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd to disappear
Dec  3 11:57:46.610: INFO: Pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 11:57:46.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3849" for this suite. 12/03/22 11:57:46.613
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":85,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.093 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:57:40.529
    Dec  3 11:57:40.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 11:57:40.53
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:40.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:40.554
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-6c02cfe5-afff-4665-a732-1f87d3a149ca 12/03/22 11:57:40.557
    STEP: Creating a pod to test consume secrets 12/03/22 11:57:40.564
    Dec  3 11:57:40.573: INFO: Waiting up to 5m0s for pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd" in namespace "secrets-3849" to be "Succeeded or Failed"
    Dec  3 11:57:40.576: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772171ms
    Dec  3 11:57:42.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007406891s
    Dec  3 11:57:44.582: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008204809s
    Dec  3 11:57:46.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007461298s
    STEP: Saw pod success 12/03/22 11:57:46.581
    Dec  3 11:57:46.581: INFO: Pod "pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd" satisfied condition "Succeeded or Failed"
    Dec  3 11:57:46.584: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 11:57:46.593
    Dec  3 11:57:46.607: INFO: Waiting for pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd to disappear
    Dec  3 11:57:46.610: INFO: Pod pod-secrets-370b1888-a5aa-4387-85af-2e629f6419fd no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 11:57:46.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3849" for this suite. 12/03/22 11:57:46.613
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:57:46.624
Dec  3 11:57:46.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 11:57:46.625
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:46.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:46.656
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 12/03/22 11:57:46.66
STEP: Wait for the Deployment to create new ReplicaSet 12/03/22 11:57:46.667
STEP: delete the deployment 12/03/22 11:57:47.185
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/03/22 11:57:47.193
STEP: Gathering metrics 12/03/22 11:57:47.714
W1203 11:57:47.719088      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 11:57:47.727: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 11:57:47.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1488" for this suite. 12/03/22 11:57:47.736
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":6,"skipped":129,"failed":0}
------------------------------
â€¢ [1.126 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:57:46.624
    Dec  3 11:57:46.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 11:57:46.625
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:46.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:46.656
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 12/03/22 11:57:46.66
    STEP: Wait for the Deployment to create new ReplicaSet 12/03/22 11:57:46.667
    STEP: delete the deployment 12/03/22 11:57:47.185
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/03/22 11:57:47.193
    STEP: Gathering metrics 12/03/22 11:57:47.714
    W1203 11:57:47.719088      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 11:57:47.727: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 11:57:47.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1488" for this suite. 12/03/22 11:57:47.736
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:57:47.752
Dec  3 11:57:47.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 11:57:47.753
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:47.774
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:47.777
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7365 12/03/22 11:57:47.78
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 12/03/22 11:57:47.786
Dec  3 11:57:47.797: INFO: Found 0 stateful pods, waiting for 3
Dec  3 11:57:57.803: INFO: Found 1 stateful pods, waiting for 3
Dec  3 11:58:07.803: INFO: Found 2 stateful pods, waiting for 3
Dec  3 11:58:17.804: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 11:58:17.804: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 11:58:17.804: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 11:58:17.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 11:58:17.979: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 11:58:17.979: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 11:58:17.979: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/03/22 11:58:27.995
Dec  3 11:58:28.017: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/03/22 11:58:28.017
STEP: Updating Pods in reverse ordinal order 12/03/22 11:58:38.046
Dec  3 11:58:38.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 11:58:38.213: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 11:58:38.213: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 11:58:38.213: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 11:58:58.242: INFO: Waiting for StatefulSet statefulset-7365/ss2 to complete update
STEP: Rolling back to a previous revision 12/03/22 11:59:08.258
Dec  3 11:59:08.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 11:59:08.436: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 11:59:08.436: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 11:59:08.436: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 11:59:18.479: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 12/03/22 11:59:28.497
Dec  3 11:59:28.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 11:59:28.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 11:59:28.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 11:59:28.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 11:59:38.681: INFO: Deleting all statefulset in ns statefulset-7365
Dec  3 11:59:38.685: INFO: Scaling statefulset ss2 to 0
Dec  3 11:59:48.713: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 11:59:48.720: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 11:59:48.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7365" for this suite. 12/03/22 11:59:48.744
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":7,"skipped":132,"failed":0}
------------------------------
â€¢ [SLOW TEST] [121.000 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:57:47.752
    Dec  3 11:57:47.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 11:57:47.753
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:57:47.774
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:57:47.777
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7365 12/03/22 11:57:47.78
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 12/03/22 11:57:47.786
    Dec  3 11:57:47.797: INFO: Found 0 stateful pods, waiting for 3
    Dec  3 11:57:57.803: INFO: Found 1 stateful pods, waiting for 3
    Dec  3 11:58:07.803: INFO: Found 2 stateful pods, waiting for 3
    Dec  3 11:58:17.804: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 11:58:17.804: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 11:58:17.804: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 11:58:17.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 11:58:17.979: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 11:58:17.979: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 11:58:17.979: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/03/22 11:58:27.995
    Dec  3 11:58:28.017: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/03/22 11:58:28.017
    STEP: Updating Pods in reverse ordinal order 12/03/22 11:58:38.046
    Dec  3 11:58:38.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 11:58:38.213: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 11:58:38.213: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 11:58:38.213: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 11:58:58.242: INFO: Waiting for StatefulSet statefulset-7365/ss2 to complete update
    STEP: Rolling back to a previous revision 12/03/22 11:59:08.258
    Dec  3 11:59:08.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 11:59:08.436: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 11:59:08.436: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 11:59:08.436: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 11:59:18.479: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 12/03/22 11:59:28.497
    Dec  3 11:59:28.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-7365 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 11:59:28.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 11:59:28.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 11:59:28.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 11:59:38.681: INFO: Deleting all statefulset in ns statefulset-7365
    Dec  3 11:59:38.685: INFO: Scaling statefulset ss2 to 0
    Dec  3 11:59:48.713: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 11:59:48.720: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 11:59:48.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7365" for this suite. 12/03/22 11:59:48.744
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:59:48.753
Dec  3 11:59:48.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename limitrange 12/03/22 11:59:48.755
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:48.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:48.789
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 12/03/22 11:59:48.806
STEP: Setting up watch 12/03/22 11:59:48.807
STEP: Submitting a LimitRange 12/03/22 11:59:48.914
STEP: Verifying LimitRange creation was observed 12/03/22 11:59:48.923
STEP: Fetching the LimitRange to ensure it has proper values 12/03/22 11:59:48.923
Dec  3 11:59:48.928: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec  3 11:59:48.928: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 12/03/22 11:59:48.928
STEP: Ensuring Pod has resource requirements applied from LimitRange 12/03/22 11:59:48.936
Dec  3 11:59:48.940: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec  3 11:59:48.940: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 12/03/22 11:59:48.94
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/03/22 11:59:48.952
Dec  3 11:59:48.958: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec  3 11:59:48.958: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 12/03/22 11:59:48.958
STEP: Failing to create a Pod with more than max resources 12/03/22 11:59:48.961
STEP: Updating a LimitRange 12/03/22 11:59:48.964
STEP: Verifying LimitRange updating is effective 12/03/22 11:59:48.969
STEP: Creating a Pod with less than former min resources 12/03/22 11:59:50.975
STEP: Failing to create a Pod with more than max resources 12/03/22 11:59:50.983
STEP: Deleting a LimitRange 12/03/22 11:59:50.987
STEP: Verifying the LimitRange was deleted 12/03/22 11:59:50.996
Dec  3 11:59:56.002: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 12/03/22 11:59:56.002
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Dec  3 11:59:56.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6816" for this suite. 12/03/22 11:59:56.016
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":8,"skipped":132,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.269 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:59:48.753
    Dec  3 11:59:48.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename limitrange 12/03/22 11:59:48.755
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:48.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:48.789
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 12/03/22 11:59:48.806
    STEP: Setting up watch 12/03/22 11:59:48.807
    STEP: Submitting a LimitRange 12/03/22 11:59:48.914
    STEP: Verifying LimitRange creation was observed 12/03/22 11:59:48.923
    STEP: Fetching the LimitRange to ensure it has proper values 12/03/22 11:59:48.923
    Dec  3 11:59:48.928: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec  3 11:59:48.928: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 12/03/22 11:59:48.928
    STEP: Ensuring Pod has resource requirements applied from LimitRange 12/03/22 11:59:48.936
    Dec  3 11:59:48.940: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec  3 11:59:48.940: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 12/03/22 11:59:48.94
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/03/22 11:59:48.952
    Dec  3 11:59:48.958: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Dec  3 11:59:48.958: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 12/03/22 11:59:48.958
    STEP: Failing to create a Pod with more than max resources 12/03/22 11:59:48.961
    STEP: Updating a LimitRange 12/03/22 11:59:48.964
    STEP: Verifying LimitRange updating is effective 12/03/22 11:59:48.969
    STEP: Creating a Pod with less than former min resources 12/03/22 11:59:50.975
    STEP: Failing to create a Pod with more than max resources 12/03/22 11:59:50.983
    STEP: Deleting a LimitRange 12/03/22 11:59:50.987
    STEP: Verifying the LimitRange was deleted 12/03/22 11:59:50.996
    Dec  3 11:59:56.002: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 12/03/22 11:59:56.002
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Dec  3 11:59:56.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-6816" for this suite. 12/03/22 11:59:56.016
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:59:56.024
Dec  3 11:59:56.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 11:59:56.024
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:56.044
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:56.046
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 11:59:56.049
Dec  3 11:59:56.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec  3 11:59:56.142: INFO: stderr: ""
Dec  3 11:59:56.142: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 12/03/22 11:59:56.142
Dec  3 11:59:56.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Dec  3 11:59:56.372: INFO: stderr: ""
Dec  3 11:59:56.372: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 11:59:56.372
Dec  3 11:59:56.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 delete pods e2e-test-httpd-pod'
Dec  3 11:59:58.444: INFO: stderr: ""
Dec  3 11:59:58.444: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 11:59:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6592" for this suite. 12/03/22 11:59:58.452
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":9,"skipped":132,"failed":0}
------------------------------
â€¢ [2.440 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:59:56.024
    Dec  3 11:59:56.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 11:59:56.024
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:56.044
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:56.046
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 11:59:56.049
    Dec  3 11:59:56.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec  3 11:59:56.142: INFO: stderr: ""
    Dec  3 11:59:56.142: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 12/03/22 11:59:56.142
    Dec  3 11:59:56.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Dec  3 11:59:56.372: INFO: stderr: ""
    Dec  3 11:59:56.372: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 11:59:56.372
    Dec  3 11:59:56.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-6592 delete pods e2e-test-httpd-pod'
    Dec  3 11:59:58.444: INFO: stderr: ""
    Dec  3 11:59:58.444: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 11:59:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6592" for this suite. 12/03/22 11:59:58.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 11:59:58.465
Dec  3 11:59:58.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption 12/03/22 11:59:58.466
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:58.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:58.537
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec  3 11:59:58.561: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 12:00:58.592: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 12/03/22 12:00:58.598
Dec  3 12:00:58.633: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec  3 12:00:58.639: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec  3 12:00:58.659: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec  3 12:00:58.669: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Dec  3 12:00:58.691: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Dec  3 12:00:58.700: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/03/22 12:00:58.7
Dec  3 12:00:58.701: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:00:58.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.990374ms
Dec  3 12:01:00.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011467277s
Dec  3 12:01:02.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010968652s
Dec  3 12:01:04.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011377996s
Dec  3 12:01:06.710: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008947193s
Dec  3 12:01:08.711: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.010075178s
Dec  3 12:01:08.711: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec  3 12:01:08.711: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.716: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.507829ms
Dec  3 12:01:08.716: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 12:01:08.716: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.721: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.088139ms
Dec  3 12:01:08.721: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 12:01:08.721: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.725: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.43848ms
Dec  3 12:01:08.725: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 12:01:08.725: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.730: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.251961ms
Dec  3 12:01:08.730: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 12:01:08.730: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.734: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.074569ms
Dec  3 12:01:08.734: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/03/22 12:01:08.734
Dec  3 12:01:08.741: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8035" to be "running"
Dec  3 12:01:08.746: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.317265ms
Dec  3 12:01:10.752: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010753182s
Dec  3 12:01:12.755: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013427315s
Dec  3 12:01:14.752: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.011155029s
Dec  3 12:01:14.752: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:01:14.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8035" for this suite. 12/03/22 12:01:14.784
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":10,"skipped":164,"failed":0}
------------------------------
â€¢ [SLOW TEST] [76.375 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 11:59:58.465
    Dec  3 11:59:58.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption 12/03/22 11:59:58.466
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 11:59:58.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 11:59:58.537
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec  3 11:59:58.561: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 12:00:58.592: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 12/03/22 12:00:58.598
    Dec  3 12:00:58.633: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec  3 12:00:58.639: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec  3 12:00:58.659: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec  3 12:00:58.669: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Dec  3 12:00:58.691: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Dec  3 12:00:58.700: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/03/22 12:00:58.7
    Dec  3 12:00:58.701: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:00:58.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.990374ms
    Dec  3 12:01:00.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011467277s
    Dec  3 12:01:02.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010968652s
    Dec  3 12:01:04.712: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011377996s
    Dec  3 12:01:06.710: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008947193s
    Dec  3 12:01:08.711: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.010075178s
    Dec  3 12:01:08.711: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec  3 12:01:08.711: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.716: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.507829ms
    Dec  3 12:01:08.716: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 12:01:08.716: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.721: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.088139ms
    Dec  3 12:01:08.721: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 12:01:08.721: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.725: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.43848ms
    Dec  3 12:01:08.725: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 12:01:08.725: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.730: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.251961ms
    Dec  3 12:01:08.730: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 12:01:08.730: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.734: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.074569ms
    Dec  3 12:01:08.734: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/03/22 12:01:08.734
    Dec  3 12:01:08.741: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8035" to be "running"
    Dec  3 12:01:08.746: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.317265ms
    Dec  3 12:01:10.752: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010753182s
    Dec  3 12:01:12.755: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013427315s
    Dec  3 12:01:14.752: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.011155029s
    Dec  3 12:01:14.752: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:01:14.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8035" for this suite. 12/03/22 12:01:14.784
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:01:14.841
Dec  3 12:01:14.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename controllerrevisions 12/03/22 12:01:14.842
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:14.865
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:14.87
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-bpwqx-daemon-set" 12/03/22 12:01:14.909
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 12:01:14.915
Dec  3 12:01:14.918: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:14.918: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:14.922: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
Dec  3 12:01:14.922: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:01:15.927: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:15.927: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:15.932: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
Dec  3 12:01:15.932: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:01:16.927: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:16.928: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:01:16.934: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 3
Dec  3 12:01:16.934: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-bpwqx-daemon-set
STEP: Confirm DaemonSet "e2e-bpwqx-daemon-set" successfully created with "daemonset-name=e2e-bpwqx-daemon-set" label 12/03/22 12:01:16.938
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-bpwqx-daemon-set" 12/03/22 12:01:16.944
Dec  3 12:01:16.950: INFO: Located ControllerRevision: "e2e-bpwqx-daemon-set-577bf56869"
STEP: Patching ControllerRevision "e2e-bpwqx-daemon-set-577bf56869" 12/03/22 12:01:16.955
Dec  3 12:01:16.967: INFO: e2e-bpwqx-daemon-set-577bf56869 has been patched
STEP: Create a new ControllerRevision 12/03/22 12:01:16.967
Dec  3 12:01:16.973: INFO: Created ControllerRevision: e2e-bpwqx-daemon-set-5684d7dbd5
STEP: Confirm that there are two ControllerRevisions 12/03/22 12:01:16.973
Dec  3 12:01:16.973: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec  3 12:01:16.977: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-bpwqx-daemon-set-577bf56869" 12/03/22 12:01:16.977
STEP: Confirm that there is only one ControllerRevision 12/03/22 12:01:16.984
Dec  3 12:01:16.984: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec  3 12:01:16.989: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-bpwqx-daemon-set-5684d7dbd5" 12/03/22 12:01:16.992
Dec  3 12:01:17.003: INFO: e2e-bpwqx-daemon-set-5684d7dbd5 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 12/03/22 12:01:17.003
W1203 12:01:17.019589      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 12/03/22 12:01:17.019
Dec  3 12:01:17.019: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec  3 12:01:18.026: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec  3 12:01:18.030: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-bpwqx-daemon-set-5684d7dbd5=updated" 12/03/22 12:01:18.03
STEP: Confirm that there is only one ControllerRevision 12/03/22 12:01:18.047
Dec  3 12:01:18.047: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec  3 12:01:18.051: INFO: Found 1 ControllerRevisions
Dec  3 12:01:18.055: INFO: ControllerRevision "e2e-bpwqx-daemon-set-7f4bb9c9b4" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-bpwqx-daemon-set" 12/03/22 12:01:18.058
STEP: deleting DaemonSet.extensions e2e-bpwqx-daemon-set in namespace controllerrevisions-6874, will wait for the garbage collector to delete the pods 12/03/22 12:01:18.058
Dec  3 12:01:18.122: INFO: Deleting DaemonSet.extensions e2e-bpwqx-daemon-set took: 8.471119ms
Dec  3 12:01:18.222: INFO: Terminating DaemonSet.extensions e2e-bpwqx-daemon-set pods took: 100.212401ms
Dec  3 12:01:19.729: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
Dec  3 12:01:19.729: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-bpwqx-daemon-set
Dec  3 12:01:19.733: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3789"},"items":null}

Dec  3 12:01:19.736: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3789"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:01:19.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-6874" for this suite. 12/03/22 12:01:19.758
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":11,"skipped":179,"failed":0}
------------------------------
â€¢ [4.924 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:01:14.841
    Dec  3 12:01:14.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename controllerrevisions 12/03/22 12:01:14.842
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:14.865
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:14.87
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-bpwqx-daemon-set" 12/03/22 12:01:14.909
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 12:01:14.915
    Dec  3 12:01:14.918: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:14.918: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:14.922: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
    Dec  3 12:01:14.922: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:01:15.927: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:15.927: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:15.932: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
    Dec  3 12:01:15.932: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:01:16.927: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:16.928: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:01:16.934: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 3
    Dec  3 12:01:16.934: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-bpwqx-daemon-set
    STEP: Confirm DaemonSet "e2e-bpwqx-daemon-set" successfully created with "daemonset-name=e2e-bpwqx-daemon-set" label 12/03/22 12:01:16.938
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-bpwqx-daemon-set" 12/03/22 12:01:16.944
    Dec  3 12:01:16.950: INFO: Located ControllerRevision: "e2e-bpwqx-daemon-set-577bf56869"
    STEP: Patching ControllerRevision "e2e-bpwqx-daemon-set-577bf56869" 12/03/22 12:01:16.955
    Dec  3 12:01:16.967: INFO: e2e-bpwqx-daemon-set-577bf56869 has been patched
    STEP: Create a new ControllerRevision 12/03/22 12:01:16.967
    Dec  3 12:01:16.973: INFO: Created ControllerRevision: e2e-bpwqx-daemon-set-5684d7dbd5
    STEP: Confirm that there are two ControllerRevisions 12/03/22 12:01:16.973
    Dec  3 12:01:16.973: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec  3 12:01:16.977: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-bpwqx-daemon-set-577bf56869" 12/03/22 12:01:16.977
    STEP: Confirm that there is only one ControllerRevision 12/03/22 12:01:16.984
    Dec  3 12:01:16.984: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec  3 12:01:16.989: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-bpwqx-daemon-set-5684d7dbd5" 12/03/22 12:01:16.992
    Dec  3 12:01:17.003: INFO: e2e-bpwqx-daemon-set-5684d7dbd5 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 12/03/22 12:01:17.003
    W1203 12:01:17.019589      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 12/03/22 12:01:17.019
    Dec  3 12:01:17.019: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec  3 12:01:18.026: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec  3 12:01:18.030: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-bpwqx-daemon-set-5684d7dbd5=updated" 12/03/22 12:01:18.03
    STEP: Confirm that there is only one ControllerRevision 12/03/22 12:01:18.047
    Dec  3 12:01:18.047: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec  3 12:01:18.051: INFO: Found 1 ControllerRevisions
    Dec  3 12:01:18.055: INFO: ControllerRevision "e2e-bpwqx-daemon-set-7f4bb9c9b4" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-bpwqx-daemon-set" 12/03/22 12:01:18.058
    STEP: deleting DaemonSet.extensions e2e-bpwqx-daemon-set in namespace controllerrevisions-6874, will wait for the garbage collector to delete the pods 12/03/22 12:01:18.058
    Dec  3 12:01:18.122: INFO: Deleting DaemonSet.extensions e2e-bpwqx-daemon-set took: 8.471119ms
    Dec  3 12:01:18.222: INFO: Terminating DaemonSet.extensions e2e-bpwqx-daemon-set pods took: 100.212401ms
    Dec  3 12:01:19.729: INFO: Number of nodes with available pods controlled by daemonset e2e-bpwqx-daemon-set: 0
    Dec  3 12:01:19.729: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-bpwqx-daemon-set
    Dec  3 12:01:19.733: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3789"},"items":null}

    Dec  3 12:01:19.736: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3789"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:01:19.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-6874" for this suite. 12/03/22 12:01:19.758
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:01:19.768
Dec  3 12:01:19.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 12:01:19.769
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:19.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:19.793
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 12/03/22 12:01:19.796
STEP: waiting for pod running 12/03/22 12:01:19.817
Dec  3 12:01:19.817: INFO: Waiting up to 2m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187" to be "running"
Dec  3 12:01:19.822: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.586353ms
Dec  3 12:01:21.827: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009987855s
Dec  3 12:01:23.827: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Running", Reason="", readiness=true. Elapsed: 4.01011374s
Dec  3 12:01:23.828: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" satisfied condition "running"
STEP: creating a file in subpath 12/03/22 12:01:23.828
Dec  3 12:01:23.833: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5187 PodName:var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:01:23.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:01:23.834: INFO: ExecWithOptions: Clientset creation
Dec  3 12:01:23.834: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5187/pods/var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 12/03/22 12:01:23.927
Dec  3 12:01:23.932: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5187 PodName:var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:01:23.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:01:23.932: INFO: ExecWithOptions: Clientset creation
Dec  3 12:01:23.932: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5187/pods/var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 12/03/22 12:01:24.009
Dec  3 12:01:24.524: INFO: Successfully updated pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202"
STEP: waiting for annotated pod running 12/03/22 12:01:24.524
Dec  3 12:01:24.524: INFO: Waiting up to 2m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187" to be "running"
Dec  3 12:01:24.528: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Running", Reason="", readiness=true. Elapsed: 3.856538ms
Dec  3 12:01:24.528: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" satisfied condition "running"
STEP: deleting the pod gracefully 12/03/22 12:01:24.528
Dec  3 12:01:24.528: INFO: Deleting pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187"
Dec  3 12:01:24.538: INFO: Wait up to 5m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 12:01:58.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5187" for this suite. 12/03/22 12:01:58.555
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":12,"skipped":211,"failed":0}
------------------------------
â€¢ [SLOW TEST] [38.796 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:01:19.768
    Dec  3 12:01:19.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 12:01:19.769
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:19.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:19.793
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 12/03/22 12:01:19.796
    STEP: waiting for pod running 12/03/22 12:01:19.817
    Dec  3 12:01:19.817: INFO: Waiting up to 2m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187" to be "running"
    Dec  3 12:01:19.822: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.586353ms
    Dec  3 12:01:21.827: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009987855s
    Dec  3 12:01:23.827: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Running", Reason="", readiness=true. Elapsed: 4.01011374s
    Dec  3 12:01:23.828: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" satisfied condition "running"
    STEP: creating a file in subpath 12/03/22 12:01:23.828
    Dec  3 12:01:23.833: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5187 PodName:var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:01:23.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:01:23.834: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:01:23.834: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5187/pods/var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 12/03/22 12:01:23.927
    Dec  3 12:01:23.932: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5187 PodName:var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:01:23.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:01:23.932: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:01:23.932: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5187/pods/var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 12/03/22 12:01:24.009
    Dec  3 12:01:24.524: INFO: Successfully updated pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202"
    STEP: waiting for annotated pod running 12/03/22 12:01:24.524
    Dec  3 12:01:24.524: INFO: Waiting up to 2m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187" to be "running"
    Dec  3 12:01:24.528: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202": Phase="Running", Reason="", readiness=true. Elapsed: 3.856538ms
    Dec  3 12:01:24.528: INFO: Pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" satisfied condition "running"
    STEP: deleting the pod gracefully 12/03/22 12:01:24.528
    Dec  3 12:01:24.528: INFO: Deleting pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" in namespace "var-expansion-5187"
    Dec  3 12:01:24.538: INFO: Wait up to 5m0s for pod "var-expansion-75932bd3-1d33-44a6-8ef0-ad436b199202" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 12:01:58.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5187" for this suite. 12/03/22 12:01:58.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:01:58.567
Dec  3 12:01:58.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:01:58.568
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:58.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:58.604
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 12/03/22 12:01:58.609
STEP: Getting a ResourceQuota 12/03/22 12:01:58.62
STEP: Updating a ResourceQuota 12/03/22 12:01:58.625
STEP: Verifying a ResourceQuota was modified 12/03/22 12:01:58.636
STEP: Deleting a ResourceQuota 12/03/22 12:01:58.64
STEP: Verifying the deleted ResourceQuota 12/03/22 12:01:58.648
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:01:58.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-608" for this suite. 12/03/22 12:01:58.658
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":13,"skipped":223,"failed":0}
------------------------------
â€¢ [0.106 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:01:58.567
    Dec  3 12:01:58.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:01:58.568
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:58.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:58.604
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 12/03/22 12:01:58.609
    STEP: Getting a ResourceQuota 12/03/22 12:01:58.62
    STEP: Updating a ResourceQuota 12/03/22 12:01:58.625
    STEP: Verifying a ResourceQuota was modified 12/03/22 12:01:58.636
    STEP: Deleting a ResourceQuota 12/03/22 12:01:58.64
    STEP: Verifying the deleted ResourceQuota 12/03/22 12:01:58.648
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:01:58.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-608" for this suite. 12/03/22 12:01:58.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:01:58.675
Dec  3 12:01:58.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:01:58.676
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:58.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:58.707
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Dec  3 12:01:58.724: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  3 12:02:03.738: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 12:02:03.738
Dec  3 12:02:03.738: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 12:02:05.742: INFO: Creating deployment "test-rollover-deployment"
Dec  3 12:02:05.752: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 12:02:07.763: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 12:02:07.772: INFO: Ensure that both replica sets have 1 created replica
Dec  3 12:02:07.784: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 12:02:07.798: INFO: Updating deployment test-rollover-deployment
Dec  3 12:02:07.798: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 12:02:09.808: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 12:02:09.816: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 12:02:09.823: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 12:02:09.824: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:02:11.834: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 12:02:11.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:02:13.835: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 12:02:13.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:02:15.833: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 12:02:15.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:02:17.834: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 12:02:17.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:02:19.838: INFO: 
Dec  3 12:02:19.838: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:02:19.848: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9071  393a5bf9-0f17-422e-9748-cd93c7a273b4 4170 2 2022-12-03 12:02:05 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00311b6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:02:05 +0000 UTC,LastTransitionTime:2022-12-03 12:02:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-03 12:02:19 +0000 UTC,LastTransitionTime:2022-12-03 12:02:05 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 12:02:19.852: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9071  3223c013-dee1-4cdb-9123-1b84787c26cf 4160 2 2022-12-03 12:02:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003285127 0xc003285128}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032851d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:02:19.852: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 12:02:19.852: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9071  07c15b39-eeb9-41cd-b73c-e6c750ac6361 4169 2 2022-12-03 12:01:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003284eef 0xc003284f00}] [] [{e2e.test Update apps/v1 2022-12-03 12:01:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003284fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:02:19.852: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9071  a4447d67-cf02-4910-a67d-5916e1233ffe 4118 2 2022-12-03 12:02:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003285017 0xc003285018}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032850c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:02:19.855: INFO: Pod "test-rollover-deployment-6d45fd857b-4pf7f" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-4pf7f test-rollover-deployment-6d45fd857b- deployment-9071  1e9822b5-b2b7-4029-adf4-592f8219f89a 4138 0 2022-12-03 12:02:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 3223c013-dee1-4cdb-9123-1b84787c26cf 0xc00311ba77 0xc00311ba78}] [] [{kube-controller-manager Update v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3223c013-dee1-4cdb-9123-1b84787c26cf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:02:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qpznh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qpznh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.82,StartTime:2022-12-03 12:02:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:02:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://bfa9c6df1738a7aad81f25ed09f63042181866ea2c5bf0a4a77adaf4bd82f358,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:02:19.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9071" for this suite. 12/03/22 12:02:19.859
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":14,"skipped":231,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.192 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:01:58.675
    Dec  3 12:01:58.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:01:58.676
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:01:58.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:01:58.707
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Dec  3 12:01:58.724: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Dec  3 12:02:03.738: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 12:02:03.738
    Dec  3 12:02:03.738: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Dec  3 12:02:05.742: INFO: Creating deployment "test-rollover-deployment"
    Dec  3 12:02:05.752: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Dec  3 12:02:07.763: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Dec  3 12:02:07.772: INFO: Ensure that both replica sets have 1 created replica
    Dec  3 12:02:07.784: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Dec  3 12:02:07.798: INFO: Updating deployment test-rollover-deployment
    Dec  3 12:02:07.798: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Dec  3 12:02:09.808: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Dec  3 12:02:09.816: INFO: Make sure deployment "test-rollover-deployment" is complete
    Dec  3 12:02:09.823: INFO: all replica sets need to contain the pod-template-hash label
    Dec  3 12:02:09.824: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:02:11.834: INFO: all replica sets need to contain the pod-template-hash label
    Dec  3 12:02:11.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:02:13.835: INFO: all replica sets need to contain the pod-template-hash label
    Dec  3 12:02:13.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:02:15.833: INFO: all replica sets need to contain the pod-template-hash label
    Dec  3 12:02:15.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:02:17.834: INFO: all replica sets need to contain the pod-template-hash label
    Dec  3 12:02:17.835: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 2, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 2, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:02:19.838: INFO: 
    Dec  3 12:02:19.838: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:02:19.848: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-9071  393a5bf9-0f17-422e-9748-cd93c7a273b4 4170 2 2022-12-03 12:02:05 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00311b6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:02:05 +0000 UTC,LastTransitionTime:2022-12-03 12:02:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-03 12:02:19 +0000 UTC,LastTransitionTime:2022-12-03 12:02:05 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec  3 12:02:19.852: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9071  3223c013-dee1-4cdb-9123-1b84787c26cf 4160 2 2022-12-03 12:02:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003285127 0xc003285128}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032851d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:02:19.852: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Dec  3 12:02:19.852: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9071  07c15b39-eeb9-41cd-b73c-e6c750ac6361 4169 2 2022-12-03 12:01:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003284eef 0xc003284f00}] [] [{e2e.test Update apps/v1 2022-12-03 12:01:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003284fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:02:19.852: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9071  a4447d67-cf02-4910-a67d-5916e1233ffe 4118 2 2022-12-03 12:02:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 393a5bf9-0f17-422e-9748-cd93c7a273b4 0xc003285017 0xc003285018}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"393a5bf9-0f17-422e-9748-cd93c7a273b4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032850c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:02:19.855: INFO: Pod "test-rollover-deployment-6d45fd857b-4pf7f" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-4pf7f test-rollover-deployment-6d45fd857b- deployment-9071  1e9822b5-b2b7-4029-adf4-592f8219f89a 4138 0 2022-12-03 12:02:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 3223c013-dee1-4cdb-9123-1b84787c26cf 0xc00311ba77 0xc00311ba78}] [] [{kube-controller-manager Update v1 2022-12-03 12:02:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3223c013-dee1-4cdb-9123-1b84787c26cf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:02:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qpznh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qpznh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:02:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.82,StartTime:2022-12-03 12:02:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:02:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://bfa9c6df1738a7aad81f25ed09f63042181866ea2c5bf0a4a77adaf4bd82f358,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:02:19.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9071" for this suite. 12/03/22 12:02:19.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:02:19.868
Dec  3 12:02:19.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:02:19.869
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:19.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:19.893
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 12/03/22 12:02:19.896
Dec  3 12:02:19.905: INFO: created test-pod-1
Dec  3 12:02:19.912: INFO: created test-pod-2
Dec  3 12:02:19.918: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 12/03/22 12:02:19.918
Dec  3 12:02:19.918: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3088' to be running and ready
Dec  3 12:02:19.941: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec  3 12:02:19.941: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec  3 12:02:19.941: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec  3 12:02:19.941: INFO: 0 / 3 pods in namespace 'pods-3088' are running and ready (0 seconds elapsed)
Dec  3 12:02:19.941: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
Dec  3 12:02:19.941: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
Dec  3 12:02:19.941: INFO: test-pod-1  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
Dec  3 12:02:19.941: INFO: test-pod-2  ip-172-31-76-203  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
Dec  3 12:02:19.941: INFO: test-pod-3                    Pending         []
Dec  3 12:02:19.941: INFO: 
Dec  3 12:02:21.955: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec  3 12:02:21.955: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec  3 12:02:21.955: INFO: 1 / 3 pods in namespace 'pods-3088' are running and ready (2 seconds elapsed)
Dec  3 12:02:21.955: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
Dec  3 12:02:21.955: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
Dec  3 12:02:21.955: INFO: test-pod-1  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
Dec  3 12:02:21.955: INFO: test-pod-3  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
Dec  3 12:02:21.955: INFO: 
Dec  3 12:02:23.956: INFO: 3 / 3 pods in namespace 'pods-3088' are running and ready (4 seconds elapsed)
Dec  3 12:02:23.956: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 12/03/22 12:02:23.988
Dec  3 12:02:23.993: INFO: Pod quantity 3 is different from expected quantity 0
Dec  3 12:02:24.999: INFO: Pod quantity 3 is different from expected quantity 0
Dec  3 12:02:25.998: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:02:26.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3088" for this suite. 12/03/22 12:02:27.001
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":15,"skipped":246,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.140 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:02:19.868
    Dec  3 12:02:19.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:02:19.869
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:19.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:19.893
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 12/03/22 12:02:19.896
    Dec  3 12:02:19.905: INFO: created test-pod-1
    Dec  3 12:02:19.912: INFO: created test-pod-2
    Dec  3 12:02:19.918: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 12/03/22 12:02:19.918
    Dec  3 12:02:19.918: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3088' to be running and ready
    Dec  3 12:02:19.941: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec  3 12:02:19.941: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec  3 12:02:19.941: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec  3 12:02:19.941: INFO: 0 / 3 pods in namespace 'pods-3088' are running and ready (0 seconds elapsed)
    Dec  3 12:02:19.941: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
    Dec  3 12:02:19.941: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
    Dec  3 12:02:19.941: INFO: test-pod-1  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
    Dec  3 12:02:19.941: INFO: test-pod-2  ip-172-31-76-203  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
    Dec  3 12:02:19.941: INFO: test-pod-3                    Pending         []
    Dec  3 12:02:19.941: INFO: 
    Dec  3 12:02:21.955: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec  3 12:02:21.955: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec  3 12:02:21.955: INFO: 1 / 3 pods in namespace 'pods-3088' are running and ready (2 seconds elapsed)
    Dec  3 12:02:21.955: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
    Dec  3 12:02:21.955: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
    Dec  3 12:02:21.955: INFO: test-pod-1  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
    Dec  3 12:02:21.955: INFO: test-pod-3  ip-172-31-38-234  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:02:19 +0000 UTC  }]
    Dec  3 12:02:21.955: INFO: 
    Dec  3 12:02:23.956: INFO: 3 / 3 pods in namespace 'pods-3088' are running and ready (4 seconds elapsed)
    Dec  3 12:02:23.956: INFO: expected 0 pod replicas in namespace 'pods-3088', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 12/03/22 12:02:23.988
    Dec  3 12:02:23.993: INFO: Pod quantity 3 is different from expected quantity 0
    Dec  3 12:02:24.999: INFO: Pod quantity 3 is different from expected quantity 0
    Dec  3 12:02:25.998: INFO: Pod quantity 1 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:02:26.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3088" for this suite. 12/03/22 12:02:27.001
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:02:27.008
Dec  3 12:02:27.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:02:27.009
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:27.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:27.038
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 12/03/22 12:02:27.041
STEP: Creating a ResourceQuota 12/03/22 12:02:32.044
STEP: Ensuring resource quota status is calculated 12/03/22 12:02:32.053
STEP: Creating a Service 12/03/22 12:02:34.061
STEP: Creating a NodePort Service 12/03/22 12:02:34.086
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/03/22 12:02:34.34
STEP: Ensuring resource quota status captures service creation 12/03/22 12:02:34.368
STEP: Deleting Services 12/03/22 12:02:36.373
STEP: Ensuring resource quota status released usage 12/03/22 12:02:36.415
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:02:38.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5884" for this suite. 12/03/22 12:02:38.424
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":16,"skipped":246,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.423 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:02:27.008
    Dec  3 12:02:27.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:02:27.009
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:27.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:27.038
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 12/03/22 12:02:27.041
    STEP: Creating a ResourceQuota 12/03/22 12:02:32.044
    STEP: Ensuring resource quota status is calculated 12/03/22 12:02:32.053
    STEP: Creating a Service 12/03/22 12:02:34.061
    STEP: Creating a NodePort Service 12/03/22 12:02:34.086
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/03/22 12:02:34.34
    STEP: Ensuring resource quota status captures service creation 12/03/22 12:02:34.368
    STEP: Deleting Services 12/03/22 12:02:36.373
    STEP: Ensuring resource quota status released usage 12/03/22 12:02:36.415
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:02:38.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5884" for this suite. 12/03/22 12:02:38.424
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:02:38.433
Dec  3 12:02:38.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:02:38.434
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:38.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:38.462
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 12/03/22 12:02:38.465
Dec  3 12:02:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 create -f -'
Dec  3 12:02:38.686: INFO: stderr: ""
Dec  3 12:02:38.686: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 12:02:38.686
Dec  3 12:02:38.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 12:02:38.769: INFO: stderr: ""
Dec  3 12:02:38.769: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
Dec  3 12:02:38.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 12:02:38.853: INFO: stderr: ""
Dec  3 12:02:38.853: INFO: stdout: ""
Dec  3 12:02:38.853: INFO: update-demo-nautilus-dlcqz is created but not running
Dec  3 12:02:43.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 12:02:43.940: INFO: stderr: ""
Dec  3 12:02:43.940: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
Dec  3 12:02:43.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 12:02:44.032: INFO: stderr: ""
Dec  3 12:02:44.032: INFO: stdout: ""
Dec  3 12:02:44.032: INFO: update-demo-nautilus-dlcqz is created but not running
Dec  3 12:02:49.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 12:02:49.109: INFO: stderr: ""
Dec  3 12:02:49.109: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
Dec  3 12:02:49.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 12:02:49.178: INFO: stderr: ""
Dec  3 12:02:49.179: INFO: stdout: "true"
Dec  3 12:02:49.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 12:02:49.252: INFO: stderr: ""
Dec  3 12:02:49.252: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 12:02:49.252: INFO: validating pod update-demo-nautilus-dlcqz
Dec  3 12:02:49.259: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 12:02:49.259: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 12:02:49.259: INFO: update-demo-nautilus-dlcqz is verified up and running
Dec  3 12:02:49.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-k2dbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 12:02:49.342: INFO: stderr: ""
Dec  3 12:02:49.342: INFO: stdout: "true"
Dec  3 12:02:49.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-k2dbd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 12:02:49.425: INFO: stderr: ""
Dec  3 12:02:49.425: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 12:02:49.425: INFO: validating pod update-demo-nautilus-k2dbd
Dec  3 12:02:49.431: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 12:02:49.432: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 12:02:49.432: INFO: update-demo-nautilus-k2dbd is verified up and running
STEP: using delete to clean up resources 12/03/22 12:02:49.432
Dec  3 12:02:49.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 delete --grace-period=0 --force -f -'
Dec  3 12:02:49.518: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 12:02:49.518: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 12:02:49.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get rc,svc -l name=update-demo --no-headers'
Dec  3 12:02:49.642: INFO: stderr: "No resources found in kubectl-8554 namespace.\n"
Dec  3 12:02:49.642: INFO: stdout: ""
Dec  3 12:02:49.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 12:02:49.829: INFO: stderr: ""
Dec  3 12:02:49.829: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:02:49.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8554" for this suite. 12/03/22 12:02:49.835
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":17,"skipped":272,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.415 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:02:38.433
    Dec  3 12:02:38.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:02:38.434
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:38.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:38.462
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 12/03/22 12:02:38.465
    Dec  3 12:02:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 create -f -'
    Dec  3 12:02:38.686: INFO: stderr: ""
    Dec  3 12:02:38.686: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 12:02:38.686
    Dec  3 12:02:38.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 12:02:38.769: INFO: stderr: ""
    Dec  3 12:02:38.769: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
    Dec  3 12:02:38.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 12:02:38.853: INFO: stderr: ""
    Dec  3 12:02:38.853: INFO: stdout: ""
    Dec  3 12:02:38.853: INFO: update-demo-nautilus-dlcqz is created but not running
    Dec  3 12:02:43.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 12:02:43.940: INFO: stderr: ""
    Dec  3 12:02:43.940: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
    Dec  3 12:02:43.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 12:02:44.032: INFO: stderr: ""
    Dec  3 12:02:44.032: INFO: stdout: ""
    Dec  3 12:02:44.032: INFO: update-demo-nautilus-dlcqz is created but not running
    Dec  3 12:02:49.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 12:02:49.109: INFO: stderr: ""
    Dec  3 12:02:49.109: INFO: stdout: "update-demo-nautilus-dlcqz update-demo-nautilus-k2dbd "
    Dec  3 12:02:49.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 12:02:49.178: INFO: stderr: ""
    Dec  3 12:02:49.179: INFO: stdout: "true"
    Dec  3 12:02:49.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-dlcqz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 12:02:49.252: INFO: stderr: ""
    Dec  3 12:02:49.252: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 12:02:49.252: INFO: validating pod update-demo-nautilus-dlcqz
    Dec  3 12:02:49.259: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 12:02:49.259: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 12:02:49.259: INFO: update-demo-nautilus-dlcqz is verified up and running
    Dec  3 12:02:49.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-k2dbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 12:02:49.342: INFO: stderr: ""
    Dec  3 12:02:49.342: INFO: stdout: "true"
    Dec  3 12:02:49.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods update-demo-nautilus-k2dbd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 12:02:49.425: INFO: stderr: ""
    Dec  3 12:02:49.425: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 12:02:49.425: INFO: validating pod update-demo-nautilus-k2dbd
    Dec  3 12:02:49.431: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 12:02:49.432: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 12:02:49.432: INFO: update-demo-nautilus-k2dbd is verified up and running
    STEP: using delete to clean up resources 12/03/22 12:02:49.432
    Dec  3 12:02:49.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 delete --grace-period=0 --force -f -'
    Dec  3 12:02:49.518: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 12:02:49.518: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec  3 12:02:49.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get rc,svc -l name=update-demo --no-headers'
    Dec  3 12:02:49.642: INFO: stderr: "No resources found in kubectl-8554 namespace.\n"
    Dec  3 12:02:49.642: INFO: stdout: ""
    Dec  3 12:02:49.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-8554 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec  3 12:02:49.829: INFO: stderr: ""
    Dec  3 12:02:49.829: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:02:49.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8554" for this suite. 12/03/22 12:02:49.835
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:02:49.855
Dec  3 12:02:49.855: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context-test 12/03/22 12:02:49.857
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:49.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:49.896
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Dec  3 12:02:49.921: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993" in namespace "security-context-test-1637" to be "Succeeded or Failed"
Dec  3 12:02:49.930: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Pending", Reason="", readiness=false. Elapsed: 9.460583ms
Dec  3 12:02:51.936: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015599282s
Dec  3 12:02:53.937: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016386424s
Dec  3 12:02:53.937: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993" satisfied condition "Succeeded or Failed"
Dec  3 12:02:53.959: INFO: Got logs for pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 12:02:53.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1637" for this suite. 12/03/22 12:02:53.964
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":18,"skipped":309,"failed":0}
------------------------------
â€¢ [4.119 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:02:49.855
    Dec  3 12:02:49.855: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context-test 12/03/22 12:02:49.857
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:49.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:49.896
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Dec  3 12:02:49.921: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993" in namespace "security-context-test-1637" to be "Succeeded or Failed"
    Dec  3 12:02:49.930: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Pending", Reason="", readiness=false. Elapsed: 9.460583ms
    Dec  3 12:02:51.936: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015599282s
    Dec  3 12:02:53.937: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016386424s
    Dec  3 12:02:53.937: INFO: Pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993" satisfied condition "Succeeded or Failed"
    Dec  3 12:02:53.959: INFO: Got logs for pod "busybox-privileged-false-5c333379-19c0-4f36-830f-f3acd8fb7993": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 12:02:53.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1637" for this suite. 12/03/22 12:02:53.964
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:02:53.976
Dec  3 12:02:53.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename subpath 12/03/22 12:02:53.977
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:53.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:54.005
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/03/22 12:02:54.013
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-ttdn 12/03/22 12:02:54.025
STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:02:54.025
Dec  3 12:02:54.039: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ttdn" in namespace "subpath-8744" to be "Succeeded or Failed"
Dec  3 12:02:54.043: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.396741ms
Dec  3 12:02:56.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312762s
Dec  3 12:02:58.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 4.009692505s
Dec  3 12:03:00.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 6.008621634s
Dec  3 12:03:02.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 8.008917743s
Dec  3 12:03:04.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 10.00828387s
Dec  3 12:03:06.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 12.008750166s
Dec  3 12:03:08.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 14.009603338s
Dec  3 12:03:10.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 16.008317058s
Dec  3 12:03:12.047: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 18.00734388s
Dec  3 12:03:14.051: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 20.010932701s
Dec  3 12:03:16.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=false. Elapsed: 22.008987499s
Dec  3 12:03:18.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008809693s
STEP: Saw pod success 12/03/22 12:03:18.049
Dec  3 12:03:18.049: INFO: Pod "pod-subpath-test-secret-ttdn" satisfied condition "Succeeded or Failed"
Dec  3 12:03:18.053: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-secret-ttdn container test-container-subpath-secret-ttdn: <nil>
STEP: delete the pod 12/03/22 12:03:18.061
Dec  3 12:03:18.079: INFO: Waiting for pod pod-subpath-test-secret-ttdn to disappear
Dec  3 12:03:18.085: INFO: Pod pod-subpath-test-secret-ttdn no longer exists
STEP: Deleting pod pod-subpath-test-secret-ttdn 12/03/22 12:03:18.085
Dec  3 12:03:18.086: INFO: Deleting pod "pod-subpath-test-secret-ttdn" in namespace "subpath-8744"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec  3 12:03:18.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8744" for this suite. 12/03/22 12:03:18.101
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":19,"skipped":327,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.134 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:02:53.976
    Dec  3 12:02:53.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename subpath 12/03/22 12:02:53.977
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:02:53.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:02:54.005
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/03/22 12:02:54.013
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-ttdn 12/03/22 12:02:54.025
    STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:02:54.025
    Dec  3 12:02:54.039: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ttdn" in namespace "subpath-8744" to be "Succeeded or Failed"
    Dec  3 12:02:54.043: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.396741ms
    Dec  3 12:02:56.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312762s
    Dec  3 12:02:58.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 4.009692505s
    Dec  3 12:03:00.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 6.008621634s
    Dec  3 12:03:02.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 8.008917743s
    Dec  3 12:03:04.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 10.00828387s
    Dec  3 12:03:06.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 12.008750166s
    Dec  3 12:03:08.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 14.009603338s
    Dec  3 12:03:10.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 16.008317058s
    Dec  3 12:03:12.047: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 18.00734388s
    Dec  3 12:03:14.051: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=true. Elapsed: 20.010932701s
    Dec  3 12:03:16.049: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Running", Reason="", readiness=false. Elapsed: 22.008987499s
    Dec  3 12:03:18.048: INFO: Pod "pod-subpath-test-secret-ttdn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008809693s
    STEP: Saw pod success 12/03/22 12:03:18.049
    Dec  3 12:03:18.049: INFO: Pod "pod-subpath-test-secret-ttdn" satisfied condition "Succeeded or Failed"
    Dec  3 12:03:18.053: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-secret-ttdn container test-container-subpath-secret-ttdn: <nil>
    STEP: delete the pod 12/03/22 12:03:18.061
    Dec  3 12:03:18.079: INFO: Waiting for pod pod-subpath-test-secret-ttdn to disappear
    Dec  3 12:03:18.085: INFO: Pod pod-subpath-test-secret-ttdn no longer exists
    STEP: Deleting pod pod-subpath-test-secret-ttdn 12/03/22 12:03:18.085
    Dec  3 12:03:18.086: INFO: Deleting pod "pod-subpath-test-secret-ttdn" in namespace "subpath-8744"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec  3 12:03:18.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8744" for this suite. 12/03/22 12:03:18.101
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:18.11
Dec  3 12:03:18.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:03:18.111
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.16
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 12/03/22 12:03:18.166
Dec  3 12:03:18.167: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-869 proxy --unix-socket=/tmp/kubectl-proxy-unix1366525279/test'
STEP: retrieving proxy /api/ output 12/03/22 12:03:18.24
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:03:18.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-869" for this suite. 12/03/22 12:03:18.247
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":20,"skipped":327,"failed":0}
------------------------------
â€¢ [0.146 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:18.11
    Dec  3 12:03:18.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:03:18.111
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.16
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 12/03/22 12:03:18.166
    Dec  3 12:03:18.167: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-869 proxy --unix-socket=/tmp/kubectl-proxy-unix1366525279/test'
    STEP: retrieving proxy /api/ output 12/03/22 12:03:18.24
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:03:18.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-869" for this suite. 12/03/22 12:03:18.247
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:18.256
Dec  3 12:03:18.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename watch 12/03/22 12:03:18.257
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.282
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 12/03/22 12:03:18.288
STEP: creating a new configmap 12/03/22 12:03:18.29
STEP: modifying the configmap once 12/03/22 12:03:18.295
STEP: closing the watch once it receives two notifications 12/03/22 12:03:18.305
Dec  3 12:03:18.306: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4589 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:03:18.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4590 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 12/03/22 12:03:18.306
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/03/22 12:03:18.318
STEP: deleting the configmap 12/03/22 12:03:18.32
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/03/22 12:03:18.331
Dec  3 12:03:18.331: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4591 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:03:18.332: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4592 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec  3 12:03:18.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3159" for this suite. 12/03/22 12:03:18.337
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":21,"skipped":327,"failed":0}
------------------------------
â€¢ [0.090 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:18.256
    Dec  3 12:03:18.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename watch 12/03/22 12:03:18.257
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.282
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 12/03/22 12:03:18.288
    STEP: creating a new configmap 12/03/22 12:03:18.29
    STEP: modifying the configmap once 12/03/22 12:03:18.295
    STEP: closing the watch once it receives two notifications 12/03/22 12:03:18.305
    Dec  3 12:03:18.306: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4589 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:03:18.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4590 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 12/03/22 12:03:18.306
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/03/22 12:03:18.318
    STEP: deleting the configmap 12/03/22 12:03:18.32
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/03/22 12:03:18.331
    Dec  3 12:03:18.331: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4591 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:03:18.332: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3159  03d7ec54-44ea-4f0d-a585-484539eaacf2 4592 0 2022-12-03 12:03:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-03 12:03:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec  3 12:03:18.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3159" for this suite. 12/03/22 12:03:18.337
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:18.347
Dec  3 12:03:18.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 12:03:18.348
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.373
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Dec  3 12:03:18.466: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4e77e892-cf24-483d-b065-180184e78d25", Controller:(*bool)(0xc0025194d6), BlockOwnerDeletion:(*bool)(0xc0025194d7)}}
Dec  3 12:03:18.481: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b18ec479-d2ad-4e3e-9e7e-8f86af60c418", Controller:(*bool)(0xc00251973e), BlockOwnerDeletion:(*bool)(0xc00251973f)}}
Dec  3 12:03:18.492: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"27d771a3-b8e6-4ee7-944b-d4d33204403d", Controller:(*bool)(0xc0009cc466), BlockOwnerDeletion:(*bool)(0xc0009cc467)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 12:03:23.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9582" for this suite. 12/03/22 12:03:23.517
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":22,"skipped":341,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.177 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:18.347
    Dec  3 12:03:18.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 12:03:18.348
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:18.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:18.373
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Dec  3 12:03:18.466: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4e77e892-cf24-483d-b065-180184e78d25", Controller:(*bool)(0xc0025194d6), BlockOwnerDeletion:(*bool)(0xc0025194d7)}}
    Dec  3 12:03:18.481: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b18ec479-d2ad-4e3e-9e7e-8f86af60c418", Controller:(*bool)(0xc00251973e), BlockOwnerDeletion:(*bool)(0xc00251973f)}}
    Dec  3 12:03:18.492: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"27d771a3-b8e6-4ee7-944b-d4d33204403d", Controller:(*bool)(0xc0009cc466), BlockOwnerDeletion:(*bool)(0xc0009cc467)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 12:03:23.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9582" for this suite. 12/03/22 12:03:23.517
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:23.525
Dec  3 12:03:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename init-container 12/03/22 12:03:23.525
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:23.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:23.548
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 12/03/22 12:03:23.564
Dec  3 12:03:23.564: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 12:03:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2812" for this suite. 12/03/22 12:03:28.893
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":23,"skipped":345,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.374 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:23.525
    Dec  3 12:03:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename init-container 12/03/22 12:03:23.525
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:23.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:23.548
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 12/03/22 12:03:23.564
    Dec  3 12:03:23.564: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 12:03:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2812" for this suite. 12/03/22 12:03:28.893
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:28.902
Dec  3 12:03:28.902: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:03:28.903
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:28.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:28.927
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-5623dab3-23a9-4bc8-95d6-f6a0cccc6729 12/03/22 12:03:28.93
STEP: Creating a pod to test consume configMaps 12/03/22 12:03:28.935
Dec  3 12:03:28.946: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782" in namespace "projected-2455" to be "Succeeded or Failed"
Dec  3 12:03:28.949: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940446ms
Dec  3 12:03:30.952: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006831536s
Dec  3 12:03:32.957: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011082784s
STEP: Saw pod success 12/03/22 12:03:32.957
Dec  3 12:03:32.957: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782" satisfied condition "Succeeded or Failed"
Dec  3 12:03:32.961: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 12:03:32.969
Dec  3 12:03:32.987: INFO: Waiting for pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 to disappear
Dec  3 12:03:32.991: INFO: Pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 12:03:32.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2455" for this suite. 12/03/22 12:03:32.997
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":24,"skipped":373,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:28.902
    Dec  3 12:03:28.902: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:03:28.903
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:28.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:28.927
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-5623dab3-23a9-4bc8-95d6-f6a0cccc6729 12/03/22 12:03:28.93
    STEP: Creating a pod to test consume configMaps 12/03/22 12:03:28.935
    Dec  3 12:03:28.946: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782" in namespace "projected-2455" to be "Succeeded or Failed"
    Dec  3 12:03:28.949: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940446ms
    Dec  3 12:03:30.952: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006831536s
    Dec  3 12:03:32.957: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011082784s
    STEP: Saw pod success 12/03/22 12:03:32.957
    Dec  3 12:03:32.957: INFO: Pod "pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782" satisfied condition "Succeeded or Failed"
    Dec  3 12:03:32.961: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 12:03:32.969
    Dec  3 12:03:32.987: INFO: Waiting for pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 to disappear
    Dec  3 12:03:32.991: INFO: Pod pod-projected-configmaps-452ec254-dfd3-4e5e-9da9-894bdaa94782 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 12:03:32.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2455" for this suite. 12/03/22 12:03:32.997
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:33.013
Dec  3 12:03:33.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:03:33.014
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:33.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:33.044
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:03:33.07
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:03:33.522
STEP: Deploying the webhook pod 12/03/22 12:03:33.533
STEP: Wait for the deployment to be ready 12/03/22 12:03:33.548
Dec  3 12:03:33.556: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 12/03/22 12:03:35.57
STEP: Verifying the service has paired with the endpoint 12/03/22 12:03:35.583
Dec  3 12:03:36.583: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 12/03/22 12:03:36.59
Dec  3 12:03:36.611: INFO: Waiting for webhook configuration to be ready...
STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/03/22 12:03:36.726
STEP: Creating a configMap that should not be mutated 12/03/22 12:03:36.735
STEP: Patching a mutating webhook configuration's rules to include the create operation 12/03/22 12:03:36.75
STEP: Creating a configMap that should be mutated 12/03/22 12:03:36.759
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:03:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2083" for this suite. 12/03/22 12:03:36.794
STEP: Destroying namespace "webhook-2083-markers" for this suite. 12/03/22 12:03:36.807
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":25,"skipped":404,"failed":0}
------------------------------
â€¢ [3.923 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:33.013
    Dec  3 12:03:33.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:03:33.014
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:33.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:33.044
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:03:33.07
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:03:33.522
    STEP: Deploying the webhook pod 12/03/22 12:03:33.533
    STEP: Wait for the deployment to be ready 12/03/22 12:03:33.548
    Dec  3 12:03:33.556: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 12/03/22 12:03:35.57
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:03:35.583
    Dec  3 12:03:36.583: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 12/03/22 12:03:36.59
    Dec  3 12:03:36.611: INFO: Waiting for webhook configuration to be ready...
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/03/22 12:03:36.726
    STEP: Creating a configMap that should not be mutated 12/03/22 12:03:36.735
    STEP: Patching a mutating webhook configuration's rules to include the create operation 12/03/22 12:03:36.75
    STEP: Creating a configMap that should be mutated 12/03/22 12:03:36.759
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:03:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2083" for this suite. 12/03/22 12:03:36.794
    STEP: Destroying namespace "webhook-2083-markers" for this suite. 12/03/22 12:03:36.807
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:03:36.936
Dec  3 12:03:36.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename cronjob 12/03/22 12:03:36.937
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:37
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:37.006
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 12/03/22 12:03:37.01
STEP: Ensuring a job is scheduled 12/03/22 12:03:37.02
STEP: Ensuring exactly one is scheduled 12/03/22 12:04:01.026
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/03/22 12:04:01.031
STEP: Ensuring no more jobs are scheduled 12/03/22 12:04:01.035
STEP: Removing cronjob 12/03/22 12:09:01.041
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec  3 12:09:01.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1675" for this suite. 12/03/22 12:09:01.055
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":26,"skipped":405,"failed":0}
------------------------------
â€¢ [SLOW TEST] [324.127 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:03:36.936
    Dec  3 12:03:36.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename cronjob 12/03/22 12:03:36.937
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:03:37
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:03:37.006
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 12/03/22 12:03:37.01
    STEP: Ensuring a job is scheduled 12/03/22 12:03:37.02
    STEP: Ensuring exactly one is scheduled 12/03/22 12:04:01.026
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/03/22 12:04:01.031
    STEP: Ensuring no more jobs are scheduled 12/03/22 12:04:01.035
    STEP: Removing cronjob 12/03/22 12:09:01.041
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec  3 12:09:01.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1675" for this suite. 12/03/22 12:09:01.055
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:09:01.065
Dec  3 12:09:01.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:09:01.067
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:01.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:01.101
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Dec  3 12:09:01.114: INFO: Waiting up to 5m0s for pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942" in namespace "container-probe-7616" to be "running and ready"
Dec  3 12:09:01.123: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Pending", Reason="", readiness=false. Elapsed: 9.641243ms
Dec  3 12:09:01.124: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:09:03.130: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 2.016453792s
Dec  3 12:09:03.130: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:05.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 4.014963245s
Dec  3 12:09:05.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:07.131: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 6.01685859s
Dec  3 12:09:07.131: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:09.128: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 8.01446756s
Dec  3 12:09:09.128: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:11.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 10.015616827s
Dec  3 12:09:11.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:13.128: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 12.014286203s
Dec  3 12:09:13.128: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:15.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 14.015521563s
Dec  3 12:09:15.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:17.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 16.014816618s
Dec  3 12:09:17.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:19.130: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 18.016013433s
Dec  3 12:09:19.130: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:21.132: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 20.017783484s
Dec  3 12:09:21.132: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
Dec  3 12:09:23.127: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=true. Elapsed: 22.013568734s
Dec  3 12:09:23.127: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = true)
Dec  3 12:09:23.127: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942" satisfied condition "running and ready"
Dec  3 12:09:23.131: INFO: Container started at 2022-12-03 12:09:02 +0000 UTC, pod became ready at 2022-12-03 12:09:21 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:09:23.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7616" for this suite. 12/03/22 12:09:23.136
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":27,"skipped":427,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.086 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:09:01.065
    Dec  3 12:09:01.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:09:01.067
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:01.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:01.101
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Dec  3 12:09:01.114: INFO: Waiting up to 5m0s for pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942" in namespace "container-probe-7616" to be "running and ready"
    Dec  3 12:09:01.123: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Pending", Reason="", readiness=false. Elapsed: 9.641243ms
    Dec  3 12:09:01.124: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:09:03.130: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 2.016453792s
    Dec  3 12:09:03.130: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:05.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 4.014963245s
    Dec  3 12:09:05.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:07.131: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 6.01685859s
    Dec  3 12:09:07.131: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:09.128: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 8.01446756s
    Dec  3 12:09:09.128: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:11.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 10.015616827s
    Dec  3 12:09:11.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:13.128: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 12.014286203s
    Dec  3 12:09:13.128: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:15.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 14.015521563s
    Dec  3 12:09:15.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:17.129: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 16.014816618s
    Dec  3 12:09:17.129: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:19.130: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 18.016013433s
    Dec  3 12:09:19.130: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:21.132: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=false. Elapsed: 20.017783484s
    Dec  3 12:09:21.132: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = false)
    Dec  3 12:09:23.127: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942": Phase="Running", Reason="", readiness=true. Elapsed: 22.013568734s
    Dec  3 12:09:23.127: INFO: The phase of Pod test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942 is Running (Ready = true)
    Dec  3 12:09:23.127: INFO: Pod "test-webserver-1c207d4f-f746-4a39-b88d-1a38067ce942" satisfied condition "running and ready"
    Dec  3 12:09:23.131: INFO: Container started at 2022-12-03 12:09:02 +0000 UTC, pod became ready at 2022-12-03 12:09:21 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:09:23.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7616" for this suite. 12/03/22 12:09:23.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:09:23.152
Dec  3 12:09:23.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:09:23.153
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:23.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:23.178
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:09:23.185
Dec  3 12:09:23.196: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4898" to be "running and ready"
Dec  3 12:09:23.199: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.784436ms
Dec  3 12:09:23.199: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:09:25.204: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008051439s
Dec  3 12:09:25.205: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec  3 12:09:25.205: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 12/03/22 12:09:25.208
Dec  3 12:09:25.217: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-4898" to be "running and ready"
Dec  3 12:09:25.222: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.279247ms
Dec  3 12:09:25.222: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:09:27.228: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011240319s
Dec  3 12:09:27.228: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Dec  3 12:09:27.228: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/03/22 12:09:27.235
Dec  3 12:09:27.249: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 12:09:27.252: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 12:09:29.252: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 12:09:29.257: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 12:09:31.252: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 12:09:31.257: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 12/03/22 12:09:31.257
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec  3 12:09:31.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4898" for this suite. 12/03/22 12:09:31.284
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":28,"skipped":436,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.140 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:09:23.152
    Dec  3 12:09:23.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:09:23.153
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:23.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:23.178
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:09:23.185
    Dec  3 12:09:23.196: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4898" to be "running and ready"
    Dec  3 12:09:23.199: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.784436ms
    Dec  3 12:09:23.199: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:09:25.204: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008051439s
    Dec  3 12:09:25.205: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec  3 12:09:25.205: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 12/03/22 12:09:25.208
    Dec  3 12:09:25.217: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-4898" to be "running and ready"
    Dec  3 12:09:25.222: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.279247ms
    Dec  3 12:09:25.222: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:09:27.228: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011240319s
    Dec  3 12:09:27.228: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Dec  3 12:09:27.228: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/03/22 12:09:27.235
    Dec  3 12:09:27.249: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec  3 12:09:27.252: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec  3 12:09:29.252: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec  3 12:09:29.257: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec  3 12:09:31.252: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec  3 12:09:31.257: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 12/03/22 12:09:31.257
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec  3 12:09:31.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4898" for this suite. 12/03/22 12:09:31.284
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:09:31.294
Dec  3 12:09:31.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:09:31.295
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:31.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:31.321
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 12/03/22 12:09:31.324
STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:09:31.331
STEP: Creating a ResourceQuota with not best effort scope 12/03/22 12:09:33.337
STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:09:33.344
STEP: Creating a best-effort pod 12/03/22 12:09:35.35
STEP: Ensuring resource quota with best effort scope captures the pod usage 12/03/22 12:09:35.365
STEP: Ensuring resource quota with not best effort ignored the pod usage 12/03/22 12:09:37.371
STEP: Deleting the pod 12/03/22 12:09:39.376
STEP: Ensuring resource quota status released the pod usage 12/03/22 12:09:39.387
STEP: Creating a not best-effort pod 12/03/22 12:09:41.393
STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/03/22 12:09:41.405
STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/03/22 12:09:43.409
STEP: Deleting the pod 12/03/22 12:09:45.415
STEP: Ensuring resource quota status released the pod usage 12/03/22 12:09:45.433
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:09:47.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3539" for this suite. 12/03/22 12:09:47.443
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":29,"skipped":455,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.157 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:09:31.294
    Dec  3 12:09:31.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:09:31.295
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:31.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:31.321
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 12/03/22 12:09:31.324
    STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:09:31.331
    STEP: Creating a ResourceQuota with not best effort scope 12/03/22 12:09:33.337
    STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:09:33.344
    STEP: Creating a best-effort pod 12/03/22 12:09:35.35
    STEP: Ensuring resource quota with best effort scope captures the pod usage 12/03/22 12:09:35.365
    STEP: Ensuring resource quota with not best effort ignored the pod usage 12/03/22 12:09:37.371
    STEP: Deleting the pod 12/03/22 12:09:39.376
    STEP: Ensuring resource quota status released the pod usage 12/03/22 12:09:39.387
    STEP: Creating a not best-effort pod 12/03/22 12:09:41.393
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/03/22 12:09:41.405
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/03/22 12:09:43.409
    STEP: Deleting the pod 12/03/22 12:09:45.415
    STEP: Ensuring resource quota status released the pod usage 12/03/22 12:09:45.433
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:09:47.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3539" for this suite. 12/03/22 12:09:47.443
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:09:47.452
Dec  3 12:09:47.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-runtime 12/03/22 12:09:47.453
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:47.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:47.481
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/03/22 12:09:47.559
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/03/22 12:10:04.718
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/03/22 12:10:04.722
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/03/22 12:10:04.729
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/03/22 12:10:04.729
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/03/22 12:10:04.752
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/03/22 12:10:07.773
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/03/22 12:10:09.786
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/03/22 12:10:09.795
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/03/22 12:10:09.795
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/03/22 12:10:09.817
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/03/22 12:10:10.825
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/03/22 12:10:13.846
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/03/22 12:10:13.853
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/03/22 12:10:13.854
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec  3 12:10:13.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7209" for this suite. 12/03/22 12:10:13.887
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":30,"skipped":466,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.442 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:09:47.452
    Dec  3 12:09:47.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-runtime 12/03/22 12:09:47.453
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:09:47.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:09:47.481
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/03/22 12:09:47.559
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/03/22 12:10:04.718
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/03/22 12:10:04.722
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/03/22 12:10:04.729
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/03/22 12:10:04.729
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/03/22 12:10:04.752
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/03/22 12:10:07.773
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/03/22 12:10:09.786
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/03/22 12:10:09.795
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/03/22 12:10:09.795
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/03/22 12:10:09.817
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/03/22 12:10:10.825
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/03/22 12:10:13.846
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/03/22 12:10:13.853
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/03/22 12:10:13.854
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec  3 12:10:13.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7209" for this suite. 12/03/22 12:10:13.887
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:13.894
Dec  3 12:10:13.894: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:10:13.895
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:13.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:13.918
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 12/03/22 12:10:13.922
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/03/22 12:10:13.923
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/03/22 12:10:13.923
STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/03/22 12:10:13.923
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/03/22 12:10:13.925
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/03/22 12:10:13.925
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/03/22 12:10:13.926
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:10:13.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2362" for this suite. 12/03/22 12:10:13.929
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":31,"skipped":466,"failed":0}
------------------------------
â€¢ [0.045 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:13.894
    Dec  3 12:10:13.894: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:10:13.895
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:13.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:13.918
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 12/03/22 12:10:13.922
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/03/22 12:10:13.923
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/03/22 12:10:13.923
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/03/22 12:10:13.923
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/03/22 12:10:13.925
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/03/22 12:10:13.925
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/03/22 12:10:13.926
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:10:13.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2362" for this suite. 12/03/22 12:10:13.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:13.942
Dec  3 12:10:13.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:10:13.944
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:13.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:13.986
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 12/03/22 12:10:13.989
Dec  3 12:10:14.002: INFO: Waiting up to 5m0s for pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec" in namespace "downward-api-2307" to be "Succeeded or Failed"
Dec  3 12:10:14.007: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050012ms
Dec  3 12:10:16.012: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009059751s
Dec  3 12:10:18.011: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008909205s
STEP: Saw pod success 12/03/22 12:10:18.012
Dec  3 12:10:18.012: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec" satisfied condition "Succeeded or Failed"
Dec  3 12:10:18.015: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec container dapi-container: <nil>
STEP: delete the pod 12/03/22 12:10:18.035
Dec  3 12:10:18.051: INFO: Waiting for pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec to disappear
Dec  3 12:10:18.055: INFO: Pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec  3 12:10:18.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2307" for this suite. 12/03/22 12:10:18.059
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":32,"skipped":476,"failed":0}
------------------------------
â€¢ [4.129 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:13.942
    Dec  3 12:10:13.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:10:13.944
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:13.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:13.986
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 12/03/22 12:10:13.989
    Dec  3 12:10:14.002: INFO: Waiting up to 5m0s for pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec" in namespace "downward-api-2307" to be "Succeeded or Failed"
    Dec  3 12:10:14.007: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050012ms
    Dec  3 12:10:16.012: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009059751s
    Dec  3 12:10:18.011: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008909205s
    STEP: Saw pod success 12/03/22 12:10:18.012
    Dec  3 12:10:18.012: INFO: Pod "downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec" satisfied condition "Succeeded or Failed"
    Dec  3 12:10:18.015: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec container dapi-container: <nil>
    STEP: delete the pod 12/03/22 12:10:18.035
    Dec  3 12:10:18.051: INFO: Waiting for pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec to disappear
    Dec  3 12:10:18.055: INFO: Pod downward-api-622cf40a-52d3-4850-8514-bb6cb8d203ec no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec  3 12:10:18.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2307" for this suite. 12/03/22 12:10:18.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:18.073
Dec  3 12:10:18.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename aggregator 12/03/22 12:10:18.074
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:18.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:18.095
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Dec  3 12:10:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 12/03/22 12:10:18.099
Dec  3 12:10:18.579: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Dec  3 12:10:20.639: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:22.643: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:24.646: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:26.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:28.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:30.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:32.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:34.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:36.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:38.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:40.643: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:42.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 12:10:44.776: INFO: Waited 123.391765ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 12/03/22 12:10:44.836
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/03/22 12:10:44.839
STEP: List APIServices 12/03/22 12:10:44.848
Dec  3 12:10:44.855: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Dec  3 12:10:45.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9025" for this suite. 12/03/22 12:10:45.091
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":33,"skipped":487,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.027 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:18.073
    Dec  3 12:10:18.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename aggregator 12/03/22 12:10:18.074
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:18.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:18.095
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Dec  3 12:10:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 12/03/22 12:10:18.099
    Dec  3 12:10:18.579: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
    Dec  3 12:10:20.639: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:22.643: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:24.646: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:26.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:28.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:30.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:32.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:34.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:36.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:38.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:40.643: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:42.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 10, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec  3 12:10:44.776: INFO: Waited 123.391765ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 12/03/22 12:10:44.836
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/03/22 12:10:44.839
    STEP: List APIServices 12/03/22 12:10:44.848
    Dec  3 12:10:44.855: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Dec  3 12:10:45.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-9025" for this suite. 12/03/22 12:10:45.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:45.104
Dec  3 12:10:45.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 12:10:45.105
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:45.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:45.135
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 12/03/22 12:10:45.137
STEP: delete the rc 12/03/22 12:10:50.149
STEP: wait for all pods to be garbage collected 12/03/22 12:10:50.158
STEP: Gathering metrics 12/03/22 12:10:55.168
W1203 12:10:55.173777      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 12:10:55.173: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 12:10:55.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3126" for this suite. 12/03/22 12:10:55.178
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":34,"skipped":513,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.085 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:45.104
    Dec  3 12:10:45.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 12:10:45.105
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:45.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:45.135
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 12/03/22 12:10:45.137
    STEP: delete the rc 12/03/22 12:10:50.149
    STEP: wait for all pods to be garbage collected 12/03/22 12:10:50.158
    STEP: Gathering metrics 12/03/22 12:10:55.168
    W1203 12:10:55.173777      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 12:10:55.173: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 12:10:55.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3126" for this suite. 12/03/22 12:10:55.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:55.193
Dec  3 12:10:55.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:10:55.194
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:55.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:55.22
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 12/03/22 12:10:55.223
Dec  3 12:10:55.234: INFO: Waiting up to 5m0s for pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce" in namespace "downward-api-4378" to be "Succeeded or Failed"
Dec  3 12:10:55.237: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.733696ms
Dec  3 12:10:57.242: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008022654s
Dec  3 12:10:59.242: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008058124s
STEP: Saw pod success 12/03/22 12:10:59.242
Dec  3 12:10:59.243: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce" satisfied condition "Succeeded or Failed"
Dec  3 12:10:59.246: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce container dapi-container: <nil>
STEP: delete the pod 12/03/22 12:10:59.254
Dec  3 12:10:59.267: INFO: Waiting for pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce to disappear
Dec  3 12:10:59.270: INFO: Pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec  3 12:10:59.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4378" for this suite. 12/03/22 12:10:59.274
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":35,"skipped":568,"failed":0}
------------------------------
â€¢ [4.088 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:55.193
    Dec  3 12:10:55.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:10:55.194
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:55.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:55.22
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 12/03/22 12:10:55.223
    Dec  3 12:10:55.234: INFO: Waiting up to 5m0s for pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce" in namespace "downward-api-4378" to be "Succeeded or Failed"
    Dec  3 12:10:55.237: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.733696ms
    Dec  3 12:10:57.242: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008022654s
    Dec  3 12:10:59.242: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008058124s
    STEP: Saw pod success 12/03/22 12:10:59.242
    Dec  3 12:10:59.243: INFO: Pod "downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce" satisfied condition "Succeeded or Failed"
    Dec  3 12:10:59.246: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce container dapi-container: <nil>
    STEP: delete the pod 12/03/22 12:10:59.254
    Dec  3 12:10:59.267: INFO: Waiting for pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce to disappear
    Dec  3 12:10:59.270: INFO: Pod downward-api-03ea9f1b-0ab7-47c3-a849-aadcad7464ce no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec  3 12:10:59.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4378" for this suite. 12/03/22 12:10:59.274
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:10:59.284
Dec  3 12:10:59.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:10:59.285
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:59.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:59.312
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 12/03/22 12:10:59.315
STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:10:59.319
STEP: Creating a ResourceQuota with not terminating scope 12/03/22 12:11:01.327
STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:11:01.339
STEP: Creating a long running pod 12/03/22 12:11:03.351
STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/03/22 12:11:03.366
STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/03/22 12:11:05.372
STEP: Deleting the pod 12/03/22 12:11:07.377
STEP: Ensuring resource quota status released the pod usage 12/03/22 12:11:07.391
STEP: Creating a terminating pod 12/03/22 12:11:09.396
STEP: Ensuring resource quota with terminating scope captures the pod usage 12/03/22 12:11:09.409
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/03/22 12:11:11.414
STEP: Deleting the pod 12/03/22 12:11:13.42
STEP: Ensuring resource quota status released the pod usage 12/03/22 12:11:13.432
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:11:15.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4070" for this suite. 12/03/22 12:11:15.448
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":36,"skipped":596,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.176 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:10:59.284
    Dec  3 12:10:59.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:10:59.285
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:10:59.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:10:59.312
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 12/03/22 12:10:59.315
    STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:10:59.319
    STEP: Creating a ResourceQuota with not terminating scope 12/03/22 12:11:01.327
    STEP: Ensuring ResourceQuota status is calculated 12/03/22 12:11:01.339
    STEP: Creating a long running pod 12/03/22 12:11:03.351
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/03/22 12:11:03.366
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/03/22 12:11:05.372
    STEP: Deleting the pod 12/03/22 12:11:07.377
    STEP: Ensuring resource quota status released the pod usage 12/03/22 12:11:07.391
    STEP: Creating a terminating pod 12/03/22 12:11:09.396
    STEP: Ensuring resource quota with terminating scope captures the pod usage 12/03/22 12:11:09.409
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/03/22 12:11:11.414
    STEP: Deleting the pod 12/03/22 12:11:13.42
    STEP: Ensuring resource quota status released the pod usage 12/03/22 12:11:13.432
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:11:15.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4070" for this suite. 12/03/22 12:11:15.448
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:11:15.463
Dec  3 12:11:15.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:11:15.464
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:11:15.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:11:15.489
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 in namespace container-probe-9839 12/03/22 12:11:15.491
Dec  3 12:11:15.508: INFO: Waiting up to 5m0s for pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7" in namespace "container-probe-9839" to be "not pending"
Dec  3 12:11:15.514: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.43816ms
Dec  3 12:11:17.518: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7": Phase="Running", Reason="", readiness=true. Elapsed: 2.009936382s
Dec  3 12:11:17.518: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7" satisfied condition "not pending"
Dec  3 12:11:17.518: INFO: Started pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 in namespace container-probe-9839
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:11:17.518
Dec  3 12:11:17.523: INFO: Initial restart count of pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 is 0
Dec  3 12:11:37.583: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 1 (20.060390526s elapsed)
Dec  3 12:11:57.636: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 2 (40.113307947s elapsed)
Dec  3 12:12:17.687: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 3 (1m0.164630088s elapsed)
Dec  3 12:12:37.736: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 4 (1m20.212808166s elapsed)
Dec  3 12:13:49.916: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 5 (2m32.393407825s elapsed)
STEP: deleting the pod 12/03/22 12:13:49.916
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:13:49.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9839" for this suite. 12/03/22 12:13:49.933
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":37,"skipped":614,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.477 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:11:15.463
    Dec  3 12:11:15.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:11:15.464
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:11:15.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:11:15.489
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 in namespace container-probe-9839 12/03/22 12:11:15.491
    Dec  3 12:11:15.508: INFO: Waiting up to 5m0s for pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7" in namespace "container-probe-9839" to be "not pending"
    Dec  3 12:11:15.514: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.43816ms
    Dec  3 12:11:17.518: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7": Phase="Running", Reason="", readiness=true. Elapsed: 2.009936382s
    Dec  3 12:11:17.518: INFO: Pod "liveness-84046dc2-571c-40c5-9e67-46e302894da7" satisfied condition "not pending"
    Dec  3 12:11:17.518: INFO: Started pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 in namespace container-probe-9839
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:11:17.518
    Dec  3 12:11:17.523: INFO: Initial restart count of pod liveness-84046dc2-571c-40c5-9e67-46e302894da7 is 0
    Dec  3 12:11:37.583: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 1 (20.060390526s elapsed)
    Dec  3 12:11:57.636: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 2 (40.113307947s elapsed)
    Dec  3 12:12:17.687: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 3 (1m0.164630088s elapsed)
    Dec  3 12:12:37.736: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 4 (1m20.212808166s elapsed)
    Dec  3 12:13:49.916: INFO: Restart count of pod container-probe-9839/liveness-84046dc2-571c-40c5-9e67-46e302894da7 is now 5 (2m32.393407825s elapsed)
    STEP: deleting the pod 12/03/22 12:13:49.916
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:13:49.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9839" for this suite. 12/03/22 12:13:49.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:13:49.943
Dec  3 12:13:49.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename ingress 12/03/22 12:13:49.945
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:13:49.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:13:49.973
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 12/03/22 12:13:49.975
STEP: getting /apis/networking.k8s.io 12/03/22 12:13:49.979
STEP: getting /apis/networking.k8s.iov1 12/03/22 12:13:49.981
STEP: creating 12/03/22 12:13:49.982
STEP: getting 12/03/22 12:13:49.999
STEP: listing 12/03/22 12:13:50.006
STEP: watching 12/03/22 12:13:50.011
Dec  3 12:13:50.011: INFO: starting watch
STEP: cluster-wide listing 12/03/22 12:13:50.014
STEP: cluster-wide watching 12/03/22 12:13:50.017
Dec  3 12:13:50.017: INFO: starting watch
STEP: patching 12/03/22 12:13:50.019
STEP: updating 12/03/22 12:13:50.031
Dec  3 12:13:50.044: INFO: waiting for watch events with expected annotations
Dec  3 12:13:50.044: INFO: saw patched and updated annotations
STEP: patching /status 12/03/22 12:13:50.045
STEP: updating /status 12/03/22 12:13:50.068
STEP: get /status 12/03/22 12:13:50.079
STEP: deleting 12/03/22 12:13:50.085
STEP: deleting a collection 12/03/22 12:13:50.106
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Dec  3 12:13:50.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-8663" for this suite. 12/03/22 12:13:50.131
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":38,"skipped":639,"failed":0}
------------------------------
â€¢ [0.202 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:13:49.943
    Dec  3 12:13:49.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename ingress 12/03/22 12:13:49.945
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:13:49.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:13:49.973
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 12/03/22 12:13:49.975
    STEP: getting /apis/networking.k8s.io 12/03/22 12:13:49.979
    STEP: getting /apis/networking.k8s.iov1 12/03/22 12:13:49.981
    STEP: creating 12/03/22 12:13:49.982
    STEP: getting 12/03/22 12:13:49.999
    STEP: listing 12/03/22 12:13:50.006
    STEP: watching 12/03/22 12:13:50.011
    Dec  3 12:13:50.011: INFO: starting watch
    STEP: cluster-wide listing 12/03/22 12:13:50.014
    STEP: cluster-wide watching 12/03/22 12:13:50.017
    Dec  3 12:13:50.017: INFO: starting watch
    STEP: patching 12/03/22 12:13:50.019
    STEP: updating 12/03/22 12:13:50.031
    Dec  3 12:13:50.044: INFO: waiting for watch events with expected annotations
    Dec  3 12:13:50.044: INFO: saw patched and updated annotations
    STEP: patching /status 12/03/22 12:13:50.045
    STEP: updating /status 12/03/22 12:13:50.068
    STEP: get /status 12/03/22 12:13:50.079
    STEP: deleting 12/03/22 12:13:50.085
    STEP: deleting a collection 12/03/22 12:13:50.106
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Dec  3 12:13:50.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-8663" for this suite. 12/03/22 12:13:50.131
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:13:50.147
Dec  3 12:13:50.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:13:50.149
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:13:50.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:13:50.179
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 in namespace container-probe-5365 12/03/22 12:13:50.195
Dec  3 12:13:50.206: INFO: Waiting up to 5m0s for pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248" in namespace "container-probe-5365" to be "not pending"
Dec  3 12:13:50.216: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248": Phase="Pending", Reason="", readiness=false. Elapsed: 9.974009ms
Dec  3 12:13:52.223: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248": Phase="Running", Reason="", readiness=true. Elapsed: 2.016665641s
Dec  3 12:13:52.223: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248" satisfied condition "not pending"
Dec  3 12:13:52.223: INFO: Started pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 in namespace container-probe-5365
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:13:52.223
Dec  3 12:13:52.226: INFO: Initial restart count of pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 is 0
Dec  3 12:14:42.360: INFO: Restart count of pod container-probe-5365/busybox-e6474b74-2654-40af-a3f1-e91b92d92248 is now 1 (50.133916611s elapsed)
STEP: deleting the pod 12/03/22 12:14:42.36
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:14:42.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5365" for this suite. 12/03/22 12:14:42.378
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":39,"skipped":659,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.239 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:13:50.147
    Dec  3 12:13:50.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:13:50.149
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:13:50.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:13:50.179
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 in namespace container-probe-5365 12/03/22 12:13:50.195
    Dec  3 12:13:50.206: INFO: Waiting up to 5m0s for pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248" in namespace "container-probe-5365" to be "not pending"
    Dec  3 12:13:50.216: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248": Phase="Pending", Reason="", readiness=false. Elapsed: 9.974009ms
    Dec  3 12:13:52.223: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248": Phase="Running", Reason="", readiness=true. Elapsed: 2.016665641s
    Dec  3 12:13:52.223: INFO: Pod "busybox-e6474b74-2654-40af-a3f1-e91b92d92248" satisfied condition "not pending"
    Dec  3 12:13:52.223: INFO: Started pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 in namespace container-probe-5365
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:13:52.223
    Dec  3 12:13:52.226: INFO: Initial restart count of pod busybox-e6474b74-2654-40af-a3f1-e91b92d92248 is 0
    Dec  3 12:14:42.360: INFO: Restart count of pod container-probe-5365/busybox-e6474b74-2654-40af-a3f1-e91b92d92248 is now 1 (50.133916611s elapsed)
    STEP: deleting the pod 12/03/22 12:14:42.36
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:14:42.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5365" for this suite. 12/03/22 12:14:42.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:14:42.387
Dec  3 12:14:42.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubelet-test 12/03/22 12:14:42.388
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:42.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:42.414
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec  3 12:14:46.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9602" for this suite. 12/03/22 12:14:46.44
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":40,"skipped":680,"failed":0}
------------------------------
â€¢ [4.064 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:14:42.387
    Dec  3 12:14:42.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubelet-test 12/03/22 12:14:42.388
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:42.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:42.414
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec  3 12:14:46.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9602" for this suite. 12/03/22 12:14:46.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:14:46.454
Dec  3 12:14:46.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:14:46.455
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:46.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:46.485
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 12/03/22 12:14:46.489
Dec  3 12:14:46.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c" in namespace "downward-api-5834" to be "Succeeded or Failed"
Dec  3 12:14:46.510: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.97203ms
Dec  3 12:14:48.515: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009957636s
Dec  3 12:14:50.516: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011104956s
STEP: Saw pod success 12/03/22 12:14:50.516
Dec  3 12:14:50.516: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c" satisfied condition "Succeeded or Failed"
Dec  3 12:14:50.520: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c container client-container: <nil>
STEP: delete the pod 12/03/22 12:14:50.539
Dec  3 12:14:50.551: INFO: Waiting for pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c to disappear
Dec  3 12:14:50.555: INFO: Pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 12:14:50.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5834" for this suite. 12/03/22 12:14:50.559
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":41,"skipped":716,"failed":0}
------------------------------
â€¢ [4.111 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:14:46.454
    Dec  3 12:14:46.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:14:46.455
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:46.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:46.485
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 12/03/22 12:14:46.489
    Dec  3 12:14:46.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c" in namespace "downward-api-5834" to be "Succeeded or Failed"
    Dec  3 12:14:46.510: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.97203ms
    Dec  3 12:14:48.515: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009957636s
    Dec  3 12:14:50.516: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011104956s
    STEP: Saw pod success 12/03/22 12:14:50.516
    Dec  3 12:14:50.516: INFO: Pod "downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c" satisfied condition "Succeeded or Failed"
    Dec  3 12:14:50.520: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c container client-container: <nil>
    STEP: delete the pod 12/03/22 12:14:50.539
    Dec  3 12:14:50.551: INFO: Waiting for pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c to disappear
    Dec  3 12:14:50.555: INFO: Pod downwardapi-volume-8cfcb85b-bb06-49b3-8a28-b7c2758e731c no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 12:14:50.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5834" for this suite. 12/03/22 12:14:50.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:14:50.567
Dec  3 12:14:50.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/03/22 12:14:50.568
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:50.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:50.594
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 12/03/22 12:14:50.598
STEP: Creating hostNetwork=false pod 12/03/22 12:14:50.599
Dec  3 12:14:50.610: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1598" to be "running and ready"
Dec  3 12:14:50.618: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.812945ms
Dec  3 12:14:50.618: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:14:52.622: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012599197s
Dec  3 12:14:52.623: INFO: The phase of Pod test-pod is Running (Ready = true)
Dec  3 12:14:52.623: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 12/03/22 12:14:52.627
Dec  3 12:14:52.636: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1598" to be "running and ready"
Dec  3 12:14:52.639: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861408ms
Dec  3 12:14:52.639: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:14:54.643: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007612406s
Dec  3 12:14:54.644: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Dec  3 12:14:54.644: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 12/03/22 12:14:54.646
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/03/22 12:14:54.647
Dec  3 12:14:54.647: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:54.647: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:54.648: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:54.648: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec  3 12:14:54.733: INFO: Exec stderr: ""
Dec  3 12:14:54.733: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:54.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:54.734: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:54.734: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec  3 12:14:54.820: INFO: Exec stderr: ""
Dec  3 12:14:54.820: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:54.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:54.821: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:54.821: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec  3 12:14:54.895: INFO: Exec stderr: ""
Dec  3 12:14:54.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:54.895: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:54.896: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:54.896: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec  3 12:14:54.979: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/03/22 12:14:54.979
Dec  3 12:14:54.979: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:54.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:54.980: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:54.980: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec  3 12:14:55.068: INFO: Exec stderr: ""
Dec  3 12:14:55.068: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:55.068: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:55.069: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:55.069: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec  3 12:14:55.142: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/03/22 12:14:55.142
Dec  3 12:14:55.142: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:55.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:55.143: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:55.143: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec  3 12:14:55.223: INFO: Exec stderr: ""
Dec  3 12:14:55.224: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:55.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:55.224: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:55.225: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec  3 12:14:55.305: INFO: Exec stderr: ""
Dec  3 12:14:55.305: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:55.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:55.306: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:55.306: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec  3 12:14:55.384: INFO: Exec stderr: ""
Dec  3 12:14:55.384: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:14:55.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:14:55.385: INFO: ExecWithOptions: Clientset creation
Dec  3 12:14:55.385: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec  3 12:14:55.445: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Dec  3 12:14:55.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1598" for this suite. 12/03/22 12:14:55.453
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":42,"skipped":756,"failed":0}
------------------------------
â€¢ [4.896 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:14:50.567
    Dec  3 12:14:50.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/03/22 12:14:50.568
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:50.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:50.594
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 12/03/22 12:14:50.598
    STEP: Creating hostNetwork=false pod 12/03/22 12:14:50.599
    Dec  3 12:14:50.610: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1598" to be "running and ready"
    Dec  3 12:14:50.618: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.812945ms
    Dec  3 12:14:50.618: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:14:52.622: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012599197s
    Dec  3 12:14:52.623: INFO: The phase of Pod test-pod is Running (Ready = true)
    Dec  3 12:14:52.623: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 12/03/22 12:14:52.627
    Dec  3 12:14:52.636: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1598" to be "running and ready"
    Dec  3 12:14:52.639: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861408ms
    Dec  3 12:14:52.639: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:14:54.643: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007612406s
    Dec  3 12:14:54.644: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Dec  3 12:14:54.644: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 12/03/22 12:14:54.646
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/03/22 12:14:54.647
    Dec  3 12:14:54.647: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:54.647: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:54.648: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:54.648: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec  3 12:14:54.733: INFO: Exec stderr: ""
    Dec  3 12:14:54.733: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:54.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:54.734: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:54.734: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec  3 12:14:54.820: INFO: Exec stderr: ""
    Dec  3 12:14:54.820: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:54.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:54.821: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:54.821: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec  3 12:14:54.895: INFO: Exec stderr: ""
    Dec  3 12:14:54.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:54.895: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:54.896: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:54.896: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec  3 12:14:54.979: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/03/22 12:14:54.979
    Dec  3 12:14:54.979: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:54.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:54.980: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:54.980: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec  3 12:14:55.068: INFO: Exec stderr: ""
    Dec  3 12:14:55.068: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:55.068: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:55.069: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:55.069: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec  3 12:14:55.142: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/03/22 12:14:55.142
    Dec  3 12:14:55.142: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:55.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:55.143: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:55.143: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec  3 12:14:55.223: INFO: Exec stderr: ""
    Dec  3 12:14:55.224: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:55.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:55.224: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:55.225: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec  3 12:14:55.305: INFO: Exec stderr: ""
    Dec  3 12:14:55.305: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:55.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:55.306: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:55.306: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec  3 12:14:55.384: INFO: Exec stderr: ""
    Dec  3 12:14:55.384: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1598 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:14:55.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:14:55.385: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:14:55.385: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1598/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec  3 12:14:55.445: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Dec  3 12:14:55.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-1598" for this suite. 12/03/22 12:14:55.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:14:55.468
Dec  3 12:14:55.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 12:14:55.469
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:55.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:55.5
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 12/03/22 12:14:55.504
STEP: Ensure pods equal to paralellism count is attached to the job 12/03/22 12:14:55.513
STEP: patching /status 12/03/22 12:14:59.518
STEP: updating /status 12/03/22 12:14:59.528
STEP: get /status 12/03/22 12:14:59.537
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 12:14:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4979" for this suite. 12/03/22 12:14:59.551
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":43,"skipped":790,"failed":0}
------------------------------
â€¢ [4.093 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:14:55.468
    Dec  3 12:14:55.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 12:14:55.469
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:55.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:55.5
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 12/03/22 12:14:55.504
    STEP: Ensure pods equal to paralellism count is attached to the job 12/03/22 12:14:55.513
    STEP: patching /status 12/03/22 12:14:59.518
    STEP: updating /status 12/03/22 12:14:59.528
    STEP: get /status 12/03/22 12:14:59.537
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 12:14:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4979" for this suite. 12/03/22 12:14:59.551
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:14:59.565
Dec  3 12:14:59.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replication-controller 12/03/22 12:14:59.566
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:59.589
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:59.593
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 12/03/22 12:14:59.596
STEP: When the matched label of one of its pods change 12/03/22 12:14:59.602
Dec  3 12:14:59.606: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  3 12:15:04.611: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 12/03/22 12:15:04.621
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec  3 12:15:05.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9960" for this suite. 12/03/22 12:15:05.634
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":44,"skipped":802,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.077 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:14:59.565
    Dec  3 12:14:59.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replication-controller 12/03/22 12:14:59.566
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:14:59.589
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:14:59.593
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 12/03/22 12:14:59.596
    STEP: When the matched label of one of its pods change 12/03/22 12:14:59.602
    Dec  3 12:14:59.606: INFO: Pod name pod-release: Found 0 pods out of 1
    Dec  3 12:15:04.611: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/03/22 12:15:04.621
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec  3 12:15:05.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9960" for this suite. 12/03/22 12:15:05.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:05.647
Dec  3 12:15:05.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 12:15:05.648
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:05.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:05.669
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 12/03/22 12:15:05.676
STEP: Verify that the required pods have come up. 12/03/22 12:15:05.682
Dec  3 12:15:05.686: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 12:15:10.690: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 12:15:10.69
STEP: Getting /status 12/03/22 12:15:10.691
Dec  3 12:15:10.695: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 12/03/22 12:15:10.695
Dec  3 12:15:10.712: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 12/03/22 12:15:10.712
Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: ADDED
Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.715: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec  3 12:15:10.715: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 12/03/22 12:15:10.715
Dec  3 12:15:10.715: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec  3 12:15:10.723: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 12/03/22 12:15:10.723
Dec  3 12:15:10.725: INFO: Observed &ReplicaSet event: ADDED
Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.726: INFO: Observed replicaset test-rs in namespace replicaset-6812 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec  3 12:15:10.727: INFO: Observed &ReplicaSet event: MODIFIED
Dec  3 12:15:10.727: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Dec  3 12:15:10.727: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 12:15:10.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6812" for this suite. 12/03/22 12:15:10.732
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":45,"skipped":846,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.094 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:05.647
    Dec  3 12:15:05.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 12:15:05.648
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:05.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:05.669
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 12/03/22 12:15:05.676
    STEP: Verify that the required pods have come up. 12/03/22 12:15:05.682
    Dec  3 12:15:05.686: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec  3 12:15:10.690: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 12:15:10.69
    STEP: Getting /status 12/03/22 12:15:10.691
    Dec  3 12:15:10.695: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 12/03/22 12:15:10.695
    Dec  3 12:15:10.712: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 12/03/22 12:15:10.712
    Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: ADDED
    Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.715: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.715: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec  3 12:15:10.715: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 12/03/22 12:15:10.715
    Dec  3 12:15:10.715: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec  3 12:15:10.723: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 12/03/22 12:15:10.723
    Dec  3 12:15:10.725: INFO: Observed &ReplicaSet event: ADDED
    Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.726: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.726: INFO: Observed replicaset test-rs in namespace replicaset-6812 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec  3 12:15:10.727: INFO: Observed &ReplicaSet event: MODIFIED
    Dec  3 12:15:10.727: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Dec  3 12:15:10.727: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 12:15:10.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6812" for this suite. 12/03/22 12:15:10.732
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:10.744
Dec  3 12:15:10.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 12:15:10.745
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:10.781
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:10.785
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-21580b31-7440-466a-bebd-c1df025efa91 12/03/22 12:15:10.788
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 12:15:10.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2762" for this suite. 12/03/22 12:15:10.795
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":46,"skipped":873,"failed":0}
------------------------------
â€¢ [0.058 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:10.744
    Dec  3 12:15:10.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 12:15:10.745
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:10.781
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:10.785
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-21580b31-7440-466a-bebd-c1df025efa91 12/03/22 12:15:10.788
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 12:15:10.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2762" for this suite. 12/03/22 12:15:10.795
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:10.805
Dec  3 12:15:10.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:15:10.807
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:10.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:10.835
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-9139 12/03/22 12:15:10.839
STEP: creating service affinity-clusterip in namespace services-9139 12/03/22 12:15:10.839
STEP: creating replication controller affinity-clusterip in namespace services-9139 12/03/22 12:15:10.851
I1203 12:15:10.863969      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9139, replica count: 3
I1203 12:15:13.915391      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 12:15:13.923: INFO: Creating new exec pod
Dec  3 12:15:13.932: INFO: Waiting up to 5m0s for pod "execpod-affinityd8rct" in namespace "services-9139" to be "running"
Dec  3 12:15:13.935: INFO: Pod "execpod-affinityd8rct": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535451ms
Dec  3 12:15:15.940: INFO: Pod "execpod-affinityd8rct": Phase="Running", Reason="", readiness=true. Elapsed: 2.008626044s
Dec  3 12:15:15.941: INFO: Pod "execpod-affinityd8rct" satisfied condition "running"
Dec  3 12:15:16.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Dec  3 12:15:17.093: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Dec  3 12:15:17.093: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:15:17.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.65 80'
Dec  3 12:15:17.264: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.65 80\nConnection to 10.152.183.65 80 port [tcp/http] succeeded!\n"
Dec  3 12:15:17.264: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:15:17.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.65:80/ ; done'
Dec  3 12:15:17.578: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n"
Dec  3 12:15:17.578: INFO: stdout: "\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242"
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
Dec  3 12:15:17.578: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-9139, will wait for the garbage collector to delete the pods 12/03/22 12:15:17.591
Dec  3 12:15:17.651: INFO: Deleting ReplicationController affinity-clusterip took: 7.337698ms
Dec  3 12:15:17.752: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.17634ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:15:19.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9139" for this suite. 12/03/22 12:15:19.981
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":47,"skipped":926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.182 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:10.805
    Dec  3 12:15:10.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:15:10.807
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:10.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:10.835
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-9139 12/03/22 12:15:10.839
    STEP: creating service affinity-clusterip in namespace services-9139 12/03/22 12:15:10.839
    STEP: creating replication controller affinity-clusterip in namespace services-9139 12/03/22 12:15:10.851
    I1203 12:15:10.863969      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9139, replica count: 3
    I1203 12:15:13.915391      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 12:15:13.923: INFO: Creating new exec pod
    Dec  3 12:15:13.932: INFO: Waiting up to 5m0s for pod "execpod-affinityd8rct" in namespace "services-9139" to be "running"
    Dec  3 12:15:13.935: INFO: Pod "execpod-affinityd8rct": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535451ms
    Dec  3 12:15:15.940: INFO: Pod "execpod-affinityd8rct": Phase="Running", Reason="", readiness=true. Elapsed: 2.008626044s
    Dec  3 12:15:15.941: INFO: Pod "execpod-affinityd8rct" satisfied condition "running"
    Dec  3 12:15:16.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Dec  3 12:15:17.093: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Dec  3 12:15:17.093: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:15:17.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.65 80'
    Dec  3 12:15:17.264: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.65 80\nConnection to 10.152.183.65 80 port [tcp/http] succeeded!\n"
    Dec  3 12:15:17.264: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:15:17.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9139 exec execpod-affinityd8rct -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.65:80/ ; done'
    Dec  3 12:15:17.578: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.65:80/\n"
    Dec  3 12:15:17.578: INFO: stdout: "\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242\naffinity-clusterip-rt242"
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Received response from host: affinity-clusterip-rt242
    Dec  3 12:15:17.578: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-9139, will wait for the garbage collector to delete the pods 12/03/22 12:15:17.591
    Dec  3 12:15:17.651: INFO: Deleting ReplicationController affinity-clusterip took: 7.337698ms
    Dec  3 12:15:17.752: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.17634ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:15:19.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9139" for this suite. 12/03/22 12:15:19.981
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:19.99
Dec  3 12:15:19.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:15:19.991
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:20.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:20.017
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 12/03/22 12:15:20.019
Dec  3 12:15:20.029: INFO: Waiting up to 5m0s for pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802" in namespace "emptydir-853" to be "Succeeded or Failed"
Dec  3 12:15:20.032: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.734364ms
Dec  3 12:15:22.039: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009381356s
Dec  3 12:15:24.037: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00725777s
STEP: Saw pod success 12/03/22 12:15:24.037
Dec  3 12:15:24.037: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802" satisfied condition "Succeeded or Failed"
Dec  3 12:15:24.041: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 container test-container: <nil>
STEP: delete the pod 12/03/22 12:15:24.054
Dec  3 12:15:24.066: INFO: Waiting for pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 to disappear
Dec  3 12:15:24.070: INFO: Pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:15:24.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-853" for this suite. 12/03/22 12:15:24.075
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":48,"skipped":946,"failed":0}
------------------------------
â€¢ [4.095 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:19.99
    Dec  3 12:15:19.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:15:19.991
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:20.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:20.017
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/03/22 12:15:20.019
    Dec  3 12:15:20.029: INFO: Waiting up to 5m0s for pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802" in namespace "emptydir-853" to be "Succeeded or Failed"
    Dec  3 12:15:20.032: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.734364ms
    Dec  3 12:15:22.039: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009381356s
    Dec  3 12:15:24.037: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00725777s
    STEP: Saw pod success 12/03/22 12:15:24.037
    Dec  3 12:15:24.037: INFO: Pod "pod-0a5f824d-165b-4ae6-841d-206a3bd28802" satisfied condition "Succeeded or Failed"
    Dec  3 12:15:24.041: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 container test-container: <nil>
    STEP: delete the pod 12/03/22 12:15:24.054
    Dec  3 12:15:24.066: INFO: Waiting for pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 to disappear
    Dec  3 12:15:24.070: INFO: Pod pod-0a5f824d-165b-4ae6-841d-206a3bd28802 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:15:24.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-853" for this suite. 12/03/22 12:15:24.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:24.088
Dec  3 12:15:24.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 12:15:24.089
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:24.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:24.115
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3144.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3144.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 12/03/22 12:15:24.118
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3144.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3144.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 12/03/22 12:15:24.118
STEP: creating a pod to probe /etc/hosts 12/03/22 12:15:24.118
STEP: submitting the pod to kubernetes 12/03/22 12:15:24.118
Dec  3 12:15:24.129: INFO: Waiting up to 15m0s for pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a" in namespace "dns-3144" to be "running"
Dec  3 12:15:24.132: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.125778ms
Dec  3 12:15:26.138: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009164413s
Dec  3 12:15:28.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007326277s
Dec  3 12:15:30.137: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007964429s
Dec  3 12:15:32.138: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009639365s
Dec  3 12:15:34.137: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007773432s
Dec  3 12:15:36.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Running", Reason="", readiness=true. Elapsed: 12.007525789s
Dec  3 12:15:36.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a" satisfied condition "running"
STEP: retrieving the pod 12/03/22 12:15:36.137
STEP: looking for the results for each expected name from probers 12/03/22 12:15:36.141
Dec  3 12:15:36.172: INFO: DNS probes using dns-3144/dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a succeeded

STEP: deleting the pod 12/03/22 12:15:36.172
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 12:15:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3144" for this suite. 12/03/22 12:15:36.189
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":49,"skipped":957,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.108 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:24.088
    Dec  3 12:15:24.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 12:15:24.089
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:24.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:24.115
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3144.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3144.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     12/03/22 12:15:24.118
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3144.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3144.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     12/03/22 12:15:24.118
    STEP: creating a pod to probe /etc/hosts 12/03/22 12:15:24.118
    STEP: submitting the pod to kubernetes 12/03/22 12:15:24.118
    Dec  3 12:15:24.129: INFO: Waiting up to 15m0s for pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a" in namespace "dns-3144" to be "running"
    Dec  3 12:15:24.132: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.125778ms
    Dec  3 12:15:26.138: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009164413s
    Dec  3 12:15:28.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007326277s
    Dec  3 12:15:30.137: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007964429s
    Dec  3 12:15:32.138: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009639365s
    Dec  3 12:15:34.137: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007773432s
    Dec  3 12:15:36.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a": Phase="Running", Reason="", readiness=true. Elapsed: 12.007525789s
    Dec  3 12:15:36.136: INFO: Pod "dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 12:15:36.137
    STEP: looking for the results for each expected name from probers 12/03/22 12:15:36.141
    Dec  3 12:15:36.172: INFO: DNS probes using dns-3144/dns-test-8b9421d4-2236-49ee-9722-7b5169a7665a succeeded

    STEP: deleting the pod 12/03/22 12:15:36.172
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 12:15:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3144" for this suite. 12/03/22 12:15:36.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:36.197
Dec  3 12:15:36.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 12:15:36.198
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:36.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:36.226
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Dec  3 12:15:36.256: INFO: created pod pod-service-account-defaultsa
Dec  3 12:15:36.256: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 12:15:36.263: INFO: created pod pod-service-account-mountsa
Dec  3 12:15:36.263: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 12:15:36.269: INFO: created pod pod-service-account-nomountsa
Dec  3 12:15:36.269: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 12:15:36.276: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 12:15:36.276: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 12:15:36.285: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 12:15:36.285: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 12:15:36.296: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 12:15:36.296: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 12:15:36.304: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 12:15:36.304: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 12:15:36.310: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 12:15:36.310: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 12:15:36.317: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 12:15:36.317: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 12:15:36.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4921" for this suite. 12/03/22 12:15:36.327
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":50,"skipped":987,"failed":0}
------------------------------
â€¢ [0.138 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:36.197
    Dec  3 12:15:36.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 12:15:36.198
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:36.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:36.226
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Dec  3 12:15:36.256: INFO: created pod pod-service-account-defaultsa
    Dec  3 12:15:36.256: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Dec  3 12:15:36.263: INFO: created pod pod-service-account-mountsa
    Dec  3 12:15:36.263: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Dec  3 12:15:36.269: INFO: created pod pod-service-account-nomountsa
    Dec  3 12:15:36.269: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Dec  3 12:15:36.276: INFO: created pod pod-service-account-defaultsa-mountspec
    Dec  3 12:15:36.276: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Dec  3 12:15:36.285: INFO: created pod pod-service-account-mountsa-mountspec
    Dec  3 12:15:36.285: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Dec  3 12:15:36.296: INFO: created pod pod-service-account-nomountsa-mountspec
    Dec  3 12:15:36.296: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Dec  3 12:15:36.304: INFO: created pod pod-service-account-defaultsa-nomountspec
    Dec  3 12:15:36.304: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Dec  3 12:15:36.310: INFO: created pod pod-service-account-mountsa-nomountspec
    Dec  3 12:15:36.310: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Dec  3 12:15:36.317: INFO: created pod pod-service-account-nomountsa-nomountspec
    Dec  3 12:15:36.317: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 12:15:36.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4921" for this suite. 12/03/22 12:15:36.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:36.336
Dec  3 12:15:36.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:15:36.337
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:36.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:36.385
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 12/03/22 12:15:36.389
Dec  3 12:15:36.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd" in namespace "downward-api-9754" to be "Succeeded or Failed"
Dec  3 12:15:36.404: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.810713ms
Dec  3 12:15:38.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008710273s
Dec  3 12:15:40.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009201687s
STEP: Saw pod success 12/03/22 12:15:40.409
Dec  3 12:15:40.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd" satisfied condition "Succeeded or Failed"
Dec  3 12:15:40.413: INFO: Trying to get logs from node ip-172-31-4-162 pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd container client-container: <nil>
STEP: delete the pod 12/03/22 12:15:40.431
Dec  3 12:15:40.446: INFO: Waiting for pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd to disappear
Dec  3 12:15:40.450: INFO: Pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 12:15:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9754" for this suite. 12/03/22 12:15:40.453
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":51,"skipped":1004,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:36.336
    Dec  3 12:15:36.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:15:36.337
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:36.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:36.385
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 12/03/22 12:15:36.389
    Dec  3 12:15:36.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd" in namespace "downward-api-9754" to be "Succeeded or Failed"
    Dec  3 12:15:36.404: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.810713ms
    Dec  3 12:15:38.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008710273s
    Dec  3 12:15:40.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009201687s
    STEP: Saw pod success 12/03/22 12:15:40.409
    Dec  3 12:15:40.409: INFO: Pod "downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd" satisfied condition "Succeeded or Failed"
    Dec  3 12:15:40.413: INFO: Trying to get logs from node ip-172-31-4-162 pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd container client-container: <nil>
    STEP: delete the pod 12/03/22 12:15:40.431
    Dec  3 12:15:40.446: INFO: Waiting for pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd to disappear
    Dec  3 12:15:40.450: INFO: Pod downwardapi-volume-6d15489b-d96e-4e98-9677-0cbff3196cfd no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 12:15:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9754" for this suite. 12/03/22 12:15:40.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:40.464
Dec  3 12:15:40.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:15:40.464
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.491
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.495
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 12/03/22 12:15:40.501
Dec  3 12:15:40.501: INFO: Creating e2e-svc-a-dmbm7
Dec  3 12:15:40.516: INFO: Creating e2e-svc-b-2psxl
Dec  3 12:15:40.529: INFO: Creating e2e-svc-c-98lq6
STEP: deleting service collection 12/03/22 12:15:40.546
Dec  3 12:15:40.581: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:15:40.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1707" for this suite. 12/03/22 12:15:40.585
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":52,"skipped":1049,"failed":0}
------------------------------
â€¢ [0.131 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:40.464
    Dec  3 12:15:40.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:15:40.464
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.491
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.495
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 12/03/22 12:15:40.501
    Dec  3 12:15:40.501: INFO: Creating e2e-svc-a-dmbm7
    Dec  3 12:15:40.516: INFO: Creating e2e-svc-b-2psxl
    Dec  3 12:15:40.529: INFO: Creating e2e-svc-c-98lq6
    STEP: deleting service collection 12/03/22 12:15:40.546
    Dec  3 12:15:40.581: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:15:40.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1707" for this suite. 12/03/22 12:15:40.585
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:40.596
Dec  3 12:15:40.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename watch 12/03/22 12:15:40.597
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.622
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 12/03/22 12:15:40.625
STEP: modifying the configmap once 12/03/22 12:15:40.63
STEP: modifying the configmap a second time 12/03/22 12:15:40.638
STEP: deleting the configmap 12/03/22 12:15:40.645
STEP: creating a watch on configmaps from the resource version returned by the first update 12/03/22 12:15:40.652
STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/03/22 12:15:40.653
Dec  3 12:15:40.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1713  499220b2-a941-4e56-ad84-53a21ed4ddd7 7547 0 2022-12-03 12:15:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-03 12:15:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:15:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1713  499220b2-a941-4e56-ad84-53a21ed4ddd7 7548 0 2022-12-03 12:15:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-03 12:15:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec  3 12:15:40.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1713" for this suite. 12/03/22 12:15:40.658
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":53,"skipped":1081,"failed":0}
------------------------------
â€¢ [0.068 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:40.596
    Dec  3 12:15:40.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename watch 12/03/22 12:15:40.597
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.622
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 12/03/22 12:15:40.625
    STEP: modifying the configmap once 12/03/22 12:15:40.63
    STEP: modifying the configmap a second time 12/03/22 12:15:40.638
    STEP: deleting the configmap 12/03/22 12:15:40.645
    STEP: creating a watch on configmaps from the resource version returned by the first update 12/03/22 12:15:40.652
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/03/22 12:15:40.653
    Dec  3 12:15:40.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1713  499220b2-a941-4e56-ad84-53a21ed4ddd7 7547 0 2022-12-03 12:15:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-03 12:15:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:15:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1713  499220b2-a941-4e56-ad84-53a21ed4ddd7 7548 0 2022-12-03 12:15:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-03 12:15:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec  3 12:15:40.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1713" for this suite. 12/03/22 12:15:40.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:40.666
Dec  3 12:15:40.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename events 12/03/22 12:15:40.667
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.688
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 12/03/22 12:15:40.691
STEP: listing all events in all namespaces 12/03/22 12:15:40.697
STEP: patching the test event 12/03/22 12:15:40.709
STEP: fetching the test event 12/03/22 12:15:40.717
STEP: updating the test event 12/03/22 12:15:40.723
STEP: getting the test event 12/03/22 12:15:40.734
STEP: deleting the test event 12/03/22 12:15:40.738
STEP: listing all events in all namespaces 12/03/22 12:15:40.745
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec  3 12:15:40.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3782" for this suite. 12/03/22 12:15:40.76
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":54,"skipped":1103,"failed":0}
------------------------------
â€¢ [0.102 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:40.666
    Dec  3 12:15:40.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename events 12/03/22 12:15:40.667
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.688
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 12/03/22 12:15:40.691
    STEP: listing all events in all namespaces 12/03/22 12:15:40.697
    STEP: patching the test event 12/03/22 12:15:40.709
    STEP: fetching the test event 12/03/22 12:15:40.717
    STEP: updating the test event 12/03/22 12:15:40.723
    STEP: getting the test event 12/03/22 12:15:40.734
    STEP: deleting the test event 12/03/22 12:15:40.738
    STEP: listing all events in all namespaces 12/03/22 12:15:40.745
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec  3 12:15:40.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-3782" for this suite. 12/03/22 12:15:40.76
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:40.769
Dec  3 12:15:40.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:15:40.77
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.794
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:15:40.801
Dec  3 12:15:40.811: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4061" to be "running and ready"
Dec  3 12:15:40.814: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.318893ms
Dec  3 12:15:40.814: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:15:42.819: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008273138s
Dec  3 12:15:42.819: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec  3 12:15:42.819: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 12/03/22 12:15:42.823
Dec  3 12:15:42.828: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4061" to be "running and ready"
Dec  3 12:15:42.832: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.322738ms
Dec  3 12:15:42.832: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:15:44.838: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009704953s
Dec  3 12:15:44.838: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Dec  3 12:15:44.838: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/03/22 12:15:44.841
STEP: delete the pod with lifecycle hook 12/03/22 12:15:44.849
Dec  3 12:15:44.859: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 12:15:44.863: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 12:15:46.864: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 12:15:46.868: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 12:15:48.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 12:15:48.868: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec  3 12:15:48.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4061" for this suite. 12/03/22 12:15:48.872
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":55,"skipped":1110,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.111 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:40.769
    Dec  3 12:15:40.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:15:40.77
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:40.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:40.794
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:15:40.801
    Dec  3 12:15:40.811: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4061" to be "running and ready"
    Dec  3 12:15:40.814: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.318893ms
    Dec  3 12:15:40.814: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:15:42.819: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008273138s
    Dec  3 12:15:42.819: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec  3 12:15:42.819: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 12/03/22 12:15:42.823
    Dec  3 12:15:42.828: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4061" to be "running and ready"
    Dec  3 12:15:42.832: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.322738ms
    Dec  3 12:15:42.832: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:15:44.838: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009704953s
    Dec  3 12:15:44.838: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Dec  3 12:15:44.838: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/03/22 12:15:44.841
    STEP: delete the pod with lifecycle hook 12/03/22 12:15:44.849
    Dec  3 12:15:44.859: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec  3 12:15:44.863: INFO: Pod pod-with-poststart-http-hook still exists
    Dec  3 12:15:46.864: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec  3 12:15:46.868: INFO: Pod pod-with-poststart-http-hook still exists
    Dec  3 12:15:48.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec  3 12:15:48.868: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec  3 12:15:48.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4061" for this suite. 12/03/22 12:15:48.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:48.881
Dec  3 12:15:48.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:15:48.882
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:48.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:48.905
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2986 12/03/22 12:15:48.913
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/03/22 12:15:48.933
STEP: creating service externalsvc in namespace services-2986 12/03/22 12:15:48.933
STEP: creating replication controller externalsvc in namespace services-2986 12/03/22 12:15:48.952
I1203 12:15:48.960994      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2986, replica count: 2
I1203 12:15:52.011650      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 12/03/22 12:15:52.017
Dec  3 12:15:52.047: INFO: Creating new exec pod
Dec  3 12:15:52.060: INFO: Waiting up to 5m0s for pod "execpodjq228" in namespace "services-2986" to be "running"
Dec  3 12:15:52.063: INFO: Pod "execpodjq228": Phase="Pending", Reason="", readiness=false. Elapsed: 3.548485ms
Dec  3 12:15:54.069: INFO: Pod "execpodjq228": Phase="Running", Reason="", readiness=true. Elapsed: 2.009345841s
Dec  3 12:15:54.069: INFO: Pod "execpodjq228" satisfied condition "running"
Dec  3 12:15:54.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2986 exec execpodjq228 -- /bin/sh -x -c nslookup nodeport-service.services-2986.svc.cluster.local'
Dec  3 12:15:54.239: INFO: stderr: "+ nslookup nodeport-service.services-2986.svc.cluster.local\n"
Dec  3 12:15:54.239: INFO: stdout: "Server:\t\t10.152.183.238\nAddress:\t10.152.183.238#53\n\nnodeport-service.services-2986.svc.cluster.local\tcanonical name = externalsvc.services-2986.svc.cluster.local.\nName:\texternalsvc.services-2986.svc.cluster.local\nAddress: 10.152.183.58\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2986, will wait for the garbage collector to delete the pods 12/03/22 12:15:54.239
Dec  3 12:15:54.301: INFO: Deleting ReplicationController externalsvc took: 7.417511ms
Dec  3 12:15:54.402: INFO: Terminating ReplicationController externalsvc pods took: 100.665738ms
Dec  3 12:15:56.634: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:15:56.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2986" for this suite. 12/03/22 12:15:56.653
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":56,"skipped":1122,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.781 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:48.881
    Dec  3 12:15:48.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:15:48.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:48.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:48.905
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-2986 12/03/22 12:15:48.913
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/03/22 12:15:48.933
    STEP: creating service externalsvc in namespace services-2986 12/03/22 12:15:48.933
    STEP: creating replication controller externalsvc in namespace services-2986 12/03/22 12:15:48.952
    I1203 12:15:48.960994      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2986, replica count: 2
    I1203 12:15:52.011650      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 12/03/22 12:15:52.017
    Dec  3 12:15:52.047: INFO: Creating new exec pod
    Dec  3 12:15:52.060: INFO: Waiting up to 5m0s for pod "execpodjq228" in namespace "services-2986" to be "running"
    Dec  3 12:15:52.063: INFO: Pod "execpodjq228": Phase="Pending", Reason="", readiness=false. Elapsed: 3.548485ms
    Dec  3 12:15:54.069: INFO: Pod "execpodjq228": Phase="Running", Reason="", readiness=true. Elapsed: 2.009345841s
    Dec  3 12:15:54.069: INFO: Pod "execpodjq228" satisfied condition "running"
    Dec  3 12:15:54.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2986 exec execpodjq228 -- /bin/sh -x -c nslookup nodeport-service.services-2986.svc.cluster.local'
    Dec  3 12:15:54.239: INFO: stderr: "+ nslookup nodeport-service.services-2986.svc.cluster.local\n"
    Dec  3 12:15:54.239: INFO: stdout: "Server:\t\t10.152.183.238\nAddress:\t10.152.183.238#53\n\nnodeport-service.services-2986.svc.cluster.local\tcanonical name = externalsvc.services-2986.svc.cluster.local.\nName:\texternalsvc.services-2986.svc.cluster.local\nAddress: 10.152.183.58\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2986, will wait for the garbage collector to delete the pods 12/03/22 12:15:54.239
    Dec  3 12:15:54.301: INFO: Deleting ReplicationController externalsvc took: 7.417511ms
    Dec  3 12:15:54.402: INFO: Terminating ReplicationController externalsvc pods took: 100.665738ms
    Dec  3 12:15:56.634: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:15:56.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2986" for this suite. 12/03/22 12:15:56.653
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:56.663
Dec  3 12:15:56.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename namespaces 12/03/22 12:15:56.664
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:56.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:56.695
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 12/03/22 12:15:56.698
Dec  3 12:15:56.702: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 12/03/22 12:15:56.702
Dec  3 12:15:56.708: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 12/03/22 12:15:56.708
Dec  3 12:15:56.719: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:15:56.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8773" for this suite. 12/03/22 12:15:56.722
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":57,"skipped":1145,"failed":0}
------------------------------
â€¢ [0.069 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:56.663
    Dec  3 12:15:56.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename namespaces 12/03/22 12:15:56.664
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:56.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:56.695
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 12/03/22 12:15:56.698
    Dec  3 12:15:56.702: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 12/03/22 12:15:56.702
    Dec  3 12:15:56.708: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 12/03/22 12:15:56.708
    Dec  3 12:15:56.719: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:15:56.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8773" for this suite. 12/03/22 12:15:56.722
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:15:56.736
Dec  3 12:15:56.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:15:56.737
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:56.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:56.764
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 12/03/22 12:15:56.767
Dec  3 12:15:56.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec  3 12:15:56.841: INFO: stderr: ""
Dec  3 12:15:56.841: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 12/03/22 12:15:56.841
Dec  3 12:15:56.841: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec  3 12:15:56.841: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1737" to be "running and ready, or succeeded"
Dec  3 12:15:56.845: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306025ms
Dec  3 12:15:56.845: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-76-203' to be 'Running' but was 'Pending'
Dec  3 12:15:58.851: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.010301673s
Dec  3 12:15:58.851: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec  3 12:15:58.851: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 12/03/22 12:15:58.851
Dec  3 12:15:58.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator'
Dec  3 12:15:58.943: INFO: stderr: ""
Dec  3 12:15:58.943: INFO: stdout: "I1203 12:15:57.671133       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bgf8 470\nI1203 12:15:57.871565       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/g9k 479\nI1203 12:15:58.071813       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/4w7 223\nI1203 12:15:58.271956       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/vczh 562\nI1203 12:15:58.471224       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/rf4 570\nI1203 12:15:58.672121       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqx 481\nI1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
STEP: limiting log lines 12/03/22 12:15:58.943
Dec  3 12:15:58.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --tail=1'
Dec  3 12:15:59.049: INFO: stderr: ""
Dec  3 12:15:59.049: INFO: stdout: "I1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
Dec  3 12:15:59.049: INFO: got output "I1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
STEP: limiting log bytes 12/03/22 12:15:59.049
Dec  3 12:15:59.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --limit-bytes=1'
Dec  3 12:15:59.137: INFO: stderr: ""
Dec  3 12:15:59.137: INFO: stdout: "I"
Dec  3 12:15:59.137: INFO: got output "I"
STEP: exposing timestamps 12/03/22 12:15:59.137
Dec  3 12:15:59.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --tail=1 --timestamps'
Dec  3 12:15:59.222: INFO: stderr: ""
Dec  3 12:15:59.222: INFO: stdout: "2022-12-03T12:15:59.072039775Z I1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\n"
Dec  3 12:15:59.222: INFO: got output "2022-12-03T12:15:59.072039775Z I1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\n"
STEP: restricting to a time range 12/03/22 12:15:59.222
Dec  3 12:16:01.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --since=1s'
Dec  3 12:16:01.832: INFO: stderr: ""
Dec  3 12:16:01.832: INFO: stdout: "I1203 12:16:00.871707       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/64ff 204\nI1203 12:16:01.071932       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cz8w 270\nI1203 12:16:01.272252       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/w9nd 356\nI1203 12:16:01.471511       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/k67b 580\nI1203 12:16:01.671750       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/s4n 389\n"
Dec  3 12:16:01.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --since=24h'
Dec  3 12:16:01.931: INFO: stderr: ""
Dec  3 12:16:01.931: INFO: stdout: "I1203 12:15:57.671133       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bgf8 470\nI1203 12:15:57.871565       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/g9k 479\nI1203 12:15:58.071813       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/4w7 223\nI1203 12:15:58.271956       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/vczh 562\nI1203 12:15:58.471224       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/rf4 570\nI1203 12:15:58.672121       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqx 481\nI1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\nI1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\nI1203 12:15:59.271153       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/8xz 465\nI1203 12:15:59.471548       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/dwcf 201\nI1203 12:15:59.671884       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/ctp 458\nI1203 12:15:59.872170       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/2rn 565\nI1203 12:16:00.071364       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/8lv 404\nI1203 12:16:00.272009       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/jnp 526\nI1203 12:16:00.471221       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/spb 461\nI1203 12:16:00.671371       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/2jjh 236\nI1203 12:16:00.871707       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/64ff 204\nI1203 12:16:01.071932       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cz8w 270\nI1203 12:16:01.272252       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/w9nd 356\nI1203 12:16:01.471511       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/k67b 580\nI1203 12:16:01.671750       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/s4n 389\nI1203 12:16:01.872192       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/4fs 334\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Dec  3 12:16:01.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 delete pod logs-generator'
Dec  3 12:16:02.979: INFO: stderr: ""
Dec  3 12:16:02.979: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:16:02.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1737" for this suite. 12/03/22 12:16:02.983
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":58,"skipped":1187,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.258 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:15:56.736
    Dec  3 12:15:56.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:15:56.737
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:15:56.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:15:56.764
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 12/03/22 12:15:56.767
    Dec  3 12:15:56.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Dec  3 12:15:56.841: INFO: stderr: ""
    Dec  3 12:15:56.841: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 12/03/22 12:15:56.841
    Dec  3 12:15:56.841: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Dec  3 12:15:56.841: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1737" to be "running and ready, or succeeded"
    Dec  3 12:15:56.845: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306025ms
    Dec  3 12:15:56.845: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-76-203' to be 'Running' but was 'Pending'
    Dec  3 12:15:58.851: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.010301673s
    Dec  3 12:15:58.851: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Dec  3 12:15:58.851: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 12/03/22 12:15:58.851
    Dec  3 12:15:58.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator'
    Dec  3 12:15:58.943: INFO: stderr: ""
    Dec  3 12:15:58.943: INFO: stdout: "I1203 12:15:57.671133       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bgf8 470\nI1203 12:15:57.871565       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/g9k 479\nI1203 12:15:58.071813       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/4w7 223\nI1203 12:15:58.271956       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/vczh 562\nI1203 12:15:58.471224       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/rf4 570\nI1203 12:15:58.672121       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqx 481\nI1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
    STEP: limiting log lines 12/03/22 12:15:58.943
    Dec  3 12:15:58.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --tail=1'
    Dec  3 12:15:59.049: INFO: stderr: ""
    Dec  3 12:15:59.049: INFO: stdout: "I1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
    Dec  3 12:15:59.049: INFO: got output "I1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\n"
    STEP: limiting log bytes 12/03/22 12:15:59.049
    Dec  3 12:15:59.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --limit-bytes=1'
    Dec  3 12:15:59.137: INFO: stderr: ""
    Dec  3 12:15:59.137: INFO: stdout: "I"
    Dec  3 12:15:59.137: INFO: got output "I"
    STEP: exposing timestamps 12/03/22 12:15:59.137
    Dec  3 12:15:59.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --tail=1 --timestamps'
    Dec  3 12:15:59.222: INFO: stderr: ""
    Dec  3 12:15:59.222: INFO: stdout: "2022-12-03T12:15:59.072039775Z I1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\n"
    Dec  3 12:15:59.222: INFO: got output "2022-12-03T12:15:59.072039775Z I1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\n"
    STEP: restricting to a time range 12/03/22 12:15:59.222
    Dec  3 12:16:01.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --since=1s'
    Dec  3 12:16:01.832: INFO: stderr: ""
    Dec  3 12:16:01.832: INFO: stdout: "I1203 12:16:00.871707       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/64ff 204\nI1203 12:16:01.071932       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cz8w 270\nI1203 12:16:01.272252       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/w9nd 356\nI1203 12:16:01.471511       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/k67b 580\nI1203 12:16:01.671750       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/s4n 389\n"
    Dec  3 12:16:01.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 logs logs-generator logs-generator --since=24h'
    Dec  3 12:16:01.931: INFO: stderr: ""
    Dec  3 12:16:01.931: INFO: stdout: "I1203 12:15:57.671133       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bgf8 470\nI1203 12:15:57.871565       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/g9k 479\nI1203 12:15:58.071813       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/4w7 223\nI1203 12:15:58.271956       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/vczh 562\nI1203 12:15:58.471224       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/rf4 570\nI1203 12:15:58.672121       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqx 481\nI1203 12:15:58.871375       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/prr 391\nI1203 12:15:59.071931       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/bdr 395\nI1203 12:15:59.271153       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/8xz 465\nI1203 12:15:59.471548       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/dwcf 201\nI1203 12:15:59.671884       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/ctp 458\nI1203 12:15:59.872170       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/2rn 565\nI1203 12:16:00.071364       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/8lv 404\nI1203 12:16:00.272009       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/jnp 526\nI1203 12:16:00.471221       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/spb 461\nI1203 12:16:00.671371       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/2jjh 236\nI1203 12:16:00.871707       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/64ff 204\nI1203 12:16:01.071932       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cz8w 270\nI1203 12:16:01.272252       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/w9nd 356\nI1203 12:16:01.471511       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/k67b 580\nI1203 12:16:01.671750       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/s4n 389\nI1203 12:16:01.872192       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/4fs 334\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Dec  3 12:16:01.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1737 delete pod logs-generator'
    Dec  3 12:16:02.979: INFO: stderr: ""
    Dec  3 12:16:02.979: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:16:02.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1737" for this suite. 12/03/22 12:16:02.983
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:16:02.993
Dec  3 12:16:02.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:16:02.994
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:03.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:03.019
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 12/03/22 12:16:03.021
STEP: Creating a ResourceQuota 12/03/22 12:16:08.025
STEP: Ensuring resource quota status is calculated 12/03/22 12:16:08.032
STEP: Creating a ReplicaSet 12/03/22 12:16:10.037
STEP: Ensuring resource quota status captures replicaset creation 12/03/22 12:16:10.057
STEP: Deleting a ReplicaSet 12/03/22 12:16:12.064
STEP: Ensuring resource quota status released usage 12/03/22 12:16:12.072
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:16:14.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6090" for this suite. 12/03/22 12:16:14.085
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":59,"skipped":1188,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.101 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:16:02.993
    Dec  3 12:16:02.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:16:02.994
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:03.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:03.019
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 12/03/22 12:16:03.021
    STEP: Creating a ResourceQuota 12/03/22 12:16:08.025
    STEP: Ensuring resource quota status is calculated 12/03/22 12:16:08.032
    STEP: Creating a ReplicaSet 12/03/22 12:16:10.037
    STEP: Ensuring resource quota status captures replicaset creation 12/03/22 12:16:10.057
    STEP: Deleting a ReplicaSet 12/03/22 12:16:12.064
    STEP: Ensuring resource quota status released usage 12/03/22 12:16:12.072
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:16:14.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6090" for this suite. 12/03/22 12:16:14.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:16:14.095
Dec  3 12:16:14.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename containers 12/03/22 12:16:14.096
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:14.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:14.135
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 12/03/22 12:16:14.14
Dec  3 12:16:14.149: INFO: Waiting up to 5m0s for pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388" in namespace "containers-4922" to be "Succeeded or Failed"
Dec  3 12:16:14.153: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Pending", Reason="", readiness=false. Elapsed: 4.134376ms
Dec  3 12:16:16.161: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011709633s
Dec  3 12:16:18.157: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008300971s
STEP: Saw pod success 12/03/22 12:16:18.157
Dec  3 12:16:18.157: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388" satisfied condition "Succeeded or Failed"
Dec  3 12:16:18.161: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 12:16:18.168
Dec  3 12:16:18.181: INFO: Waiting for pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 to disappear
Dec  3 12:16:18.184: INFO: Pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec  3 12:16:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4922" for this suite. 12/03/22 12:16:18.188
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":60,"skipped":1195,"failed":0}
------------------------------
â€¢ [4.101 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:16:14.095
    Dec  3 12:16:14.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename containers 12/03/22 12:16:14.096
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:14.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:14.135
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 12/03/22 12:16:14.14
    Dec  3 12:16:14.149: INFO: Waiting up to 5m0s for pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388" in namespace "containers-4922" to be "Succeeded or Failed"
    Dec  3 12:16:14.153: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Pending", Reason="", readiness=false. Elapsed: 4.134376ms
    Dec  3 12:16:16.161: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011709633s
    Dec  3 12:16:18.157: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008300971s
    STEP: Saw pod success 12/03/22 12:16:18.157
    Dec  3 12:16:18.157: INFO: Pod "client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388" satisfied condition "Succeeded or Failed"
    Dec  3 12:16:18.161: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 12:16:18.168
    Dec  3 12:16:18.181: INFO: Waiting for pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 to disappear
    Dec  3 12:16:18.184: INFO: Pod client-containers-362ffc34-2f83-4dfe-9594-02eb12b18388 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec  3 12:16:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4922" for this suite. 12/03/22 12:16:18.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:16:18.198
Dec  3 12:16:18.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 12:16:18.199
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:18.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:18.223
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 12/03/22 12:16:18.226
STEP: Ensuring active pods == parallelism 12/03/22 12:16:18.234
STEP: delete a job 12/03/22 12:16:20.239
STEP: deleting Job.batch foo in namespace job-7720, will wait for the garbage collector to delete the pods 12/03/22 12:16:20.24
Dec  3 12:16:20.301: INFO: Deleting Job.batch foo took: 7.811552ms
Dec  3 12:16:20.401: INFO: Terminating Job.batch foo pods took: 100.194882ms
STEP: Ensuring job was deleted 12/03/22 12:16:53.102
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 12:16:53.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7720" for this suite. 12/03/22 12:16:53.113
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":61,"skipped":1206,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.924 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:16:18.198
    Dec  3 12:16:18.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 12:16:18.199
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:18.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:18.223
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 12/03/22 12:16:18.226
    STEP: Ensuring active pods == parallelism 12/03/22 12:16:18.234
    STEP: delete a job 12/03/22 12:16:20.239
    STEP: deleting Job.batch foo in namespace job-7720, will wait for the garbage collector to delete the pods 12/03/22 12:16:20.24
    Dec  3 12:16:20.301: INFO: Deleting Job.batch foo took: 7.811552ms
    Dec  3 12:16:20.401: INFO: Terminating Job.batch foo pods took: 100.194882ms
    STEP: Ensuring job was deleted 12/03/22 12:16:53.102
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 12:16:53.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7720" for this suite. 12/03/22 12:16:53.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:16:53.124
Dec  3 12:16:53.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 12:16:53.125
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:53.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:53.152
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Dec  3 12:16:53.174: INFO: created pod
Dec  3 12:16:53.174: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7257" to be "Succeeded or Failed"
Dec  3 12:16:53.180: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496834ms
Dec  3 12:16:55.185: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010981277s
Dec  3 12:16:57.185: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010657529s
Dec  3 12:16:59.185: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010475682s
STEP: Saw pod success 12/03/22 12:16:59.185
Dec  3 12:16:59.185: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Dec  3 12:17:29.187: INFO: polling logs
Dec  3 12:17:29.194: INFO: Pod logs: 
I1203 12:16:55.285240       1 log.go:195] OK: Got token
I1203 12:16:55.285275       1 log.go:195] validating with in-cluster discovery
I1203 12:16:55.285635       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1203 12:16:55.285672       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7257:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1670070413, NotBefore:1670069813, IssuedAt:1670069813, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7257", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7f6bd19c-aa8d-4f1d-b905-32b374405aae"}}}
I1203 12:16:55.295169       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1203 12:16:55.300670       1 log.go:195] OK: Validated signature on JWT
I1203 12:16:55.300762       1 log.go:195] OK: Got valid claims from token!
I1203 12:16:55.300790       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7257:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1670070413, NotBefore:1670069813, IssuedAt:1670069813, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7257", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7f6bd19c-aa8d-4f1d-b905-32b374405aae"}}}

Dec  3 12:17:29.194: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 12:17:29.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7257" for this suite. 12/03/22 12:17:29.207
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":62,"skipped":1243,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.093 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:16:53.124
    Dec  3 12:16:53.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 12:16:53.125
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:16:53.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:16:53.152
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Dec  3 12:16:53.174: INFO: created pod
    Dec  3 12:16:53.174: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7257" to be "Succeeded or Failed"
    Dec  3 12:16:53.180: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496834ms
    Dec  3 12:16:55.185: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010981277s
    Dec  3 12:16:57.185: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010657529s
    Dec  3 12:16:59.185: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010475682s
    STEP: Saw pod success 12/03/22 12:16:59.185
    Dec  3 12:16:59.185: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Dec  3 12:17:29.187: INFO: polling logs
    Dec  3 12:17:29.194: INFO: Pod logs: 
    I1203 12:16:55.285240       1 log.go:195] OK: Got token
    I1203 12:16:55.285275       1 log.go:195] validating with in-cluster discovery
    I1203 12:16:55.285635       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1203 12:16:55.285672       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7257:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1670070413, NotBefore:1670069813, IssuedAt:1670069813, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7257", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7f6bd19c-aa8d-4f1d-b905-32b374405aae"}}}
    I1203 12:16:55.295169       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1203 12:16:55.300670       1 log.go:195] OK: Validated signature on JWT
    I1203 12:16:55.300762       1 log.go:195] OK: Got valid claims from token!
    I1203 12:16:55.300790       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7257:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1670070413, NotBefore:1670069813, IssuedAt:1670069813, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7257", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7f6bd19c-aa8d-4f1d-b905-32b374405aae"}}}

    Dec  3 12:17:29.194: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 12:17:29.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7257" for this suite. 12/03/22 12:17:29.207
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:29.22
Dec  3 12:17:29.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename watch 12/03/22 12:17:29.221
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:29.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:29.298
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 12/03/22 12:17:29.303
STEP: creating a new configmap 12/03/22 12:17:29.305
STEP: modifying the configmap once 12/03/22 12:17:29.315
STEP: changing the label value of the configmap 12/03/22 12:17:29.334
STEP: Expecting to observe a delete notification for the watched object 12/03/22 12:17:29.344
Dec  3 12:17:29.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8229 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:17:29.344: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8230 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:17:29.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8231 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 12/03/22 12:17:29.345
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/03/22 12:17:29.36
STEP: changing the label value of the configmap back 12/03/22 12:17:39.363
STEP: modifying the configmap a third time 12/03/22 12:17:39.373
STEP: deleting the configmap 12/03/22 12:17:39.384
STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/03/22 12:17:39.391
Dec  3 12:17:39.391: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8264 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:17:39.391: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8265 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 12:17:39.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8266 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec  3 12:17:39.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3105" for this suite. 12/03/22 12:17:39.396
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":63,"skipped":1264,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.183 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:29.22
    Dec  3 12:17:29.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename watch 12/03/22 12:17:29.221
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:29.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:29.298
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 12/03/22 12:17:29.303
    STEP: creating a new configmap 12/03/22 12:17:29.305
    STEP: modifying the configmap once 12/03/22 12:17:29.315
    STEP: changing the label value of the configmap 12/03/22 12:17:29.334
    STEP: Expecting to observe a delete notification for the watched object 12/03/22 12:17:29.344
    Dec  3 12:17:29.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8229 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:17:29.344: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8230 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:17:29.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8231 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 12/03/22 12:17:29.345
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/03/22 12:17:29.36
    STEP: changing the label value of the configmap back 12/03/22 12:17:39.363
    STEP: modifying the configmap a third time 12/03/22 12:17:39.373
    STEP: deleting the configmap 12/03/22 12:17:39.384
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/03/22 12:17:39.391
    Dec  3 12:17:39.391: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8264 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:17:39.391: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8265 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 12:17:39.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3105  3c30f440-8b55-4a73-82ef-3b8a73fa347f 8266 0 2022-12-03 12:17:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-03 12:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec  3 12:17:39.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3105" for this suite. 12/03/22 12:17:39.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:39.404
Dec  3 12:17:39.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 12:17:39.405
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:39.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:39.433
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-ac4cd3a6-7351-4eda-8a17-034398293efe 12/03/22 12:17:39.437
STEP: Creating a pod to test consume configMaps 12/03/22 12:17:39.442
Dec  3 12:17:39.456: INFO: Waiting up to 5m0s for pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a" in namespace "configmap-4176" to be "Succeeded or Failed"
Dec  3 12:17:39.461: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.507242ms
Dec  3 12:17:41.465: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008712141s
Dec  3 12:17:43.466: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009267921s
STEP: Saw pod success 12/03/22 12:17:43.466
Dec  3 12:17:43.466: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a" satisfied condition "Succeeded or Failed"
Dec  3 12:17:43.470: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a container configmap-volume-test: <nil>
STEP: delete the pod 12/03/22 12:17:43.478
Dec  3 12:17:43.491: INFO: Waiting for pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a to disappear
Dec  3 12:17:43.494: INFO: Pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 12:17:43.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4176" for this suite. 12/03/22 12:17:43.498
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":64,"skipped":1275,"failed":0}
------------------------------
â€¢ [4.100 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:39.404
    Dec  3 12:17:39.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 12:17:39.405
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:39.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:39.433
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-ac4cd3a6-7351-4eda-8a17-034398293efe 12/03/22 12:17:39.437
    STEP: Creating a pod to test consume configMaps 12/03/22 12:17:39.442
    Dec  3 12:17:39.456: INFO: Waiting up to 5m0s for pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a" in namespace "configmap-4176" to be "Succeeded or Failed"
    Dec  3 12:17:39.461: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.507242ms
    Dec  3 12:17:41.465: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008712141s
    Dec  3 12:17:43.466: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009267921s
    STEP: Saw pod success 12/03/22 12:17:43.466
    Dec  3 12:17:43.466: INFO: Pod "pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a" satisfied condition "Succeeded or Failed"
    Dec  3 12:17:43.470: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a container configmap-volume-test: <nil>
    STEP: delete the pod 12/03/22 12:17:43.478
    Dec  3 12:17:43.491: INFO: Waiting for pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a to disappear
    Dec  3 12:17:43.494: INFO: Pod pod-configmaps-a327645c-bf0d-401b-aae9-a926c8bbfa1a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 12:17:43.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4176" for this suite. 12/03/22 12:17:43.498
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:43.504
Dec  3 12:17:43.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:17:43.505
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:43.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:43.526
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Dec  3 12:17:43.529: INFO: Creating simple deployment test-new-deployment
Dec  3 12:17:43.542: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 12/03/22 12:17:45.563
STEP: updating a scale subresource 12/03/22 12:17:45.567
STEP: verifying the deployment Spec.Replicas was modified 12/03/22 12:17:45.573
STEP: Patch a scale subresource 12/03/22 12:17:45.577
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:17:45.595: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-6027  af2e4537-e4c9-4134-89c8-b34b53e8e04a 8349 3 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-03 12:17:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a6fab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:17:44 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-03 12:17:44 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 12:17:45.598: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6027  5ce19169-23db-4881-95fa-263db83d48d3 8348 2 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment af2e4537-e4c9-4134-89c8-b34b53e8e04a 0xc003a6ff00 0xc003a6ff01}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:17:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"af2e4537-e4c9-4134-89c8-b34b53e8e04a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a6ff88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:17:45.602: INFO: Pod "test-new-deployment-845c8977d9-7sdc7" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-7sdc7 test-new-deployment-845c8977d9- deployment-6027  6ce157c7-141b-4386-aa37-a7ffe7e5b489 8351 0 2022-12-03 12:17:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ce19169-23db-4881-95fa-263db83d48d3 0xc003bdb670 0xc003bdb671}] [] [{kube-controller-manager Update v1 2022-12-03 12:17:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ce19169-23db-4881-95fa-263db83d48d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6pzcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6pzcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:17:45.602: INFO: Pod "test-new-deployment-845c8977d9-wmd86" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-wmd86 test-new-deployment-845c8977d9- deployment-6027  3421f8fb-7081-4c7b-a768-28e1550c25b5 8341 0 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ce19169-23db-4881-95fa-263db83d48d3 0xc003bdb7a7 0xc003bdb7a8}] [] [{kube-controller-manager Update v1 2022-12-03 12:17:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ce19169-23db-4881-95fa-263db83d48d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vlt8j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vlt8j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.121,StartTime:2022-12-03 12:17:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:17:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1c6b1828d392a19fb16f2a3b3a505e02b6152d9da5deb660ca657a1616a42280,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:17:45.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6027" for this suite. 12/03/22 12:17:45.611
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":65,"skipped":1278,"failed":0}
------------------------------
â€¢ [2.120 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:43.504
    Dec  3 12:17:43.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:17:43.505
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:43.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:43.526
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Dec  3 12:17:43.529: INFO: Creating simple deployment test-new-deployment
    Dec  3 12:17:43.542: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 12/03/22 12:17:45.563
    STEP: updating a scale subresource 12/03/22 12:17:45.567
    STEP: verifying the deployment Spec.Replicas was modified 12/03/22 12:17:45.573
    STEP: Patch a scale subresource 12/03/22 12:17:45.577
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:17:45.595: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-6027  af2e4537-e4c9-4134-89c8-b34b53e8e04a 8349 3 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-03 12:17:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a6fab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:17:44 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-03 12:17:44 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec  3 12:17:45.598: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6027  5ce19169-23db-4881-95fa-263db83d48d3 8348 2 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment af2e4537-e4c9-4134-89c8-b34b53e8e04a 0xc003a6ff00 0xc003a6ff01}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:17:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"af2e4537-e4c9-4134-89c8-b34b53e8e04a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a6ff88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:17:45.602: INFO: Pod "test-new-deployment-845c8977d9-7sdc7" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-7sdc7 test-new-deployment-845c8977d9- deployment-6027  6ce157c7-141b-4386-aa37-a7ffe7e5b489 8351 0 2022-12-03 12:17:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ce19169-23db-4881-95fa-263db83d48d3 0xc003bdb670 0xc003bdb671}] [] [{kube-controller-manager Update v1 2022-12-03 12:17:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ce19169-23db-4881-95fa-263db83d48d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6pzcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6pzcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:17:45.602: INFO: Pod "test-new-deployment-845c8977d9-wmd86" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-wmd86 test-new-deployment-845c8977d9- deployment-6027  3421f8fb-7081-4c7b-a768-28e1550c25b5 8341 0 2022-12-03 12:17:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ce19169-23db-4881-95fa-263db83d48d3 0xc003bdb7a7 0xc003bdb7a8}] [] [{kube-controller-manager Update v1 2022-12-03 12:17:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ce19169-23db-4881-95fa-263db83d48d3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:17:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vlt8j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vlt8j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:17:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.121,StartTime:2022-12-03 12:17:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:17:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1c6b1828d392a19fb16f2a3b3a505e02b6152d9da5deb660ca657a1616a42280,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:17:45.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6027" for this suite. 12/03/22 12:17:45.611
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:45.626
Dec  3 12:17:45.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 12:17:45.627
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:45.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:45.656
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-761a5b3f-b2ad-42dc-8ff8-976308f9a45d 12/03/22 12:17:45.663
STEP: Creating the pod 12/03/22 12:17:45.667
Dec  3 12:17:45.676: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c" in namespace "configmap-5391" to be "running"
Dec  3 12:17:45.679: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.229184ms
Dec  3 12:17:47.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008624244s
Dec  3 12:17:49.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Running", Reason="", readiness=false. Elapsed: 4.008461463s
Dec  3 12:17:49.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c" satisfied condition "running"
STEP: Waiting for pod with text data 12/03/22 12:17:49.684
STEP: Waiting for pod with binary data 12/03/22 12:17:49.693
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 12:17:49.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5391" for this suite. 12/03/22 12:17:49.705
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":66,"skipped":1309,"failed":0}
------------------------------
â€¢ [4.087 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:45.626
    Dec  3 12:17:45.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 12:17:45.627
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:45.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:45.656
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-761a5b3f-b2ad-42dc-8ff8-976308f9a45d 12/03/22 12:17:45.663
    STEP: Creating the pod 12/03/22 12:17:45.667
    Dec  3 12:17:45.676: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c" in namespace "configmap-5391" to be "running"
    Dec  3 12:17:45.679: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.229184ms
    Dec  3 12:17:47.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008624244s
    Dec  3 12:17:49.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c": Phase="Running", Reason="", readiness=false. Elapsed: 4.008461463s
    Dec  3 12:17:49.684: INFO: Pod "pod-configmaps-ac599762-d971-42ae-8461-a7e2e870014c" satisfied condition "running"
    STEP: Waiting for pod with text data 12/03/22 12:17:49.684
    STEP: Waiting for pod with binary data 12/03/22 12:17:49.693
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 12:17:49.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5391" for this suite. 12/03/22 12:17:49.705
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:49.713
Dec  3 12:17:49.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:17:49.714
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:49.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:49.738
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:17:49.761
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:17:50.251
STEP: Deploying the webhook pod 12/03/22 12:17:50.26
STEP: Wait for the deployment to be ready 12/03/22 12:17:50.273
Dec  3 12:17:50.280: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 12:17:52.296
STEP: Verifying the service has paired with the endpoint 12/03/22 12:17:52.31
Dec  3 12:17:53.310: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 12/03/22 12:17:53.314
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/03/22 12:17:53.315
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/03/22 12:17:53.316
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/03/22 12:17:53.316
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/03/22 12:17:53.317
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/03/22 12:17:53.317
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/03/22 12:17:53.318
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:17:53.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6379" for this suite. 12/03/22 12:17:53.326
STEP: Destroying namespace "webhook-6379-markers" for this suite. 12/03/22 12:17:53.332
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":67,"skipped":1309,"failed":0}
------------------------------
â€¢ [3.670 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:49.713
    Dec  3 12:17:49.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:17:49.714
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:49.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:49.738
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:17:49.761
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:17:50.251
    STEP: Deploying the webhook pod 12/03/22 12:17:50.26
    STEP: Wait for the deployment to be ready 12/03/22 12:17:50.273
    Dec  3 12:17:50.280: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 12:17:52.296
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:17:52.31
    Dec  3 12:17:53.310: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 12/03/22 12:17:53.314
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/03/22 12:17:53.315
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/03/22 12:17:53.316
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/03/22 12:17:53.316
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/03/22 12:17:53.317
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/03/22 12:17:53.317
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/03/22 12:17:53.318
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:17:53.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6379" for this suite. 12/03/22 12:17:53.326
    STEP: Destroying namespace "webhook-6379-markers" for this suite. 12/03/22 12:17:53.332
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:53.389
Dec  3 12:17:53.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 12:17:53.39
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:53.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:53.468
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Dec  3 12:17:53.482: INFO: Waiting up to 2m0s for pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" in namespace "var-expansion-5086" to be "container 0 failed with reason CreateContainerConfigError"
Dec  3 12:17:53.489: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511415ms
Dec  3 12:17:55.493: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011343794s
Dec  3 12:17:55.494: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec  3 12:17:55.494: INFO: Deleting pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" in namespace "var-expansion-5086"
Dec  3 12:17:55.502: INFO: Wait up to 5m0s for pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 12:17:57.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5086" for this suite. 12/03/22 12:17:57.517
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":68,"skipped":1362,"failed":0}
------------------------------
â€¢ [4.133 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:53.389
    Dec  3 12:17:53.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 12:17:53.39
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:53.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:53.468
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Dec  3 12:17:53.482: INFO: Waiting up to 2m0s for pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" in namespace "var-expansion-5086" to be "container 0 failed with reason CreateContainerConfigError"
    Dec  3 12:17:53.489: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511415ms
    Dec  3 12:17:55.493: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011343794s
    Dec  3 12:17:55.494: INFO: Pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec  3 12:17:55.494: INFO: Deleting pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" in namespace "var-expansion-5086"
    Dec  3 12:17:55.502: INFO: Wait up to 5m0s for pod "var-expansion-f9633d85-5a18-4485-82d9-8eee6579ba87" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 12:17:57.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5086" for this suite. 12/03/22 12:17:57.517
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:17:57.523
Dec  3 12:17:57.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir-wrapper 12/03/22 12:17:57.524
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:57.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:57.55
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 12/03/22 12:17:57.553
STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:17:57.831
Dec  3 12:17:57.888: INFO: Pod name wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295: Found 2 pods out of 5
Dec  3 12:18:02.897: INFO: Pod name wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/03/22 12:18:02.897
Dec  3 12:18:02.898: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:02.902: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.421306ms
Dec  3 12:18:04.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009525058s
Dec  3 12:18:06.909: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011699913s
Dec  3 12:18:08.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009747791s
Dec  3 12:18:10.911: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013459447s
Dec  3 12:18:12.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Running", Reason="", readiness=true. Elapsed: 10.00923798s
Dec  3 12:18:12.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc" satisfied condition "running"
Dec  3 12:18:12.907: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:12.910: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls": Phase="Running", Reason="", readiness=true. Elapsed: 3.064324ms
Dec  3 12:18:12.910: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls" satisfied condition "running"
Dec  3 12:18:12.910: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:12.914: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv": Phase="Running", Reason="", readiness=true. Elapsed: 3.846272ms
Dec  3 12:18:12.914: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv" satisfied condition "running"
Dec  3 12:18:12.914: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:12.917: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j": Phase="Running", Reason="", readiness=true. Elapsed: 3.503325ms
Dec  3 12:18:12.917: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j" satisfied condition "running"
Dec  3 12:18:12.917: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:12.920: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57": Phase="Running", Reason="", readiness=true. Elapsed: 2.782097ms
Dec  3 12:18:12.920: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:12.92
Dec  3 12:18:12.983: INFO: Deleting ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 took: 8.064993ms
Dec  3 12:18:13.084: INFO: Terminating ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 pods took: 100.686183ms
STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:18:17.89
Dec  3 12:18:17.905: INFO: Pod name wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c: Found 0 pods out of 5
Dec  3 12:18:22.917: INFO: Pod name wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/03/22 12:18:22.917
Dec  3 12:18:22.918: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:22.922: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.754339ms
Dec  3 12:18:24.928: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010595589s
Dec  3 12:18:26.932: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01393854s
Dec  3 12:18:28.934: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016283708s
Dec  3 12:18:30.931: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013760729s
Dec  3 12:18:32.930: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Running", Reason="", readiness=true. Elapsed: 10.011944547s
Dec  3 12:18:32.930: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5" satisfied condition "running"
Dec  3 12:18:32.930: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:32.937: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz": Phase="Running", Reason="", readiness=true. Elapsed: 7.228785ms
Dec  3 12:18:32.937: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz" satisfied condition "running"
Dec  3 12:18:32.937: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:32.947: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf": Phase="Running", Reason="", readiness=true. Elapsed: 9.616026ms
Dec  3 12:18:32.947: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf" satisfied condition "running"
Dec  3 12:18:32.947: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:32.951: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6": Phase="Running", Reason="", readiness=true. Elapsed: 4.387912ms
Dec  3 12:18:32.951: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6" satisfied condition "running"
Dec  3 12:18:32.951: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:32.956: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds": Phase="Running", Reason="", readiness=true. Elapsed: 4.742285ms
Dec  3 12:18:32.956: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:32.956
Dec  3 12:18:33.020: INFO: Deleting ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c took: 7.249895ms
Dec  3 12:18:33.121: INFO: Terminating ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c pods took: 100.567092ms
STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:18:37.827
Dec  3 12:18:37.844: INFO: Pod name wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293: Found 0 pods out of 5
Dec  3 12:18:42.854: INFO: Pod name wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/03/22 12:18:42.854
Dec  3 12:18:42.855: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:42.860: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240957ms
Dec  3 12:18:44.864: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009685482s
Dec  3 12:18:46.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011864357s
Dec  3 12:18:48.866: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01133137s
Dec  3 12:18:50.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016332615s
Dec  3 12:18:52.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Running", Reason="", readiness=true. Elapsed: 10.012052299s
Dec  3 12:18:52.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8" satisfied condition "running"
Dec  3 12:18:52.867: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:52.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq": Phase="Running", Reason="", readiness=true. Elapsed: 4.372761ms
Dec  3 12:18:52.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq" satisfied condition "running"
Dec  3 12:18:52.871: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:52.876: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22": Phase="Pending", Reason="", readiness=false. Elapsed: 4.331952ms
Dec  3 12:18:54.882: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22": Phase="Running", Reason="", readiness=true. Elapsed: 2.010305557s
Dec  3 12:18:54.882: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22" satisfied condition "running"
Dec  3 12:18:54.882: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:54.888: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2": Phase="Running", Reason="", readiness=true. Elapsed: 6.15881ms
Dec  3 12:18:54.888: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2" satisfied condition "running"
Dec  3 12:18:54.888: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv" in namespace "emptydir-wrapper-5647" to be "running"
Dec  3 12:18:54.893: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv": Phase="Running", Reason="", readiness=true. Elapsed: 4.823262ms
Dec  3 12:18:54.893: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:54.893
Dec  3 12:18:54.956: INFO: Deleting ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 took: 8.422492ms
Dec  3 12:18:55.057: INFO: Terminating ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 pods took: 100.828118ms
STEP: Cleaning up the configMaps 12/03/22 12:18:58.258
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec  3 12:18:58.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5647" for this suite. 12/03/22 12:18:58.65
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":69,"skipped":1364,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.143 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:17:57.523
    Dec  3 12:17:57.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir-wrapper 12/03/22 12:17:57.524
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:17:57.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:17:57.55
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 12/03/22 12:17:57.553
    STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:17:57.831
    Dec  3 12:17:57.888: INFO: Pod name wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295: Found 2 pods out of 5
    Dec  3 12:18:02.897: INFO: Pod name wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/03/22 12:18:02.897
    Dec  3 12:18:02.898: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:02.902: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.421306ms
    Dec  3 12:18:04.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009525058s
    Dec  3 12:18:06.909: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011699913s
    Dec  3 12:18:08.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009747791s
    Dec  3 12:18:10.911: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013459447s
    Dec  3 12:18:12.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc": Phase="Running", Reason="", readiness=true. Elapsed: 10.00923798s
    Dec  3 12:18:12.907: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-f4cbc" satisfied condition "running"
    Dec  3 12:18:12.907: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:12.910: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls": Phase="Running", Reason="", readiness=true. Elapsed: 3.064324ms
    Dec  3 12:18:12.910: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-gc4ls" satisfied condition "running"
    Dec  3 12:18:12.910: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:12.914: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv": Phase="Running", Reason="", readiness=true. Elapsed: 3.846272ms
    Dec  3 12:18:12.914: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-shcrv" satisfied condition "running"
    Dec  3 12:18:12.914: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:12.917: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j": Phase="Running", Reason="", readiness=true. Elapsed: 3.503325ms
    Dec  3 12:18:12.917: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-vbt8j" satisfied condition "running"
    Dec  3 12:18:12.917: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:12.920: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57": Phase="Running", Reason="", readiness=true. Elapsed: 2.782097ms
    Dec  3 12:18:12.920: INFO: Pod "wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295-xtg57" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:12.92
    Dec  3 12:18:12.983: INFO: Deleting ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 took: 8.064993ms
    Dec  3 12:18:13.084: INFO: Terminating ReplicationController wrapped-volume-race-5b2b07e7-0290-4afb-9f67-62b25a5d0295 pods took: 100.686183ms
    STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:18:17.89
    Dec  3 12:18:17.905: INFO: Pod name wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c: Found 0 pods out of 5
    Dec  3 12:18:22.917: INFO: Pod name wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/03/22 12:18:22.917
    Dec  3 12:18:22.918: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:22.922: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.754339ms
    Dec  3 12:18:24.928: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010595589s
    Dec  3 12:18:26.932: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01393854s
    Dec  3 12:18:28.934: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016283708s
    Dec  3 12:18:30.931: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013760729s
    Dec  3 12:18:32.930: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5": Phase="Running", Reason="", readiness=true. Elapsed: 10.011944547s
    Dec  3 12:18:32.930: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-gxkn5" satisfied condition "running"
    Dec  3 12:18:32.930: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:32.937: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz": Phase="Running", Reason="", readiness=true. Elapsed: 7.228785ms
    Dec  3 12:18:32.937: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-hkqfz" satisfied condition "running"
    Dec  3 12:18:32.937: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:32.947: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf": Phase="Running", Reason="", readiness=true. Elapsed: 9.616026ms
    Dec  3 12:18:32.947: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-tctvf" satisfied condition "running"
    Dec  3 12:18:32.947: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:32.951: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6": Phase="Running", Reason="", readiness=true. Elapsed: 4.387912ms
    Dec  3 12:18:32.951: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-wxmc6" satisfied condition "running"
    Dec  3 12:18:32.951: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:32.956: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds": Phase="Running", Reason="", readiness=true. Elapsed: 4.742285ms
    Dec  3 12:18:32.956: INFO: Pod "wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c-xx4ds" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:32.956
    Dec  3 12:18:33.020: INFO: Deleting ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c took: 7.249895ms
    Dec  3 12:18:33.121: INFO: Terminating ReplicationController wrapped-volume-race-d2ddaa9e-0692-4ce9-8d3e-b11f6a003a0c pods took: 100.567092ms
    STEP: Creating RC which spawns configmap-volume pods 12/03/22 12:18:37.827
    Dec  3 12:18:37.844: INFO: Pod name wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293: Found 0 pods out of 5
    Dec  3 12:18:42.854: INFO: Pod name wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/03/22 12:18:42.854
    Dec  3 12:18:42.855: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:42.860: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240957ms
    Dec  3 12:18:44.864: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009685482s
    Dec  3 12:18:46.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011864357s
    Dec  3 12:18:48.866: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01133137s
    Dec  3 12:18:50.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016332615s
    Dec  3 12:18:52.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8": Phase="Running", Reason="", readiness=true. Elapsed: 10.012052299s
    Dec  3 12:18:52.867: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-2vdm8" satisfied condition "running"
    Dec  3 12:18:52.867: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:52.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq": Phase="Running", Reason="", readiness=true. Elapsed: 4.372761ms
    Dec  3 12:18:52.871: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4dcsq" satisfied condition "running"
    Dec  3 12:18:52.871: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:52.876: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22": Phase="Pending", Reason="", readiness=false. Elapsed: 4.331952ms
    Dec  3 12:18:54.882: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22": Phase="Running", Reason="", readiness=true. Elapsed: 2.010305557s
    Dec  3 12:18:54.882: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-4rj22" satisfied condition "running"
    Dec  3 12:18:54.882: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:54.888: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2": Phase="Running", Reason="", readiness=true. Elapsed: 6.15881ms
    Dec  3 12:18:54.888: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-kj4f2" satisfied condition "running"
    Dec  3 12:18:54.888: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv" in namespace "emptydir-wrapper-5647" to be "running"
    Dec  3 12:18:54.893: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv": Phase="Running", Reason="", readiness=true. Elapsed: 4.823262ms
    Dec  3 12:18:54.893: INFO: Pod "wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293-r9pjv" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 in namespace emptydir-wrapper-5647, will wait for the garbage collector to delete the pods 12/03/22 12:18:54.893
    Dec  3 12:18:54.956: INFO: Deleting ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 took: 8.422492ms
    Dec  3 12:18:55.057: INFO: Terminating ReplicationController wrapped-volume-race-541e2f16-98c3-450a-948a-a0c37352c293 pods took: 100.828118ms
    STEP: Cleaning up the configMaps 12/03/22 12:18:58.258
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:18:58.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5647" for this suite. 12/03/22 12:18:58.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:18:58.67
Dec  3 12:18:58.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:18:58.671
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:18:58.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:18:58.697
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Dec  3 12:18:58.699: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 12:18:58.718: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 12:18:58.718
Dec  3 12:18:58.718: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-fc6vt" in namespace "deployment-3990" to be "running"
Dec  3 12:18:58.721: INFO: Pod "test-rolling-update-controller-fc6vt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.138036ms
Dec  3 12:19:00.729: INFO: Pod "test-rolling-update-controller-fc6vt": Phase="Running", Reason="", readiness=true. Elapsed: 2.011667152s
Dec  3 12:19:00.730: INFO: Pod "test-rolling-update-controller-fc6vt" satisfied condition "running"
Dec  3 12:19:00.730: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 12:19:00.736: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 12:19:00.744: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  3 12:19:02.754: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 12:19:02.757: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:19:02.772: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3990  2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 9484 1 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b3c8f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:19:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-03 12:19:02 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 12:19:02.778: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3990  612642c5-9eb7-4617-998c-113860bc852c 9474 1 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 0xc002de9b37 0xc002de9b38}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2f4cd075-6e51-4d82-a1ed-17ebe3d376bf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002de9be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:19:02.778: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 12:19:02.778: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3990  280aae64-dda6-404e-a716-fe757abbb757 9483 2 2022-12-03 12:18:58 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 0xc002de9a0f 0xc002de9a20}] [] [{e2e.test Update apps/v1 2022-12-03 12:18:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2f4cd075-6e51-4d82-a1ed-17ebe3d376bf\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002de9ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:19:02.783: INFO: Pod "test-rolling-update-deployment-78f575d8ff-2wzrx" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-2wzrx test-rolling-update-deployment-78f575d8ff- deployment-3990  289b98fb-b56b-4478-964f-9b10785e71e5 9473 0 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 612642c5-9eb7-4617-998c-113860bc852c 0xc003b3daf7 0xc003b3daf8}] [] [{kube-controller-manager Update v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"612642c5-9eb7-4617-998c-113860bc852c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.126\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-spq6q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-spq6q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.126,StartTime:2022-12-03 12:19:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:19:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://5deba00fefb3de080448ed78a8e31f1d6e53ef5e9a7f489120c86d0e2a251ec1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.126,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:19:02.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3990" for this suite. 12/03/22 12:19:02.788
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":70,"skipped":1394,"failed":0}
------------------------------
â€¢ [4.125 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:18:58.67
    Dec  3 12:18:58.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:18:58.671
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:18:58.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:18:58.697
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Dec  3 12:18:58.699: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Dec  3 12:18:58.718: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 12:18:58.718
    Dec  3 12:18:58.718: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-fc6vt" in namespace "deployment-3990" to be "running"
    Dec  3 12:18:58.721: INFO: Pod "test-rolling-update-controller-fc6vt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.138036ms
    Dec  3 12:19:00.729: INFO: Pod "test-rolling-update-controller-fc6vt": Phase="Running", Reason="", readiness=true. Elapsed: 2.011667152s
    Dec  3 12:19:00.730: INFO: Pod "test-rolling-update-controller-fc6vt" satisfied condition "running"
    Dec  3 12:19:00.730: INFO: Creating deployment "test-rolling-update-deployment"
    Dec  3 12:19:00.736: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Dec  3 12:19:00.744: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Dec  3 12:19:02.754: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Dec  3 12:19:02.757: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:19:02.772: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3990  2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 9484 1 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b3c8f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-03 12:19:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-03 12:19:02 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec  3 12:19:02.778: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3990  612642c5-9eb7-4617-998c-113860bc852c 9474 1 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 0xc002de9b37 0xc002de9b38}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2f4cd075-6e51-4d82-a1ed-17ebe3d376bf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002de9be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:19:02.778: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Dec  3 12:19:02.778: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3990  280aae64-dda6-404e-a716-fe757abbb757 9483 2 2022-12-03 12:18:58 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2f4cd075-6e51-4d82-a1ed-17ebe3d376bf 0xc002de9a0f 0xc002de9a20}] [] [{e2e.test Update apps/v1 2022-12-03 12:18:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2f4cd075-6e51-4d82-a1ed-17ebe3d376bf\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:19:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002de9ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:19:02.783: INFO: Pod "test-rolling-update-deployment-78f575d8ff-2wzrx" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-2wzrx test-rolling-update-deployment-78f575d8ff- deployment-3990  289b98fb-b56b-4478-964f-9b10785e71e5 9473 0 2022-12-03 12:19:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 612642c5-9eb7-4617-998c-113860bc852c 0xc003b3daf7 0xc003b3daf8}] [] [{kube-controller-manager Update v1 2022-12-03 12:19:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"612642c5-9eb7-4617-998c-113860bc852c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:19:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.126\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-spq6q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-spq6q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:19:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.126,StartTime:2022-12-03 12:19:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:19:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://5deba00fefb3de080448ed78a8e31f1d6e53ef5e9a7f489120c86d0e2a251ec1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.126,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:19:02.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3990" for this suite. 12/03/22 12:19:02.788
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:19:02.797
Dec  3 12:19:02.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename endpointslice 12/03/22 12:19:02.798
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:02.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:02.822
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec  3 12:19:06.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8061" for this suite. 12/03/22 12:19:06.901
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":71,"skipped":1432,"failed":0}
------------------------------
â€¢ [4.112 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:19:02.797
    Dec  3 12:19:02.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename endpointslice 12/03/22 12:19:02.798
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:02.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:02.822
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec  3 12:19:06.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8061" for this suite. 12/03/22 12:19:06.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:19:06.91
Dec  3 12:19:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-pred 12/03/22 12:19:06.911
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:06.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:06.932
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec  3 12:19:06.936: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 12:19:06.944: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 12:19:06.947: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
Dec  3 12:19:06.953: INFO: test-rolling-update-deployment-78f575d8ff-2wzrx from deployment-3990 started at 2022-12-03 12:19:00 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.953: INFO: 	Container agnhost ready: true, restart count 0
Dec  3 12:19:06.953: INFO: nginx-ingress-controller-kubernetes-worker-cxx89 from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:07 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.953: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Dec  3 12:19:06.953: INFO: calico-kube-controllers-77cf5c5988-cx58t from kube-system started at 2022-12-03 11:50:46 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.953: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 12:19:06.953: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:19:06.953: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:19:06.953: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:19:06.953: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
Dec  3 12:19:06.959: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  3 12:19:06.959: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:19:06.959: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container coredns ready: true, restart count 0
Dec  3 12:19:06.959: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec  3 12:19:06.959: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 12:19:06.959: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  3 12:19:06.959: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec  3 12:19:06.959: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 12:19:06.959: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:19:06.959: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:19:06.959: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:19:06.959: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
Dec  3 12:19:06.964: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.965: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:19:06.965: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
Dec  3 12:19:06.965: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 12:19:06.965: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:19:06.965: INFO: 	Container e2e ready: true, restart count 0
Dec  3 12:19:06.965: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:19:06.965: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:19:06.965: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:19:06.965: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node ip-172-31-38-234 12/03/22 12:19:06.981
STEP: verifying the node has the label node ip-172-31-4-162 12/03/22 12:19:06.997
STEP: verifying the node has the label node ip-172-31-76-203 12/03/22 12:19:07.01
Dec  3 12:19:07.023: INFO: Pod test-rolling-update-deployment-78f575d8ff-2wzrx requesting resource cpu=0m on Node ip-172-31-38-234
Dec  3 12:19:07.023: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-f44gm requesting resource cpu=10m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-29vwl requesting resource cpu=0m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-c786f requesting resource cpu=0m on Node ip-172-31-76-203
Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-cxx89 requesting resource cpu=0m on Node ip-172-31-38-234
Dec  3 12:19:07.023: INFO: Pod calico-kube-controllers-77cf5c5988-cx58t requesting resource cpu=0m on Node ip-172-31-38-234
Dec  3 12:19:07.023: INFO: Pod coredns-6bcf44f4cc-nlwz2 requesting resource cpu=100m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod kube-state-metrics-74f5d549cc-njnx9 requesting resource cpu=0m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-scdrh requesting resource cpu=5m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod dashboard-metrics-scraper-85d45476c6-n9g62 requesting resource cpu=0m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod kubernetes-dashboard-7fb574cb-4xr9k requesting resource cpu=0m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-76-203
Dec  3 12:19:07.023: INFO: Pod sonobuoy-e2e-job-642e753251e54e6e requesting resource cpu=0m on Node ip-172-31-76-203
Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn requesting resource cpu=0m on Node ip-172-31-76-203
Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n requesting resource cpu=0m on Node ip-172-31-4-162
Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q requesting resource cpu=0m on Node ip-172-31-38-234
STEP: Starting Pods to consume most of the cluster CPU. 12/03/22 12:19:07.023
Dec  3 12:19:07.024: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-38-234
Dec  3 12:19:07.035: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-4-162
Dec  3 12:19:07.044: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-76-203
Dec  3 12:19:07.050: INFO: Waiting up to 5m0s for pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc" in namespace "sched-pred-3168" to be "running"
Dec  3 12:19:07.054: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.12456ms
Dec  3 12:19:09.061: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc": Phase="Running", Reason="", readiness=true. Elapsed: 2.01011917s
Dec  3 12:19:09.061: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc" satisfied condition "running"
Dec  3 12:19:09.061: INFO: Waiting up to 5m0s for pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10" in namespace "sched-pred-3168" to be "running"
Dec  3 12:19:09.066: INFO: Pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10": Phase="Running", Reason="", readiness=true. Elapsed: 5.275814ms
Dec  3 12:19:09.066: INFO: Pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10" satisfied condition "running"
Dec  3 12:19:09.066: INFO: Waiting up to 5m0s for pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c" in namespace "sched-pred-3168" to be "running"
Dec  3 12:19:09.070: INFO: Pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c": Phase="Running", Reason="", readiness=true. Elapsed: 3.673412ms
Dec  3 12:19:09.070: INFO: Pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 12/03/22 12:19:09.07
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4b8f29943], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10 to ip-172-31-4-162] 12/03/22 12:19:09.075
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4e8d14168], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.075
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4ec9cb797], Reason = [Created], Message = [Created container filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10] 12/03/22 12:19:09.075
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4f5889c1e], Reason = [Started], Message = [Started container filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10] 12/03/22 12:19:09.075
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4b9c8c6a0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c to ip-172-31-76-203] 12/03/22 12:19:09.076
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4e638bb64], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.076
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4e977f2a2], Reason = [Created], Message = [Created container filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c] 12/03/22 12:19:09.076
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4eeff2c87], Reason = [Started], Message = [Started container filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c] 12/03/22 12:19:09.077
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4b7a5df7a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc to ip-172-31-38-234] 12/03/22 12:19:09.077
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4f1ad74a2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.077
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4f4e05793], Reason = [Created], Message = [Created container filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc] 12/03/22 12:19:09.078
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4fbe6fe96], Reason = [Started], Message = [Started container filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc] 12/03/22 12:19:09.078
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.172d47c53137a8aa], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 12/03/22 12:19:09.091
STEP: removing the label node off the node ip-172-31-38-234 12/03/22 12:19:10.09
STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.105
STEP: removing the label node off the node ip-172-31-4-162 12/03/22 12:19:10.109
STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.122
STEP: removing the label node off the node ip-172-31-76-203 12/03/22 12:19:10.126
STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.141
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:19:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3168" for this suite. 12/03/22 12:19:10.151
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":72,"skipped":1441,"failed":0}
------------------------------
â€¢ [3.252 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:19:06.91
    Dec  3 12:19:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-pred 12/03/22 12:19:06.911
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:06.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:06.932
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec  3 12:19:06.936: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec  3 12:19:06.944: INFO: Waiting for terminating namespaces to be deleted...
    Dec  3 12:19:06.947: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
    Dec  3 12:19:06.953: INFO: test-rolling-update-deployment-78f575d8ff-2wzrx from deployment-3990 started at 2022-12-03 12:19:00 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.953: INFO: 	Container agnhost ready: true, restart count 0
    Dec  3 12:19:06.953: INFO: nginx-ingress-controller-kubernetes-worker-cxx89 from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:07 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.953: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Dec  3 12:19:06.953: INFO: calico-kube-controllers-77cf5c5988-cx58t from kube-system started at 2022-12-03 11:50:46 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.953: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Dec  3 12:19:06.953: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:19:06.953: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:19:06.953: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:19:06.953: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
    Dec  3 12:19:06.959: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container coredns ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container metrics-server ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:19:06.959: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:19:06.959: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
    Dec  3 12:19:06.964: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.965: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:19:06.965: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
    Dec  3 12:19:06.965: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Dec  3 12:19:06.965: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:19:06.965: INFO: 	Container e2e ready: true, restart count 0
    Dec  3 12:19:06.965: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:19:06.965: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:19:06.965: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:19:06.965: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node ip-172-31-38-234 12/03/22 12:19:06.981
    STEP: verifying the node has the label node ip-172-31-4-162 12/03/22 12:19:06.997
    STEP: verifying the node has the label node ip-172-31-76-203 12/03/22 12:19:07.01
    Dec  3 12:19:07.023: INFO: Pod test-rolling-update-deployment-78f575d8ff-2wzrx requesting resource cpu=0m on Node ip-172-31-38-234
    Dec  3 12:19:07.023: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-f44gm requesting resource cpu=10m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-29vwl requesting resource cpu=0m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-c786f requesting resource cpu=0m on Node ip-172-31-76-203
    Dec  3 12:19:07.023: INFO: Pod nginx-ingress-controller-kubernetes-worker-cxx89 requesting resource cpu=0m on Node ip-172-31-38-234
    Dec  3 12:19:07.023: INFO: Pod calico-kube-controllers-77cf5c5988-cx58t requesting resource cpu=0m on Node ip-172-31-38-234
    Dec  3 12:19:07.023: INFO: Pod coredns-6bcf44f4cc-nlwz2 requesting resource cpu=100m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod kube-state-metrics-74f5d549cc-njnx9 requesting resource cpu=0m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-scdrh requesting resource cpu=5m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod dashboard-metrics-scraper-85d45476c6-n9g62 requesting resource cpu=0m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod kubernetes-dashboard-7fb574cb-4xr9k requesting resource cpu=0m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-76-203
    Dec  3 12:19:07.023: INFO: Pod sonobuoy-e2e-job-642e753251e54e6e requesting resource cpu=0m on Node ip-172-31-76-203
    Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn requesting resource cpu=0m on Node ip-172-31-76-203
    Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n requesting resource cpu=0m on Node ip-172-31-4-162
    Dec  3 12:19:07.023: INFO: Pod sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q requesting resource cpu=0m on Node ip-172-31-38-234
    STEP: Starting Pods to consume most of the cluster CPU. 12/03/22 12:19:07.023
    Dec  3 12:19:07.024: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-38-234
    Dec  3 12:19:07.035: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-4-162
    Dec  3 12:19:07.044: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-76-203
    Dec  3 12:19:07.050: INFO: Waiting up to 5m0s for pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc" in namespace "sched-pred-3168" to be "running"
    Dec  3 12:19:07.054: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.12456ms
    Dec  3 12:19:09.061: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc": Phase="Running", Reason="", readiness=true. Elapsed: 2.01011917s
    Dec  3 12:19:09.061: INFO: Pod "filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc" satisfied condition "running"
    Dec  3 12:19:09.061: INFO: Waiting up to 5m0s for pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10" in namespace "sched-pred-3168" to be "running"
    Dec  3 12:19:09.066: INFO: Pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10": Phase="Running", Reason="", readiness=true. Elapsed: 5.275814ms
    Dec  3 12:19:09.066: INFO: Pod "filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10" satisfied condition "running"
    Dec  3 12:19:09.066: INFO: Waiting up to 5m0s for pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c" in namespace "sched-pred-3168" to be "running"
    Dec  3 12:19:09.070: INFO: Pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c": Phase="Running", Reason="", readiness=true. Elapsed: 3.673412ms
    Dec  3 12:19:09.070: INFO: Pod "filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 12/03/22 12:19:09.07
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4b8f29943], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10 to ip-172-31-4-162] 12/03/22 12:19:09.075
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4e8d14168], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.075
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4ec9cb797], Reason = [Created], Message = [Created container filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10] 12/03/22 12:19:09.075
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10.172d47c4f5889c1e], Reason = [Started], Message = [Started container filler-pod-00b41bef-eb8c-4454-9036-39f6b6058e10] 12/03/22 12:19:09.075
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4b9c8c6a0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c to ip-172-31-76-203] 12/03/22 12:19:09.076
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4e638bb64], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.076
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4e977f2a2], Reason = [Created], Message = [Created container filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c] 12/03/22 12:19:09.076
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c.172d47c4eeff2c87], Reason = [Started], Message = [Started container filler-pod-892234f2-3d5a-4f05-ae0a-7150c71d8d9c] 12/03/22 12:19:09.077
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4b7a5df7a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3168/filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc to ip-172-31-38-234] 12/03/22 12:19:09.077
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4f1ad74a2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/03/22 12:19:09.077
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4f4e05793], Reason = [Created], Message = [Created container filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc] 12/03/22 12:19:09.078
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc.172d47c4fbe6fe96], Reason = [Started], Message = [Started container filler-pod-918eaab7-b81a-4e86-b6ab-0537cb063dcc] 12/03/22 12:19:09.078
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.172d47c53137a8aa], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 12/03/22 12:19:09.091
    STEP: removing the label node off the node ip-172-31-38-234 12/03/22 12:19:10.09
    STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.105
    STEP: removing the label node off the node ip-172-31-4-162 12/03/22 12:19:10.109
    STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.122
    STEP: removing the label node off the node ip-172-31-76-203 12/03/22 12:19:10.126
    STEP: verifying the node doesn't have the label node 12/03/22 12:19:10.141
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:19:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3168" for this suite. 12/03/22 12:19:10.151
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:19:10.162
Dec  3 12:19:10.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename cronjob 12/03/22 12:19:10.163
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:10.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:10.191
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 12/03/22 12:19:10.194
STEP: Ensuring more than one job is running at a time 12/03/22 12:19:10.208
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/03/22 12:21:00.213
STEP: Removing cronjob 12/03/22 12:21:00.217
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec  3 12:21:00.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8999" for this suite. 12/03/22 12:21:00.23
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":73,"skipped":1445,"failed":0}
------------------------------
â€¢ [SLOW TEST] [110.081 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:19:10.162
    Dec  3 12:19:10.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename cronjob 12/03/22 12:19:10.163
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:19:10.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:19:10.191
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 12/03/22 12:19:10.194
    STEP: Ensuring more than one job is running at a time 12/03/22 12:19:10.208
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/03/22 12:21:00.213
    STEP: Removing cronjob 12/03/22 12:21:00.217
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec  3 12:21:00.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8999" for this suite. 12/03/22 12:21:00.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:00.247
Dec  3 12:21:00.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:21:00.251
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:00.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:00.453
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-b1e346c1-dadf-4079-b028-ae3eca70597a 12/03/22 12:21:00.459
STEP: Creating secret with name s-test-opt-upd-0846eb8f-36f1-4fb5-8cba-7bac67bca3b2 12/03/22 12:21:00.466
STEP: Creating the pod 12/03/22 12:21:00.475
Dec  3 12:21:00.490: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c" in namespace "projected-8625" to be "running and ready"
Dec  3 12:21:00.494: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.713649ms
Dec  3 12:21:00.494: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:21:02.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00946031s
Dec  3 12:21:02.499: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:21:04.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.008756937s
Dec  3 12:21:04.499: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Running (Ready = true)
Dec  3 12:21:04.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-b1e346c1-dadf-4079-b028-ae3eca70597a 12/03/22 12:21:04.539
STEP: Updating secret s-test-opt-upd-0846eb8f-36f1-4fb5-8cba-7bac67bca3b2 12/03/22 12:21:04.545
STEP: Creating secret with name s-test-opt-create-244d981e-36d8-45e9-a4a8-8e6b9a157873 12/03/22 12:21:04.55
STEP: waiting to observe update in volume 12/03/22 12:21:04.555
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 12:21:06.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8625" for this suite. 12/03/22 12:21:06.59
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":74,"skipped":1490,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.353 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:00.247
    Dec  3 12:21:00.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:21:00.251
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:00.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:00.453
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-b1e346c1-dadf-4079-b028-ae3eca70597a 12/03/22 12:21:00.459
    STEP: Creating secret with name s-test-opt-upd-0846eb8f-36f1-4fb5-8cba-7bac67bca3b2 12/03/22 12:21:00.466
    STEP: Creating the pod 12/03/22 12:21:00.475
    Dec  3 12:21:00.490: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c" in namespace "projected-8625" to be "running and ready"
    Dec  3 12:21:00.494: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.713649ms
    Dec  3 12:21:00.494: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:21:02.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00946031s
    Dec  3 12:21:02.499: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:21:04.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.008756937s
    Dec  3 12:21:04.499: INFO: The phase of Pod pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c is Running (Ready = true)
    Dec  3 12:21:04.499: INFO: Pod "pod-projected-secrets-e66b9ffb-d19d-4557-ad08-272ee518ca4c" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-b1e346c1-dadf-4079-b028-ae3eca70597a 12/03/22 12:21:04.539
    STEP: Updating secret s-test-opt-upd-0846eb8f-36f1-4fb5-8cba-7bac67bca3b2 12/03/22 12:21:04.545
    STEP: Creating secret with name s-test-opt-create-244d981e-36d8-45e9-a4a8-8e6b9a157873 12/03/22 12:21:04.55
    STEP: waiting to observe update in volume 12/03/22 12:21:04.555
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 12:21:06.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8625" for this suite. 12/03/22 12:21:06.59
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:06.601
Dec  3 12:21:06.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename containers 12/03/22 12:21:06.602
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:06.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:06.623
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 12/03/22 12:21:06.627
Dec  3 12:21:06.641: INFO: Waiting up to 5m0s for pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906" in namespace "containers-793" to be "Succeeded or Failed"
Dec  3 12:21:06.647: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Pending", Reason="", readiness=false. Elapsed: 6.205563ms
Dec  3 12:21:08.652: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011656202s
Dec  3 12:21:10.652: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011659299s
STEP: Saw pod success 12/03/22 12:21:10.652
Dec  3 12:21:10.653: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906" satisfied condition "Succeeded or Failed"
Dec  3 12:21:10.656: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 12:21:10.678
Dec  3 12:21:10.692: INFO: Waiting for pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 to disappear
Dec  3 12:21:10.695: INFO: Pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec  3 12:21:10.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-793" for this suite. 12/03/22 12:21:10.7
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":75,"skipped":1491,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:06.601
    Dec  3 12:21:06.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename containers 12/03/22 12:21:06.602
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:06.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:06.623
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 12/03/22 12:21:06.627
    Dec  3 12:21:06.641: INFO: Waiting up to 5m0s for pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906" in namespace "containers-793" to be "Succeeded or Failed"
    Dec  3 12:21:06.647: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Pending", Reason="", readiness=false. Elapsed: 6.205563ms
    Dec  3 12:21:08.652: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011656202s
    Dec  3 12:21:10.652: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011659299s
    STEP: Saw pod success 12/03/22 12:21:10.652
    Dec  3 12:21:10.653: INFO: Pod "client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906" satisfied condition "Succeeded or Failed"
    Dec  3 12:21:10.656: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 12:21:10.678
    Dec  3 12:21:10.692: INFO: Waiting for pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 to disappear
    Dec  3 12:21:10.695: INFO: Pod client-containers-8feb9dcd-02a4-41a4-829e-00aec003e906 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec  3 12:21:10.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-793" for this suite. 12/03/22 12:21:10.7
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:10.709
Dec  3 12:21:10.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:21:10.71
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:10.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:10.75
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-da2b8634-575c-4f8d-bb19-7a9f3d7c24e6 12/03/22 12:21:10.756
STEP: Creating a pod to test consume secrets 12/03/22 12:21:10.762
Dec  3 12:21:10.776: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb" in namespace "projected-8502" to be "Succeeded or Failed"
Dec  3 12:21:10.779: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357661ms
Dec  3 12:21:12.783: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007367895s
Dec  3 12:21:14.784: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008329827s
STEP: Saw pod success 12/03/22 12:21:14.784
Dec  3 12:21:14.784: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb" satisfied condition "Succeeded or Failed"
Dec  3 12:21:14.790: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 12:21:14.797
Dec  3 12:21:14.814: INFO: Waiting for pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb to disappear
Dec  3 12:21:14.819: INFO: Pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 12:21:14.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8502" for this suite. 12/03/22 12:21:14.827
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":76,"skipped":1511,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:10.709
    Dec  3 12:21:10.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:21:10.71
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:10.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:10.75
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-da2b8634-575c-4f8d-bb19-7a9f3d7c24e6 12/03/22 12:21:10.756
    STEP: Creating a pod to test consume secrets 12/03/22 12:21:10.762
    Dec  3 12:21:10.776: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb" in namespace "projected-8502" to be "Succeeded or Failed"
    Dec  3 12:21:10.779: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357661ms
    Dec  3 12:21:12.783: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007367895s
    Dec  3 12:21:14.784: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008329827s
    STEP: Saw pod success 12/03/22 12:21:14.784
    Dec  3 12:21:14.784: INFO: Pod "pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb" satisfied condition "Succeeded or Failed"
    Dec  3 12:21:14.790: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 12:21:14.797
    Dec  3 12:21:14.814: INFO: Waiting for pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb to disappear
    Dec  3 12:21:14.819: INFO: Pod pod-projected-secrets-dedd0766-d020-412e-a798-72a467b26eeb no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 12:21:14.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8502" for this suite. 12/03/22 12:21:14.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:14.836
Dec  3 12:21:14.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:21:14.836
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:14.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:14.869
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 12/03/22 12:21:14.873
Dec  3 12:21:14.884: INFO: Waiting up to 5m0s for pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3" in namespace "emptydir-9121" to be "Succeeded or Failed"
Dec  3 12:21:14.887: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445341ms
Dec  3 12:21:16.891: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00717568s
Dec  3 12:21:18.891: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007261972s
STEP: Saw pod success 12/03/22 12:21:18.891
Dec  3 12:21:18.892: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3" satisfied condition "Succeeded or Failed"
Dec  3 12:21:18.896: INFO: Trying to get logs from node ip-172-31-76-203 pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 container test-container: <nil>
STEP: delete the pod 12/03/22 12:21:18.904
Dec  3 12:21:18.917: INFO: Waiting for pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 to disappear
Dec  3 12:21:18.921: INFO: Pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:21:18.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9121" for this suite. 12/03/22 12:21:18.925
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":77,"skipped":1521,"failed":0}
------------------------------
â€¢ [4.099 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:14.836
    Dec  3 12:21:14.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:21:14.836
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:14.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:14.869
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 12/03/22 12:21:14.873
    Dec  3 12:21:14.884: INFO: Waiting up to 5m0s for pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3" in namespace "emptydir-9121" to be "Succeeded or Failed"
    Dec  3 12:21:14.887: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445341ms
    Dec  3 12:21:16.891: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00717568s
    Dec  3 12:21:18.891: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007261972s
    STEP: Saw pod success 12/03/22 12:21:18.891
    Dec  3 12:21:18.892: INFO: Pod "pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3" satisfied condition "Succeeded or Failed"
    Dec  3 12:21:18.896: INFO: Trying to get logs from node ip-172-31-76-203 pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 container test-container: <nil>
    STEP: delete the pod 12/03/22 12:21:18.904
    Dec  3 12:21:18.917: INFO: Waiting for pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 to disappear
    Dec  3 12:21:18.921: INFO: Pod pod-a095a89b-88f4-49d9-a9dd-4fdbaf9116c3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:21:18.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9121" for this suite. 12/03/22 12:21:18.925
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:18.938
Dec  3 12:21:18.938: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename init-container 12/03/22 12:21:18.939
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:18.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:18.972
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 12/03/22 12:21:18.977
Dec  3 12:21:18.977: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 12:21:22.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9982" for this suite. 12/03/22 12:21:22.237
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":78,"skipped":1556,"failed":0}
------------------------------
â€¢ [3.309 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:18.938
    Dec  3 12:21:18.938: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename init-container 12/03/22 12:21:18.939
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:18.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:18.972
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 12/03/22 12:21:18.977
    Dec  3 12:21:18.977: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 12:21:22.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9982" for this suite. 12/03/22 12:21:22.237
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:22.249
Dec  3 12:21:22.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 12:21:22.25
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:22.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:22.274
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/03/22 12:21:22.277
Dec  3 12:21:22.289: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 12:21:27.297: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 12:21:27.297
STEP: getting scale subresource 12/03/22 12:21:27.297
STEP: updating a scale subresource 12/03/22 12:21:27.3
STEP: verifying the replicaset Spec.Replicas was modified 12/03/22 12:21:27.306
STEP: Patch a scale subresource 12/03/22 12:21:27.31
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 12:21:27.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-780" for this suite. 12/03/22 12:21:27.325
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":79,"skipped":1587,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.082 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:22.249
    Dec  3 12:21:22.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 12:21:22.25
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:22.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:22.274
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/03/22 12:21:22.277
    Dec  3 12:21:22.289: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec  3 12:21:27.297: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 12:21:27.297
    STEP: getting scale subresource 12/03/22 12:21:27.297
    STEP: updating a scale subresource 12/03/22 12:21:27.3
    STEP: verifying the replicaset Spec.Replicas was modified 12/03/22 12:21:27.306
    STEP: Patch a scale subresource 12/03/22 12:21:27.31
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 12:21:27.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-780" for this suite. 12/03/22 12:21:27.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:27.333
Dec  3 12:21:27.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:21:27.334
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:27.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:27.399
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-7506 12/03/22 12:21:27.401
STEP: creating a selector 12/03/22 12:21:27.401
STEP: Creating the service pods in kubernetes 12/03/22 12:21:27.402
Dec  3 12:21:27.402: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec  3 12:21:27.434: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7506" to be "running and ready"
Dec  3 12:21:27.444: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.848878ms
Dec  3 12:21:27.444: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:21:29.453: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018253672s
Dec  3 12:21:29.453: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:31.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.015425189s
Dec  3 12:21:31.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:33.452: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017556981s
Dec  3 12:21:33.452: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:35.452: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017826484s
Dec  3 12:21:35.452: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:37.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.015829903s
Dec  3 12:21:37.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:39.451: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016364484s
Dec  3 12:21:39.451: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:41.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.015569988s
Dec  3 12:21:41.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:43.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02103039s
Dec  3 12:21:43.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:45.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.015517674s
Dec  3 12:21:45.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:47.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.015951368s
Dec  3 12:21:47.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:21:49.451: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.016417259s
Dec  3 12:21:49.451: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec  3 12:21:49.451: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec  3 12:21:49.455: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7506" to be "running and ready"
Dec  3 12:21:49.459: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.00955ms
Dec  3 12:21:49.459: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec  3 12:21:49.459: INFO: Pod "netserver-1" satisfied condition "running and ready"
Dec  3 12:21:49.464: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7506" to be "running and ready"
Dec  3 12:21:49.469: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.670793ms
Dec  3 12:21:49.469: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Dec  3 12:21:49.469: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 12/03/22 12:21:49.472
Dec  3 12:21:49.488: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7506" to be "running"
Dec  3 12:21:49.491: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031916ms
Dec  3 12:21:51.497: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.00918347s
Dec  3 12:21:51.497: INFO: Pod "test-container-pod" satisfied condition "running"
Dec  3 12:21:51.501: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7506" to be "running"
Dec  3 12:21:51.504: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.018928ms
Dec  3 12:21:51.504: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec  3 12:21:51.508: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Dec  3 12:21:51.508: INFO: Going to poll 192.168.197.69 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:21:51.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.197.69:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:21:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:21:51.512: INFO: ExecWithOptions: Clientset creation
Dec  3 12:21:51.512: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.197.69%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:21:51.600: INFO: Found all 1 expected endpoints: [netserver-0]
Dec  3 12:21:51.600: INFO: Going to poll 192.168.197.25 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:21:51.605: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.197.25:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:21:51.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:21:51.605: INFO: ExecWithOptions: Clientset creation
Dec  3 12:21:51.605: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.197.25%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:21:51.703: INFO: Found all 1 expected endpoints: [netserver-1]
Dec  3 12:21:51.703: INFO: Going to poll 192.168.71.227 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:21:51.708: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.71.227:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:21:51.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:21:51.708: INFO: ExecWithOptions: Clientset creation
Dec  3 12:21:51.709: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.71.227%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:21:51.790: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec  3 12:21:51.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7506" for this suite. 12/03/22 12:21:51.795
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":80,"skipped":1592,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.470 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:27.333
    Dec  3 12:21:27.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:21:27.334
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:27.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:27.399
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-7506 12/03/22 12:21:27.401
    STEP: creating a selector 12/03/22 12:21:27.401
    STEP: Creating the service pods in kubernetes 12/03/22 12:21:27.402
    Dec  3 12:21:27.402: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec  3 12:21:27.434: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7506" to be "running and ready"
    Dec  3 12:21:27.444: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.848878ms
    Dec  3 12:21:27.444: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:21:29.453: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018253672s
    Dec  3 12:21:29.453: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:31.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.015425189s
    Dec  3 12:21:31.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:33.452: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017556981s
    Dec  3 12:21:33.452: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:35.452: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017826484s
    Dec  3 12:21:35.452: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:37.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.015829903s
    Dec  3 12:21:37.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:39.451: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016364484s
    Dec  3 12:21:39.451: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:41.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.015569988s
    Dec  3 12:21:41.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:43.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02103039s
    Dec  3 12:21:43.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:45.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.015517674s
    Dec  3 12:21:45.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:47.450: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.015951368s
    Dec  3 12:21:47.450: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:21:49.451: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.016417259s
    Dec  3 12:21:49.451: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec  3 12:21:49.451: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec  3 12:21:49.455: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7506" to be "running and ready"
    Dec  3 12:21:49.459: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.00955ms
    Dec  3 12:21:49.459: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec  3 12:21:49.459: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Dec  3 12:21:49.464: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7506" to be "running and ready"
    Dec  3 12:21:49.469: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.670793ms
    Dec  3 12:21:49.469: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Dec  3 12:21:49.469: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 12/03/22 12:21:49.472
    Dec  3 12:21:49.488: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7506" to be "running"
    Dec  3 12:21:49.491: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031916ms
    Dec  3 12:21:51.497: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.00918347s
    Dec  3 12:21:51.497: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec  3 12:21:51.501: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7506" to be "running"
    Dec  3 12:21:51.504: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.018928ms
    Dec  3 12:21:51.504: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec  3 12:21:51.508: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Dec  3 12:21:51.508: INFO: Going to poll 192.168.197.69 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:21:51.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.197.69:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:21:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:21:51.512: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:21:51.512: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.197.69%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:21:51.600: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec  3 12:21:51.600: INFO: Going to poll 192.168.197.25 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:21:51.605: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.197.25:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:21:51.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:21:51.605: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:21:51.605: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.197.25%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:21:51.703: INFO: Found all 1 expected endpoints: [netserver-1]
    Dec  3 12:21:51.703: INFO: Going to poll 192.168.71.227 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:21:51.708: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.71.227:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7506 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:21:51.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:21:51.708: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:21:51.709: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7506/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.71.227%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:21:51.790: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec  3 12:21:51.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7506" for this suite. 12/03/22 12:21:51.795
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:21:51.803
Dec  3 12:21:51.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename subpath 12/03/22 12:21:51.804
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:51.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:51.842
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/03/22 12:21:51.845
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-9h9s 12/03/22 12:21:51.855
STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:21:51.855
Dec  3 12:21:51.865: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9h9s" in namespace "subpath-7891" to be "Succeeded or Failed"
Dec  3 12:21:51.871: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.359879ms
Dec  3 12:21:53.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010536914s
Dec  3 12:21:55.877: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 4.011690838s
Dec  3 12:21:57.877: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 6.012430384s
Dec  3 12:21:59.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 8.011347569s
Dec  3 12:22:01.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 10.010335394s
Dec  3 12:22:03.881: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 12.015686079s
Dec  3 12:22:05.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 14.009741265s
Dec  3 12:22:07.879: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 16.014113229s
Dec  3 12:22:09.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 18.010502187s
Dec  3 12:22:11.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 20.010628086s
Dec  3 12:22:13.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 22.010973884s
Dec  3 12:22:15.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=false. Elapsed: 24.010629409s
Dec  3 12:22:17.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010478442s
STEP: Saw pod success 12/03/22 12:22:17.876
Dec  3 12:22:17.876: INFO: Pod "pod-subpath-test-configmap-9h9s" satisfied condition "Succeeded or Failed"
Dec  3 12:22:17.878: INFO: Trying to get logs from node ip-172-31-76-203 pod pod-subpath-test-configmap-9h9s container test-container-subpath-configmap-9h9s: <nil>
STEP: delete the pod 12/03/22 12:22:17.885
Dec  3 12:22:17.901: INFO: Waiting for pod pod-subpath-test-configmap-9h9s to disappear
Dec  3 12:22:17.905: INFO: Pod pod-subpath-test-configmap-9h9s no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9h9s 12/03/22 12:22:17.905
Dec  3 12:22:17.905: INFO: Deleting pod "pod-subpath-test-configmap-9h9s" in namespace "subpath-7891"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec  3 12:22:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7891" for this suite. 12/03/22 12:22:17.913
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":81,"skipped":1594,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.117 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:21:51.803
    Dec  3 12:21:51.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename subpath 12/03/22 12:21:51.804
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:21:51.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:21:51.842
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/03/22 12:21:51.845
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-9h9s 12/03/22 12:21:51.855
    STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:21:51.855
    Dec  3 12:21:51.865: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9h9s" in namespace "subpath-7891" to be "Succeeded or Failed"
    Dec  3 12:21:51.871: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.359879ms
    Dec  3 12:21:53.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010536914s
    Dec  3 12:21:55.877: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 4.011690838s
    Dec  3 12:21:57.877: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 6.012430384s
    Dec  3 12:21:59.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 8.011347569s
    Dec  3 12:22:01.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 10.010335394s
    Dec  3 12:22:03.881: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 12.015686079s
    Dec  3 12:22:05.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 14.009741265s
    Dec  3 12:22:07.879: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 16.014113229s
    Dec  3 12:22:09.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 18.010502187s
    Dec  3 12:22:11.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 20.010628086s
    Dec  3 12:22:13.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=true. Elapsed: 22.010973884s
    Dec  3 12:22:15.876: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Running", Reason="", readiness=false. Elapsed: 24.010629409s
    Dec  3 12:22:17.875: INFO: Pod "pod-subpath-test-configmap-9h9s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010478442s
    STEP: Saw pod success 12/03/22 12:22:17.876
    Dec  3 12:22:17.876: INFO: Pod "pod-subpath-test-configmap-9h9s" satisfied condition "Succeeded or Failed"
    Dec  3 12:22:17.878: INFO: Trying to get logs from node ip-172-31-76-203 pod pod-subpath-test-configmap-9h9s container test-container-subpath-configmap-9h9s: <nil>
    STEP: delete the pod 12/03/22 12:22:17.885
    Dec  3 12:22:17.901: INFO: Waiting for pod pod-subpath-test-configmap-9h9s to disappear
    Dec  3 12:22:17.905: INFO: Pod pod-subpath-test-configmap-9h9s no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-9h9s 12/03/22 12:22:17.905
    Dec  3 12:22:17.905: INFO: Deleting pod "pod-subpath-test-configmap-9h9s" in namespace "subpath-7891"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec  3 12:22:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7891" for this suite. 12/03/22 12:22:17.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:22:17.923
Dec  3 12:22:17.923: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename init-container 12/03/22 12:22:17.924
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:22:17.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:22:17.946
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 12/03/22 12:22:17.948
Dec  3 12:22:17.948: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 12:22:57.478: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c127c235-f5f8-4c88-b7ad-8c5ea21d2c72", GenerateName:"", Namespace:"init-container-8659", SelfLink:"", UID:"947eed18-c43a-4067-bde8-fe2863503e9e", ResourceVersion:"10770", Generation:0, CreationTimestamp:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"948946125"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f5c120), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 3, 12, 22, 57, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f5c150), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-gs8wr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002dd8100), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002adc5b0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-38-234", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0038dc150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002adc640)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002adc660)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002adc668), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002adc66c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000c3c0a0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.38.234", PodIP:"192.168.197.71", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.197.71"}}, StartTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0038dc230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0038dc2a0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://e2ecb8bda759aefdcefc0470a8b6f19c0fe425d0a81da47475bfcb5b59cdafee", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002dd8180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002dd8160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc002adc6e4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 12:22:57.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8659" for this suite. 12/03/22 12:22:57.482
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":82,"skipped":1617,"failed":0}
------------------------------
â€¢ [SLOW TEST] [39.571 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:22:17.923
    Dec  3 12:22:17.923: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename init-container 12/03/22 12:22:17.924
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:22:17.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:22:17.946
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 12/03/22 12:22:17.948
    Dec  3 12:22:17.948: INFO: PodSpec: initContainers in spec.initContainers
    Dec  3 12:22:57.478: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c127c235-f5f8-4c88-b7ad-8c5ea21d2c72", GenerateName:"", Namespace:"init-container-8659", SelfLink:"", UID:"947eed18-c43a-4067-bde8-fe2863503e9e", ResourceVersion:"10770", Generation:0, CreationTimestamp:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"948946125"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f5c120), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 3, 12, 22, 57, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f5c150), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-gs8wr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002dd8100), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-gs8wr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002adc5b0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-38-234", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0038dc150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002adc640)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002adc660)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002adc668), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002adc66c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000c3c0a0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.38.234", PodIP:"192.168.197.71", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.197.71"}}, StartTime:time.Date(2022, time.December, 3, 12, 22, 17, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0038dc230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0038dc2a0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://e2ecb8bda759aefdcefc0470a8b6f19c0fe425d0a81da47475bfcb5b59cdafee", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002dd8180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002dd8160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc002adc6e4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 12:22:57.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8659" for this suite. 12/03/22 12:22:57.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:22:57.497
Dec  3 12:22:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 12:22:57.499
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:22:57.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:22:57.536
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Dec  3 12:22:57.543: INFO: Creating ReplicaSet my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06
Dec  3 12:22:57.555: INFO: Pod name my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Found 0 pods out of 1
Dec  3 12:23:02.563: INFO: Pod name my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Found 1 pods out of 1
Dec  3 12:23:02.563: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06" is running
Dec  3 12:23:02.563: INFO: Waiting up to 5m0s for pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" in namespace "replicaset-2464" to be "running"
Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl": Phase="Running", Reason="", readiness=true. Elapsed: 3.440159ms
Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" satisfied condition "running"
Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:57 +0000 UTC Reason: Message:}])
Dec  3 12:23:02.567: INFO: Trying to dial the pod
Dec  3 12:23:07.581: INFO: Controller my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Got expected result from replica 1 [my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl]: "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 12:23:07.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2464" for this suite. 12/03/22 12:23:07.587
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":83,"skipped":1646,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.097 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:22:57.497
    Dec  3 12:22:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 12:22:57.499
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:22:57.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:22:57.536
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Dec  3 12:22:57.543: INFO: Creating ReplicaSet my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06
    Dec  3 12:22:57.555: INFO: Pod name my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Found 0 pods out of 1
    Dec  3 12:23:02.563: INFO: Pod name my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Found 1 pods out of 1
    Dec  3 12:23:02.563: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06" is running
    Dec  3 12:23:02.563: INFO: Waiting up to 5m0s for pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" in namespace "replicaset-2464" to be "running"
    Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl": Phase="Running", Reason="", readiness=true. Elapsed: 3.440159ms
    Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" satisfied condition "running"
    Dec  3 12:23:02.566: INFO: Pod "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:22:57 +0000 UTC Reason: Message:}])
    Dec  3 12:23:02.567: INFO: Trying to dial the pod
    Dec  3 12:23:07.581: INFO: Controller my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06: Got expected result from replica 1 [my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl]: "my-hostname-basic-974c4d71-32a0-4e51-b50c-3662634caf06-zhszl", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 12:23:07.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2464" for this suite. 12/03/22 12:23:07.587
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:23:07.594
Dec  3 12:23:07.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:23:07.595
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:07.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:07.619
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 12/03/22 12:23:07.621
STEP: getting /apis/node.k8s.io 12/03/22 12:23:07.624
STEP: getting /apis/node.k8s.io/v1 12/03/22 12:23:07.627
STEP: creating 12/03/22 12:23:07.628
STEP: watching 12/03/22 12:23:07.647
Dec  3 12:23:07.648: INFO: starting watch
STEP: getting 12/03/22 12:23:07.656
STEP: listing 12/03/22 12:23:07.66
STEP: patching 12/03/22 12:23:07.665
STEP: updating 12/03/22 12:23:07.671
Dec  3 12:23:07.678: INFO: waiting for watch events with expected annotations
STEP: deleting 12/03/22 12:23:07.679
STEP: deleting a collection 12/03/22 12:23:07.694
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec  3 12:23:07.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4968" for this suite. 12/03/22 12:23:07.727
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":84,"skipped":1646,"failed":0}
------------------------------
â€¢ [0.141 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:23:07.594
    Dec  3 12:23:07.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:23:07.595
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:07.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:07.619
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 12/03/22 12:23:07.621
    STEP: getting /apis/node.k8s.io 12/03/22 12:23:07.624
    STEP: getting /apis/node.k8s.io/v1 12/03/22 12:23:07.627
    STEP: creating 12/03/22 12:23:07.628
    STEP: watching 12/03/22 12:23:07.647
    Dec  3 12:23:07.648: INFO: starting watch
    STEP: getting 12/03/22 12:23:07.656
    STEP: listing 12/03/22 12:23:07.66
    STEP: patching 12/03/22 12:23:07.665
    STEP: updating 12/03/22 12:23:07.671
    Dec  3 12:23:07.678: INFO: waiting for watch events with expected annotations
    STEP: deleting 12/03/22 12:23:07.679
    STEP: deleting a collection 12/03/22 12:23:07.694
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec  3 12:23:07.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4968" for this suite. 12/03/22 12:23:07.727
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:23:07.736
Dec  3 12:23:07.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:23:07.737
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:07.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:07.765
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Dec  3 12:23:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 12:23:10.271
Dec  3 12:23:10.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 create -f -'
Dec  3 12:23:10.938: INFO: stderr: ""
Dec  3 12:23:10.938: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 12:23:10.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 delete e2e-test-crd-publish-openapi-9550-crds test-cr'
Dec  3 12:23:11.016: INFO: stderr: ""
Dec  3 12:23:11.016: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec  3 12:23:11.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 apply -f -'
Dec  3 12:23:11.689: INFO: stderr: ""
Dec  3 12:23:11.689: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 12:23:11.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 delete e2e-test-crd-publish-openapi-9550-crds test-cr'
Dec  3 12:23:11.771: INFO: stderr: ""
Dec  3 12:23:11.771: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/03/22 12:23:11.771
Dec  3 12:23:11.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 explain e2e-test-crd-publish-openapi-9550-crds'
Dec  3 12:23:11.968: INFO: stderr: ""
Dec  3 12:23:11.968: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9550-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:23:14.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3191" for this suite. 12/03/22 12:23:14.623
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":85,"skipped":1650,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.895 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:23:07.736
    Dec  3 12:23:07.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:23:07.737
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:07.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:07.765
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Dec  3 12:23:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 12:23:10.271
    Dec  3 12:23:10.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 create -f -'
    Dec  3 12:23:10.938: INFO: stderr: ""
    Dec  3 12:23:10.938: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec  3 12:23:10.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 delete e2e-test-crd-publish-openapi-9550-crds test-cr'
    Dec  3 12:23:11.016: INFO: stderr: ""
    Dec  3 12:23:11.016: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Dec  3 12:23:11.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 apply -f -'
    Dec  3 12:23:11.689: INFO: stderr: ""
    Dec  3 12:23:11.689: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec  3 12:23:11.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 --namespace=crd-publish-openapi-3191 delete e2e-test-crd-publish-openapi-9550-crds test-cr'
    Dec  3 12:23:11.771: INFO: stderr: ""
    Dec  3 12:23:11.771: INFO: stdout: "e2e-test-crd-publish-openapi-9550-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/03/22 12:23:11.771
    Dec  3 12:23:11.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3191 explain e2e-test-crd-publish-openapi-9550-crds'
    Dec  3 12:23:11.968: INFO: stderr: ""
    Dec  3 12:23:11.968: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9550-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:23:14.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3191" for this suite. 12/03/22 12:23:14.623
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:23:14.631
Dec  3 12:23:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sysctl 12/03/22 12:23:14.632
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:14.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:14.667
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 12/03/22 12:23:14.671
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 12:23:14.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5262" for this suite. 12/03/22 12:23:14.681
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":86,"skipped":1650,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:23:14.631
    Dec  3 12:23:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sysctl 12/03/22 12:23:14.632
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:14.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:14.667
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 12/03/22 12:23:14.671
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 12:23:14.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5262" for this suite. 12/03/22 12:23:14.681
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:23:14.693
Dec  3 12:23:14.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 12:23:14.694
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:14.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:14.735
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/03/22 12:23:14.739
Dec  3 12:23:14.750: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8515  8c7a0000-3182-4964-8e32-9c0e88d00fb4 10914 0 2022-12-03 12:23:14 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-03 12:23:14 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-md9gl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-md9gl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:23:14.750: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8515" to be "running and ready"
Dec  3 12:23:14.754: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 3.966139ms
Dec  3 12:23:14.754: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:23:16.763: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.013429402s
Dec  3 12:23:16.763: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Dec  3 12:23:16.764: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 12/03/22 12:23:16.764
Dec  3 12:23:16.764: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8515 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:23:16.764: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:23:16.764: INFO: ExecWithOptions: Clientset creation
Dec  3 12:23:16.764: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8515/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 12/03/22 12:23:16.868
Dec  3 12:23:16.868: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8515 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:23:16.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:23:16.869: INFO: ExecWithOptions: Clientset creation
Dec  3 12:23:16.869: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8515/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:23:16.976: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 12:23:16.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8515" for this suite. 12/03/22 12:23:17.001
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":87,"skipped":1695,"failed":0}
------------------------------
â€¢ [2.317 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:23:14.693
    Dec  3 12:23:14.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 12:23:14.694
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:14.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:14.735
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/03/22 12:23:14.739
    Dec  3 12:23:14.750: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8515  8c7a0000-3182-4964-8e32-9c0e88d00fb4 10914 0 2022-12-03 12:23:14 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-03 12:23:14 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-md9gl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-md9gl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:23:14.750: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8515" to be "running and ready"
    Dec  3 12:23:14.754: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 3.966139ms
    Dec  3 12:23:14.754: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:23:16.763: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.013429402s
    Dec  3 12:23:16.763: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Dec  3 12:23:16.764: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 12/03/22 12:23:16.764
    Dec  3 12:23:16.764: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8515 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:23:16.764: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:23:16.764: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:23:16.764: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8515/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 12/03/22 12:23:16.868
    Dec  3 12:23:16.868: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8515 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:23:16.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:23:16.869: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:23:16.869: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8515/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:23:16.976: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 12:23:16.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8515" for this suite. 12/03/22 12:23:17.001
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:23:17.017
Dec  3 12:23:17.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-pred 12/03/22 12:23:17.018
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:17.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:17.043
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec  3 12:23:17.046: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 12:23:17.056: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 12:23:17.060: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
Dec  3 12:23:17.066: INFO: nginx-ingress-controller-kubernetes-worker-cxx89 from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:07 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.066: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Dec  3 12:23:17.066: INFO: calico-kube-controllers-77cf5c5988-cx58t from kube-system started at 2022-12-03 11:50:46 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.066: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 12:23:17.066: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:23:17.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:23:17.066: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:23:17.066: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
Dec  3 12:23:17.082: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  3 12:23:17.082: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:23:17.082: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container coredns ready: true, restart count 0
Dec  3 12:23:17.082: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec  3 12:23:17.082: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 12:23:17.082: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  3 12:23:17.082: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.082: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec  3 12:23:17.083: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.083: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 12:23:17.083: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:23:17.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:23:17.083: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:23:17.083: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
Dec  3 12:23:17.094: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.094: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:23:17.094: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
Dec  3 12:23:17.094: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 12:23:17.094: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:23:17.094: INFO: 	Container e2e ready: true, restart count 0
Dec  3 12:23:17.094: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:23:17.094: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:23:17.095: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:23:17.095: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 12:23:17.095
Dec  3 12:23:17.106: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3423" to be "running"
Dec  3 12:23:17.111: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.498189ms
Dec  3 12:23:19.126: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.019884086s
Dec  3 12:23:19.126: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 12:23:19.135
STEP: Trying to apply a random label on the found node. 12/03/22 12:23:19.153
STEP: verifying the node has the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba 95 12/03/22 12:23:19.163
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/03/22 12:23:19.167
Dec  3 12:23:19.173: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3423" to be "not pending"
Dec  3 12:23:19.178: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58075ms
Dec  3 12:23:21.183: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.009857487s
Dec  3 12:23:21.183: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.38.234 on the node which pod4 resides and expect not scheduled 12/03/22 12:23:21.183
Dec  3 12:23:21.189: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3423" to be "not pending"
Dec  3 12:23:21.202: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.238761ms
Dec  3 12:23:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018220519s
Dec  3 12:23:25.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018489464s
Dec  3 12:23:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01841174s
Dec  3 12:23:29.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01845307s
Dec  3 12:23:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018005792s
Dec  3 12:23:33.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020546659s
Dec  3 12:23:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018462263s
Dec  3 12:23:37.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.017910725s
Dec  3 12:23:39.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.017367562s
Dec  3 12:23:41.211: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.021659166s
Dec  3 12:23:43.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017608422s
Dec  3 12:23:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018002958s
Dec  3 12:23:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018799377s
Dec  3 12:23:49.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019806772s
Dec  3 12:23:51.210: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020752068s
Dec  3 12:23:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017571421s
Dec  3 12:23:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.017932279s
Dec  3 12:23:57.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.017677034s
Dec  3 12:23:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.018990108s
Dec  3 12:24:01.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.019925699s
Dec  3 12:24:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.017974599s
Dec  3 12:24:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017674022s
Dec  3 12:24:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.018240166s
Dec  3 12:24:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017812317s
Dec  3 12:24:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018083842s
Dec  3 12:24:13.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.019962111s
Dec  3 12:24:15.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.019046866s
Dec  3 12:24:17.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019276989s
Dec  3 12:24:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017918993s
Dec  3 12:24:21.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020024861s
Dec  3 12:24:23.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019905949s
Dec  3 12:24:25.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.019253442s
Dec  3 12:24:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.018278191s
Dec  3 12:24:29.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017405885s
Dec  3 12:24:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017746048s
Dec  3 12:24:33.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.017554886s
Dec  3 12:24:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018279884s
Dec  3 12:24:37.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.017003408s
Dec  3 12:24:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.018576281s
Dec  3 12:24:41.214: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.025271729s
Dec  3 12:24:43.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.0180328s
Dec  3 12:24:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.017752594s
Dec  3 12:24:47.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017868399s
Dec  3 12:24:49.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.018280746s
Dec  3 12:24:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.01791238s
Dec  3 12:24:53.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.018217236s
Dec  3 12:24:55.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.017381162s
Dec  3 12:24:57.212: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023093182s
Dec  3 12:24:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.018658471s
Dec  3 12:25:01.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.017967395s
Dec  3 12:25:03.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.017386652s
Dec  3 12:25:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.018427038s
Dec  3 12:25:07.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.017103312s
Dec  3 12:25:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.018571389s
Dec  3 12:25:11.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.018640219s
Dec  3 12:25:13.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019180746s
Dec  3 12:25:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018231215s
Dec  3 12:25:17.215: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.026102528s
Dec  3 12:25:19.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.019652794s
Dec  3 12:25:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.018261282s
Dec  3 12:25:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.018199493s
Dec  3 12:25:25.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.018749424s
Dec  3 12:25:27.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.018604487s
Dec  3 12:25:29.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.018007186s
Dec  3 12:25:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.01801716s
Dec  3 12:25:33.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.019229261s
Dec  3 12:25:35.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.017588744s
Dec  3 12:25:37.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.018456216s
Dec  3 12:25:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.018510659s
Dec  3 12:25:41.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.017305794s
Dec  3 12:25:43.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.018614181s
Dec  3 12:25:45.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.017412656s
Dec  3 12:25:47.211: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.021694495s
Dec  3 12:25:49.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.019888962s
Dec  3 12:25:51.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.019424634s
Dec  3 12:25:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.017307976s
Dec  3 12:25:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.017970418s
Dec  3 12:25:57.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.01758006s
Dec  3 12:25:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.018993904s
Dec  3 12:26:01.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.018078335s
Dec  3 12:26:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.017853428s
Dec  3 12:26:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.018029703s
Dec  3 12:26:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.017936798s
Dec  3 12:26:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.017953333s
Dec  3 12:26:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.017982476s
Dec  3 12:26:13.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017312106s
Dec  3 12:26:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.018248885s
Dec  3 12:26:17.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.017644237s
Dec  3 12:26:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.01788006s
Dec  3 12:26:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.017650299s
Dec  3 12:26:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.018196938s
Dec  3 12:26:25.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.018157178s
Dec  3 12:26:27.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.017391891s
Dec  3 12:26:29.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.018686548s
Dec  3 12:26:31.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.017315328s
Dec  3 12:26:33.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.020369751s
Dec  3 12:26:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.017609099s
Dec  3 12:26:37.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.018852694s
Dec  3 12:26:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.017726961s
Dec  3 12:26:41.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.018346847s
Dec  3 12:26:43.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.017152453s
Dec  3 12:26:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.018531414s
Dec  3 12:26:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.018924299s
Dec  3 12:26:49.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.018776563s
Dec  3 12:26:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.017824697s
Dec  3 12:26:53.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.018060952s
Dec  3 12:26:55.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.019941166s
Dec  3 12:26:57.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.01913945s
Dec  3 12:26:59.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.017964305s
Dec  3 12:27:01.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.017512907s
Dec  3 12:27:03.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.019132939s
Dec  3 12:27:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.017964694s
Dec  3 12:27:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018401975s
Dec  3 12:27:09.214: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024639853s
Dec  3 12:27:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.017780622s
Dec  3 12:27:13.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.01783306s
Dec  3 12:27:15.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.019692543s
Dec  3 12:27:17.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.017376406s
Dec  3 12:27:19.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.019565362s
Dec  3 12:27:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.01852189s
Dec  3 12:27:23.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.017529826s
Dec  3 12:27:25.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.017531195s
Dec  3 12:27:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.017742554s
Dec  3 12:27:29.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.018762206s
Dec  3 12:27:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.017936104s
Dec  3 12:27:33.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.018272632s
Dec  3 12:27:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.018016309s
Dec  3 12:27:37.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.017363477s
Dec  3 12:27:39.205: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.016592101s
Dec  3 12:27:41.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.018929662s
Dec  3 12:27:43.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.016912712s
Dec  3 12:27:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.018402986s
Dec  3 12:27:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.019119393s
Dec  3 12:27:49.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.01869768s
Dec  3 12:27:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.018232623s
Dec  3 12:27:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.016909042s
Dec  3 12:27:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.018187178s
Dec  3 12:27:57.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.018256516s
Dec  3 12:27:59.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017838154s
Dec  3 12:28:01.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.01948655s
Dec  3 12:28:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.017992365s
Dec  3 12:28:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.01835771s
Dec  3 12:28:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.018233877s
Dec  3 12:28:09.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.017477397s
Dec  3 12:28:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.017913027s
Dec  3 12:28:13.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.016985328s
Dec  3 12:28:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.017811926s
Dec  3 12:28:17.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.020420335s
Dec  3 12:28:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.017812545s
Dec  3 12:28:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.018266056s
Dec  3 12:28:21.210: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021403104s
STEP: removing the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba off the node ip-172-31-38-234 12/03/22 12:28:21.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba 12/03/22 12:28:21.227
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:28:21.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3423" for this suite. 12/03/22 12:28:21.237
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":88,"skipped":1763,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.232 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:23:17.017
    Dec  3 12:23:17.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-pred 12/03/22 12:23:17.018
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:23:17.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:23:17.043
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec  3 12:23:17.046: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec  3 12:23:17.056: INFO: Waiting for terminating namespaces to be deleted...
    Dec  3 12:23:17.060: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
    Dec  3 12:23:17.066: INFO: nginx-ingress-controller-kubernetes-worker-cxx89 from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:07 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.066: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Dec  3 12:23:17.066: INFO: calico-kube-controllers-77cf5c5988-cx58t from kube-system started at 2022-12-03 11:50:46 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.066: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Dec  3 12:23:17.066: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:23:17.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:23:17.066: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:23:17.066: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
    Dec  3 12:23:17.082: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container coredns ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container metrics-server ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Dec  3 12:23:17.082: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.082: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec  3 12:23:17.083: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.083: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec  3 12:23:17.083: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:23:17.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:23:17.083: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:23:17.083: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
    Dec  3 12:23:17.094: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.094: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:23:17.094: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
    Dec  3 12:23:17.094: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Dec  3 12:23:17.094: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:23:17.094: INFO: 	Container e2e ready: true, restart count 0
    Dec  3 12:23:17.094: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:23:17.094: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:23:17.095: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:23:17.095: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 12:23:17.095
    Dec  3 12:23:17.106: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3423" to be "running"
    Dec  3 12:23:17.111: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.498189ms
    Dec  3 12:23:19.126: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.019884086s
    Dec  3 12:23:19.126: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 12:23:19.135
    STEP: Trying to apply a random label on the found node. 12/03/22 12:23:19.153
    STEP: verifying the node has the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba 95 12/03/22 12:23:19.163
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/03/22 12:23:19.167
    Dec  3 12:23:19.173: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3423" to be "not pending"
    Dec  3 12:23:19.178: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58075ms
    Dec  3 12:23:21.183: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.009857487s
    Dec  3 12:23:21.183: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.38.234 on the node which pod4 resides and expect not scheduled 12/03/22 12:23:21.183
    Dec  3 12:23:21.189: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3423" to be "not pending"
    Dec  3 12:23:21.202: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.238761ms
    Dec  3 12:23:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018220519s
    Dec  3 12:23:25.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018489464s
    Dec  3 12:23:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01841174s
    Dec  3 12:23:29.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01845307s
    Dec  3 12:23:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018005792s
    Dec  3 12:23:33.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020546659s
    Dec  3 12:23:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018462263s
    Dec  3 12:23:37.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.017910725s
    Dec  3 12:23:39.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.017367562s
    Dec  3 12:23:41.211: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.021659166s
    Dec  3 12:23:43.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017608422s
    Dec  3 12:23:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018002958s
    Dec  3 12:23:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018799377s
    Dec  3 12:23:49.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019806772s
    Dec  3 12:23:51.210: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020752068s
    Dec  3 12:23:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017571421s
    Dec  3 12:23:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.017932279s
    Dec  3 12:23:57.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.017677034s
    Dec  3 12:23:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.018990108s
    Dec  3 12:24:01.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.019925699s
    Dec  3 12:24:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.017974599s
    Dec  3 12:24:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017674022s
    Dec  3 12:24:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.018240166s
    Dec  3 12:24:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017812317s
    Dec  3 12:24:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018083842s
    Dec  3 12:24:13.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.019962111s
    Dec  3 12:24:15.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.019046866s
    Dec  3 12:24:17.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019276989s
    Dec  3 12:24:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017918993s
    Dec  3 12:24:21.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020024861s
    Dec  3 12:24:23.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019905949s
    Dec  3 12:24:25.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.019253442s
    Dec  3 12:24:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.018278191s
    Dec  3 12:24:29.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017405885s
    Dec  3 12:24:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017746048s
    Dec  3 12:24:33.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.017554886s
    Dec  3 12:24:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018279884s
    Dec  3 12:24:37.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.017003408s
    Dec  3 12:24:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.018576281s
    Dec  3 12:24:41.214: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.025271729s
    Dec  3 12:24:43.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.0180328s
    Dec  3 12:24:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.017752594s
    Dec  3 12:24:47.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017868399s
    Dec  3 12:24:49.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.018280746s
    Dec  3 12:24:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.01791238s
    Dec  3 12:24:53.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.018217236s
    Dec  3 12:24:55.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.017381162s
    Dec  3 12:24:57.212: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.023093182s
    Dec  3 12:24:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.018658471s
    Dec  3 12:25:01.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.017967395s
    Dec  3 12:25:03.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.017386652s
    Dec  3 12:25:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.018427038s
    Dec  3 12:25:07.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.017103312s
    Dec  3 12:25:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.018571389s
    Dec  3 12:25:11.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.018640219s
    Dec  3 12:25:13.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019180746s
    Dec  3 12:25:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018231215s
    Dec  3 12:25:17.215: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.026102528s
    Dec  3 12:25:19.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.019652794s
    Dec  3 12:25:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.018261282s
    Dec  3 12:25:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.018199493s
    Dec  3 12:25:25.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.018749424s
    Dec  3 12:25:27.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.018604487s
    Dec  3 12:25:29.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.018007186s
    Dec  3 12:25:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.01801716s
    Dec  3 12:25:33.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.019229261s
    Dec  3 12:25:35.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.017588744s
    Dec  3 12:25:37.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.018456216s
    Dec  3 12:25:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.018510659s
    Dec  3 12:25:41.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.017305794s
    Dec  3 12:25:43.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.018614181s
    Dec  3 12:25:45.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.017412656s
    Dec  3 12:25:47.211: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.021694495s
    Dec  3 12:25:49.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.019888962s
    Dec  3 12:25:51.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.019424634s
    Dec  3 12:25:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.017307976s
    Dec  3 12:25:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.017970418s
    Dec  3 12:25:57.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.01758006s
    Dec  3 12:25:59.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.018993904s
    Dec  3 12:26:01.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.018078335s
    Dec  3 12:26:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.017853428s
    Dec  3 12:26:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.018029703s
    Dec  3 12:26:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.017936798s
    Dec  3 12:26:09.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.017953333s
    Dec  3 12:26:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.017982476s
    Dec  3 12:26:13.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017312106s
    Dec  3 12:26:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.018248885s
    Dec  3 12:26:17.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.017644237s
    Dec  3 12:26:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.01788006s
    Dec  3 12:26:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.017650299s
    Dec  3 12:26:23.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.018196938s
    Dec  3 12:26:25.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.018157178s
    Dec  3 12:26:27.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.017391891s
    Dec  3 12:26:29.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.018686548s
    Dec  3 12:26:31.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.017315328s
    Dec  3 12:26:33.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.020369751s
    Dec  3 12:26:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.017609099s
    Dec  3 12:26:37.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.018852694s
    Dec  3 12:26:39.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.017726961s
    Dec  3 12:26:41.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.018346847s
    Dec  3 12:26:43.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.017152453s
    Dec  3 12:26:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.018531414s
    Dec  3 12:26:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.018924299s
    Dec  3 12:26:49.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.018776563s
    Dec  3 12:26:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.017824697s
    Dec  3 12:26:53.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.018060952s
    Dec  3 12:26:55.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.019941166s
    Dec  3 12:26:57.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.01913945s
    Dec  3 12:26:59.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.017964305s
    Dec  3 12:27:01.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.017512907s
    Dec  3 12:27:03.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.019132939s
    Dec  3 12:27:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.017964694s
    Dec  3 12:27:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018401975s
    Dec  3 12:27:09.214: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024639853s
    Dec  3 12:27:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.017780622s
    Dec  3 12:27:13.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.01783306s
    Dec  3 12:27:15.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.019692543s
    Dec  3 12:27:17.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.017376406s
    Dec  3 12:27:19.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.019565362s
    Dec  3 12:27:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.01852189s
    Dec  3 12:27:23.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.017529826s
    Dec  3 12:27:25.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.017531195s
    Dec  3 12:27:27.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.017742554s
    Dec  3 12:27:29.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.018762206s
    Dec  3 12:27:31.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.017936104s
    Dec  3 12:27:33.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.018272632s
    Dec  3 12:27:35.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.018016309s
    Dec  3 12:27:37.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.017363477s
    Dec  3 12:27:39.205: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.016592101s
    Dec  3 12:27:41.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.018929662s
    Dec  3 12:27:43.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.016912712s
    Dec  3 12:27:45.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.018402986s
    Dec  3 12:27:47.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.019119393s
    Dec  3 12:27:49.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.01869768s
    Dec  3 12:27:51.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.018232623s
    Dec  3 12:27:53.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.016909042s
    Dec  3 12:27:55.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.018187178s
    Dec  3 12:27:57.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.018256516s
    Dec  3 12:27:59.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017838154s
    Dec  3 12:28:01.208: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.01948655s
    Dec  3 12:28:03.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.017992365s
    Dec  3 12:28:05.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.01835771s
    Dec  3 12:28:07.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.018233877s
    Dec  3 12:28:09.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.017477397s
    Dec  3 12:28:11.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.017913027s
    Dec  3 12:28:13.206: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.016985328s
    Dec  3 12:28:15.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.017811926s
    Dec  3 12:28:17.209: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.020420335s
    Dec  3 12:28:19.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.017812545s
    Dec  3 12:28:21.207: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.018266056s
    Dec  3 12:28:21.210: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021403104s
    STEP: removing the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba off the node ip-172-31-38-234 12/03/22 12:28:21.21
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-83321e96-1f8d-42a1-ade4-f013b3e707ba 12/03/22 12:28:21.227
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:28:21.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3423" for this suite. 12/03/22 12:28:21.237
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:28:21.249
Dec  3 12:28:21.250: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 12:28:21.251
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:21.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:21.285
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Dec  3 12:28:21.309: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 12:28:21.318
Dec  3 12:28:21.326: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:21.326: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:21.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 12:28:21.332: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:28:22.337: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:22.338: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:22.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 12:28:22.343: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:28:23.338: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:23.339: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:23.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 12:28:23.343: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 12:28:24.337: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:24.337: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:24.340: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 12:28:24.341: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 12/03/22 12:28:24.355
STEP: Check that daemon pods images are updated. 12/03/22 12:28:24.366
Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-9rtxm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:24.375: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:24.376: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:25.380: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:25.380: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:25.384: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:25.384: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:26.381: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:26.382: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:26.386: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:26.386: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:27.380: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:27.380: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:27.380: INFO: Pod daemon-set-wsrk4 is not available
Dec  3 12:28:27.389: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:27.389: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:28.380: INFO: Pod daemon-set-2gmgh is not available
Dec  3 12:28:28.381: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec  3 12:28:28.385: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:28.385: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:29.385: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:29.385: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:30.381: INFO: Pod daemon-set-nhjfb is not available
Dec  3 12:28:30.386: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:30.386: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 12/03/22 12:28:30.386
Dec  3 12:28:30.389: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:30.389: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:30.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 12:28:30.393: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 12:28:31.398: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:31.398: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:28:31.403: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 12:28:31.403: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 12:28:31.42
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7010, will wait for the garbage collector to delete the pods 12/03/22 12:28:31.42
Dec  3 12:28:31.482: INFO: Deleting DaemonSet.extensions daemon-set took: 7.686528ms
Dec  3 12:28:31.583: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.878374ms
Dec  3 12:28:33.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 12:28:33.787: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 12:28:33.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11759"},"items":null}

Dec  3 12:28:33.795: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11759"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:28:33.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7010" for this suite. 12/03/22 12:28:33.814
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":89,"skipped":1767,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.575 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:28:21.249
    Dec  3 12:28:21.250: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 12:28:21.251
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:21.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:21.285
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Dec  3 12:28:21.309: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 12:28:21.318
    Dec  3 12:28:21.326: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:21.326: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:21.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 12:28:21.332: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:28:22.337: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:22.338: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:22.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 12:28:22.343: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:28:23.338: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:23.339: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:23.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 12:28:23.343: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 12:28:24.337: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:24.337: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:24.340: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 12:28:24.341: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 12/03/22 12:28:24.355
    STEP: Check that daemon pods images are updated. 12/03/22 12:28:24.366
    Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-9rtxm. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:24.371: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:24.375: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:24.376: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:25.380: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:25.380: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:25.384: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:25.384: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:26.381: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:26.382: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:26.386: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:26.386: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:27.380: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:27.380: INFO: Wrong image for pod: daemon-set-mhn4s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:27.380: INFO: Pod daemon-set-wsrk4 is not available
    Dec  3 12:28:27.389: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:27.389: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:28.380: INFO: Pod daemon-set-2gmgh is not available
    Dec  3 12:28:28.381: INFO: Wrong image for pod: daemon-set-f6trt. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec  3 12:28:28.385: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:28.385: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:29.385: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:29.385: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:30.381: INFO: Pod daemon-set-nhjfb is not available
    Dec  3 12:28:30.386: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:30.386: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 12/03/22 12:28:30.386
    Dec  3 12:28:30.389: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:30.389: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:30.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 12:28:30.393: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 12:28:31.398: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:31.398: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:28:31.403: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 12:28:31.403: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 12:28:31.42
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7010, will wait for the garbage collector to delete the pods 12/03/22 12:28:31.42
    Dec  3 12:28:31.482: INFO: Deleting DaemonSet.extensions daemon-set took: 7.686528ms
    Dec  3 12:28:31.583: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.878374ms
    Dec  3 12:28:33.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 12:28:33.787: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 12:28:33.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11759"},"items":null}

    Dec  3 12:28:33.795: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11759"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:28:33.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7010" for this suite. 12/03/22 12:28:33.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:28:33.83
Dec  3 12:28:33.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:28:33.832
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:33.863
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:33.867
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 12/03/22 12:28:33.869
Dec  3 12:28:33.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1" in namespace "downward-api-1637" to be "Succeeded or Failed"
Dec  3 12:28:33.891: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.083955ms
Dec  3 12:28:35.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016683042s
Dec  3 12:28:37.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016014671s
STEP: Saw pod success 12/03/22 12:28:37.895
Dec  3 12:28:37.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1" satisfied condition "Succeeded or Failed"
Dec  3 12:28:37.899: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 container client-container: <nil>
STEP: delete the pod 12/03/22 12:28:37.921
Dec  3 12:28:37.935: INFO: Waiting for pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 to disappear
Dec  3 12:28:37.939: INFO: Pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 12:28:37.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1637" for this suite. 12/03/22 12:28:37.945
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":90,"skipped":1776,"failed":0}
------------------------------
â€¢ [4.125 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:28:33.83
    Dec  3 12:28:33.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:28:33.832
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:33.863
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:33.867
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 12/03/22 12:28:33.869
    Dec  3 12:28:33.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1" in namespace "downward-api-1637" to be "Succeeded or Failed"
    Dec  3 12:28:33.891: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.083955ms
    Dec  3 12:28:35.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016683042s
    Dec  3 12:28:37.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016014671s
    STEP: Saw pod success 12/03/22 12:28:37.895
    Dec  3 12:28:37.895: INFO: Pod "downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1" satisfied condition "Succeeded or Failed"
    Dec  3 12:28:37.899: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 container client-container: <nil>
    STEP: delete the pod 12/03/22 12:28:37.921
    Dec  3 12:28:37.935: INFO: Waiting for pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 to disappear
    Dec  3 12:28:37.939: INFO: Pod downwardapi-volume-0e5a2631-5226-43ca-8723-743842df02d1 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 12:28:37.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1637" for this suite. 12/03/22 12:28:37.945
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:28:37.956
Dec  3 12:28:37.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:28:37.958
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:37.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:37.985
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 12/03/22 12:28:37.99
Dec  3 12:28:38.004: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2" in namespace "emptydir-6126" to be "running"
Dec  3 12:28:38.008: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.60311ms
Dec  3 12:28:40.013: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2": Phase="Running", Reason="", readiness=false. Elapsed: 2.009430464s
Dec  3 12:28:40.013: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2" satisfied condition "running"
STEP: Reading file content from the nginx-container 12/03/22 12:28:40.013
Dec  3 12:28:40.013: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6126 PodName:pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:28:40.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:28:40.014: INFO: ExecWithOptions: Clientset creation
Dec  3 12:28:40.014: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-6126/pods/pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Dec  3 12:28:40.087: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:28:40.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6126" for this suite. 12/03/22 12:28:40.091
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":91,"skipped":1778,"failed":0}
------------------------------
â€¢ [2.142 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:28:37.956
    Dec  3 12:28:37.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:28:37.958
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:37.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:37.985
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 12/03/22 12:28:37.99
    Dec  3 12:28:38.004: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2" in namespace "emptydir-6126" to be "running"
    Dec  3 12:28:38.008: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.60311ms
    Dec  3 12:28:40.013: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2": Phase="Running", Reason="", readiness=false. Elapsed: 2.009430464s
    Dec  3 12:28:40.013: INFO: Pod "pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2" satisfied condition "running"
    STEP: Reading file content from the nginx-container 12/03/22 12:28:40.013
    Dec  3 12:28:40.013: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6126 PodName:pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:28:40.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:28:40.014: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:28:40.014: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-6126/pods/pod-sharedvolume-d5d174a7-ca0b-4a7f-9903-827bfb4c27d2/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Dec  3 12:28:40.087: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:28:40.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6126" for this suite. 12/03/22 12:28:40.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:28:40.099
Dec  3 12:28:40.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:28:40.1
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:40.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:40.133
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 in namespace container-probe-3213 12/03/22 12:28:40.141
Dec  3 12:28:40.152: INFO: Waiting up to 5m0s for pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695" in namespace "container-probe-3213" to be "not pending"
Dec  3 12:28:40.157: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126201ms
Dec  3 12:28:42.163: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781695s
Dec  3 12:28:42.163: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695" satisfied condition "not pending"
Dec  3 12:28:42.163: INFO: Started pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 in namespace container-probe-3213
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:28:42.163
Dec  3 12:28:42.167: INFO: Initial restart count of pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 is 0
STEP: deleting the pod 12/03/22 12:32:42.822
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:32:42.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3213" for this suite. 12/03/22 12:32:42.851
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":92,"skipped":1793,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.768 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:28:40.099
    Dec  3 12:28:40.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:28:40.1
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:28:40.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:28:40.133
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 in namespace container-probe-3213 12/03/22 12:28:40.141
    Dec  3 12:28:40.152: INFO: Waiting up to 5m0s for pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695" in namespace "container-probe-3213" to be "not pending"
    Dec  3 12:28:40.157: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126201ms
    Dec  3 12:28:42.163: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781695s
    Dec  3 12:28:42.163: INFO: Pod "liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695" satisfied condition "not pending"
    Dec  3 12:28:42.163: INFO: Started pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 in namespace container-probe-3213
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:28:42.163
    Dec  3 12:28:42.167: INFO: Initial restart count of pod liveness-d57c3f9d-4e88-4678-bd85-695d6f6d6695 is 0
    STEP: deleting the pod 12/03/22 12:32:42.822
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:32:42.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3213" for this suite. 12/03/22 12:32:42.851
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:32:42.867
Dec  3 12:32:42.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:32:42.868
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:42.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:42.917
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 12/03/22 12:32:42.931
Dec  3 12:32:42.957: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624" in namespace "downward-api-7504" to be "Succeeded or Failed"
Dec  3 12:32:42.973: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Pending", Reason="", readiness=false. Elapsed: 15.544519ms
Dec  3 12:32:44.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021115987s
Dec  3 12:32:46.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021448752s
STEP: Saw pod success 12/03/22 12:32:46.979
Dec  3 12:32:46.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624" satisfied condition "Succeeded or Failed"
Dec  3 12:32:46.984: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 container client-container: <nil>
STEP: delete the pod 12/03/22 12:32:46.999
Dec  3 12:32:47.011: INFO: Waiting for pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 to disappear
Dec  3 12:32:47.015: INFO: Pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 12:32:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7504" for this suite. 12/03/22 12:32:47.019
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":93,"skipped":1795,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:32:42.867
    Dec  3 12:32:42.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:32:42.868
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:42.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:42.917
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 12/03/22 12:32:42.931
    Dec  3 12:32:42.957: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624" in namespace "downward-api-7504" to be "Succeeded or Failed"
    Dec  3 12:32:42.973: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Pending", Reason="", readiness=false. Elapsed: 15.544519ms
    Dec  3 12:32:44.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021115987s
    Dec  3 12:32:46.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021448752s
    STEP: Saw pod success 12/03/22 12:32:46.979
    Dec  3 12:32:46.979: INFO: Pod "downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624" satisfied condition "Succeeded or Failed"
    Dec  3 12:32:46.984: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 container client-container: <nil>
    STEP: delete the pod 12/03/22 12:32:46.999
    Dec  3 12:32:47.011: INFO: Waiting for pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 to disappear
    Dec  3 12:32:47.015: INFO: Pod downwardapi-volume-e07fc03f-3bc8-4fe3-90d4-329d80c18624 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 12:32:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7504" for this suite. 12/03/22 12:32:47.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:32:47.028
Dec  3 12:32:47.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:32:47.03
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:47.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:47.06
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Dec  3 12:32:47.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:32:48.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3519" for this suite. 12/03/22 12:32:48.1
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":94,"skipped":1825,"failed":0}
------------------------------
â€¢ [1.083 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:32:47.028
    Dec  3 12:32:47.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:32:47.03
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:47.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:47.06
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Dec  3 12:32:47.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:32:48.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3519" for this suite. 12/03/22 12:32:48.1
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:32:48.112
Dec  3 12:32:48.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:32:48.113
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:48.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:48.145
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 12/03/22 12:32:48.149
Dec  3 12:32:48.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: mark a version not serverd 12/03/22 12:32:55.236
STEP: check the unserved version gets removed 12/03/22 12:32:55.257
STEP: check the other version is not changed 12/03/22 12:32:58.122
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:33:03.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-173" for this suite. 12/03/22 12:33:03.223
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":95,"skipped":1835,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.120 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:32:48.112
    Dec  3 12:32:48.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:32:48.113
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:32:48.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:32:48.145
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 12/03/22 12:32:48.149
    Dec  3 12:32:48.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: mark a version not serverd 12/03/22 12:32:55.236
    STEP: check the unserved version gets removed 12/03/22 12:32:55.257
    STEP: check the other version is not changed 12/03/22 12:32:58.122
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:33:03.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-173" for this suite. 12/03/22 12:33:03.223
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:33:03.236
Dec  3 12:33:03.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:33:03.237
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:03.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:03.268
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 12/03/22 12:33:03.271
Dec  3 12:33:03.283: INFO: Waiting up to 5m0s for pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5" in namespace "projected-3050" to be "running and ready"
Dec  3 12:33:03.287: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.50068ms
Dec  3 12:33:03.287: INFO: The phase of Pod labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:33:05.292: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008617931s
Dec  3 12:33:05.292: INFO: The phase of Pod labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5 is Running (Ready = true)
Dec  3 12:33:05.292: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5" satisfied condition "running and ready"
Dec  3 12:33:05.816: INFO: Successfully updated pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 12:33:09.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3050" for this suite. 12/03/22 12:33:09.854
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":96,"skipped":1925,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.624 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:33:03.236
    Dec  3 12:33:03.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:33:03.237
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:03.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:03.268
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 12/03/22 12:33:03.271
    Dec  3 12:33:03.283: INFO: Waiting up to 5m0s for pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5" in namespace "projected-3050" to be "running and ready"
    Dec  3 12:33:03.287: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.50068ms
    Dec  3 12:33:03.287: INFO: The phase of Pod labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:33:05.292: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008617931s
    Dec  3 12:33:05.292: INFO: The phase of Pod labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5 is Running (Ready = true)
    Dec  3 12:33:05.292: INFO: Pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5" satisfied condition "running and ready"
    Dec  3 12:33:05.816: INFO: Successfully updated pod "labelsupdatea64758bd-ee9c-4d96-90ca-6e8d57f51de5"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 12:33:09.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3050" for this suite. 12/03/22 12:33:09.854
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:33:09.862
Dec  3 12:33:09.862: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:33:09.863
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:09.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:09.888
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Dec  3 12:33:09.902: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  3 12:33:14.909: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 12:33:14.909
Dec  3 12:33:14.909: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/03/22 12:33:14.923
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:33:14.934: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3993  7c1032c9-6cdd-4333-b040-ef79a25ce004 12545 1 2022-12-03 12:33:14 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-12-03 12:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004604478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 12:33:14.937: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec  3 12:33:14.937: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  3 12:33:14.938: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3993  da7648e0-55a9-4d9d-8332-1c7edbe03c67 12547 1 2022-12-03 12:33:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 7c1032c9-6cdd-4333-b040-ef79a25ce004 0xc0045dacc7 0xc0045dacc8}] [] [{e2e.test Update apps/v1 2022-12-03 12:33:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:33:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"7c1032c9-6cdd-4333-b040-ef79a25ce004\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0045dad88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:33:14.941: INFO: Pod "test-cleanup-controller-25zxn" is available:
&Pod{ObjectMeta:{test-cleanup-controller-25zxn test-cleanup-controller- deployment-3993  f4cbd1d9-9b30-44fe-ab61-c947df237ca9 12538 0 2022-12-03 12:33:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller da7648e0-55a9-4d9d-8332-1c7edbe03c67 0xc0046047d7 0xc0046047d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:33:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"da7648e0-55a9-4d9d-8332-1c7edbe03c67\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:33:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tgbnk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tgbnk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.84,StartTime:2022-12-03 12:33:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:33:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ff7f02389ff1e05b597d6b5151c7116f2f11683e55f949a53e947570d3dcb64d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:33:14.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3993" for this suite. 12/03/22 12:33:14.947
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":97,"skipped":1931,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.092 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:33:09.862
    Dec  3 12:33:09.862: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:33:09.863
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:09.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:09.888
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Dec  3 12:33:09.902: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Dec  3 12:33:14.909: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 12:33:14.909
    Dec  3 12:33:14.909: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/03/22 12:33:14.923
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:33:14.934: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3993  7c1032c9-6cdd-4333-b040-ef79a25ce004 12545 1 2022-12-03 12:33:14 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-12-03 12:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004604478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Dec  3 12:33:14.937: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Dec  3 12:33:14.937: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Dec  3 12:33:14.938: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3993  da7648e0-55a9-4d9d-8332-1c7edbe03c67 12547 1 2022-12-03 12:33:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 7c1032c9-6cdd-4333-b040-ef79a25ce004 0xc0045dacc7 0xc0045dacc8}] [] [{e2e.test Update apps/v1 2022-12-03 12:33:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:33:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"7c1032c9-6cdd-4333-b040-ef79a25ce004\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0045dad88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:33:14.941: INFO: Pod "test-cleanup-controller-25zxn" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-25zxn test-cleanup-controller- deployment-3993  f4cbd1d9-9b30-44fe-ab61-c947df237ca9 12538 0 2022-12-03 12:33:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller da7648e0-55a9-4d9d-8332-1c7edbe03c67 0xc0046047d7 0xc0046047d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:33:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"da7648e0-55a9-4d9d-8332-1c7edbe03c67\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:33:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tgbnk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tgbnk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:33:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.84,StartTime:2022-12-03 12:33:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:33:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ff7f02389ff1e05b597d6b5151c7116f2f11683e55f949a53e947570d3dcb64d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:33:14.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3993" for this suite. 12/03/22 12:33:14.947
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:33:14.96
Dec  3 12:33:14.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 12:33:14.962
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:15.02
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:15.024
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 12/03/22 12:33:15.028
Dec  3 12:33:15.039: INFO: Waiting up to 2m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808" to be "running"
Dec  3 12:33:15.042: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2.63923ms
Dec  3 12:33:17.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008021274s
Dec  3 12:33:19.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009048559s
Dec  3 12:33:21.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007974611s
Dec  3 12:33:23.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008713463s
Dec  3 12:33:25.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008965292s
Dec  3 12:33:27.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 12.00734653s
Dec  3 12:33:29.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009848608s
Dec  3 12:33:31.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 16.008049342s
Dec  3 12:33:33.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 18.009687429s
Dec  3 12:33:35.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 20.009703932s
Dec  3 12:33:37.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 22.009094104s
Dec  3 12:33:39.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010854237s
Dec  3 12:33:41.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 26.009403039s
Dec  3 12:33:43.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008175471s
Dec  3 12:33:45.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 30.009045098s
Dec  3 12:33:47.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006646733s
Dec  3 12:33:49.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 34.010944406s
Dec  3 12:33:51.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 36.007693271s
Dec  3 12:33:53.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 38.009503804s
Dec  3 12:33:55.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007051304s
Dec  3 12:33:57.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007903328s
Dec  3 12:33:59.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 44.008103914s
Dec  3 12:34:01.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 46.007220249s
Dec  3 12:34:03.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007236177s
Dec  3 12:34:05.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 50.007546061s
Dec  3 12:34:07.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007243016s
Dec  3 12:34:09.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 54.008827696s
Dec  3 12:34:11.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 56.007115049s
Dec  3 12:34:13.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007732571s
Dec  3 12:34:15.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007460246s
Dec  3 12:34:17.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007747874s
Dec  3 12:34:19.052: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012524083s
Dec  3 12:34:21.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.007186104s
Dec  3 12:34:23.053: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.014281231s
Dec  3 12:34:25.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007634355s
Dec  3 12:34:27.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009894885s
Dec  3 12:34:29.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.008001759s
Dec  3 12:34:31.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.008362846s
Dec  3 12:34:33.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.008667805s
Dec  3 12:34:35.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.008078006s
Dec  3 12:34:37.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.007309083s
Dec  3 12:34:39.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.008020276s
Dec  3 12:34:41.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.008202161s
Dec  3 12:34:43.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007529392s
Dec  3 12:34:45.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.007362089s
Dec  3 12:34:47.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006907723s
Dec  3 12:34:49.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007597625s
Dec  3 12:34:51.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007734021s
Dec  3 12:34:53.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010560151s
Dec  3 12:34:55.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.008623229s
Dec  3 12:34:57.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009122309s
Dec  3 12:34:59.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.00821511s
Dec  3 12:35:01.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008795456s
Dec  3 12:35:03.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007204012s
Dec  3 12:35:05.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008990419s
Dec  3 12:35:07.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.010554979s
Dec  3 12:35:09.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007835594s
Dec  3 12:35:11.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007436179s
Dec  3 12:35:13.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.008545703s
Dec  3 12:35:15.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.006959819s
Dec  3 12:35:15.051: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.011778005s
STEP: updating the pod 12/03/22 12:35:15.051
Dec  3 12:35:15.571: INFO: Successfully updated pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100"
STEP: waiting for pod running 12/03/22 12:35:15.571
Dec  3 12:35:15.571: INFO: Waiting up to 2m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808" to be "running"
Dec  3 12:35:15.576: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110786ms
Dec  3 12:35:17.583: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Running", Reason="", readiness=true. Elapsed: 2.011179319s
Dec  3 12:35:17.583: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" satisfied condition "running"
STEP: deleting the pod gracefully 12/03/22 12:35:17.583
Dec  3 12:35:17.583: INFO: Deleting pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808"
Dec  3 12:35:17.594: INFO: Wait up to 5m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 12:35:49.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-808" for this suite. 12/03/22 12:35:49.609
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":98,"skipped":1944,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.655 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:33:14.96
    Dec  3 12:33:14.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 12:33:14.962
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:33:15.02
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:33:15.024
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 12/03/22 12:33:15.028
    Dec  3 12:33:15.039: INFO: Waiting up to 2m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808" to be "running"
    Dec  3 12:33:15.042: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2.63923ms
    Dec  3 12:33:17.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008021274s
    Dec  3 12:33:19.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009048559s
    Dec  3 12:33:21.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007974611s
    Dec  3 12:33:23.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008713463s
    Dec  3 12:33:25.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008965292s
    Dec  3 12:33:27.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 12.00734653s
    Dec  3 12:33:29.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009848608s
    Dec  3 12:33:31.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 16.008049342s
    Dec  3 12:33:33.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 18.009687429s
    Dec  3 12:33:35.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 20.009703932s
    Dec  3 12:33:37.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 22.009094104s
    Dec  3 12:33:39.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010854237s
    Dec  3 12:33:41.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 26.009403039s
    Dec  3 12:33:43.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008175471s
    Dec  3 12:33:45.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 30.009045098s
    Dec  3 12:33:47.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006646733s
    Dec  3 12:33:49.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 34.010944406s
    Dec  3 12:33:51.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 36.007693271s
    Dec  3 12:33:53.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 38.009503804s
    Dec  3 12:33:55.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007051304s
    Dec  3 12:33:57.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007903328s
    Dec  3 12:33:59.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 44.008103914s
    Dec  3 12:34:01.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 46.007220249s
    Dec  3 12:34:03.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007236177s
    Dec  3 12:34:05.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 50.007546061s
    Dec  3 12:34:07.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007243016s
    Dec  3 12:34:09.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 54.008827696s
    Dec  3 12:34:11.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 56.007115049s
    Dec  3 12:34:13.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007732571s
    Dec  3 12:34:15.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007460246s
    Dec  3 12:34:17.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007747874s
    Dec  3 12:34:19.052: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012524083s
    Dec  3 12:34:21.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.007186104s
    Dec  3 12:34:23.053: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.014281231s
    Dec  3 12:34:25.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007634355s
    Dec  3 12:34:27.049: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009894885s
    Dec  3 12:34:29.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.008001759s
    Dec  3 12:34:31.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.008362846s
    Dec  3 12:34:33.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.008667805s
    Dec  3 12:34:35.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.008078006s
    Dec  3 12:34:37.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.007309083s
    Dec  3 12:34:39.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.008020276s
    Dec  3 12:34:41.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.008202161s
    Dec  3 12:34:43.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007529392s
    Dec  3 12:34:45.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.007362089s
    Dec  3 12:34:47.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006907723s
    Dec  3 12:34:49.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007597625s
    Dec  3 12:34:51.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007734021s
    Dec  3 12:34:53.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010560151s
    Dec  3 12:34:55.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.008623229s
    Dec  3 12:34:57.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009122309s
    Dec  3 12:34:59.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.00821511s
    Dec  3 12:35:01.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008795456s
    Dec  3 12:35:03.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007204012s
    Dec  3 12:35:05.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008990419s
    Dec  3 12:35:07.050: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.010554979s
    Dec  3 12:35:09.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007835594s
    Dec  3 12:35:11.047: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007436179s
    Dec  3 12:35:13.048: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.008545703s
    Dec  3 12:35:15.046: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.006959819s
    Dec  3 12:35:15.051: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.011778005s
    STEP: updating the pod 12/03/22 12:35:15.051
    Dec  3 12:35:15.571: INFO: Successfully updated pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100"
    STEP: waiting for pod running 12/03/22 12:35:15.571
    Dec  3 12:35:15.571: INFO: Waiting up to 2m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808" to be "running"
    Dec  3 12:35:15.576: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110786ms
    Dec  3 12:35:17.583: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100": Phase="Running", Reason="", readiness=true. Elapsed: 2.011179319s
    Dec  3 12:35:17.583: INFO: Pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" satisfied condition "running"
    STEP: deleting the pod gracefully 12/03/22 12:35:17.583
    Dec  3 12:35:17.583: INFO: Deleting pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" in namespace "var-expansion-808"
    Dec  3 12:35:17.594: INFO: Wait up to 5m0s for pod "var-expansion-c8bd4f6a-4cca-477f-945a-b40dae838100" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 12:35:49.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-808" for this suite. 12/03/22 12:35:49.609
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:35:49.616
Dec  3 12:35:49.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:35:49.617
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:35:49.636
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:35:49.639
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Dec  3 12:35:49.641: INFO: Creating deployment "webserver-deployment"
Dec  3 12:35:49.646: INFO: Waiting for observed generation 1
Dec  3 12:35:51.655: INFO: Waiting for all required pods to come up
Dec  3 12:35:51.664: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 12/03/22 12:35:51.664
Dec  3 12:35:51.664: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-b66t2" in namespace "deployment-1870" to be "running"
Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bfd8w" in namespace "deployment-1870" to be "running"
Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-blhdn" in namespace "deployment-1870" to be "running"
Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j79wz" in namespace "deployment-1870" to be "running"
Dec  3 12:35:51.669: INFO: Pod "webserver-deployment-845c8977d9-blhdn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026506ms
Dec  3 12:35:51.669: INFO: Pod "webserver-deployment-845c8977d9-j79wz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.434941ms
Dec  3 12:35:51.670: INFO: Pod "webserver-deployment-845c8977d9-bfd8w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.992355ms
Dec  3 12:35:51.670: INFO: Pod "webserver-deployment-845c8977d9-b66t2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.820794ms
Dec  3 12:35:53.675: INFO: Pod "webserver-deployment-845c8977d9-b66t2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010260458s
Dec  3 12:35:53.675: INFO: Pod "webserver-deployment-845c8977d9-b66t2" satisfied condition "running"
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-bfd8w": Phase="Running", Reason="", readiness=true. Elapsed: 2.011038712s
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-bfd8w" satisfied condition "running"
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-j79wz": Phase="Running", Reason="", readiness=true. Elapsed: 2.011152209s
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-j79wz" satisfied condition "running"
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-blhdn": Phase="Running", Reason="", readiness=true. Elapsed: 2.011428767s
Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-blhdn" satisfied condition "running"
Dec  3 12:35:53.676: INFO: Waiting for deployment "webserver-deployment" to complete
Dec  3 12:35:53.682: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec  3 12:35:53.702: INFO: Updating deployment webserver-deployment
Dec  3 12:35:53.702: INFO: Waiting for observed generation 2
Dec  3 12:35:55.713: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 12:35:55.717: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 12:35:55.719: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 12:35:55.736: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 12:35:55.736: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 12:35:55.742: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 12:35:55.748: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec  3 12:35:55.748: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec  3 12:35:55.757: INFO: Updating deployment webserver-deployment
Dec  3 12:35:55.757: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec  3 12:35:55.765: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 12:35:55.768: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:35:57.791: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1870  5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 13272 3 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ffedb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-03 12:35:55 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-03 12:35:56 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 12:35:57.794: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-1870  27cb47d3-07d7-449f-9f65-e5684d7599d8 13267 3 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 0xc003b23187 0xc003b23188}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b23228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:35:57.794: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec  3 12:35:57.794: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-1870  2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 13264 3 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 0xc003b23287 0xc003b23288}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b23318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:35:57.802: INFO: Pod "webserver-deployment-69b7448995-2mw8f" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2mw8f webserver-deployment-69b7448995- deployment-1870  7a5a6a65-1925-47ec-93a1-ff617646087b 13094 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff1e7 0xc003fff1e8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57zdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57zdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.802: INFO: Pod "webserver-deployment-69b7448995-44lvk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-44lvk webserver-deployment-69b7448995- deployment-1870  f0cda8e3-9432-4473-aef4-d52ede726d6b 13210 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff3d7 0xc003fff3d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q8fcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q8fcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.803: INFO: Pod "webserver-deployment-69b7448995-5lqfv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5lqfv webserver-deployment-69b7448995- deployment-1870  a63a3088-357c-4f05-870c-b511586cddba 13183 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff5c7 0xc003fff5c8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59xqc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59xqc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.235,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-6qgcd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6qgcd webserver-deployment-69b7448995- deployment-1870  1e164716-93d9-4432-9fe4-071b6ca3b7a1 13186 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff7f7 0xc003fff7f8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.236\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qlnp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qlnp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.236,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.236,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-9bbn8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9bbn8 webserver-deployment-69b7448995- deployment-1870  cd78c9eb-020e-491f-86f7-16bdbc1f5f67 13295 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffa17 0xc003fffa18}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6j48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6j48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-bh6s6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-bh6s6 webserver-deployment-69b7448995- deployment-1870  6dd7a396-0a77-4e10-a265-f3d3908d3d94 13234 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffc07 0xc003fffc08}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4d8t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4d8t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-dmhc7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dmhc7 webserver-deployment-69b7448995- deployment-1870  b7dbc6fc-a00f-45e4-b9fc-0c82fee82804 13274 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffdf7 0xc003fffdf8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n6r84,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n6r84,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-j2l2h" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-j2l2h webserver-deployment-69b7448995- deployment-1870  559846a0-a217-452b-9f40-97501a0b670c 13331 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003ffffe7 0xc003ffffe8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqt57,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqt57,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-jfph7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jfph7 webserver-deployment-69b7448995- deployment-1870  2f32af07-fbc0-403e-875d-9193b252e4a4 13124 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024963e7 0xc0024963e8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j2xm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j2xm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-mkdx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mkdx9 webserver-deployment-69b7448995- deployment-1870  6bc3178a-cede-476d-b1f4-56b072f143c6 13231 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024965d7 0xc0024965d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtpzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtpzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-qw6fs" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qw6fs webserver-deployment-69b7448995- deployment-1870  b8ed551b-317c-46a6-a343-5e742e10ce89 13225 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024967c7 0xc0024967c8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-528pp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-528pp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-z6qpx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-z6qpx webserver-deployment-69b7448995- deployment-1870  4947f41f-1860-4ceb-ac12-a745f1d751f0 13263 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024969b7 0xc0024969b8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmp5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmp5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-zh7bg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zh7bg webserver-deployment-69b7448995- deployment-1870  65705fde-728d-44ff-a7c1-de9ee8eb4c40 13189 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc002496b30 0xc002496b31}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-thksr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-thksr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.31,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-845c8977d9-2jxx6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2jxx6 webserver-deployment-845c8977d9- deployment-1870  9c32fd54-9f2f-4f9d-aa0f-7969df9a5df1 13054 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002496d47 0xc002496d48}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.29\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tw2gh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tw2gh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.29,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bfed24018edb2f8527ed71b605cd61a6e08cfa974edd66a387bf4e5eb689114a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-845c8977d9-2pwc8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2pwc8 webserver-deployment-845c8977d9- deployment-1870  1e22d615-85b2-458e-bcc8-8152e53f638c 13043 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002496f37 0xc002496f38}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bb8f9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bb8f9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.233,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0e3fc76e36335a6a58125585c1b58df7716b07c326efe482fb042f2b80a79258,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-4jwn6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4jwn6 webserver-deployment-845c8977d9- deployment-1870  3fdfd14c-b3b0-4056-8893-6a4ee99533bd 13241 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497127 0xc002497128}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-txmrg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-txmrg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-8lct9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8lct9 webserver-deployment-845c8977d9- deployment-1870  6c18d77f-bf6e-419e-bf87-cd8d3c1ff2ab 13059 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497290 0xc002497291}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v9mjk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v9mjk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.28,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b88a3cd9aac4b176340a40325b9d8e9348651a3ea6e63afa38c80fb7d145fca1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-8npx7" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8npx7 webserver-deployment-845c8977d9- deployment-1870  7f5c8af1-52a1-4c4f-a7aa-59613e259faa 13057 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497477 0xc002497478}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qzd7s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qzd7s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.30,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c7129af4da33f9cc5e7993ac60899bda455cd66feba163c50b131de8eb527dad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-b66t2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b66t2 webserver-deployment-845c8977d9- deployment-1870  9817796e-a84f-4220-b26e-d8bcba874e3f 13072 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497667 0xc002497668}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kjxfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kjxfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.87,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://07bbd5570973cceb13ab4aeca774676a6422dcb13c6797e9f8a7deba195b7122,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-bfd8w" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bfd8w webserver-deployment-845c8977d9- deployment-1870  5189223d-33d3-434e-bd54-1d33355dda28 13066 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497857 0xc002497858}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5qfd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5qfd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.85,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6f84917bd481599e5ed0dc4f355a955878ba34a5d100c11459e979de54c56317,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.808: INFO: Pod "webserver-deployment-845c8977d9-cdck6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cdck6 webserver-deployment-845c8977d9- deployment-1870  46a3ce1b-2fbf-4ba7-a72e-6f078a68de79 13039 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497a57 0xc002497a58}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wpl2l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wpl2l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.232,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5e35fd78e5f1e1c8020f2448519dbef898d0fe05de04ca5447b4a6bf9afcb7e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.808: INFO: Pod "webserver-deployment-845c8977d9-dtxw9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dtxw9 webserver-deployment-845c8977d9- deployment-1870  4404a490-ef13-49a2-9c72-80401bc57061 13365 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497c47 0xc002497c48}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7rsmt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7rsmt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-f9kv9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-f9kv9 webserver-deployment-845c8977d9- deployment-1870  ea3b87bd-5982-4385-a9a3-322aa56f108a 13265 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497e17 0xc002497e18}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hmjpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hmjpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-fd8rd" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fd8rd webserver-deployment-845c8977d9- deployment-1870  26cefd01-4621-4bd7-addd-5b9a7ed051c6 13253 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497fe7 0xc002497fe8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nsmf9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nsmf9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-l472z" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-l472z webserver-deployment-845c8977d9- deployment-1870  6cf22b70-1e08-4d18-b391-b35196fb9c9b 13046 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930150 0xc002930151}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-drg9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-drg9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.234,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6b3deef3e47c804d628ddeb02c083787802e196dd93eb16ca8d14cb448693ee4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-l9652" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-l9652 webserver-deployment-845c8977d9- deployment-1870  cd4238d5-48b5-467d-a4e3-7f48139c8f8a 13262 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930337 0xc002930338}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-647k5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-647k5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-ngb5z" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ngb5z webserver-deployment-845c8977d9- deployment-1870  e0baf46a-2a2a-4208-86e9-3a226ff5e131 13275 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930507 0xc002930508}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-56fwf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-56fwf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-nl7tz" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nl7tz webserver-deployment-845c8977d9- deployment-1870  028dbcc3-43dc-465e-afd7-756cabd5e5dd 13360 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc0029306d7 0xc0029306d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pxhf7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pxhf7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-p2nqc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2nqc webserver-deployment-845c8977d9- deployment-1870  9926261d-2053-4768-807c-731f58e850a6 13207 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc0029308a7 0xc0029308a8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pdxqt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pdxqt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-q7wsr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-q7wsr webserver-deployment-845c8977d9- deployment-1870  9f559974-688f-4e2c-8d00-7a2ec073716b 13270 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930a77 0xc002930a78}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-chklc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-chklc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-qjprd" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qjprd webserver-deployment-845c8977d9- deployment-1870  75f3d269-727b-4ca7-9dfc-a65500b9ac44 13249 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930df7 0xc002930df8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-88hkh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-88hkh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-qkb66" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qkb66 webserver-deployment-845c8977d9- deployment-1870  8537b6c8-772a-4eab-b5dc-363472bda0b7 13282 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002931157 0xc002931158}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gwtsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gwtsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-ts22f" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ts22f webserver-deployment-845c8977d9- deployment-1870  aaa92bf7-050f-4f27-8592-badad867a651 13259 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002931327 0xc002931328}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4bxxw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4bxxw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:35:57.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1870" for this suite. 12/03/22 12:35:57.817
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":99,"skipped":1946,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.209 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:35:49.616
    Dec  3 12:35:49.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:35:49.617
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:35:49.636
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:35:49.639
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Dec  3 12:35:49.641: INFO: Creating deployment "webserver-deployment"
    Dec  3 12:35:49.646: INFO: Waiting for observed generation 1
    Dec  3 12:35:51.655: INFO: Waiting for all required pods to come up
    Dec  3 12:35:51.664: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 12/03/22 12:35:51.664
    Dec  3 12:35:51.664: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-b66t2" in namespace "deployment-1870" to be "running"
    Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bfd8w" in namespace "deployment-1870" to be "running"
    Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-blhdn" in namespace "deployment-1870" to be "running"
    Dec  3 12:35:51.665: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j79wz" in namespace "deployment-1870" to be "running"
    Dec  3 12:35:51.669: INFO: Pod "webserver-deployment-845c8977d9-blhdn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026506ms
    Dec  3 12:35:51.669: INFO: Pod "webserver-deployment-845c8977d9-j79wz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.434941ms
    Dec  3 12:35:51.670: INFO: Pod "webserver-deployment-845c8977d9-bfd8w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.992355ms
    Dec  3 12:35:51.670: INFO: Pod "webserver-deployment-845c8977d9-b66t2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.820794ms
    Dec  3 12:35:53.675: INFO: Pod "webserver-deployment-845c8977d9-b66t2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010260458s
    Dec  3 12:35:53.675: INFO: Pod "webserver-deployment-845c8977d9-b66t2" satisfied condition "running"
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-bfd8w": Phase="Running", Reason="", readiness=true. Elapsed: 2.011038712s
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-bfd8w" satisfied condition "running"
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-j79wz": Phase="Running", Reason="", readiness=true. Elapsed: 2.011152209s
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-j79wz" satisfied condition "running"
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-blhdn": Phase="Running", Reason="", readiness=true. Elapsed: 2.011428767s
    Dec  3 12:35:53.676: INFO: Pod "webserver-deployment-845c8977d9-blhdn" satisfied condition "running"
    Dec  3 12:35:53.676: INFO: Waiting for deployment "webserver-deployment" to complete
    Dec  3 12:35:53.682: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Dec  3 12:35:53.702: INFO: Updating deployment webserver-deployment
    Dec  3 12:35:53.702: INFO: Waiting for observed generation 2
    Dec  3 12:35:55.713: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Dec  3 12:35:55.717: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Dec  3 12:35:55.719: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec  3 12:35:55.736: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Dec  3 12:35:55.736: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Dec  3 12:35:55.742: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec  3 12:35:55.748: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Dec  3 12:35:55.748: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Dec  3 12:35:55.757: INFO: Updating deployment webserver-deployment
    Dec  3 12:35:55.757: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Dec  3 12:35:55.765: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Dec  3 12:35:55.768: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:35:57.791: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-1870  5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 13272 3 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ffedb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-03 12:35:55 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-03 12:35:56 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Dec  3 12:35:57.794: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-1870  27cb47d3-07d7-449f-9f65-e5684d7599d8 13267 3 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 0xc003b23187 0xc003b23188}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b23228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:35:57.794: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Dec  3 12:35:57.794: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-1870  2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 13264 3 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3 0xc003b23287 0xc003b23288}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d82ebd8-0ab3-4eb1-b46c-cd563fa46aa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b23318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:35:57.802: INFO: Pod "webserver-deployment-69b7448995-2mw8f" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2mw8f webserver-deployment-69b7448995- deployment-1870  7a5a6a65-1925-47ec-93a1-ff617646087b 13094 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff1e7 0xc003fff1e8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57zdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57zdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.802: INFO: Pod "webserver-deployment-69b7448995-44lvk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-44lvk webserver-deployment-69b7448995- deployment-1870  f0cda8e3-9432-4473-aef4-d52ede726d6b 13210 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff3d7 0xc003fff3d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q8fcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q8fcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.803: INFO: Pod "webserver-deployment-69b7448995-5lqfv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5lqfv webserver-deployment-69b7448995- deployment-1870  a63a3088-357c-4f05-870c-b511586cddba 13183 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff5c7 0xc003fff5c8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59xqc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59xqc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.235,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-6qgcd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6qgcd webserver-deployment-69b7448995- deployment-1870  1e164716-93d9-4432-9fe4-071b6ca3b7a1 13186 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fff7f7 0xc003fff7f8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.236\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qlnp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qlnp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.236,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.236,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-9bbn8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9bbn8 webserver-deployment-69b7448995- deployment-1870  cd78c9eb-020e-491f-86f7-16bdbc1f5f67 13295 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffa17 0xc003fffa18}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6j48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6j48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-bh6s6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-bh6s6 webserver-deployment-69b7448995- deployment-1870  6dd7a396-0a77-4e10-a265-f3d3908d3d94 13234 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffc07 0xc003fffc08}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4d8t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4d8t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-dmhc7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dmhc7 webserver-deployment-69b7448995- deployment-1870  b7dbc6fc-a00f-45e4-b9fc-0c82fee82804 13274 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003fffdf7 0xc003fffdf8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n6r84,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n6r84,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.804: INFO: Pod "webserver-deployment-69b7448995-j2l2h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-j2l2h webserver-deployment-69b7448995- deployment-1870  559846a0-a217-452b-9f40-97501a0b670c 13331 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc003ffffe7 0xc003ffffe8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqt57,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqt57,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-jfph7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jfph7 webserver-deployment-69b7448995- deployment-1870  2f32af07-fbc0-403e-875d-9193b252e4a4 13124 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024963e7 0xc0024963e8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j2xm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j2xm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-mkdx9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mkdx9 webserver-deployment-69b7448995- deployment-1870  6bc3178a-cede-476d-b1f4-56b072f143c6 13231 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024965d7 0xc0024965d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtpzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtpzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-qw6fs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qw6fs webserver-deployment-69b7448995- deployment-1870  b8ed551b-317c-46a6-a343-5e742e10ce89 13225 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024967c7 0xc0024967c8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-528pp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-528pp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-z6qpx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-z6qpx webserver-deployment-69b7448995- deployment-1870  4947f41f-1860-4ceb-ac12-a745f1d751f0 13263 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc0024969b7 0xc0024969b8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmp5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmp5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-69b7448995-zh7bg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zh7bg webserver-deployment-69b7448995- deployment-1870  65705fde-728d-44ff-a7c1-de9ee8eb4c40 13189 0 2022-12-03 12:35:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 27cb47d3-07d7-449f-9f65-e5684d7599d8 0xc002496b30 0xc002496b31}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"27cb47d3-07d7-449f-9f65-e5684d7599d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-thksr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-thksr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.31,StartTime:2022-12-03 12:35:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-845c8977d9-2jxx6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2jxx6 webserver-deployment-845c8977d9- deployment-1870  9c32fd54-9f2f-4f9d-aa0f-7969df9a5df1 13054 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002496d47 0xc002496d48}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.29\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tw2gh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tw2gh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.29,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bfed24018edb2f8527ed71b605cd61a6e08cfa974edd66a387bf4e5eb689114a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.805: INFO: Pod "webserver-deployment-845c8977d9-2pwc8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2pwc8 webserver-deployment-845c8977d9- deployment-1870  1e22d615-85b2-458e-bcc8-8152e53f638c 13043 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002496f37 0xc002496f38}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bb8f9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bb8f9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.233,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0e3fc76e36335a6a58125585c1b58df7716b07c326efe482fb042f2b80a79258,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-4jwn6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4jwn6 webserver-deployment-845c8977d9- deployment-1870  3fdfd14c-b3b0-4056-8893-6a4ee99533bd 13241 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497127 0xc002497128}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-txmrg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-txmrg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-8lct9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8lct9 webserver-deployment-845c8977d9- deployment-1870  6c18d77f-bf6e-419e-bf87-cd8d3c1ff2ab 13059 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497290 0xc002497291}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v9mjk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v9mjk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.28,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b88a3cd9aac4b176340a40325b9d8e9348651a3ea6e63afa38c80fb7d145fca1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-8npx7" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8npx7 webserver-deployment-845c8977d9- deployment-1870  7f5c8af1-52a1-4c4f-a7aa-59613e259faa 13057 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497477 0xc002497478}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qzd7s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qzd7s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:192.168.197.30,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c7129af4da33f9cc5e7993ac60899bda455cd66feba163c50b131de8eb527dad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-b66t2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b66t2 webserver-deployment-845c8977d9- deployment-1870  9817796e-a84f-4220-b26e-d8bcba874e3f 13072 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497667 0xc002497668}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kjxfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kjxfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.87,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://07bbd5570973cceb13ab4aeca774676a6422dcb13c6797e9f8a7deba195b7122,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.806: INFO: Pod "webserver-deployment-845c8977d9-bfd8w" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bfd8w webserver-deployment-845c8977d9- deployment-1870  5189223d-33d3-434e-bd54-1d33355dda28 13066 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497857 0xc002497858}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5qfd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5qfd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.85,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6f84917bd481599e5ed0dc4f355a955878ba34a5d100c11459e979de54c56317,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.808: INFO: Pod "webserver-deployment-845c8977d9-cdck6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cdck6 webserver-deployment-845c8977d9- deployment-1870  46a3ce1b-2fbf-4ba7-a72e-6f078a68de79 13039 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497a57 0xc002497a58}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wpl2l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wpl2l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.232,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5e35fd78e5f1e1c8020f2448519dbef898d0fe05de04ca5447b4a6bf9afcb7e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.808: INFO: Pod "webserver-deployment-845c8977d9-dtxw9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dtxw9 webserver-deployment-845c8977d9- deployment-1870  4404a490-ef13-49a2-9c72-80401bc57061 13365 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497c47 0xc002497c48}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7rsmt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7rsmt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-f9kv9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-f9kv9 webserver-deployment-845c8977d9- deployment-1870  ea3b87bd-5982-4385-a9a3-322aa56f108a 13265 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497e17 0xc002497e18}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hmjpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hmjpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-fd8rd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fd8rd webserver-deployment-845c8977d9- deployment-1870  26cefd01-4621-4bd7-addd-5b9a7ed051c6 13253 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002497fe7 0xc002497fe8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nsmf9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nsmf9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-l472z" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-l472z webserver-deployment-845c8977d9- deployment-1870  6cf22b70-1e08-4d18-b391-b35196fb9c9b 13046 0 2022-12-03 12:35:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930150 0xc002930151}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-drg9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-drg9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.234,StartTime:2022-12-03 12:35:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:35:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6b3deef3e47c804d628ddeb02c083787802e196dd93eb16ca8d14cb448693ee4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.809: INFO: Pod "webserver-deployment-845c8977d9-l9652" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-l9652 webserver-deployment-845c8977d9- deployment-1870  cd4238d5-48b5-467d-a4e3-7f48139c8f8a 13262 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930337 0xc002930338}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-647k5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-647k5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-ngb5z" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ngb5z webserver-deployment-845c8977d9- deployment-1870  e0baf46a-2a2a-4208-86e9-3a226ff5e131 13275 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930507 0xc002930508}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-56fwf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-56fwf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-4-162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.4.162,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-nl7tz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nl7tz webserver-deployment-845c8977d9- deployment-1870  028dbcc3-43dc-465e-afd7-756cabd5e5dd 13360 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc0029306d7 0xc0029306d8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pxhf7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pxhf7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-p2nqc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p2nqc webserver-deployment-845c8977d9- deployment-1870  9926261d-2053-4768-807c-731f58e850a6 13207 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc0029308a7 0xc0029308a8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pdxqt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pdxqt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.810: INFO: Pod "webserver-deployment-845c8977d9-q7wsr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-q7wsr webserver-deployment-845c8977d9- deployment-1870  9f559974-688f-4e2c-8d00-7a2ec073716b 13270 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930a77 0xc002930a78}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-chklc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-chklc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-qjprd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qjprd webserver-deployment-845c8977d9- deployment-1870  75f3d269-727b-4ca7-9dfc-a65500b9ac44 13249 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002930df7 0xc002930df8}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-88hkh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-88hkh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-qkb66" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qkb66 webserver-deployment-845c8977d9- deployment-1870  8537b6c8-772a-4eab-b5dc-363472bda0b7 13282 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002931157 0xc002931158}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gwtsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gwtsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec  3 12:35:57.812: INFO: Pod "webserver-deployment-845c8977d9-ts22f" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ts22f webserver-deployment-845c8977d9- deployment-1870  aaa92bf7-050f-4f27-8592-badad867a651 13259 0 2022-12-03 12:35:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8 0xc002931327 0xc002931328}] [] [{kube-controller-manager Update v1 2022-12-03 12:35:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2cfd4f21-b1f7-4f22-83b0-0e1e7044c4f8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:35:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4bxxw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4bxxw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:35:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 12:35:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:35:57.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1870" for this suite. 12/03/22 12:35:57.817
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:35:57.826
Dec  3 12:35:57.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption 12/03/22 12:35:57.828
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:35:57.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:35:57.856
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec  3 12:35:57.879: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 12:36:57.901: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:36:57.905
Dec  3 12:36:57.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption-path 12/03/22 12:36:57.907
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:57.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:57.93
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Dec  3 12:36:57.951: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Dec  3 12:36:57.956: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Dec  3 12:36:57.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3629" for this suite. 12/03/22 12:36:57.985
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:36:58.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4674" for this suite. 12/03/22 12:36:58.023
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":100,"skipped":1948,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.278 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:35:57.826
    Dec  3 12:35:57.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption 12/03/22 12:35:57.828
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:35:57.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:35:57.856
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec  3 12:35:57.879: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 12:36:57.901: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:36:57.905
    Dec  3 12:36:57.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption-path 12/03/22 12:36:57.907
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:57.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:57.93
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Dec  3 12:36:57.951: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Dec  3 12:36:57.956: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Dec  3 12:36:57.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-3629" for this suite. 12/03/22 12:36:57.985
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:36:58.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4674" for this suite. 12/03/22 12:36:58.023
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:36:58.107
Dec  3 12:36:58.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:36:58.109
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:58.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:58.142
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Dec  3 12:36:58.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:36:58.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-882" for this suite. 12/03/22 12:36:58.705
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":101,"skipped":1981,"failed":0}
------------------------------
â€¢ [0.612 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:36:58.107
    Dec  3 12:36:58.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:36:58.109
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:58.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:58.142
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Dec  3 12:36:58.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:36:58.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-882" for this suite. 12/03/22 12:36:58.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:36:58.722
Dec  3 12:36:58.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename init-container 12/03/22 12:36:58.723
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:58.742
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:58.745
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 12/03/22 12:36:58.748
Dec  3 12:36:58.748: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 12:37:03.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9587" for this suite. 12/03/22 12:37:03.264
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":102,"skipped":1998,"failed":0}
------------------------------
â€¢ [4.553 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:36:58.722
    Dec  3 12:36:58.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename init-container 12/03/22 12:36:58.723
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:36:58.742
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:36:58.745
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 12/03/22 12:36:58.748
    Dec  3 12:36:58.748: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 12:37:03.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9587" for this suite. 12/03/22 12:37:03.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:03.275
Dec  3 12:37:03.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:37:03.276
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:03.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:03.321
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 12/03/22 12:37:03.324
Dec  3 12:37:03.335: INFO: Waiting up to 5m0s for pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e" in namespace "emptydir-45" to be "Succeeded or Failed"
Dec  3 12:37:03.339: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667589ms
Dec  3 12:37:05.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008277075s
Dec  3 12:37:07.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007912604s
STEP: Saw pod success 12/03/22 12:37:07.344
Dec  3 12:37:07.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e" satisfied condition "Succeeded or Failed"
Dec  3 12:37:07.352: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e container test-container: <nil>
STEP: delete the pod 12/03/22 12:37:07.372
Dec  3 12:37:07.384: INFO: Waiting for pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e to disappear
Dec  3 12:37:07.388: INFO: Pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:37:07.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-45" for this suite. 12/03/22 12:37:07.393
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":2008,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:03.275
    Dec  3 12:37:03.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:37:03.276
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:03.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:03.321
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/03/22 12:37:03.324
    Dec  3 12:37:03.335: INFO: Waiting up to 5m0s for pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e" in namespace "emptydir-45" to be "Succeeded or Failed"
    Dec  3 12:37:03.339: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667589ms
    Dec  3 12:37:05.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008277075s
    Dec  3 12:37:07.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007912604s
    STEP: Saw pod success 12/03/22 12:37:07.344
    Dec  3 12:37:07.344: INFO: Pod "pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e" satisfied condition "Succeeded or Failed"
    Dec  3 12:37:07.352: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e container test-container: <nil>
    STEP: delete the pod 12/03/22 12:37:07.372
    Dec  3 12:37:07.384: INFO: Waiting for pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e to disappear
    Dec  3 12:37:07.388: INFO: Pod pod-b8f32cb4-e878-42eb-a7ef-964ac56e983e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:37:07.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-45" for this suite. 12/03/22 12:37:07.393
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:07.402
Dec  3 12:37:07.402: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context 12/03/22 12:37:07.403
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:07.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:07.429
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/03/22 12:37:07.432
Dec  3 12:37:07.443: INFO: Waiting up to 5m0s for pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f" in namespace "security-context-4770" to be "Succeeded or Failed"
Dec  3 12:37:07.448: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.975419ms
Dec  3 12:37:09.452: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009520762s
Dec  3 12:37:11.453: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010641934s
STEP: Saw pod success 12/03/22 12:37:11.453
Dec  3 12:37:11.454: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f" satisfied condition "Succeeded or Failed"
Dec  3 12:37:11.458: INFO: Trying to get logs from node ip-172-31-38-234 pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f container test-container: <nil>
STEP: delete the pod 12/03/22 12:37:11.466
Dec  3 12:37:11.477: INFO: Waiting for pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f to disappear
Dec  3 12:37:11.481: INFO: Pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 12:37:11.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4770" for this suite. 12/03/22 12:37:11.485
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":104,"skipped":2017,"failed":0}
------------------------------
â€¢ [4.093 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:07.402
    Dec  3 12:37:07.402: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context 12/03/22 12:37:07.403
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:07.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:07.429
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/03/22 12:37:07.432
    Dec  3 12:37:07.443: INFO: Waiting up to 5m0s for pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f" in namespace "security-context-4770" to be "Succeeded or Failed"
    Dec  3 12:37:07.448: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.975419ms
    Dec  3 12:37:09.452: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009520762s
    Dec  3 12:37:11.453: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010641934s
    STEP: Saw pod success 12/03/22 12:37:11.453
    Dec  3 12:37:11.454: INFO: Pod "security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f" satisfied condition "Succeeded or Failed"
    Dec  3 12:37:11.458: INFO: Trying to get logs from node ip-172-31-38-234 pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f container test-container: <nil>
    STEP: delete the pod 12/03/22 12:37:11.466
    Dec  3 12:37:11.477: INFO: Waiting for pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f to disappear
    Dec  3 12:37:11.481: INFO: Pod security-context-e9b8d875-1817-4358-b53b-6a98e6d8887f no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 12:37:11.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4770" for this suite. 12/03/22 12:37:11.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:11.501
Dec  3 12:37:11.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:37:11.503
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:11.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:11.536
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/03/22 12:37:11.538
Dec  3 12:37:11.549: INFO: Waiting up to 5m0s for pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c" in namespace "emptydir-8784" to be "Succeeded or Failed"
Dec  3 12:37:11.555: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.449348ms
Dec  3 12:37:13.561: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011459192s
Dec  3 12:37:15.561: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012208832s
STEP: Saw pod success 12/03/22 12:37:15.561
Dec  3 12:37:15.562: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c" satisfied condition "Succeeded or Failed"
Dec  3 12:37:15.566: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c container test-container: <nil>
STEP: delete the pod 12/03/22 12:37:15.574
Dec  3 12:37:15.586: INFO: Waiting for pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c to disappear
Dec  3 12:37:15.590: INFO: Pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:37:15.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8784" for this suite. 12/03/22 12:37:15.595
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":105,"skipped":2052,"failed":0}
------------------------------
â€¢ [4.102 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:11.501
    Dec  3 12:37:11.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:37:11.503
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:11.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:11.536
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/03/22 12:37:11.538
    Dec  3 12:37:11.549: INFO: Waiting up to 5m0s for pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c" in namespace "emptydir-8784" to be "Succeeded or Failed"
    Dec  3 12:37:11.555: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.449348ms
    Dec  3 12:37:13.561: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011459192s
    Dec  3 12:37:15.561: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012208832s
    STEP: Saw pod success 12/03/22 12:37:15.561
    Dec  3 12:37:15.562: INFO: Pod "pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c" satisfied condition "Succeeded or Failed"
    Dec  3 12:37:15.566: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c container test-container: <nil>
    STEP: delete the pod 12/03/22 12:37:15.574
    Dec  3 12:37:15.586: INFO: Waiting for pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c to disappear
    Dec  3 12:37:15.590: INFO: Pod pod-d38d8c00-70ba-4a42-90a1-16586c9baf3c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:37:15.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8784" for this suite. 12/03/22 12:37:15.595
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:15.606
Dec  3 12:37:15.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:37:15.607
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:15.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:15.631
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-3885 12/03/22 12:37:15.635
STEP: creating a selector 12/03/22 12:37:15.635
STEP: Creating the service pods in kubernetes 12/03/22 12:37:15.636
Dec  3 12:37:15.637: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec  3 12:37:15.673: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3885" to be "running and ready"
Dec  3 12:37:15.681: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.181774ms
Dec  3 12:37:15.682: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:37:17.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013862528s
Dec  3 12:37:17.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:19.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013976238s
Dec  3 12:37:19.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:21.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013752597s
Dec  3 12:37:21.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:23.688: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014972076s
Dec  3 12:37:23.688: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:25.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013798216s
Dec  3 12:37:25.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:27.689: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015637541s
Dec  3 12:37:27.689: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:29.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013778861s
Dec  3 12:37:29.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:31.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01359703s
Dec  3 12:37:31.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:33.688: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014591712s
Dec  3 12:37:33.688: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:35.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.012340085s
Dec  3 12:37:35.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:37:37.689: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.015334823s
Dec  3 12:37:37.689: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec  3 12:37:37.689: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec  3 12:37:37.692: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3885" to be "running and ready"
Dec  3 12:37:37.696: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.788802ms
Dec  3 12:37:37.696: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec  3 12:37:37.696: INFO: Pod "netserver-1" satisfied condition "running and ready"
Dec  3 12:37:37.699: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3885" to be "running and ready"
Dec  3 12:37:37.702: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.782044ms
Dec  3 12:37:37.702: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Dec  3 12:37:37.702: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 12/03/22 12:37:37.706
Dec  3 12:37:37.724: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3885" to be "running"
Dec  3 12:37:37.731: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.302409ms
Dec  3 12:37:39.736: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011843546s
Dec  3 12:37:39.736: INFO: Pod "test-container-pod" satisfied condition "running"
Dec  3 12:37:39.741: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3885" to be "running"
Dec  3 12:37:39.745: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.615546ms
Dec  3 12:37:39.745: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec  3 12:37:39.748: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Dec  3 12:37:39.748: INFO: Going to poll 192.168.197.103 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:37:39.752: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.197.103 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:37:39.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:37:39.753: INFO: ExecWithOptions: Clientset creation
Dec  3 12:37:39.753: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.197.103+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:37:40.830: INFO: Found all 1 expected endpoints: [netserver-0]
Dec  3 12:37:40.830: INFO: Going to poll 192.168.197.38 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:37:40.835: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.197.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:37:40.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:37:40.835: INFO: ExecWithOptions: Clientset creation
Dec  3 12:37:40.835: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.197.38+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:37:41.916: INFO: Found all 1 expected endpoints: [netserver-1]
Dec  3 12:37:41.916: INFO: Going to poll 192.168.71.243 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Dec  3 12:37:41.919: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.71.243 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:37:41.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:37:41.920: INFO: ExecWithOptions: Clientset creation
Dec  3 12:37:41.920: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.71.243+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec  3 12:37:43.000: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec  3 12:37:43.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3885" for this suite. 12/03/22 12:37:43.005
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":106,"skipped":2067,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.407 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:15.606
    Dec  3 12:37:15.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:37:15.607
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:15.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:15.631
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-3885 12/03/22 12:37:15.635
    STEP: creating a selector 12/03/22 12:37:15.635
    STEP: Creating the service pods in kubernetes 12/03/22 12:37:15.636
    Dec  3 12:37:15.637: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec  3 12:37:15.673: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3885" to be "running and ready"
    Dec  3 12:37:15.681: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.181774ms
    Dec  3 12:37:15.682: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:37:17.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013862528s
    Dec  3 12:37:17.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:19.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013976238s
    Dec  3 12:37:19.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:21.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013752597s
    Dec  3 12:37:21.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:23.688: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014972076s
    Dec  3 12:37:23.688: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:25.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013798216s
    Dec  3 12:37:25.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:27.689: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015637541s
    Dec  3 12:37:27.689: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:29.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013778861s
    Dec  3 12:37:29.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:31.687: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01359703s
    Dec  3 12:37:31.687: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:33.688: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014591712s
    Dec  3 12:37:33.688: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:35.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.012340085s
    Dec  3 12:37:35.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:37:37.689: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.015334823s
    Dec  3 12:37:37.689: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec  3 12:37:37.689: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec  3 12:37:37.692: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3885" to be "running and ready"
    Dec  3 12:37:37.696: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.788802ms
    Dec  3 12:37:37.696: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec  3 12:37:37.696: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Dec  3 12:37:37.699: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3885" to be "running and ready"
    Dec  3 12:37:37.702: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.782044ms
    Dec  3 12:37:37.702: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Dec  3 12:37:37.702: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 12/03/22 12:37:37.706
    Dec  3 12:37:37.724: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3885" to be "running"
    Dec  3 12:37:37.731: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.302409ms
    Dec  3 12:37:39.736: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011843546s
    Dec  3 12:37:39.736: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec  3 12:37:39.741: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3885" to be "running"
    Dec  3 12:37:39.745: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.615546ms
    Dec  3 12:37:39.745: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec  3 12:37:39.748: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Dec  3 12:37:39.748: INFO: Going to poll 192.168.197.103 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:37:39.752: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.197.103 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:37:39.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:37:39.753: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:37:39.753: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.197.103+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:37:40.830: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec  3 12:37:40.830: INFO: Going to poll 192.168.197.38 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:37:40.835: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.197.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:37:40.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:37:40.835: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:37:40.835: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.197.38+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:37:41.916: INFO: Found all 1 expected endpoints: [netserver-1]
    Dec  3 12:37:41.916: INFO: Going to poll 192.168.71.243 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Dec  3 12:37:41.919: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.71.243 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3885 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:37:41.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:37:41.920: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:37:41.920: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3885/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.71.243+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec  3 12:37:43.000: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec  3 12:37:43.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3885" for this suite. 12/03/22 12:37:43.005
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:43.014
Dec  3 12:37:43.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:37:43.015
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:43.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:43.038
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Dec  3 12:37:43.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-9145 version'
Dec  3 12:37:43.100: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Dec  3 12:37:43.100: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:37:43.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9145" for this suite. 12/03/22 12:37:43.105
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":107,"skipped":2068,"failed":0}
------------------------------
â€¢ [0.099 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:43.014
    Dec  3 12:37:43.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:37:43.015
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:43.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:43.038
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Dec  3 12:37:43.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-9145 version'
    Dec  3 12:37:43.100: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Dec  3 12:37:43.100: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:37:43.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9145" for this suite. 12/03/22 12:37:43.105
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:43.114
Dec  3 12:37:43.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:37:43.115
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:43.139
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:43.142
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Dec  3 12:37:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:37:46.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-938" for this suite. 12/03/22 12:37:46.373
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":108,"skipped":2070,"failed":0}
------------------------------
â€¢ [3.272 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:43.114
    Dec  3 12:37:43.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 12:37:43.115
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:43.139
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:43.142
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Dec  3 12:37:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:37:46.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-938" for this suite. 12/03/22 12:37:46.373
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:46.387
Dec  3 12:37:46.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption 12/03/22 12:37:46.387
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:46.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:46.412
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:46.415
Dec  3 12:37:46.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption-2 12/03/22 12:37:46.416
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:46.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:46.444
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 12/03/22 12:37:46.456
STEP: Waiting for the pdb to be processed 12/03/22 12:37:48.484
STEP: Waiting for the pdb to be processed 12/03/22 12:37:48.506
STEP: listing a collection of PDBs across all namespaces 12/03/22 12:37:48.547
STEP: listing a collection of PDBs in namespace disruption-308 12/03/22 12:37:48.555
STEP: deleting a collection of PDBs 12/03/22 12:37:48.568
STEP: Waiting for the PDB collection to be deleted 12/03/22 12:37:48.584
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Dec  3 12:37:48.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-6794" for this suite. 12/03/22 12:37:48.596
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec  3 12:37:48.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-308" for this suite. 12/03/22 12:37:48.623
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":109,"skipped":2078,"failed":0}
------------------------------
â€¢ [2.247 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:46.387
    Dec  3 12:37:46.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption 12/03/22 12:37:46.387
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:46.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:46.412
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:46.415
    Dec  3 12:37:46.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption-2 12/03/22 12:37:46.416
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:46.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:46.444
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 12/03/22 12:37:46.456
    STEP: Waiting for the pdb to be processed 12/03/22 12:37:48.484
    STEP: Waiting for the pdb to be processed 12/03/22 12:37:48.506
    STEP: listing a collection of PDBs across all namespaces 12/03/22 12:37:48.547
    STEP: listing a collection of PDBs in namespace disruption-308 12/03/22 12:37:48.555
    STEP: deleting a collection of PDBs 12/03/22 12:37:48.568
    STEP: Waiting for the PDB collection to be deleted 12/03/22 12:37:48.584
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Dec  3 12:37:48.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-6794" for this suite. 12/03/22 12:37:48.596
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec  3 12:37:48.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-308" for this suite. 12/03/22 12:37:48.623
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:48.634
Dec  3 12:37:48.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 12:37:48.636
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:48.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:48.659
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Dec  3 12:37:48.692: INFO: Create a RollingUpdate DaemonSet
Dec  3 12:37:48.701: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 12:37:48.705: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:48.705: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:48.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 12:37:48.715: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:37:49.724: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:49.725: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:49.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec  3 12:37:49.729: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 12:37:50.719: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:50.719: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:50.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 12:37:50.724: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 12:37:51.720: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:51.721: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:51.725: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 12:37:51.725: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Dec  3 12:37:51.725: INFO: Update the DaemonSet to trigger a rollout
Dec  3 12:37:51.736: INFO: Updating DaemonSet daemon-set
Dec  3 12:37:54.756: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 12:37:54.768: INFO: Updating DaemonSet daemon-set
Dec  3 12:37:54.768: INFO: Make sure DaemonSet rollback is complete
Dec  3 12:37:54.771: INFO: Wrong image for pod: daemon-set-l28mw. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Dec  3 12:37:54.771: INFO: Pod daemon-set-l28mw is not available
Dec  3 12:37:54.777: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:54.777: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:55.792: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:55.792: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:56.781: INFO: Pod daemon-set-rlwvw is not available
Dec  3 12:37:56.785: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 12:37:56.785: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 12:37:56.792
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8125, will wait for the garbage collector to delete the pods 12/03/22 12:37:56.792
Dec  3 12:37:56.855: INFO: Deleting DaemonSet.extensions daemon-set took: 7.215741ms
Dec  3 12:37:56.955: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.644592ms
Dec  3 12:37:58.063: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 12:37:58.063: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 12:37:58.067: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14518"},"items":null}

Dec  3 12:37:58.071: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14518"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:37:58.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8125" for this suite. 12/03/22 12:37:58.102
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":110,"skipped":2080,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.474 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:48.634
    Dec  3 12:37:48.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 12:37:48.636
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:48.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:48.659
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Dec  3 12:37:48.692: INFO: Create a RollingUpdate DaemonSet
    Dec  3 12:37:48.701: INFO: Check that daemon pods launch on every node of the cluster
    Dec  3 12:37:48.705: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:48.705: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:48.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 12:37:48.715: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:37:49.724: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:49.725: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:49.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec  3 12:37:49.729: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 12:37:50.719: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:50.719: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:50.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 12:37:50.724: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 12:37:51.720: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:51.721: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:51.725: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 12:37:51.725: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Dec  3 12:37:51.725: INFO: Update the DaemonSet to trigger a rollout
    Dec  3 12:37:51.736: INFO: Updating DaemonSet daemon-set
    Dec  3 12:37:54.756: INFO: Roll back the DaemonSet before rollout is complete
    Dec  3 12:37:54.768: INFO: Updating DaemonSet daemon-set
    Dec  3 12:37:54.768: INFO: Make sure DaemonSet rollback is complete
    Dec  3 12:37:54.771: INFO: Wrong image for pod: daemon-set-l28mw. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Dec  3 12:37:54.771: INFO: Pod daemon-set-l28mw is not available
    Dec  3 12:37:54.777: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:54.777: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:55.792: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:55.792: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:56.781: INFO: Pod daemon-set-rlwvw is not available
    Dec  3 12:37:56.785: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 12:37:56.785: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 12:37:56.792
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8125, will wait for the garbage collector to delete the pods 12/03/22 12:37:56.792
    Dec  3 12:37:56.855: INFO: Deleting DaemonSet.extensions daemon-set took: 7.215741ms
    Dec  3 12:37:56.955: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.644592ms
    Dec  3 12:37:58.063: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 12:37:58.063: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 12:37:58.067: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14518"},"items":null}

    Dec  3 12:37:58.071: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14518"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:37:58.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8125" for this suite. 12/03/22 12:37:58.102
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:37:58.112
Dec  3 12:37:58.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:37:58.113
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:58.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:58.137
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Dec  3 12:37:58.140: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: creating the pod 12/03/22 12:37:58.141
STEP: submitting the pod to kubernetes 12/03/22 12:37:58.141
Dec  3 12:37:58.155: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6" in namespace "pods-4294" to be "running and ready"
Dec  3 12:37:58.158: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031308ms
Dec  3 12:37:58.158: INFO: The phase of Pod pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:38:00.163: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008076392s
Dec  3 12:38:00.163: INFO: The phase of Pod pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6 is Running (Ready = true)
Dec  3 12:38:00.163: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:38:00.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4294" for this suite. 12/03/22 12:38:00.264
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":111,"skipped":2123,"failed":0}
------------------------------
â€¢ [2.160 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:37:58.112
    Dec  3 12:37:58.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:37:58.113
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:37:58.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:37:58.137
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Dec  3 12:37:58.140: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: creating the pod 12/03/22 12:37:58.141
    STEP: submitting the pod to kubernetes 12/03/22 12:37:58.141
    Dec  3 12:37:58.155: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6" in namespace "pods-4294" to be "running and ready"
    Dec  3 12:37:58.158: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031308ms
    Dec  3 12:37:58.158: INFO: The phase of Pod pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:38:00.163: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008076392s
    Dec  3 12:38:00.163: INFO: The phase of Pod pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6 is Running (Ready = true)
    Dec  3 12:38:00.163: INFO: Pod "pod-exec-websocket-bbcedeff-8c62-42e8-b896-0015915e60e6" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:38:00.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4294" for this suite. 12/03/22 12:38:00.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:38:00.274
Dec  3 12:38:00.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:38:00.275
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:38:00.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:38:00.295
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-46575be1-25eb-4896-babf-920fe69ad980 in namespace container-probe-3024 12/03/22 12:38:00.389
Dec  3 12:38:00.405: INFO: Waiting up to 5m0s for pod "busybox-46575be1-25eb-4896-babf-920fe69ad980" in namespace "container-probe-3024" to be "not pending"
Dec  3 12:38:00.410: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Pending", Reason="", readiness=false. Elapsed: 5.084465ms
Dec  3 12:38:02.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010176253s
Dec  3 12:38:04.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Running", Reason="", readiness=true. Elapsed: 4.010476212s
Dec  3 12:38:04.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980" satisfied condition "not pending"
Dec  3 12:38:04.416: INFO: Started pod busybox-46575be1-25eb-4896-babf-920fe69ad980 in namespace container-probe-3024
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:38:04.416
Dec  3 12:38:04.419: INFO: Initial restart count of pod busybox-46575be1-25eb-4896-babf-920fe69ad980 is 0
STEP: deleting the pod 12/03/22 12:42:05.03
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:42:05.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3024" for this suite. 12/03/22 12:42:05.055
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":112,"skipped":2145,"failed":0}
------------------------------
â€¢ [SLOW TEST] [244.789 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:38:00.274
    Dec  3 12:38:00.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:38:00.275
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:38:00.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:38:00.295
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-46575be1-25eb-4896-babf-920fe69ad980 in namespace container-probe-3024 12/03/22 12:38:00.389
    Dec  3 12:38:00.405: INFO: Waiting up to 5m0s for pod "busybox-46575be1-25eb-4896-babf-920fe69ad980" in namespace "container-probe-3024" to be "not pending"
    Dec  3 12:38:00.410: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Pending", Reason="", readiness=false. Elapsed: 5.084465ms
    Dec  3 12:38:02.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010176253s
    Dec  3 12:38:04.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980": Phase="Running", Reason="", readiness=true. Elapsed: 4.010476212s
    Dec  3 12:38:04.416: INFO: Pod "busybox-46575be1-25eb-4896-babf-920fe69ad980" satisfied condition "not pending"
    Dec  3 12:38:04.416: INFO: Started pod busybox-46575be1-25eb-4896-babf-920fe69ad980 in namespace container-probe-3024
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:38:04.416
    Dec  3 12:38:04.419: INFO: Initial restart count of pod busybox-46575be1-25eb-4896-babf-920fe69ad980 is 0
    STEP: deleting the pod 12/03/22 12:42:05.03
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:42:05.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3024" for this suite. 12/03/22 12:42:05.055
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:05.069
Dec  3 12:42:05.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:42:05.071
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:05.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:05.107
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 12/03/22 12:42:05.11
Dec  3 12:42:05.121: INFO: Waiting up to 5m0s for pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3" in namespace "pods-3217" to be "running and ready"
Dec  3 12:42:05.124: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.197711ms
Dec  3 12:42:05.124: INFO: The phase of Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:07.130: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3": Phase="Running", Reason="", readiness=true. Elapsed: 2.008862417s
Dec  3 12:42:07.130: INFO: The phase of Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 is Running (Ready = true)
Dec  3 12:42:07.130: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3" satisfied condition "running and ready"
Dec  3 12:42:07.138: INFO: Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 has hostIP: 172.31.38.234
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:42:07.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3217" for this suite. 12/03/22 12:42:07.141
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":113,"skipped":2191,"failed":0}
------------------------------
â€¢ [2.086 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:05.069
    Dec  3 12:42:05.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:42:05.071
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:05.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:05.107
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 12/03/22 12:42:05.11
    Dec  3 12:42:05.121: INFO: Waiting up to 5m0s for pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3" in namespace "pods-3217" to be "running and ready"
    Dec  3 12:42:05.124: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.197711ms
    Dec  3 12:42:05.124: INFO: The phase of Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:07.130: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3": Phase="Running", Reason="", readiness=true. Elapsed: 2.008862417s
    Dec  3 12:42:07.130: INFO: The phase of Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 is Running (Ready = true)
    Dec  3 12:42:07.130: INFO: Pod "pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3" satisfied condition "running and ready"
    Dec  3 12:42:07.138: INFO: Pod pod-hostip-86946e11-649b-4522-96a8-ba2ca5a83ab3 has hostIP: 172.31.38.234
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:42:07.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3217" for this suite. 12/03/22 12:42:07.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:07.157
Dec  3 12:42:07.158: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubelet-test 12/03/22 12:42:07.163
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:07.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:07.2
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Dec  3 12:42:07.217: INFO: Waiting up to 5m0s for pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f" in namespace "kubelet-test-8004" to be "running and ready"
Dec  3 12:42:07.223: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060328ms
Dec  3 12:42:07.223: INFO: The phase of Pod busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:09.230: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.013190604s
Dec  3 12:42:09.230: INFO: The phase of Pod busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f is Running (Ready = true)
Dec  3 12:42:09.230: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec  3 12:42:09.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8004" for this suite. 12/03/22 12:42:09.263
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":114,"skipped":2234,"failed":0}
------------------------------
â€¢ [2.115 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:07.157
    Dec  3 12:42:07.158: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubelet-test 12/03/22 12:42:07.163
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:07.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:07.2
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Dec  3 12:42:07.217: INFO: Waiting up to 5m0s for pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f" in namespace "kubelet-test-8004" to be "running and ready"
    Dec  3 12:42:07.223: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060328ms
    Dec  3 12:42:07.223: INFO: The phase of Pod busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:09.230: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.013190604s
    Dec  3 12:42:09.230: INFO: The phase of Pod busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f is Running (Ready = true)
    Dec  3 12:42:09.230: INFO: Pod "busybox-scheduling-d99c0905-b68e-4a91-a9a4-9ceb301d8c5f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec  3 12:42:09.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8004" for this suite. 12/03/22 12:42:09.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:09.276
Dec  3 12:42:09.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:42:09.284
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:09.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:09.31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 12/03/22 12:42:09.313
Dec  3 12:42:09.323: INFO: Waiting up to 5m0s for pod "pod-jndl4" in namespace "pods-2492" to be "running"
Dec  3 12:42:09.327: INFO: Pod "pod-jndl4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014756ms
Dec  3 12:42:11.332: INFO: Pod "pod-jndl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008568044s
Dec  3 12:42:11.332: INFO: Pod "pod-jndl4" satisfied condition "running"
STEP: patching /status 12/03/22 12:42:11.332
Dec  3 12:42:11.346: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:42:11.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2492" for this suite. 12/03/22 12:42:11.351
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":115,"skipped":2247,"failed":0}
------------------------------
â€¢ [2.082 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:09.276
    Dec  3 12:42:09.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:42:09.284
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:09.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:09.31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 12/03/22 12:42:09.313
    Dec  3 12:42:09.323: INFO: Waiting up to 5m0s for pod "pod-jndl4" in namespace "pods-2492" to be "running"
    Dec  3 12:42:09.327: INFO: Pod "pod-jndl4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014756ms
    Dec  3 12:42:11.332: INFO: Pod "pod-jndl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008568044s
    Dec  3 12:42:11.332: INFO: Pod "pod-jndl4" satisfied condition "running"
    STEP: patching /status 12/03/22 12:42:11.332
    Dec  3 12:42:11.346: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:42:11.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2492" for this suite. 12/03/22 12:42:11.351
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:11.359
Dec  3 12:42:11.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:42:11.36
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:11.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:11.392
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 12/03/22 12:42:11.395
Dec  3 12:42:11.406: INFO: Waiting up to 5m0s for pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8" in namespace "downward-api-8231" to be "Succeeded or Failed"
Dec  3 12:42:11.409: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930491ms
Dec  3 12:42:13.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007684519s
Dec  3 12:42:15.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008072832s
STEP: Saw pod success 12/03/22 12:42:15.414
Dec  3 12:42:15.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8" satisfied condition "Succeeded or Failed"
Dec  3 12:42:15.417: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 container dapi-container: <nil>
STEP: delete the pod 12/03/22 12:42:15.43
Dec  3 12:42:15.492: INFO: Waiting for pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 to disappear
Dec  3 12:42:15.496: INFO: Pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec  3 12:42:15.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8231" for this suite. 12/03/22 12:42:15.499
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":116,"skipped":2255,"failed":0}
------------------------------
â€¢ [4.147 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:11.359
    Dec  3 12:42:11.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:42:11.36
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:11.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:11.392
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 12/03/22 12:42:11.395
    Dec  3 12:42:11.406: INFO: Waiting up to 5m0s for pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8" in namespace "downward-api-8231" to be "Succeeded or Failed"
    Dec  3 12:42:11.409: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930491ms
    Dec  3 12:42:13.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007684519s
    Dec  3 12:42:15.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008072832s
    STEP: Saw pod success 12/03/22 12:42:15.414
    Dec  3 12:42:15.414: INFO: Pod "downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8" satisfied condition "Succeeded or Failed"
    Dec  3 12:42:15.417: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 12:42:15.43
    Dec  3 12:42:15.492: INFO: Waiting for pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 to disappear
    Dec  3 12:42:15.496: INFO: Pod downward-api-54c65a7f-75b3-4d7c-b098-3b05f44431b8 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec  3 12:42:15.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8231" for this suite. 12/03/22 12:42:15.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:15.508
Dec  3 12:42:15.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:42:15.509
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:15.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:15.533
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-ecb3ec01-664c-4b0b-9bc4-f0a7a255952c 12/03/22 12:42:15.536
STEP: Creating a pod to test consume secrets 12/03/22 12:42:15.546
Dec  3 12:42:15.555: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675" in namespace "projected-3160" to be "Succeeded or Failed"
Dec  3 12:42:15.558: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525694ms
Dec  3 12:42:17.563: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008234801s
Dec  3 12:42:19.564: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009114818s
STEP: Saw pod success 12/03/22 12:42:19.564
Dec  3 12:42:19.564: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675" satisfied condition "Succeeded or Failed"
Dec  3 12:42:19.568: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/03/22 12:42:19.574
Dec  3 12:42:19.588: INFO: Waiting for pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 to disappear
Dec  3 12:42:19.592: INFO: Pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 12:42:19.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3160" for this suite. 12/03/22 12:42:19.596
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":117,"skipped":2272,"failed":0}
------------------------------
â€¢ [4.096 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:15.508
    Dec  3 12:42:15.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:42:15.509
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:15.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:15.533
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-ecb3ec01-664c-4b0b-9bc4-f0a7a255952c 12/03/22 12:42:15.536
    STEP: Creating a pod to test consume secrets 12/03/22 12:42:15.546
    Dec  3 12:42:15.555: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675" in namespace "projected-3160" to be "Succeeded or Failed"
    Dec  3 12:42:15.558: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525694ms
    Dec  3 12:42:17.563: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008234801s
    Dec  3 12:42:19.564: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009114818s
    STEP: Saw pod success 12/03/22 12:42:19.564
    Dec  3 12:42:19.564: INFO: Pod "pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675" satisfied condition "Succeeded or Failed"
    Dec  3 12:42:19.568: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 12:42:19.574
    Dec  3 12:42:19.588: INFO: Waiting for pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 to disappear
    Dec  3 12:42:19.592: INFO: Pod pod-projected-secrets-94a2ab08-cc6e-4811-a3cb-0eb49a106675 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 12:42:19.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3160" for this suite. 12/03/22 12:42:19.596
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:19.605
Dec  3 12:42:19.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename hostport 12/03/22 12:42:19.606
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:19.625
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:19.628
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/03/22 12:42:19.635
Dec  3 12:42:19.648: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4196" to be "running and ready"
Dec  3 12:42:19.650: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767712ms
Dec  3 12:42:19.651: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:21.656: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008586362s
Dec  3 12:42:21.656: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec  3 12:42:21.656: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.4.162 on the node which pod1 resides and expect scheduled 12/03/22 12:42:21.656
Dec  3 12:42:21.665: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4196" to be "running and ready"
Dec  3 12:42:21.668: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.16352ms
Dec  3 12:42:21.668: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:23.673: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.008333886s
Dec  3 12:42:23.674: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec  3 12:42:23.674: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.4.162 but use UDP protocol on the node which pod2 resides 12/03/22 12:42:23.674
Dec  3 12:42:23.683: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4196" to be "running and ready"
Dec  3 12:42:23.688: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757473ms
Dec  3 12:42:23.688: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:25.694: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.010990442s
Dec  3 12:42:25.695: INFO: The phase of Pod pod3 is Running (Ready = true)
Dec  3 12:42:25.695: INFO: Pod "pod3" satisfied condition "running and ready"
Dec  3 12:42:25.702: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4196" to be "running and ready"
Dec  3 12:42:25.706: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63418ms
Dec  3 12:42:25.706: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:42:27.710: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.008214706s
Dec  3 12:42:27.710: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Dec  3 12:42:27.711: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/03/22 12:42:27.715
Dec  3 12:42:27.715: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.4.162 http://127.0.0.1:54323/hostname] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:42:27.715: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:42:27.715: INFO: ExecWithOptions: Clientset creation
Dec  3 12:42:27.715: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.4.162+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.4.162, port: 54323 12/03/22 12:42:27.799
Dec  3 12:42:27.799: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.4.162:54323/hostname] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:42:27.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:42:27.800: INFO: ExecWithOptions: Clientset creation
Dec  3 12:42:27.800: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.4.162%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.4.162, port: 54323 UDP 12/03/22 12:42:27.881
Dec  3 12:42:27.882: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.4.162 54323] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:42:27.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:42:27.882: INFO: ExecWithOptions: Clientset creation
Dec  3 12:42:27.883: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.4.162+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Dec  3 12:42:32.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-4196" for this suite. 12/03/22 12:42:32.957
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":118,"skipped":2276,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.360 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:19.605
    Dec  3 12:42:19.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename hostport 12/03/22 12:42:19.606
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:19.625
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:19.628
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/03/22 12:42:19.635
    Dec  3 12:42:19.648: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4196" to be "running and ready"
    Dec  3 12:42:19.650: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767712ms
    Dec  3 12:42:19.651: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:21.656: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008586362s
    Dec  3 12:42:21.656: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec  3 12:42:21.656: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.4.162 on the node which pod1 resides and expect scheduled 12/03/22 12:42:21.656
    Dec  3 12:42:21.665: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4196" to be "running and ready"
    Dec  3 12:42:21.668: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.16352ms
    Dec  3 12:42:21.668: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:23.673: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.008333886s
    Dec  3 12:42:23.674: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec  3 12:42:23.674: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.4.162 but use UDP protocol on the node which pod2 resides 12/03/22 12:42:23.674
    Dec  3 12:42:23.683: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4196" to be "running and ready"
    Dec  3 12:42:23.688: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757473ms
    Dec  3 12:42:23.688: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:25.694: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.010990442s
    Dec  3 12:42:25.695: INFO: The phase of Pod pod3 is Running (Ready = true)
    Dec  3 12:42:25.695: INFO: Pod "pod3" satisfied condition "running and ready"
    Dec  3 12:42:25.702: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4196" to be "running and ready"
    Dec  3 12:42:25.706: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63418ms
    Dec  3 12:42:25.706: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:42:27.710: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.008214706s
    Dec  3 12:42:27.710: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Dec  3 12:42:27.711: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/03/22 12:42:27.715
    Dec  3 12:42:27.715: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.4.162 http://127.0.0.1:54323/hostname] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:42:27.715: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:42:27.715: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:42:27.715: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.4.162+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.4.162, port: 54323 12/03/22 12:42:27.799
    Dec  3 12:42:27.799: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.4.162:54323/hostname] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:42:27.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:42:27.800: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:42:27.800: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.4.162%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.4.162, port: 54323 UDP 12/03/22 12:42:27.881
    Dec  3 12:42:27.882: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.4.162 54323] Namespace:hostport-4196 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:42:27.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:42:27.882: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:42:27.883: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-4196/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.4.162+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Dec  3 12:42:32.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-4196" for this suite. 12/03/22 12:42:32.957
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:32.966
Dec  3 12:42:32.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption 12/03/22 12:42:32.967
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:32.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:33.002
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 12/03/22 12:42:33.008
STEP: Waiting for the pdb to be processed 12/03/22 12:42:33.021
STEP: First trying to evict a pod which shouldn't be evictable 12/03/22 12:42:35.035
STEP: Waiting for all pods to be running 12/03/22 12:42:35.035
Dec  3 12:42:35.039: INFO: pods: 0 < 3
Dec  3 12:42:37.044: INFO: running pods: 2 < 3
STEP: locating a running pod 12/03/22 12:42:39.05
STEP: Updating the pdb to allow a pod to be evicted 12/03/22 12:42:39.062
STEP: Waiting for the pdb to be processed 12/03/22 12:42:39.071
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/03/22 12:42:41.086
STEP: Waiting for all pods to be running 12/03/22 12:42:41.086
STEP: Waiting for the pdb to observed all healthy pods 12/03/22 12:42:41.091
STEP: Patching the pdb to disallow a pod to be evicted 12/03/22 12:42:41.113
STEP: Waiting for the pdb to be processed 12/03/22 12:42:41.135
STEP: Waiting for all pods to be running 12/03/22 12:42:43.148
STEP: locating a running pod 12/03/22 12:42:43.152
STEP: Deleting the pdb to allow a pod to be evicted 12/03/22 12:42:43.163
STEP: Waiting for the pdb to be deleted 12/03/22 12:42:43.173
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/03/22 12:42:43.176
STEP: Waiting for all pods to be running 12/03/22 12:42:43.176
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec  3 12:42:43.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9994" for this suite. 12/03/22 12:42:43.202
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":119,"skipped":2277,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.250 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:32.966
    Dec  3 12:42:32.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption 12/03/22 12:42:32.967
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:32.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:33.002
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 12/03/22 12:42:33.008
    STEP: Waiting for the pdb to be processed 12/03/22 12:42:33.021
    STEP: First trying to evict a pod which shouldn't be evictable 12/03/22 12:42:35.035
    STEP: Waiting for all pods to be running 12/03/22 12:42:35.035
    Dec  3 12:42:35.039: INFO: pods: 0 < 3
    Dec  3 12:42:37.044: INFO: running pods: 2 < 3
    STEP: locating a running pod 12/03/22 12:42:39.05
    STEP: Updating the pdb to allow a pod to be evicted 12/03/22 12:42:39.062
    STEP: Waiting for the pdb to be processed 12/03/22 12:42:39.071
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/03/22 12:42:41.086
    STEP: Waiting for all pods to be running 12/03/22 12:42:41.086
    STEP: Waiting for the pdb to observed all healthy pods 12/03/22 12:42:41.091
    STEP: Patching the pdb to disallow a pod to be evicted 12/03/22 12:42:41.113
    STEP: Waiting for the pdb to be processed 12/03/22 12:42:41.135
    STEP: Waiting for all pods to be running 12/03/22 12:42:43.148
    STEP: locating a running pod 12/03/22 12:42:43.152
    STEP: Deleting the pdb to allow a pod to be evicted 12/03/22 12:42:43.163
    STEP: Waiting for the pdb to be deleted 12/03/22 12:42:43.173
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/03/22 12:42:43.176
    STEP: Waiting for all pods to be running 12/03/22 12:42:43.176
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec  3 12:42:43.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9994" for this suite. 12/03/22 12:42:43.202
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:43.217
Dec  3 12:42:43.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:42:43.22
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:43.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:43.335
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Dec  3 12:42:43.338: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/03/22 12:42:45.885
Dec  3 12:42:45.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
Dec  3 12:42:46.530: INFO: stderr: ""
Dec  3 12:42:46.530: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 12:42:46.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 delete e2e-test-crd-publish-openapi-6888-crds test-foo'
Dec  3 12:42:46.631: INFO: stderr: ""
Dec  3 12:42:46.631: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec  3 12:42:46.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
Dec  3 12:42:46.836: INFO: stderr: ""
Dec  3 12:42:46.836: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 12:42:46.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 delete e2e-test-crd-publish-openapi-6888-crds test-foo'
Dec  3 12:42:46.916: INFO: stderr: ""
Dec  3 12:42:46.916: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/03/22 12:42:46.916
Dec  3 12:42:46.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
Dec  3 12:42:47.094: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/03/22 12:42:47.094
Dec  3 12:42:47.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
Dec  3 12:42:47.282: INFO: rc: 1
Dec  3 12:42:47.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
Dec  3 12:42:47.485: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/03/22 12:42:47.485
Dec  3 12:42:47.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
Dec  3 12:42:47.684: INFO: rc: 1
Dec  3 12:42:47.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
Dec  3 12:42:48.252: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 12/03/22 12:42:48.252
Dec  3 12:42:48.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds'
Dec  3 12:42:48.451: INFO: stderr: ""
Dec  3 12:42:48.451: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 12/03/22 12:42:48.451
Dec  3 12:42:48.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.metadata'
Dec  3 12:42:48.662: INFO: stderr: ""
Dec  3 12:42:48.662: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec  3 12:42:48.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec'
Dec  3 12:42:48.953: INFO: stderr: ""
Dec  3 12:42:48.953: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec  3 12:42:48.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec.bars'
Dec  3 12:42:49.250: INFO: stderr: ""
Dec  3 12:42:49.250: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/03/22 12:42:49.25
Dec  3 12:42:49.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec.bars2'
Dec  3 12:42:49.541: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:42:51.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-68" for this suite. 12/03/22 12:42:51.82
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":120,"skipped":2294,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.613 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:43.217
    Dec  3 12:42:43.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:42:43.22
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:43.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:43.335
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Dec  3 12:42:43.338: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/03/22 12:42:45.885
    Dec  3 12:42:45.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
    Dec  3 12:42:46.530: INFO: stderr: ""
    Dec  3 12:42:46.530: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec  3 12:42:46.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 delete e2e-test-crd-publish-openapi-6888-crds test-foo'
    Dec  3 12:42:46.631: INFO: stderr: ""
    Dec  3 12:42:46.631: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Dec  3 12:42:46.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
    Dec  3 12:42:46.836: INFO: stderr: ""
    Dec  3 12:42:46.836: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec  3 12:42:46.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 delete e2e-test-crd-publish-openapi-6888-crds test-foo'
    Dec  3 12:42:46.916: INFO: stderr: ""
    Dec  3 12:42:46.916: INFO: stdout: "e2e-test-crd-publish-openapi-6888-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/03/22 12:42:46.916
    Dec  3 12:42:46.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
    Dec  3 12:42:47.094: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/03/22 12:42:47.094
    Dec  3 12:42:47.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
    Dec  3 12:42:47.282: INFO: rc: 1
    Dec  3 12:42:47.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
    Dec  3 12:42:47.485: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/03/22 12:42:47.485
    Dec  3 12:42:47.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 create -f -'
    Dec  3 12:42:47.684: INFO: rc: 1
    Dec  3 12:42:47.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 --namespace=crd-publish-openapi-68 apply -f -'
    Dec  3 12:42:48.252: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 12/03/22 12:42:48.252
    Dec  3 12:42:48.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds'
    Dec  3 12:42:48.451: INFO: stderr: ""
    Dec  3 12:42:48.451: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 12/03/22 12:42:48.451
    Dec  3 12:42:48.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.metadata'
    Dec  3 12:42:48.662: INFO: stderr: ""
    Dec  3 12:42:48.662: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Dec  3 12:42:48.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec'
    Dec  3 12:42:48.953: INFO: stderr: ""
    Dec  3 12:42:48.953: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Dec  3 12:42:48.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec.bars'
    Dec  3 12:42:49.250: INFO: stderr: ""
    Dec  3 12:42:49.250: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6888-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/03/22 12:42:49.25
    Dec  3 12:42:49.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-68 explain e2e-test-crd-publish-openapi-6888-crds.spec.bars2'
    Dec  3 12:42:49.541: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:42:51.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-68" for this suite. 12/03/22 12:42:51.82
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:51.832
Dec  3 12:42:51.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename endpointslice 12/03/22 12:42:51.833
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:51.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:51.86
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Dec  3 12:42:51.879: INFO: Endpoints addresses: [172.31.47.238 172.31.70.229] , ports: [6443]
Dec  3 12:42:51.879: INFO: EndpointSlices addresses: [172.31.47.238 172.31.70.229] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec  3 12:42:51.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2244" for this suite. 12/03/22 12:42:51.889
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":121,"skipped":2299,"failed":0}
------------------------------
â€¢ [0.069 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:51.832
    Dec  3 12:42:51.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename endpointslice 12/03/22 12:42:51.833
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:51.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:51.86
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Dec  3 12:42:51.879: INFO: Endpoints addresses: [172.31.47.238 172.31.70.229] , ports: [6443]
    Dec  3 12:42:51.879: INFO: EndpointSlices addresses: [172.31.47.238 172.31.70.229] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec  3 12:42:51.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2244" for this suite. 12/03/22 12:42:51.889
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:42:51.904
Dec  3 12:42:51.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename taint-multiple-pods 12/03/22 12:42:51.905
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:51.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:51.934
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Dec  3 12:42:51.942: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 12:43:51.965: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Dec  3 12:43:51.981: INFO: Starting informer...
STEP: Starting pods... 12/03/22 12:43:51.981
Dec  3 12:43:52.209: INFO: Pod1 is running on ip-172-31-38-234. Tainting Node
Dec  3 12:43:52.429: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1116" to be "running"
Dec  3 12:43:52.435: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.324783ms
Dec  3 12:43:54.442: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01331278s
Dec  3 12:43:54.442: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Dec  3 12:43:54.442: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1116" to be "running"
Dec  3 12:43:54.447: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 5.156177ms
Dec  3 12:43:54.448: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Dec  3 12:43:54.448: INFO: Pod2 is running on ip-172-31-38-234. Tainting Node
STEP: Trying to apply a taint on the Node 12/03/22 12:43:54.448
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:43:54.461
STEP: Waiting for Pod1 and Pod2 to be deleted 12/03/22 12:43:54.468
Dec  3 12:44:00.299: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec  3 12:44:20.332: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:44:20.348
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:44:20.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1116" for this suite. 12/03/22 12:44:20.361
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":122,"skipped":2335,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.473 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:42:51.904
    Dec  3 12:42:51.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename taint-multiple-pods 12/03/22 12:42:51.905
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:42:51.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:42:51.934
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Dec  3 12:42:51.942: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 12:43:51.965: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Dec  3 12:43:51.981: INFO: Starting informer...
    STEP: Starting pods... 12/03/22 12:43:51.981
    Dec  3 12:43:52.209: INFO: Pod1 is running on ip-172-31-38-234. Tainting Node
    Dec  3 12:43:52.429: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1116" to be "running"
    Dec  3 12:43:52.435: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.324783ms
    Dec  3 12:43:54.442: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01331278s
    Dec  3 12:43:54.442: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Dec  3 12:43:54.442: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1116" to be "running"
    Dec  3 12:43:54.447: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 5.156177ms
    Dec  3 12:43:54.448: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Dec  3 12:43:54.448: INFO: Pod2 is running on ip-172-31-38-234. Tainting Node
    STEP: Trying to apply a taint on the Node 12/03/22 12:43:54.448
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:43:54.461
    STEP: Waiting for Pod1 and Pod2 to be deleted 12/03/22 12:43:54.468
    Dec  3 12:44:00.299: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Dec  3 12:44:20.332: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:44:20.348
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:44:20.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-1116" for this suite. 12/03/22 12:44:20.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:20.384
Dec  3 12:44:20.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename subpath 12/03/22 12:44:20.385
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:20.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:20.432
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/03/22 12:44:20.436
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-6vpr 12/03/22 12:44:20.451
STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:44:20.451
Dec  3 12:44:20.466: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-6vpr" in namespace "subpath-7477" to be "Succeeded or Failed"
Dec  3 12:44:20.471: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.466147ms
Dec  3 12:44:22.476: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 2.010162301s
Dec  3 12:44:24.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 4.010866742s
Dec  3 12:44:26.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 6.010349187s
Dec  3 12:44:28.480: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 8.013669036s
Dec  3 12:44:30.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 10.011204462s
Dec  3 12:44:32.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 12.011639544s
Dec  3 12:44:34.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 14.010576624s
Dec  3 12:44:36.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 16.01186748s
Dec  3 12:44:38.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 18.011060777s
Dec  3 12:44:40.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 20.010612758s
Dec  3 12:44:42.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=false. Elapsed: 22.011339097s
Dec  3 12:44:44.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.011055951s
STEP: Saw pod success 12/03/22 12:44:44.477
Dec  3 12:44:44.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr" satisfied condition "Succeeded or Failed"
Dec  3 12:44:44.482: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-downwardapi-6vpr container test-container-subpath-downwardapi-6vpr: <nil>
STEP: delete the pod 12/03/22 12:44:44.497
Dec  3 12:44:44.519: INFO: Waiting for pod pod-subpath-test-downwardapi-6vpr to disappear
Dec  3 12:44:44.526: INFO: Pod pod-subpath-test-downwardapi-6vpr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-6vpr 12/03/22 12:44:44.526
Dec  3 12:44:44.527: INFO: Deleting pod "pod-subpath-test-downwardapi-6vpr" in namespace "subpath-7477"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec  3 12:44:44.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7477" for this suite. 12/03/22 12:44:44.541
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":123,"skipped":2367,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.167 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:20.384
    Dec  3 12:44:20.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename subpath 12/03/22 12:44:20.385
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:20.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:20.432
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/03/22 12:44:20.436
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-6vpr 12/03/22 12:44:20.451
    STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:44:20.451
    Dec  3 12:44:20.466: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-6vpr" in namespace "subpath-7477" to be "Succeeded or Failed"
    Dec  3 12:44:20.471: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.466147ms
    Dec  3 12:44:22.476: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 2.010162301s
    Dec  3 12:44:24.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 4.010866742s
    Dec  3 12:44:26.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 6.010349187s
    Dec  3 12:44:28.480: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 8.013669036s
    Dec  3 12:44:30.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 10.011204462s
    Dec  3 12:44:32.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 12.011639544s
    Dec  3 12:44:34.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 14.010576624s
    Dec  3 12:44:36.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 16.01186748s
    Dec  3 12:44:38.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 18.011060777s
    Dec  3 12:44:40.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=true. Elapsed: 20.010612758s
    Dec  3 12:44:42.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Running", Reason="", readiness=false. Elapsed: 22.011339097s
    Dec  3 12:44:44.477: INFO: Pod "pod-subpath-test-downwardapi-6vpr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.011055951s
    STEP: Saw pod success 12/03/22 12:44:44.477
    Dec  3 12:44:44.478: INFO: Pod "pod-subpath-test-downwardapi-6vpr" satisfied condition "Succeeded or Failed"
    Dec  3 12:44:44.482: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-downwardapi-6vpr container test-container-subpath-downwardapi-6vpr: <nil>
    STEP: delete the pod 12/03/22 12:44:44.497
    Dec  3 12:44:44.519: INFO: Waiting for pod pod-subpath-test-downwardapi-6vpr to disappear
    Dec  3 12:44:44.526: INFO: Pod pod-subpath-test-downwardapi-6vpr no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-6vpr 12/03/22 12:44:44.526
    Dec  3 12:44:44.527: INFO: Deleting pod "pod-subpath-test-downwardapi-6vpr" in namespace "subpath-7477"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec  3 12:44:44.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7477" for this suite. 12/03/22 12:44:44.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:44.554
Dec  3 12:44:44.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename endpointslicemirroring 12/03/22 12:44:44.555
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:44.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:44.582
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 12/03/22 12:44:44.599
Dec  3 12:44:44.619: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 12/03/22 12:44:46.624
Dec  3 12:44:46.638: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 12/03/22 12:44:48.643
Dec  3 12:44:48.659: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Dec  3 12:44:50.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-6442" for this suite. 12/03/22 12:44:50.671
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":124,"skipped":2388,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.126 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:44.554
    Dec  3 12:44:44.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename endpointslicemirroring 12/03/22 12:44:44.555
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:44.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:44.582
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 12/03/22 12:44:44.599
    Dec  3 12:44:44.619: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 12/03/22 12:44:46.624
    Dec  3 12:44:46.638: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 12/03/22 12:44:48.643
    Dec  3 12:44:48.659: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Dec  3 12:44:50.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-6442" for this suite. 12/03/22 12:44:50.671
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:50.685
Dec  3 12:44:50.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:44:50.686
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:50.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:50.716
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-e6297c06-2032-4ea3-b5c5-940a9d546312 12/03/22 12:44:50.721
STEP: Creating a pod to test consume configMaps 12/03/22 12:44:50.729
Dec  3 12:44:50.742: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28" in namespace "projected-268" to be "Succeeded or Failed"
Dec  3 12:44:50.750: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Pending", Reason="", readiness=false. Elapsed: 7.428118ms
Dec  3 12:44:52.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013751257s
Dec  3 12:44:54.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013531472s
STEP: Saw pod success 12/03/22 12:44:54.756
Dec  3 12:44:54.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28" satisfied condition "Succeeded or Failed"
Dec  3 12:44:54.762: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 12:44:54.772
Dec  3 12:44:54.792: INFO: Waiting for pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 to disappear
Dec  3 12:44:54.798: INFO: Pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 12:44:54.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-268" for this suite. 12/03/22 12:44:54.804
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":125,"skipped":2423,"failed":0}
------------------------------
â€¢ [4.131 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:50.685
    Dec  3 12:44:50.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:44:50.686
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:50.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:50.716
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-e6297c06-2032-4ea3-b5c5-940a9d546312 12/03/22 12:44:50.721
    STEP: Creating a pod to test consume configMaps 12/03/22 12:44:50.729
    Dec  3 12:44:50.742: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28" in namespace "projected-268" to be "Succeeded or Failed"
    Dec  3 12:44:50.750: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Pending", Reason="", readiness=false. Elapsed: 7.428118ms
    Dec  3 12:44:52.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013751257s
    Dec  3 12:44:54.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013531472s
    STEP: Saw pod success 12/03/22 12:44:54.756
    Dec  3 12:44:54.756: INFO: Pod "pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28" satisfied condition "Succeeded or Failed"
    Dec  3 12:44:54.762: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 12:44:54.772
    Dec  3 12:44:54.792: INFO: Waiting for pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 to disappear
    Dec  3 12:44:54.798: INFO: Pod pod-projected-configmaps-b071674f-21a5-463d-903e-9810c6631c28 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 12:44:54.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-268" for this suite. 12/03/22 12:44:54.804
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:54.819
Dec  3 12:44:54.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:44:54.82
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:54.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:54.851
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 12/03/22 12:44:54.857
STEP: submitting the pod to kubernetes 12/03/22 12:44:54.859
STEP: verifying QOS class is set on the pod 12/03/22 12:44:54.872
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Dec  3 12:44:54.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2854" for this suite. 12/03/22 12:44:54.902
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":126,"skipped":2440,"failed":0}
------------------------------
â€¢ [0.095 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:54.819
    Dec  3 12:44:54.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:44:54.82
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:54.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:54.851
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 12/03/22 12:44:54.857
    STEP: submitting the pod to kubernetes 12/03/22 12:44:54.859
    STEP: verifying QOS class is set on the pod 12/03/22 12:44:54.872
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Dec  3 12:44:54.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2854" for this suite. 12/03/22 12:44:54.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:54.916
Dec  3 12:44:54.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:44:54.917
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:54.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:54.943
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 12/03/22 12:44:54.954
Dec  3 12:44:54.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9" in namespace "projected-1383" to be "Succeeded or Failed"
Dec  3 12:44:54.976: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.654697ms
Dec  3 12:44:56.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01408183s
Dec  3 12:44:58.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013913201s
STEP: Saw pod success 12/03/22 12:44:58.984
Dec  3 12:44:58.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9" satisfied condition "Succeeded or Failed"
Dec  3 12:44:58.989: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 container client-container: <nil>
STEP: delete the pod 12/03/22 12:44:58.998
Dec  3 12:44:59.018: INFO: Waiting for pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 to disappear
Dec  3 12:44:59.022: INFO: Pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 12:44:59.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1383" for this suite. 12/03/22 12:44:59.028
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":127,"skipped":2446,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:54.916
    Dec  3 12:44:54.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:44:54.917
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:54.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:54.943
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 12/03/22 12:44:54.954
    Dec  3 12:44:54.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9" in namespace "projected-1383" to be "Succeeded or Failed"
    Dec  3 12:44:54.976: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.654697ms
    Dec  3 12:44:56.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01408183s
    Dec  3 12:44:58.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013913201s
    STEP: Saw pod success 12/03/22 12:44:58.984
    Dec  3 12:44:58.984: INFO: Pod "downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9" satisfied condition "Succeeded or Failed"
    Dec  3 12:44:58.989: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 container client-container: <nil>
    STEP: delete the pod 12/03/22 12:44:58.998
    Dec  3 12:44:59.018: INFO: Waiting for pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 to disappear
    Dec  3 12:44:59.022: INFO: Pod downwardapi-volume-b3e62dc6-8346-439f-bd12-1706abc47ec9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 12:44:59.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1383" for this suite. 12/03/22 12:44:59.028
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:44:59.04
Dec  3 12:44:59.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:44:59.041
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:59.067
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:59.085
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/03/22 12:44:59.09
Dec  3 12:44:59.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/03/22 12:45:09.95
Dec  3 12:45:09.951: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:45:12.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:45:22.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7150" for this suite. 12/03/22 12:45:22.726
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":128,"skipped":2446,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.697 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:44:59.04
    Dec  3 12:44:59.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:44:59.041
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:44:59.067
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:44:59.085
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/03/22 12:44:59.09
    Dec  3 12:44:59.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/03/22 12:45:09.95
    Dec  3 12:45:09.951: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:45:12.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:45:22.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7150" for this suite. 12/03/22 12:45:22.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:22.739
Dec  3 12:45:22.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:45:22.74
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:22.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:22.767
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 12/03/22 12:45:22.77
Dec  3 12:45:22.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 create -f -'
Dec  3 12:45:23.367: INFO: stderr: ""
Dec  3 12:45:23.367: INFO: stdout: "pod/pause created\n"
Dec  3 12:45:23.367: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 12:45:23.367: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1123" to be "running and ready"
Dec  3 12:45:23.372: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.092413ms
Dec  3 12:45:23.372: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-38-234' to be 'Running' but was 'Pending'
Dec  3 12:45:25.376: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009476421s
Dec  3 12:45:25.376: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 12:45:25.376: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 12/03/22 12:45:25.377
Dec  3 12:45:25.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 label pods pause testing-label=testing-label-value'
Dec  3 12:45:25.463: INFO: stderr: ""
Dec  3 12:45:25.463: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 12/03/22 12:45:25.463
Dec  3 12:45:25.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pod pause -L testing-label'
Dec  3 12:45:25.536: INFO: stderr: ""
Dec  3 12:45:25.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 12/03/22 12:45:25.536
Dec  3 12:45:25.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 label pods pause testing-label-'
Dec  3 12:45:25.617: INFO: stderr: ""
Dec  3 12:45:25.617: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 12/03/22 12:45:25.617
Dec  3 12:45:25.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pod pause -L testing-label'
Dec  3 12:45:25.693: INFO: stderr: ""
Dec  3 12:45:25.693: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 12/03/22 12:45:25.693
Dec  3 12:45:25.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 delete --grace-period=0 --force -f -'
Dec  3 12:45:25.782: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 12:45:25.782: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 12:45:25.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get rc,svc -l name=pause --no-headers'
Dec  3 12:45:25.862: INFO: stderr: "No resources found in kubectl-1123 namespace.\n"
Dec  3 12:45:25.862: INFO: stdout: ""
Dec  3 12:45:25.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 12:45:25.933: INFO: stderr: ""
Dec  3 12:45:25.933: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:45:25.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1123" for this suite. 12/03/22 12:45:25.939
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":129,"skipped":2465,"failed":0}
------------------------------
â€¢ [3.211 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:22.739
    Dec  3 12:45:22.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:45:22.74
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:22.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:22.767
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 12/03/22 12:45:22.77
    Dec  3 12:45:22.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 create -f -'
    Dec  3 12:45:23.367: INFO: stderr: ""
    Dec  3 12:45:23.367: INFO: stdout: "pod/pause created\n"
    Dec  3 12:45:23.367: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Dec  3 12:45:23.367: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1123" to be "running and ready"
    Dec  3 12:45:23.372: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.092413ms
    Dec  3 12:45:23.372: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-38-234' to be 'Running' but was 'Pending'
    Dec  3 12:45:25.376: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009476421s
    Dec  3 12:45:25.376: INFO: Pod "pause" satisfied condition "running and ready"
    Dec  3 12:45:25.376: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 12/03/22 12:45:25.377
    Dec  3 12:45:25.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 label pods pause testing-label=testing-label-value'
    Dec  3 12:45:25.463: INFO: stderr: ""
    Dec  3 12:45:25.463: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 12/03/22 12:45:25.463
    Dec  3 12:45:25.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pod pause -L testing-label'
    Dec  3 12:45:25.536: INFO: stderr: ""
    Dec  3 12:45:25.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 12/03/22 12:45:25.536
    Dec  3 12:45:25.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 label pods pause testing-label-'
    Dec  3 12:45:25.617: INFO: stderr: ""
    Dec  3 12:45:25.617: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 12/03/22 12:45:25.617
    Dec  3 12:45:25.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pod pause -L testing-label'
    Dec  3 12:45:25.693: INFO: stderr: ""
    Dec  3 12:45:25.693: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 12/03/22 12:45:25.693
    Dec  3 12:45:25.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 delete --grace-period=0 --force -f -'
    Dec  3 12:45:25.782: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 12:45:25.782: INFO: stdout: "pod \"pause\" force deleted\n"
    Dec  3 12:45:25.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get rc,svc -l name=pause --no-headers'
    Dec  3 12:45:25.862: INFO: stderr: "No resources found in kubectl-1123 namespace.\n"
    Dec  3 12:45:25.862: INFO: stdout: ""
    Dec  3 12:45:25.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1123 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec  3 12:45:25.933: INFO: stderr: ""
    Dec  3 12:45:25.933: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:45:25.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1123" for this suite. 12/03/22 12:45:25.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:25.954
Dec  3 12:45:25.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:45:25.955
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:25.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:25.984
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-4702 12/03/22 12:45:25.993
STEP: creating service affinity-nodeport-transition in namespace services-4702 12/03/22 12:45:25.993
STEP: creating replication controller affinity-nodeport-transition in namespace services-4702 12/03/22 12:45:26.012
I1203 12:45:26.023539      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4702, replica count: 3
I1203 12:45:29.074908      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 12:45:32.075609      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 12:45:32.089: INFO: Creating new exec pod
Dec  3 12:45:32.099: INFO: Waiting up to 5m0s for pod "execpod-affinityt2dnn" in namespace "services-4702" to be "running"
Dec  3 12:45:32.105: INFO: Pod "execpod-affinityt2dnn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549851ms
Dec  3 12:45:34.113: INFO: Pod "execpod-affinityt2dnn": Phase="Running", Reason="", readiness=true. Elapsed: 2.014264803s
Dec  3 12:45:34.113: INFO: Pod "execpod-affinityt2dnn" satisfied condition "running"
Dec  3 12:45:35.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Dec  3 12:45:35.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Dec  3 12:45:35.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:45:35.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.27 80'
Dec  3 12:45:35.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.27 80\nConnection to 10.152.183.27 80 port [tcp/http] succeeded!\n"
Dec  3 12:45:35.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:45:35.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 32713'
Dec  3 12:45:35.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.76.203 32713\nConnection to 172.31.76.203 32713 port [tcp/*] succeeded!\n"
Dec  3 12:45:35.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:45:35.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 32713'
Dec  3 12:45:35.768: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 32713\nConnection to 172.31.38.234 32713 port [tcp/*] succeeded!\n"
Dec  3 12:45:35.768: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 12:45:35.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:32713/ ; done'
Dec  3 12:45:36.063: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n"
Dec  3 12:45:36.063: INFO: stdout: "\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4"
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
Dec  3 12:45:36.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:32713/ ; done'
Dec  3 12:45:36.315: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n"
Dec  3 12:45:36.315: INFO: stdout: "\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs"
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
Dec  3 12:45:36.315: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4702, will wait for the garbage collector to delete the pods 12/03/22 12:45:36.34
Dec  3 12:45:36.403: INFO: Deleting ReplicationController affinity-nodeport-transition took: 9.775056ms
Dec  3 12:45:36.503: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.286111ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:45:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4702" for this suite. 12/03/22 12:45:38.632
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":130,"skipped":2531,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.763 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:25.954
    Dec  3 12:45:25.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:45:25.955
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:25.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:25.984
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-4702 12/03/22 12:45:25.993
    STEP: creating service affinity-nodeport-transition in namespace services-4702 12/03/22 12:45:25.993
    STEP: creating replication controller affinity-nodeport-transition in namespace services-4702 12/03/22 12:45:26.012
    I1203 12:45:26.023539      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4702, replica count: 3
    I1203 12:45:29.074908      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 12:45:32.075609      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 12:45:32.089: INFO: Creating new exec pod
    Dec  3 12:45:32.099: INFO: Waiting up to 5m0s for pod "execpod-affinityt2dnn" in namespace "services-4702" to be "running"
    Dec  3 12:45:32.105: INFO: Pod "execpod-affinityt2dnn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549851ms
    Dec  3 12:45:34.113: INFO: Pod "execpod-affinityt2dnn": Phase="Running", Reason="", readiness=true. Elapsed: 2.014264803s
    Dec  3 12:45:34.113: INFO: Pod "execpod-affinityt2dnn" satisfied condition "running"
    Dec  3 12:45:35.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Dec  3 12:45:35.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Dec  3 12:45:35.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:45:35.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.27 80'
    Dec  3 12:45:35.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.27 80\nConnection to 10.152.183.27 80 port [tcp/http] succeeded!\n"
    Dec  3 12:45:35.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:45:35.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 32713'
    Dec  3 12:45:35.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.76.203 32713\nConnection to 172.31.76.203 32713 port [tcp/*] succeeded!\n"
    Dec  3 12:45:35.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:45:35.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 32713'
    Dec  3 12:45:35.768: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 32713\nConnection to 172.31.38.234 32713 port [tcp/*] succeeded!\n"
    Dec  3 12:45:35.768: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 12:45:35.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:32713/ ; done'
    Dec  3 12:45:36.063: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n"
    Dec  3 12:45:36.063: INFO: stdout: "\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-b4rl4\naffinity-nodeport-transition-wwrfb\naffinity-nodeport-transition-b4rl4"
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-wwrfb
    Dec  3 12:45:36.063: INFO: Received response from host: affinity-nodeport-transition-b4rl4
    Dec  3 12:45:36.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4702 exec execpod-affinityt2dnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:32713/ ; done'
    Dec  3 12:45:36.315: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:32713/\n"
    Dec  3 12:45:36.315: INFO: stdout: "\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs\naffinity-nodeport-transition-qclzs"
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Received response from host: affinity-nodeport-transition-qclzs
    Dec  3 12:45:36.315: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4702, will wait for the garbage collector to delete the pods 12/03/22 12:45:36.34
    Dec  3 12:45:36.403: INFO: Deleting ReplicationController affinity-nodeport-transition took: 9.775056ms
    Dec  3 12:45:36.503: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.286111ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:45:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4702" for this suite. 12/03/22 12:45:38.632
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:38.718
Dec  3 12:45:38.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-webhook 12/03/22 12:45:38.719
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:38.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:38.755
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/03/22 12:45:38.758
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/03/22 12:45:38.951
STEP: Deploying the custom resource conversion webhook pod 12/03/22 12:45:38.964
STEP: Wait for the deployment to be ready 12/03/22 12:45:38.98
Dec  3 12:45:38.989: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 12:45:41
STEP: Verifying the service has paired with the endpoint 12/03/22 12:45:41.013
Dec  3 12:45:42.013: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Dec  3 12:45:42.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Creating a v1 custom resource 12/03/22 12:45:44.651
STEP: v2 custom resource should be converted 12/03/22 12:45:44.659
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:45:45.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-604" for this suite. 12/03/22 12:45:45.184
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":131,"skipped":2543,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.611 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:38.718
    Dec  3 12:45:38.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-webhook 12/03/22 12:45:38.719
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:38.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:38.755
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/03/22 12:45:38.758
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/03/22 12:45:38.951
    STEP: Deploying the custom resource conversion webhook pod 12/03/22 12:45:38.964
    STEP: Wait for the deployment to be ready 12/03/22 12:45:38.98
    Dec  3 12:45:38.989: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 12:45:41
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:45:41.013
    Dec  3 12:45:42.013: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Dec  3 12:45:42.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Creating a v1 custom resource 12/03/22 12:45:44.651
    STEP: v2 custom resource should be converted 12/03/22 12:45:44.659
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:45:45.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-604" for this suite. 12/03/22 12:45:45.184
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:45.33
Dec  3 12:45:45.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 12:45:45.331
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:45.364
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:45.367
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 12/03/22 12:45:45.371
Dec  3 12:45:45.391: INFO: Waiting up to 5m0s for pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380" in namespace "downward-api-9603" to be "running and ready"
Dec  3 12:45:45.394: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380": Phase="Pending", Reason="", readiness=false. Elapsed: 2.721295ms
Dec  3 12:45:45.394: INFO: The phase of Pod labelsupdatecd987145-4821-41e3-99b5-964d38ba0380 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:45:47.399: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380": Phase="Running", Reason="", readiness=true. Elapsed: 2.007885269s
Dec  3 12:45:47.399: INFO: The phase of Pod labelsupdatecd987145-4821-41e3-99b5-964d38ba0380 is Running (Ready = true)
Dec  3 12:45:47.399: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380" satisfied condition "running and ready"
Dec  3 12:45:47.933: INFO: Successfully updated pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 12:45:51.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9603" for this suite. 12/03/22 12:45:51.969
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":132,"skipped":2556,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.647 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:45.33
    Dec  3 12:45:45.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 12:45:45.331
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:45.364
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:45.367
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 12/03/22 12:45:45.371
    Dec  3 12:45:45.391: INFO: Waiting up to 5m0s for pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380" in namespace "downward-api-9603" to be "running and ready"
    Dec  3 12:45:45.394: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380": Phase="Pending", Reason="", readiness=false. Elapsed: 2.721295ms
    Dec  3 12:45:45.394: INFO: The phase of Pod labelsupdatecd987145-4821-41e3-99b5-964d38ba0380 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:45:47.399: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380": Phase="Running", Reason="", readiness=true. Elapsed: 2.007885269s
    Dec  3 12:45:47.399: INFO: The phase of Pod labelsupdatecd987145-4821-41e3-99b5-964d38ba0380 is Running (Ready = true)
    Dec  3 12:45:47.399: INFO: Pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380" satisfied condition "running and ready"
    Dec  3 12:45:47.933: INFO: Successfully updated pod "labelsupdatecd987145-4821-41e3-99b5-964d38ba0380"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 12:45:51.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9603" for this suite. 12/03/22 12:45:51.969
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:51.978
Dec  3 12:45:51.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename events 12/03/22 12:45:51.98
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:52.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:52.006
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 12/03/22 12:45:52.011
STEP: get a list of Events with a label in the current namespace 12/03/22 12:45:52.041
STEP: delete a list of events 12/03/22 12:45:52.046
Dec  3 12:45:52.046: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/03/22 12:45:52.074
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec  3 12:45:52.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4158" for this suite. 12/03/22 12:45:52.083
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":133,"skipped":2560,"failed":0}
------------------------------
â€¢ [0.114 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:51.978
    Dec  3 12:45:51.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename events 12/03/22 12:45:51.98
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:52.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:52.006
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 12/03/22 12:45:52.011
    STEP: get a list of Events with a label in the current namespace 12/03/22 12:45:52.041
    STEP: delete a list of events 12/03/22 12:45:52.046
    Dec  3 12:45:52.046: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/03/22 12:45:52.074
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec  3 12:45:52.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4158" for this suite. 12/03/22 12:45:52.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:45:52.093
Dec  3 12:45:52.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 12:45:52.094
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:52.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:52.124
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 12/03/22 12:45:52.127
STEP: Counting existing ResourceQuota 12/03/22 12:45:57.132
STEP: Creating a ResourceQuota 12/03/22 12:46:02.137
STEP: Ensuring resource quota status is calculated 12/03/22 12:46:02.143
STEP: Creating a Secret 12/03/22 12:46:04.149
STEP: Ensuring resource quota status captures secret creation 12/03/22 12:46:04.166
STEP: Deleting a secret 12/03/22 12:46:06.17
STEP: Ensuring resource quota status released usage 12/03/22 12:46:06.178
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 12:46:08.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7353" for this suite. 12/03/22 12:46:08.188
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":134,"skipped":2573,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.103 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:45:52.093
    Dec  3 12:45:52.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 12:45:52.094
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:45:52.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:45:52.124
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 12/03/22 12:45:52.127
    STEP: Counting existing ResourceQuota 12/03/22 12:45:57.132
    STEP: Creating a ResourceQuota 12/03/22 12:46:02.137
    STEP: Ensuring resource quota status is calculated 12/03/22 12:46:02.143
    STEP: Creating a Secret 12/03/22 12:46:04.149
    STEP: Ensuring resource quota status captures secret creation 12/03/22 12:46:04.166
    STEP: Deleting a secret 12/03/22 12:46:06.17
    STEP: Ensuring resource quota status released usage 12/03/22 12:46:06.178
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 12:46:08.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7353" for this suite. 12/03/22 12:46:08.188
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:08.197
Dec  3 12:46:08.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption 12/03/22 12:46:08.199
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:08.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:08.241
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 12/03/22 12:46:08.245
STEP: Waiting for the pdb to be processed 12/03/22 12:46:08.251
STEP: updating the pdb 12/03/22 12:46:10.259
STEP: Waiting for the pdb to be processed 12/03/22 12:46:10.275
STEP: patching the pdb 12/03/22 12:46:12.284
STEP: Waiting for the pdb to be processed 12/03/22 12:46:12.294
STEP: Waiting for the pdb to be deleted 12/03/22 12:46:14.315
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec  3 12:46:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9229" for this suite. 12/03/22 12:46:14.323
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":135,"skipped":2575,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.134 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:08.197
    Dec  3 12:46:08.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption 12/03/22 12:46:08.199
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:08.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:08.241
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 12/03/22 12:46:08.245
    STEP: Waiting for the pdb to be processed 12/03/22 12:46:08.251
    STEP: updating the pdb 12/03/22 12:46:10.259
    STEP: Waiting for the pdb to be processed 12/03/22 12:46:10.275
    STEP: patching the pdb 12/03/22 12:46:12.284
    STEP: Waiting for the pdb to be processed 12/03/22 12:46:12.294
    STEP: Waiting for the pdb to be deleted 12/03/22 12:46:14.315
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec  3 12:46:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9229" for this suite. 12/03/22 12:46:14.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:14.333
Dec  3 12:46:14.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:46:14.334
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:14.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:14.36
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:46:14.388
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:46:14.831
STEP: Deploying the webhook pod 12/03/22 12:46:14.844
STEP: Wait for the deployment to be ready 12/03/22 12:46:14.857
Dec  3 12:46:14.866: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 12/03/22 12:46:16.88
STEP: Verifying the service has paired with the endpoint 12/03/22 12:46:16.897
Dec  3 12:46:17.899: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 12/03/22 12:46:17.905
STEP: create a pod 12/03/22 12:46:17.925
Dec  3 12:46:17.936: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2987" to be "running"
Dec  3 12:46:17.939: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.841877ms
Dec  3 12:46:19.945: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008348746s
Dec  3 12:46:19.945: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 12/03/22 12:46:19.945
Dec  3 12:46:19.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=webhook-2987 attach --namespace=webhook-2987 to-be-attached-pod -i -c=container1'
Dec  3 12:46:20.046: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:46:20.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2987" for this suite. 12/03/22 12:46:20.063
STEP: Destroying namespace "webhook-2987-markers" for this suite. 12/03/22 12:46:20.07
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":136,"skipped":2596,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.793 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:14.333
    Dec  3 12:46:14.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:46:14.334
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:14.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:14.36
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:46:14.388
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:46:14.831
    STEP: Deploying the webhook pod 12/03/22 12:46:14.844
    STEP: Wait for the deployment to be ready 12/03/22 12:46:14.857
    Dec  3 12:46:14.866: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 12/03/22 12:46:16.88
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:46:16.897
    Dec  3 12:46:17.899: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 12/03/22 12:46:17.905
    STEP: create a pod 12/03/22 12:46:17.925
    Dec  3 12:46:17.936: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2987" to be "running"
    Dec  3 12:46:17.939: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.841877ms
    Dec  3 12:46:19.945: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008348746s
    Dec  3 12:46:19.945: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 12/03/22 12:46:19.945
    Dec  3 12:46:19.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=webhook-2987 attach --namespace=webhook-2987 to-be-attached-pod -i -c=container1'
    Dec  3 12:46:20.046: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:46:20.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2987" for this suite. 12/03/22 12:46:20.063
    STEP: Destroying namespace "webhook-2987-markers" for this suite. 12/03/22 12:46:20.07
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:20.128
Dec  3 12:46:20.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename namespaces 12/03/22 12:46:20.129
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.177
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 12/03/22 12:46:20.188
STEP: patching the Namespace 12/03/22 12:46:20.222
STEP: get the Namespace and ensuring it has the label 12/03/22 12:46:20.23
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:46:20.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4568" for this suite. 12/03/22 12:46:20.239
STEP: Destroying namespace "nspatchtest-ee047fc9-2ae3-45a6-b4ef-46f050be9b5f-6989" for this suite. 12/03/22 12:46:20.246
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":137,"skipped":2610,"failed":0}
------------------------------
â€¢ [0.127 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:20.128
    Dec  3 12:46:20.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename namespaces 12/03/22 12:46:20.129
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.177
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 12/03/22 12:46:20.188
    STEP: patching the Namespace 12/03/22 12:46:20.222
    STEP: get the Namespace and ensuring it has the label 12/03/22 12:46:20.23
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:46:20.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4568" for this suite. 12/03/22 12:46:20.239
    STEP: Destroying namespace "nspatchtest-ee047fc9-2ae3-45a6-b4ef-46f050be9b5f-6989" for this suite. 12/03/22 12:46:20.246
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:20.256
Dec  3 12:46:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename cronjob 12/03/22 12:46:20.257
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.281
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 12/03/22 12:46:20.284
STEP: creating 12/03/22 12:46:20.284
STEP: getting 12/03/22 12:46:20.293
STEP: listing 12/03/22 12:46:20.296
STEP: watching 12/03/22 12:46:20.3
Dec  3 12:46:20.300: INFO: starting watch
STEP: cluster-wide listing 12/03/22 12:46:20.302
STEP: cluster-wide watching 12/03/22 12:46:20.305
Dec  3 12:46:20.305: INFO: starting watch
STEP: patching 12/03/22 12:46:20.307
STEP: updating 12/03/22 12:46:20.315
Dec  3 12:46:20.327: INFO: waiting for watch events with expected annotations
Dec  3 12:46:20.327: INFO: saw patched and updated annotations
STEP: patching /status 12/03/22 12:46:20.327
STEP: updating /status 12/03/22 12:46:20.341
STEP: get /status 12/03/22 12:46:20.357
STEP: deleting 12/03/22 12:46:20.361
STEP: deleting a collection 12/03/22 12:46:20.384
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec  3 12:46:20.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6337" for this suite. 12/03/22 12:46:20.402
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":138,"skipped":2615,"failed":0}
------------------------------
â€¢ [0.156 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:20.256
    Dec  3 12:46:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename cronjob 12/03/22 12:46:20.257
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.281
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 12/03/22 12:46:20.284
    STEP: creating 12/03/22 12:46:20.284
    STEP: getting 12/03/22 12:46:20.293
    STEP: listing 12/03/22 12:46:20.296
    STEP: watching 12/03/22 12:46:20.3
    Dec  3 12:46:20.300: INFO: starting watch
    STEP: cluster-wide listing 12/03/22 12:46:20.302
    STEP: cluster-wide watching 12/03/22 12:46:20.305
    Dec  3 12:46:20.305: INFO: starting watch
    STEP: patching 12/03/22 12:46:20.307
    STEP: updating 12/03/22 12:46:20.315
    Dec  3 12:46:20.327: INFO: waiting for watch events with expected annotations
    Dec  3 12:46:20.327: INFO: saw patched and updated annotations
    STEP: patching /status 12/03/22 12:46:20.327
    STEP: updating /status 12/03/22 12:46:20.341
    STEP: get /status 12/03/22 12:46:20.357
    STEP: deleting 12/03/22 12:46:20.361
    STEP: deleting a collection 12/03/22 12:46:20.384
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec  3 12:46:20.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6337" for this suite. 12/03/22 12:46:20.402
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:20.416
Dec  3 12:46:20.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:46:20.418
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.442
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-a1a1cfae-1af3-4165-8770-15fa715de58c 12/03/22 12:46:20.444
STEP: Creating secret with name secret-projected-all-test-volume-237c5f4f-fb1c-4af3-8e9e-c9f02cdb66e1 12/03/22 12:46:20.451
STEP: Creating a pod to test Check all projections for projected volume plugin 12/03/22 12:46:20.457
Dec  3 12:46:20.470: INFO: Waiting up to 5m0s for pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470" in namespace "projected-3674" to be "Succeeded or Failed"
Dec  3 12:46:20.474: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869011ms
Dec  3 12:46:22.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009858346s
Dec  3 12:46:24.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009777363s
STEP: Saw pod success 12/03/22 12:46:24.48
Dec  3 12:46:24.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470" satisfied condition "Succeeded or Failed"
Dec  3 12:46:24.483: INFO: Trying to get logs from node ip-172-31-38-234 pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 container projected-all-volume-test: <nil>
STEP: delete the pod 12/03/22 12:46:24.492
Dec  3 12:46:24.504: INFO: Waiting for pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 to disappear
Dec  3 12:46:24.513: INFO: Pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Dec  3 12:46:24.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3674" for this suite. 12/03/22 12:46:24.518
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":139,"skipped":2659,"failed":0}
------------------------------
â€¢ [4.110 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:20.416
    Dec  3 12:46:20.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:46:20.418
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:20.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:20.442
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-a1a1cfae-1af3-4165-8770-15fa715de58c 12/03/22 12:46:20.444
    STEP: Creating secret with name secret-projected-all-test-volume-237c5f4f-fb1c-4af3-8e9e-c9f02cdb66e1 12/03/22 12:46:20.451
    STEP: Creating a pod to test Check all projections for projected volume plugin 12/03/22 12:46:20.457
    Dec  3 12:46:20.470: INFO: Waiting up to 5m0s for pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470" in namespace "projected-3674" to be "Succeeded or Failed"
    Dec  3 12:46:20.474: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869011ms
    Dec  3 12:46:22.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009858346s
    Dec  3 12:46:24.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009777363s
    STEP: Saw pod success 12/03/22 12:46:24.48
    Dec  3 12:46:24.480: INFO: Pod "projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470" satisfied condition "Succeeded or Failed"
    Dec  3 12:46:24.483: INFO: Trying to get logs from node ip-172-31-38-234 pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 container projected-all-volume-test: <nil>
    STEP: delete the pod 12/03/22 12:46:24.492
    Dec  3 12:46:24.504: INFO: Waiting for pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 to disappear
    Dec  3 12:46:24.513: INFO: Pod projected-volume-9fc8fc2d-717d-4f12-a04d-3701a96c3470 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Dec  3 12:46:24.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3674" for this suite. 12/03/22 12:46:24.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:24.528
Dec  3 12:46:24.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-pred 12/03/22 12:46:24.529
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:24.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:24.554
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec  3 12:46:24.558: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 12:46:24.567: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 12:46:24.574: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
Dec  3 12:46:24.580: INFO: nginx-ingress-controller-kubernetes-worker-2v6sc from ingress-nginx-kubernetes-worker started at 2022-12-03 12:44:20 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.580: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:46:24.580: INFO: pod-qos-class-f4fb0a7c-ae96-46b3-bf89-ea16a5aa19f5 from pods-2854 started at 2022-12-03 12:44:54 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.580: INFO: 	Container agnhost ready: false, restart count 0
Dec  3 12:46:24.580: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:46:24.580: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:46:24.580: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:46:24.580: INFO: to-be-attached-pod from webhook-2987 started at 2022-12-03 12:46:17 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.581: INFO: 	Container container1 ready: true, restart count 0
Dec  3 12:46:24.581: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
Dec  3 12:46:24.588: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.588: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  3 12:46:24.588: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.588: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:46:24.588: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container coredns ready: true, restart count 0
Dec  3 12:46:24.589: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec  3 12:46:24.589: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 12:46:24.589: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  3 12:46:24.589: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec  3 12:46:24.589: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 12:46:24.589: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:46:24.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:46:24.589: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 12:46:24.589: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
Dec  3 12:46:24.594: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.595: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 12:46:24.595: INFO: calico-kube-controllers-77cf5c5988-8l65n from kube-system started at 2022-12-03 12:43:54 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.595: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 12:46:24.595: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
Dec  3 12:46:24.595: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 12:46:24.595: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:46:24.595: INFO: 	Container e2e ready: true, restart count 0
Dec  3 12:46:24.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:46:24.595: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 12:46:24.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 12:46:24.595: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 12/03/22 12:46:24.595
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.172d4941fe8970a6], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 12/03/22 12:46:24.622
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:46:25.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7891" for this suite. 12/03/22 12:46:25.625
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":140,"skipped":2668,"failed":0}
------------------------------
â€¢ [1.106 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:24.528
    Dec  3 12:46:24.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-pred 12/03/22 12:46:24.529
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:24.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:24.554
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec  3 12:46:24.558: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec  3 12:46:24.567: INFO: Waiting for terminating namespaces to be deleted...
    Dec  3 12:46:24.574: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
    Dec  3 12:46:24.580: INFO: nginx-ingress-controller-kubernetes-worker-2v6sc from ingress-nginx-kubernetes-worker started at 2022-12-03 12:44:20 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.580: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:46:24.580: INFO: pod-qos-class-f4fb0a7c-ae96-46b3-bf89-ea16a5aa19f5 from pods-2854 started at 2022-12-03 12:44:54 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.580: INFO: 	Container agnhost ready: false, restart count 0
    Dec  3 12:46:24.580: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:46:24.580: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:46:24.580: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:46:24.580: INFO: to-be-attached-pod from webhook-2987 started at 2022-12-03 12:46:17 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.581: INFO: 	Container container1 ready: true, restart count 0
    Dec  3 12:46:24.581: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
    Dec  3 12:46:24.588: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.588: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Dec  3 12:46:24.588: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.588: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:46:24.588: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container coredns ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container metrics-server ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:46:24.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 12:46:24.589: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
    Dec  3 12:46:24.594: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.595: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: calico-kube-controllers-77cf5c5988-8l65n from kube-system started at 2022-12-03 12:43:54 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.595: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
    Dec  3 12:46:24.595: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:46:24.595: INFO: 	Container e2e ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 12:46:24.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 12:46:24.595: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 12/03/22 12:46:24.595
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.172d4941fe8970a6], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 12/03/22 12:46:24.622
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:46:25.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7891" for this suite. 12/03/22 12:46:25.625
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:25.635
Dec  3 12:46:25.635: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replication-controller 12/03/22 12:46:25.636
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:25.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:25.676
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30 12/03/22 12:46:25.681
Dec  3 12:46:25.693: INFO: Pod name my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Found 0 pods out of 1
Dec  3 12:46:30.697: INFO: Pod name my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Found 1 pods out of 1
Dec  3 12:46:30.697: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30" are running
Dec  3 12:46:30.697: INFO: Waiting up to 5m0s for pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" in namespace "replication-controller-5165" to be "running"
Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz": Phase="Running", Reason="", readiness=true. Elapsed: 9.108159ms
Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" satisfied condition "running"
Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:25 +0000 UTC Reason: Message:}])
Dec  3 12:46:30.706: INFO: Trying to dial the pod
Dec  3 12:46:35.722: INFO: Controller my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Got expected result from replica 1 [my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz]: "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec  3 12:46:35.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5165" for this suite. 12/03/22 12:46:35.727
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":141,"skipped":2677,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.101 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:25.635
    Dec  3 12:46:25.635: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replication-controller 12/03/22 12:46:25.636
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:25.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:25.676
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30 12/03/22 12:46:25.681
    Dec  3 12:46:25.693: INFO: Pod name my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Found 0 pods out of 1
    Dec  3 12:46:30.697: INFO: Pod name my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Found 1 pods out of 1
    Dec  3 12:46:30.697: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30" are running
    Dec  3 12:46:30.697: INFO: Waiting up to 5m0s for pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" in namespace "replication-controller-5165" to be "running"
    Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz": Phase="Running", Reason="", readiness=true. Elapsed: 9.108159ms
    Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" satisfied condition "running"
    Dec  3 12:46:30.706: INFO: Pod "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-03 12:46:25 +0000 UTC Reason: Message:}])
    Dec  3 12:46:30.706: INFO: Trying to dial the pod
    Dec  3 12:46:35.722: INFO: Controller my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30: Got expected result from replica 1 [my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz]: "my-hostname-basic-df328007-b297-49e0-8c27-4264aaa60f30-6xxwz", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec  3 12:46:35.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5165" for this suite. 12/03/22 12:46:35.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:46:35.736
Dec  3 12:46:35.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 12:46:35.737
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:35.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:35.758
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6649 12/03/22 12:46:35.762
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-6649 12/03/22 12:46:35.772
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6649 12/03/22 12:46:35.781
Dec  3 12:46:35.786: INFO: Found 0 stateful pods, waiting for 1
Dec  3 12:46:45.792: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/03/22 12:46:45.792
Dec  3 12:46:45.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 12:46:45.988: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 12:46:45.988: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 12:46:45.988: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 12:46:45.993: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 12:46:55.998: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 12:46:55.998: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 12:46:56.017: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  3 12:46:56.017: INFO: ss-0  ip-172-31-38-234  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
Dec  3 12:46:56.017: INFO: 
Dec  3 12:46:56.017: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  3 12:46:57.023: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996806549s
Dec  3 12:46:58.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990815428s
Dec  3 12:46:59.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985977809s
Dec  3 12:47:00.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979820605s
Dec  3 12:47:01.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973434299s
Dec  3 12:47:02.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96800625s
Dec  3 12:47:03.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96256559s
Dec  3 12:47:04.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956605899s
Dec  3 12:47:05.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.462854ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6649 12/03/22 12:47:06.071
Dec  3 12:47:06.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 12:47:06.248: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 12:47:06.248: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 12:47:06.248: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 12:47:06.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 12:47:06.464: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 12:47:06.464: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 12:47:06.464: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 12:47:06.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 12:47:06.664: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 12:47:06.664: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 12:47:06.664: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 12:47:06.670: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  3 12:47:16.676: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:47:16.676: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:47:16.676: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 12/03/22 12:47:16.676
Dec  3 12:47:16.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 12:47:16.885: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 12:47:16.885: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 12:47:16.885: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 12:47:16.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 12:47:17.064: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 12:47:17.064: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 12:47:17.064: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 12:47:17.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 12:47:17.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 12:47:17.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 12:47:17.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 12:47:17.249: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 12:47:17.253: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  3 12:47:27.264: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 12:47:27.264: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 12:47:27.264: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 12:47:27.281: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  3 12:47:27.281: INFO: ss-0  ip-172-31-38-234  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
Dec  3 12:47:27.281: INFO: ss-1  ip-172-31-76-203  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
Dec  3 12:47:27.281: INFO: ss-2  ip-172-31-4-162   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
Dec  3 12:47:27.281: INFO: 
Dec  3 12:47:27.281: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 12:47:28.286: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  3 12:47:28.286: INFO: ss-0  ip-172-31-38-234  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
Dec  3 12:47:28.286: INFO: ss-1  ip-172-31-76-203  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
Dec  3 12:47:28.286: INFO: 
Dec  3 12:47:28.286: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 12:47:29.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.990652328s
Dec  3 12:47:30.297: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.985050515s
Dec  3 12:47:31.306: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974955651s
Dec  3 12:47:32.312: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.970782016s
Dec  3 12:47:33.317: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.964570535s
Dec  3 12:47:34.322: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.959582841s
Dec  3 12:47:35.327: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954815037s
Dec  3 12:47:36.332: INFO: Verifying statefulset ss doesn't scale past 0 for another 949.621934ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6649 12/03/22 12:47:37.332
Dec  3 12:47:37.338: INFO: Scaling statefulset ss to 0
Dec  3 12:47:37.357: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 12:47:37.361: INFO: Deleting all statefulset in ns statefulset-6649
Dec  3 12:47:37.364: INFO: Scaling statefulset ss to 0
Dec  3 12:47:37.378: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 12:47:37.383: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 12:47:37.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6649" for this suite. 12/03/22 12:47:37.403
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":142,"skipped":2683,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.674 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:46:35.736
    Dec  3 12:46:35.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 12:46:35.737
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:46:35.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:46:35.758
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6649 12/03/22 12:46:35.762
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-6649 12/03/22 12:46:35.772
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6649 12/03/22 12:46:35.781
    Dec  3 12:46:35.786: INFO: Found 0 stateful pods, waiting for 1
    Dec  3 12:46:45.792: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/03/22 12:46:45.792
    Dec  3 12:46:45.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 12:46:45.988: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 12:46:45.988: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 12:46:45.988: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 12:46:45.993: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec  3 12:46:55.998: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 12:46:55.998: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 12:46:56.017: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Dec  3 12:46:56.017: INFO: ss-0  ip-172-31-38-234  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
    Dec  3 12:46:56.017: INFO: 
    Dec  3 12:46:56.017: INFO: StatefulSet ss has not reached scale 3, at 1
    Dec  3 12:46:57.023: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996806549s
    Dec  3 12:46:58.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990815428s
    Dec  3 12:46:59.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985977809s
    Dec  3 12:47:00.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979820605s
    Dec  3 12:47:01.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973434299s
    Dec  3 12:47:02.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96800625s
    Dec  3 12:47:03.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96256559s
    Dec  3 12:47:04.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956605899s
    Dec  3 12:47:05.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.462854ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6649 12/03/22 12:47:06.071
    Dec  3 12:47:06.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 12:47:06.248: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 12:47:06.248: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 12:47:06.248: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 12:47:06.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 12:47:06.464: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec  3 12:47:06.464: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 12:47:06.464: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 12:47:06.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 12:47:06.664: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec  3 12:47:06.664: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 12:47:06.664: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 12:47:06.670: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Dec  3 12:47:16.676: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:47:16.676: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:47:16.676: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 12/03/22 12:47:16.676
    Dec  3 12:47:16.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 12:47:16.885: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 12:47:16.885: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 12:47:16.885: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 12:47:16.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 12:47:17.064: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 12:47:17.064: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 12:47:17.064: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 12:47:17.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-6649 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 12:47:17.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 12:47:17.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 12:47:17.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 12:47:17.249: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 12:47:17.253: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Dec  3 12:47:27.264: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 12:47:27.264: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 12:47:27.264: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 12:47:27.281: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Dec  3 12:47:27.281: INFO: ss-0  ip-172-31-38-234  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
    Dec  3 12:47:27.281: INFO: ss-1  ip-172-31-76-203  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
    Dec  3 12:47:27.281: INFO: ss-2  ip-172-31-4-162   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
    Dec  3 12:47:27.281: INFO: 
    Dec  3 12:47:27.281: INFO: StatefulSet ss has not reached scale 0, at 3
    Dec  3 12:47:28.286: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Dec  3 12:47:28.286: INFO: ss-0  ip-172-31-38-234  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:35 +0000 UTC  }]
    Dec  3 12:47:28.286: INFO: ss-1  ip-172-31-76-203  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:47:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 12:46:56 +0000 UTC  }]
    Dec  3 12:47:28.286: INFO: 
    Dec  3 12:47:28.286: INFO: StatefulSet ss has not reached scale 0, at 2
    Dec  3 12:47:29.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.990652328s
    Dec  3 12:47:30.297: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.985050515s
    Dec  3 12:47:31.306: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974955651s
    Dec  3 12:47:32.312: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.970782016s
    Dec  3 12:47:33.317: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.964570535s
    Dec  3 12:47:34.322: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.959582841s
    Dec  3 12:47:35.327: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954815037s
    Dec  3 12:47:36.332: INFO: Verifying statefulset ss doesn't scale past 0 for another 949.621934ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6649 12/03/22 12:47:37.332
    Dec  3 12:47:37.338: INFO: Scaling statefulset ss to 0
    Dec  3 12:47:37.357: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 12:47:37.361: INFO: Deleting all statefulset in ns statefulset-6649
    Dec  3 12:47:37.364: INFO: Scaling statefulset ss to 0
    Dec  3 12:47:37.378: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 12:47:37.383: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 12:47:37.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6649" for this suite. 12/03/22 12:47:37.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:47:37.417
Dec  3 12:47:37.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svc-latency 12/03/22 12:47:37.418
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:37.442
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:37.445
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Dec  3 12:47:37.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8851 12/03/22 12:47:37.453
I1203 12:47:37.460242      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8851, replica count: 1
I1203 12:47:38.510961      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 12:47:39.511136      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 12:47:39.623: INFO: Created: latency-svc-6kdhb
Dec  3 12:47:39.636: INFO: Got endpoints: latency-svc-6kdhb [24.246721ms]
Dec  3 12:47:39.668: INFO: Created: latency-svc-lv65p
Dec  3 12:47:39.674: INFO: Created: latency-svc-nb4bh
Dec  3 12:47:39.676: INFO: Got endpoints: latency-svc-lv65p [39.894634ms]
Dec  3 12:47:39.683: INFO: Created: latency-svc-tn95t
Dec  3 12:47:39.687: INFO: Got endpoints: latency-svc-nb4bh [50.153978ms]
Dec  3 12:47:39.692: INFO: Created: latency-svc-8v8k8
Dec  3 12:47:39.696: INFO: Created: latency-svc-n7vsg
Dec  3 12:47:39.700: INFO: Got endpoints: latency-svc-tn95t [64.138779ms]
Dec  3 12:47:39.704: INFO: Created: latency-svc-h45wk
Dec  3 12:47:39.713: INFO: Created: latency-svc-frpxf
Dec  3 12:47:39.719: INFO: Created: latency-svc-vn74f
Dec  3 12:47:39.726: INFO: Got endpoints: latency-svc-n7vsg [89.247574ms]
Dec  3 12:47:39.729: INFO: Got endpoints: latency-svc-8v8k8 [93.121961ms]
Dec  3 12:47:39.732: INFO: Got endpoints: latency-svc-h45wk [95.979355ms]
Dec  3 12:47:39.736: INFO: Created: latency-svc-96crt
Dec  3 12:47:39.743: INFO: Created: latency-svc-2khsr
Dec  3 12:47:39.757: INFO: Created: latency-svc-dpbl6
Dec  3 12:47:39.761: INFO: Created: latency-svc-884hd
Dec  3 12:47:39.762: INFO: Got endpoints: latency-svc-frpxf [125.875561ms]
Dec  3 12:47:39.765: INFO: Got endpoints: latency-svc-vn74f [129.152213ms]
Dec  3 12:47:39.769: INFO: Got endpoints: latency-svc-96crt [132.737552ms]
Dec  3 12:47:39.777: INFO: Created: latency-svc-wb76f
Dec  3 12:47:39.783: INFO: Got endpoints: latency-svc-2khsr [146.293965ms]
Dec  3 12:47:39.786: INFO: Created: latency-svc-fxt56
Dec  3 12:47:39.786: INFO: Got endpoints: latency-svc-dpbl6 [149.968433ms]
Dec  3 12:47:39.790: INFO: Got endpoints: latency-svc-884hd [152.891666ms]
Dec  3 12:47:39.791: INFO: Created: latency-svc-m9zvz
Dec  3 12:47:39.796: INFO: Got endpoints: latency-svc-wb76f [159.409117ms]
Dec  3 12:47:39.796: INFO: Got endpoints: latency-svc-fxt56 [159.269182ms]
Dec  3 12:47:39.802: INFO: Got endpoints: latency-svc-m9zvz [165.436939ms]
Dec  3 12:47:39.811: INFO: Created: latency-svc-k5hw4
Dec  3 12:47:39.819: INFO: Created: latency-svc-tk5g5
Dec  3 12:47:39.820: INFO: Got endpoints: latency-svc-k5hw4 [144.150302ms]
Dec  3 12:47:39.827: INFO: Got endpoints: latency-svc-tk5g5 [139.787025ms]
Dec  3 12:47:39.828: INFO: Created: latency-svc-4lmsr
Dec  3 12:47:39.834: INFO: Created: latency-svc-zkl9q
Dec  3 12:47:39.847: INFO: Got endpoints: latency-svc-4lmsr [147.020989ms]
Dec  3 12:47:39.848: INFO: Got endpoints: latency-svc-zkl9q [122.206645ms]
Dec  3 12:47:39.855: INFO: Created: latency-svc-hnghf
Dec  3 12:47:39.863: INFO: Got endpoints: latency-svc-hnghf [134.504335ms]
Dec  3 12:47:39.865: INFO: Created: latency-svc-z59qx
Dec  3 12:47:39.869: INFO: Created: latency-svc-8n78v
Dec  3 12:47:39.881: INFO: Got endpoints: latency-svc-z59qx [148.708852ms]
Dec  3 12:47:39.881: INFO: Got endpoints: latency-svc-8n78v [118.469865ms]
Dec  3 12:47:40.080: INFO: Created: latency-svc-mdt9q
Dec  3 12:47:40.083: INFO: Created: latency-svc-p2nps
Dec  3 12:47:40.085: INFO: Created: latency-svc-hnzck
Dec  3 12:47:40.085: INFO: Created: latency-svc-m8k9x
Dec  3 12:47:40.089: INFO: Created: latency-svc-lq7c6
Dec  3 12:47:40.089: INFO: Created: latency-svc-nmvst
Dec  3 12:47:40.089: INFO: Created: latency-svc-89glx
Dec  3 12:47:40.089: INFO: Created: latency-svc-hpqrf
Dec  3 12:47:40.092: INFO: Created: latency-svc-ffsbs
Dec  3 12:47:40.093: INFO: Created: latency-svc-ldgbx
Dec  3 12:47:40.093: INFO: Created: latency-svc-95sqs
Dec  3 12:47:40.093: INFO: Created: latency-svc-fvfn7
Dec  3 12:47:40.093: INFO: Created: latency-svc-dw6hc
Dec  3 12:47:40.094: INFO: Created: latency-svc-59gpl
Dec  3 12:47:40.094: INFO: Created: latency-svc-xzqqj
Dec  3 12:47:40.099: INFO: Got endpoints: latency-svc-mdt9q [217.820678ms]
Dec  3 12:47:40.104: INFO: Got endpoints: latency-svc-p2nps [256.899074ms]
Dec  3 12:47:40.107: INFO: Got endpoints: latency-svc-hnzck [287.437649ms]
Dec  3 12:47:40.110: INFO: Got endpoints: latency-svc-hpqrf [313.928758ms]
Dec  3 12:47:40.114: INFO: Got endpoints: latency-svc-dw6hc [330.530168ms]
Dec  3 12:47:40.115: INFO: Got endpoints: latency-svc-95sqs [324.981293ms]
Dec  3 12:47:40.117: INFO: Got endpoints: latency-svc-ldgbx [236.059616ms]
Dec  3 12:47:40.120: INFO: Created: latency-svc-lrt4b
Dec  3 12:47:40.123: INFO: Got endpoints: latency-svc-89glx [327.256123ms]
Dec  3 12:47:40.130: INFO: Created: latency-svc-j762k
Dec  3 12:47:40.131: INFO: Got endpoints: latency-svc-ffsbs [329.351298ms]
Dec  3 12:47:40.133: INFO: Got endpoints: latency-svc-m8k9x [346.964791ms]
Dec  3 12:47:40.137: INFO: Got endpoints: latency-svc-fvfn7 [371.200108ms]
Dec  3 12:47:40.138: INFO: Got endpoints: latency-svc-nmvst [311.352282ms]
Dec  3 12:47:40.139: INFO: Got endpoints: latency-svc-lq7c6 [290.422926ms]
Dec  3 12:47:40.139: INFO: Created: latency-svc-j6gx7
Dec  3 12:47:40.147: INFO: Created: latency-svc-cnl9j
Dec  3 12:47:40.151: INFO: Got endpoints: latency-svc-xzqqj [382.442752ms]
Dec  3 12:47:40.154: INFO: Got endpoints: latency-svc-lrt4b [55.258036ms]
Dec  3 12:47:40.156: INFO: Created: latency-svc-k5qf9
Dec  3 12:47:40.157: INFO: Got endpoints: latency-svc-j762k [49.816431ms]
Dec  3 12:47:40.157: INFO: Got endpoints: latency-svc-59gpl [293.87325ms]
Dec  3 12:47:40.171: INFO: Created: latency-svc-cppck
Dec  3 12:47:40.175: INFO: Created: latency-svc-vfhhl
Dec  3 12:47:40.181: INFO: Created: latency-svc-qfwvg
Dec  3 12:47:40.181: INFO: Got endpoints: latency-svc-j6gx7 [77.032036ms]
Dec  3 12:47:40.190: INFO: Created: latency-svc-2tw9x
Dec  3 12:47:40.195: INFO: Created: latency-svc-qb5gk
Dec  3 12:47:40.203: INFO: Created: latency-svc-hvs8j
Dec  3 12:47:40.215: INFO: Created: latency-svc-s9jnm
Dec  3 12:47:40.220: INFO: Created: latency-svc-457w8
Dec  3 12:47:40.224: INFO: Created: latency-svc-7fm87
Dec  3 12:47:40.232: INFO: Got endpoints: latency-svc-cnl9j [121.859216ms]
Dec  3 12:47:40.233: INFO: Created: latency-svc-x8wds
Dec  3 12:47:40.239: INFO: Created: latency-svc-xrb9f
Dec  3 12:47:40.245: INFO: Created: latency-svc-wh77p
Dec  3 12:47:40.256: INFO: Created: latency-svc-hknvc
Dec  3 12:47:40.260: INFO: Created: latency-svc-4x6sz
Dec  3 12:47:40.281: INFO: Got endpoints: latency-svc-k5qf9 [167.802677ms]
Dec  3 12:47:40.294: INFO: Created: latency-svc-mqk7r
Dec  3 12:47:40.332: INFO: Got endpoints: latency-svc-cppck [217.899725ms]
Dec  3 12:47:40.347: INFO: Created: latency-svc-ll2t4
Dec  3 12:47:40.382: INFO: Got endpoints: latency-svc-vfhhl [264.978808ms]
Dec  3 12:47:40.393: INFO: Created: latency-svc-hhv2k
Dec  3 12:47:40.435: INFO: Got endpoints: latency-svc-qfwvg [311.852809ms]
Dec  3 12:47:40.449: INFO: Created: latency-svc-xtd4p
Dec  3 12:47:40.482: INFO: Got endpoints: latency-svc-2tw9x [350.45553ms]
Dec  3 12:47:40.496: INFO: Created: latency-svc-vhwr2
Dec  3 12:47:40.532: INFO: Got endpoints: latency-svc-qb5gk [398.874593ms]
Dec  3 12:47:40.544: INFO: Created: latency-svc-8tdm9
Dec  3 12:47:40.581: INFO: Got endpoints: latency-svc-hvs8j [444.829653ms]
Dec  3 12:47:40.593: INFO: Created: latency-svc-jngfq
Dec  3 12:47:40.630: INFO: Got endpoints: latency-svc-s9jnm [491.843766ms]
Dec  3 12:47:40.644: INFO: Created: latency-svc-q2mfx
Dec  3 12:47:40.684: INFO: Got endpoints: latency-svc-457w8 [545.608709ms]
Dec  3 12:47:40.696: INFO: Created: latency-svc-dk5ls
Dec  3 12:47:40.732: INFO: Got endpoints: latency-svc-7fm87 [580.16747ms]
Dec  3 12:47:40.750: INFO: Created: latency-svc-tf6r9
Dec  3 12:47:40.780: INFO: Got endpoints: latency-svc-x8wds [625.396912ms]
Dec  3 12:47:40.793: INFO: Created: latency-svc-f88dp
Dec  3 12:47:40.831: INFO: Got endpoints: latency-svc-xrb9f [673.920597ms]
Dec  3 12:47:40.843: INFO: Created: latency-svc-cn4fz
Dec  3 12:47:40.881: INFO: Got endpoints: latency-svc-wh77p [723.252559ms]
Dec  3 12:47:40.890: INFO: Created: latency-svc-tr2cg
Dec  3 12:47:40.932: INFO: Got endpoints: latency-svc-hknvc [750.144157ms]
Dec  3 12:47:40.943: INFO: Created: latency-svc-v64ll
Dec  3 12:47:40.983: INFO: Got endpoints: latency-svc-4x6sz [750.690591ms]
Dec  3 12:47:40.993: INFO: Created: latency-svc-p2wxn
Dec  3 12:47:41.032: INFO: Got endpoints: latency-svc-mqk7r [750.285983ms]
Dec  3 12:47:41.042: INFO: Created: latency-svc-5np4q
Dec  3 12:47:41.081: INFO: Got endpoints: latency-svc-ll2t4 [748.015408ms]
Dec  3 12:47:41.093: INFO: Created: latency-svc-c5hqd
Dec  3 12:47:41.130: INFO: Got endpoints: latency-svc-hhv2k [747.876802ms]
Dec  3 12:47:41.140: INFO: Created: latency-svc-2w78b
Dec  3 12:47:41.183: INFO: Got endpoints: latency-svc-xtd4p [747.998714ms]
Dec  3 12:47:41.193: INFO: Created: latency-svc-fvbhh
Dec  3 12:47:41.230: INFO: Got endpoints: latency-svc-vhwr2 [748.147522ms]
Dec  3 12:47:41.245: INFO: Created: latency-svc-7jcch
Dec  3 12:47:41.281: INFO: Got endpoints: latency-svc-8tdm9 [748.33815ms]
Dec  3 12:47:41.291: INFO: Created: latency-svc-k9sxp
Dec  3 12:47:41.331: INFO: Got endpoints: latency-svc-jngfq [749.416366ms]
Dec  3 12:47:41.343: INFO: Created: latency-svc-rfngx
Dec  3 12:47:41.381: INFO: Got endpoints: latency-svc-q2mfx [750.03842ms]
Dec  3 12:47:41.393: INFO: Created: latency-svc-wkf4n
Dec  3 12:47:41.434: INFO: Got endpoints: latency-svc-dk5ls [749.657935ms]
Dec  3 12:47:41.504: INFO: Got endpoints: latency-svc-tf6r9 [772.464815ms]
Dec  3 12:47:41.513: INFO: Created: latency-svc-dzpzh
Dec  3 12:47:41.518: INFO: Created: latency-svc-7ccrl
Dec  3 12:47:41.531: INFO: Got endpoints: latency-svc-f88dp [751.660881ms]
Dec  3 12:47:41.544: INFO: Created: latency-svc-xp8kz
Dec  3 12:47:41.580: INFO: Got endpoints: latency-svc-cn4fz [748.34677ms]
Dec  3 12:47:41.592: INFO: Created: latency-svc-pv86k
Dec  3 12:47:41.633: INFO: Got endpoints: latency-svc-tr2cg [752.41507ms]
Dec  3 12:47:41.644: INFO: Created: latency-svc-mrhqb
Dec  3 12:47:41.685: INFO: Got endpoints: latency-svc-v64ll [752.900453ms]
Dec  3 12:47:41.696: INFO: Created: latency-svc-j2gnn
Dec  3 12:47:41.731: INFO: Got endpoints: latency-svc-p2wxn [748.081766ms]
Dec  3 12:47:41.742: INFO: Created: latency-svc-tv4gc
Dec  3 12:47:41.785: INFO: Got endpoints: latency-svc-5np4q [753.093914ms]
Dec  3 12:47:41.796: INFO: Created: latency-svc-snx99
Dec  3 12:47:41.830: INFO: Got endpoints: latency-svc-c5hqd [748.915918ms]
Dec  3 12:47:41.842: INFO: Created: latency-svc-984nq
Dec  3 12:47:41.881: INFO: Got endpoints: latency-svc-2w78b [750.632251ms]
Dec  3 12:47:41.892: INFO: Created: latency-svc-z4mfb
Dec  3 12:47:41.932: INFO: Got endpoints: latency-svc-fvbhh [748.875956ms]
Dec  3 12:47:41.943: INFO: Created: latency-svc-jh7xh
Dec  3 12:47:41.982: INFO: Got endpoints: latency-svc-7jcch [751.282812ms]
Dec  3 12:47:41.994: INFO: Created: latency-svc-v4m7v
Dec  3 12:47:42.033: INFO: Got endpoints: latency-svc-k9sxp [752.106899ms]
Dec  3 12:47:42.045: INFO: Created: latency-svc-c9lng
Dec  3 12:47:42.080: INFO: Got endpoints: latency-svc-rfngx [749.40817ms]
Dec  3 12:47:42.090: INFO: Created: latency-svc-587nf
Dec  3 12:47:42.130: INFO: Got endpoints: latency-svc-wkf4n [749.701851ms]
Dec  3 12:47:42.143: INFO: Created: latency-svc-zlwqh
Dec  3 12:47:42.181: INFO: Got endpoints: latency-svc-dzpzh [746.422319ms]
Dec  3 12:47:42.198: INFO: Created: latency-svc-sdfw8
Dec  3 12:47:42.231: INFO: Got endpoints: latency-svc-7ccrl [727.035584ms]
Dec  3 12:47:42.244: INFO: Created: latency-svc-jcdt2
Dec  3 12:47:42.280: INFO: Got endpoints: latency-svc-xp8kz [748.668252ms]
Dec  3 12:47:42.293: INFO: Created: latency-svc-lqrbz
Dec  3 12:47:42.330: INFO: Got endpoints: latency-svc-pv86k [750.346975ms]
Dec  3 12:47:42.342: INFO: Created: latency-svc-czs8c
Dec  3 12:47:42.382: INFO: Got endpoints: latency-svc-mrhqb [748.528145ms]
Dec  3 12:47:42.392: INFO: Created: latency-svc-c6zg8
Dec  3 12:47:42.442: INFO: Got endpoints: latency-svc-j2gnn [757.303353ms]
Dec  3 12:47:42.454: INFO: Created: latency-svc-pd7qr
Dec  3 12:47:42.480: INFO: Got endpoints: latency-svc-tv4gc [749.35825ms]
Dec  3 12:47:42.491: INFO: Created: latency-svc-xh8b4
Dec  3 12:47:42.532: INFO: Got endpoints: latency-svc-snx99 [746.768613ms]
Dec  3 12:47:42.542: INFO: Created: latency-svc-4sckl
Dec  3 12:47:42.580: INFO: Got endpoints: latency-svc-984nq [750.54834ms]
Dec  3 12:47:42.593: INFO: Created: latency-svc-p67d6
Dec  3 12:47:42.632: INFO: Got endpoints: latency-svc-z4mfb [751.693208ms]
Dec  3 12:47:42.653: INFO: Created: latency-svc-qwrgd
Dec  3 12:47:42.683: INFO: Got endpoints: latency-svc-jh7xh [751.15056ms]
Dec  3 12:47:42.700: INFO: Created: latency-svc-lqv5d
Dec  3 12:47:42.733: INFO: Got endpoints: latency-svc-v4m7v [750.451207ms]
Dec  3 12:47:42.747: INFO: Created: latency-svc-nrt2c
Dec  3 12:47:42.783: INFO: Got endpoints: latency-svc-c9lng [750.463592ms]
Dec  3 12:47:42.797: INFO: Created: latency-svc-ql66v
Dec  3 12:47:42.833: INFO: Got endpoints: latency-svc-587nf [752.085618ms]
Dec  3 12:47:42.842: INFO: Created: latency-svc-x4lqd
Dec  3 12:47:42.880: INFO: Got endpoints: latency-svc-zlwqh [749.611853ms]
Dec  3 12:47:42.891: INFO: Created: latency-svc-h896c
Dec  3 12:47:42.931: INFO: Got endpoints: latency-svc-sdfw8 [749.744929ms]
Dec  3 12:47:42.960: INFO: Created: latency-svc-bmvjf
Dec  3 12:47:42.980: INFO: Got endpoints: latency-svc-jcdt2 [748.559035ms]
Dec  3 12:47:42.991: INFO: Created: latency-svc-q5cqr
Dec  3 12:47:43.038: INFO: Got endpoints: latency-svc-lqrbz [757.344735ms]
Dec  3 12:47:43.050: INFO: Created: latency-svc-rt6kj
Dec  3 12:47:43.085: INFO: Got endpoints: latency-svc-czs8c [754.110214ms]
Dec  3 12:47:43.098: INFO: Created: latency-svc-t42jg
Dec  3 12:47:43.131: INFO: Got endpoints: latency-svc-c6zg8 [748.661045ms]
Dec  3 12:47:43.143: INFO: Created: latency-svc-mlc4b
Dec  3 12:47:43.183: INFO: Got endpoints: latency-svc-pd7qr [740.952572ms]
Dec  3 12:47:43.197: INFO: Created: latency-svc-629b2
Dec  3 12:47:43.281: INFO: Got endpoints: latency-svc-xh8b4 [800.814999ms]
Dec  3 12:47:43.300: INFO: Created: latency-svc-tm78w
Dec  3 12:47:43.331: INFO: Got endpoints: latency-svc-4sckl [798.888476ms]
Dec  3 12:47:43.340: INFO: Created: latency-svc-kbnxz
Dec  3 12:47:43.381: INFO: Got endpoints: latency-svc-p67d6 [801.012805ms]
Dec  3 12:47:43.392: INFO: Created: latency-svc-tjkvg
Dec  3 12:47:43.433: INFO: Got endpoints: latency-svc-qwrgd [800.113026ms]
Dec  3 12:47:43.446: INFO: Created: latency-svc-pnkjn
Dec  3 12:47:43.480: INFO: Got endpoints: latency-svc-lqv5d [796.665341ms]
Dec  3 12:47:43.493: INFO: Created: latency-svc-xfvmp
Dec  3 12:47:43.535: INFO: Got endpoints: latency-svc-nrt2c [802.11792ms]
Dec  3 12:47:43.547: INFO: Created: latency-svc-dp65d
Dec  3 12:47:43.584: INFO: Got endpoints: latency-svc-ql66v [799.751647ms]
Dec  3 12:47:43.596: INFO: Created: latency-svc-7xlx5
Dec  3 12:47:43.632: INFO: Got endpoints: latency-svc-x4lqd [799.318145ms]
Dec  3 12:47:43.646: INFO: Created: latency-svc-k5288
Dec  3 12:47:43.684: INFO: Got endpoints: latency-svc-h896c [803.543382ms]
Dec  3 12:47:43.696: INFO: Created: latency-svc-v2s2m
Dec  3 12:47:43.730: INFO: Got endpoints: latency-svc-bmvjf [798.710581ms]
Dec  3 12:47:43.741: INFO: Created: latency-svc-ljs8z
Dec  3 12:47:43.780: INFO: Got endpoints: latency-svc-q5cqr [799.814978ms]
Dec  3 12:47:43.792: INFO: Created: latency-svc-4ktlx
Dec  3 12:47:43.833: INFO: Got endpoints: latency-svc-rt6kj [795.443134ms]
Dec  3 12:47:43.847: INFO: Created: latency-svc-xmww8
Dec  3 12:47:43.882: INFO: Got endpoints: latency-svc-t42jg [796.896667ms]
Dec  3 12:47:43.893: INFO: Created: latency-svc-49hq7
Dec  3 12:47:43.931: INFO: Got endpoints: latency-svc-mlc4b [800.680084ms]
Dec  3 12:47:43.941: INFO: Created: latency-svc-xqlc8
Dec  3 12:47:43.982: INFO: Got endpoints: latency-svc-629b2 [798.224437ms]
Dec  3 12:47:43.994: INFO: Created: latency-svc-htq4s
Dec  3 12:47:44.031: INFO: Got endpoints: latency-svc-tm78w [749.48115ms]
Dec  3 12:47:44.041: INFO: Created: latency-svc-26vck
Dec  3 12:47:44.084: INFO: Got endpoints: latency-svc-kbnxz [752.81304ms]
Dec  3 12:47:44.097: INFO: Created: latency-svc-9rqlm
Dec  3 12:47:44.132: INFO: Got endpoints: latency-svc-tjkvg [750.602457ms]
Dec  3 12:47:44.144: INFO: Created: latency-svc-vk9k4
Dec  3 12:47:44.182: INFO: Got endpoints: latency-svc-pnkjn [749.430584ms]
Dec  3 12:47:44.197: INFO: Created: latency-svc-xxkxz
Dec  3 12:47:44.231: INFO: Got endpoints: latency-svc-xfvmp [750.122476ms]
Dec  3 12:47:44.241: INFO: Created: latency-svc-s9fps
Dec  3 12:47:44.283: INFO: Got endpoints: latency-svc-dp65d [747.692319ms]
Dec  3 12:47:44.294: INFO: Created: latency-svc-9rp9f
Dec  3 12:47:44.333: INFO: Got endpoints: latency-svc-7xlx5 [748.591511ms]
Dec  3 12:47:44.356: INFO: Created: latency-svc-q9226
Dec  3 12:47:44.380: INFO: Got endpoints: latency-svc-k5288 [747.879368ms]
Dec  3 12:47:44.391: INFO: Created: latency-svc-knhxb
Dec  3 12:47:44.432: INFO: Got endpoints: latency-svc-v2s2m [748.316923ms]
Dec  3 12:47:44.448: INFO: Created: latency-svc-4cdc6
Dec  3 12:47:44.482: INFO: Got endpoints: latency-svc-ljs8z [752.041688ms]
Dec  3 12:47:44.493: INFO: Created: latency-svc-9h228
Dec  3 12:47:44.533: INFO: Got endpoints: latency-svc-4ktlx [752.325967ms]
Dec  3 12:47:44.543: INFO: Created: latency-svc-c9z59
Dec  3 12:47:44.580: INFO: Got endpoints: latency-svc-xmww8 [747.100719ms]
Dec  3 12:47:44.593: INFO: Created: latency-svc-dzqlk
Dec  3 12:47:44.633: INFO: Got endpoints: latency-svc-49hq7 [750.921001ms]
Dec  3 12:47:44.650: INFO: Created: latency-svc-wclf7
Dec  3 12:47:44.683: INFO: Got endpoints: latency-svc-xqlc8 [751.727845ms]
Dec  3 12:47:44.696: INFO: Created: latency-svc-wcvc5
Dec  3 12:47:44.733: INFO: Got endpoints: latency-svc-htq4s [751.519617ms]
Dec  3 12:47:44.747: INFO: Created: latency-svc-s54tc
Dec  3 12:47:44.784: INFO: Got endpoints: latency-svc-26vck [752.714794ms]
Dec  3 12:47:44.796: INFO: Created: latency-svc-5258r
Dec  3 12:47:44.833: INFO: Got endpoints: latency-svc-9rqlm [749.046315ms]
Dec  3 12:47:44.843: INFO: Created: latency-svc-6m2wq
Dec  3 12:47:44.882: INFO: Got endpoints: latency-svc-vk9k4 [749.637632ms]
Dec  3 12:47:44.896: INFO: Created: latency-svc-v2jsr
Dec  3 12:47:44.931: INFO: Got endpoints: latency-svc-xxkxz [749.33342ms]
Dec  3 12:47:44.943: INFO: Created: latency-svc-slbw2
Dec  3 12:47:44.981: INFO: Got endpoints: latency-svc-s9fps [750.587495ms]
Dec  3 12:47:44.991: INFO: Created: latency-svc-wbdqt
Dec  3 12:47:45.032: INFO: Got endpoints: latency-svc-9rp9f [748.236357ms]
Dec  3 12:47:45.045: INFO: Created: latency-svc-5wwmq
Dec  3 12:47:45.082: INFO: Got endpoints: latency-svc-q9226 [748.454416ms]
Dec  3 12:47:45.094: INFO: Created: latency-svc-9hdlz
Dec  3 12:47:45.131: INFO: Got endpoints: latency-svc-knhxb [750.480489ms]
Dec  3 12:47:45.143: INFO: Created: latency-svc-ngb8r
Dec  3 12:47:45.181: INFO: Got endpoints: latency-svc-4cdc6 [748.937063ms]
Dec  3 12:47:45.194: INFO: Created: latency-svc-n8nmh
Dec  3 12:47:45.230: INFO: Got endpoints: latency-svc-9h228 [747.327406ms]
Dec  3 12:47:45.244: INFO: Created: latency-svc-mf76c
Dec  3 12:47:45.281: INFO: Got endpoints: latency-svc-c9z59 [748.039015ms]
Dec  3 12:47:45.290: INFO: Created: latency-svc-b52k9
Dec  3 12:47:45.333: INFO: Got endpoints: latency-svc-dzqlk [751.59237ms]
Dec  3 12:47:45.350: INFO: Created: latency-svc-hk6xd
Dec  3 12:47:45.381: INFO: Got endpoints: latency-svc-wclf7 [748.279157ms]
Dec  3 12:47:45.394: INFO: Created: latency-svc-b9gd9
Dec  3 12:47:45.432: INFO: Got endpoints: latency-svc-wcvc5 [748.547305ms]
Dec  3 12:47:45.442: INFO: Created: latency-svc-7gvb6
Dec  3 12:47:45.483: INFO: Got endpoints: latency-svc-s54tc [749.694001ms]
Dec  3 12:47:45.499: INFO: Created: latency-svc-tztb2
Dec  3 12:47:45.530: INFO: Got endpoints: latency-svc-5258r [746.564737ms]
Dec  3 12:47:45.542: INFO: Created: latency-svc-xkj87
Dec  3 12:47:45.585: INFO: Got endpoints: latency-svc-6m2wq [751.974892ms]
Dec  3 12:47:45.594: INFO: Created: latency-svc-m2dxb
Dec  3 12:47:45.634: INFO: Got endpoints: latency-svc-v2jsr [752.426285ms]
Dec  3 12:47:45.652: INFO: Created: latency-svc-6nbns
Dec  3 12:47:45.683: INFO: Got endpoints: latency-svc-slbw2 [751.172482ms]
Dec  3 12:47:45.695: INFO: Created: latency-svc-js6hr
Dec  3 12:47:45.732: INFO: Got endpoints: latency-svc-wbdqt [750.389597ms]
Dec  3 12:47:45.743: INFO: Created: latency-svc-lf9gl
Dec  3 12:47:45.780: INFO: Got endpoints: latency-svc-5wwmq [748.644357ms]
Dec  3 12:47:45.793: INFO: Created: latency-svc-krftk
Dec  3 12:47:45.834: INFO: Got endpoints: latency-svc-9hdlz [751.756453ms]
Dec  3 12:47:45.849: INFO: Created: latency-svc-zwnx6
Dec  3 12:47:45.881: INFO: Got endpoints: latency-svc-ngb8r [750.722653ms]
Dec  3 12:47:45.898: INFO: Created: latency-svc-2w4m5
Dec  3 12:47:45.930: INFO: Got endpoints: latency-svc-n8nmh [748.8259ms]
Dec  3 12:47:45.944: INFO: Created: latency-svc-w9fht
Dec  3 12:47:45.982: INFO: Got endpoints: latency-svc-mf76c [752.150265ms]
Dec  3 12:47:45.998: INFO: Created: latency-svc-c6lzs
Dec  3 12:47:46.032: INFO: Got endpoints: latency-svc-b52k9 [751.185257ms]
Dec  3 12:47:46.043: INFO: Created: latency-svc-x4qlj
Dec  3 12:47:46.082: INFO: Got endpoints: latency-svc-hk6xd [748.815308ms]
Dec  3 12:47:46.094: INFO: Created: latency-svc-89pmm
Dec  3 12:47:46.132: INFO: Got endpoints: latency-svc-b9gd9 [750.656264ms]
Dec  3 12:47:46.149: INFO: Created: latency-svc-vbcxt
Dec  3 12:47:46.183: INFO: Got endpoints: latency-svc-7gvb6 [750.707387ms]
Dec  3 12:47:46.196: INFO: Created: latency-svc-zxtzj
Dec  3 12:47:46.232: INFO: Got endpoints: latency-svc-tztb2 [748.624058ms]
Dec  3 12:47:46.246: INFO: Created: latency-svc-8tn5h
Dec  3 12:47:46.284: INFO: Got endpoints: latency-svc-xkj87 [753.094002ms]
Dec  3 12:47:46.296: INFO: Created: latency-svc-xvzjp
Dec  3 12:47:46.332: INFO: Got endpoints: latency-svc-m2dxb [746.498276ms]
Dec  3 12:47:46.345: INFO: Created: latency-svc-8ltth
Dec  3 12:47:46.381: INFO: Got endpoints: latency-svc-6nbns [745.827452ms]
Dec  3 12:47:46.396: INFO: Created: latency-svc-xvqcs
Dec  3 12:47:46.431: INFO: Got endpoints: latency-svc-js6hr [748.01416ms]
Dec  3 12:47:46.444: INFO: Created: latency-svc-k5pmq
Dec  3 12:47:46.481: INFO: Got endpoints: latency-svc-lf9gl [748.666716ms]
Dec  3 12:47:46.493: INFO: Created: latency-svc-fzn4j
Dec  3 12:47:46.533: INFO: Got endpoints: latency-svc-krftk [752.563204ms]
Dec  3 12:47:46.554: INFO: Created: latency-svc-thxnp
Dec  3 12:47:46.581: INFO: Got endpoints: latency-svc-zwnx6 [747.571312ms]
Dec  3 12:47:46.594: INFO: Created: latency-svc-bk5jn
Dec  3 12:47:46.631: INFO: Got endpoints: latency-svc-2w4m5 [748.931519ms]
Dec  3 12:47:46.650: INFO: Created: latency-svc-cwt4m
Dec  3 12:47:46.683: INFO: Got endpoints: latency-svc-w9fht [753.085472ms]
Dec  3 12:47:46.702: INFO: Created: latency-svc-fxw6b
Dec  3 12:47:46.731: INFO: Got endpoints: latency-svc-c6lzs [749.047539ms]
Dec  3 12:47:46.749: INFO: Created: latency-svc-gk24w
Dec  3 12:47:46.786: INFO: Got endpoints: latency-svc-x4qlj [753.628352ms]
Dec  3 12:47:46.800: INFO: Created: latency-svc-2jrxg
Dec  3 12:47:46.830: INFO: Got endpoints: latency-svc-89pmm [748.687233ms]
Dec  3 12:47:46.847: INFO: Created: latency-svc-d2wjs
Dec  3 12:47:46.885: INFO: Got endpoints: latency-svc-vbcxt [752.807861ms]
Dec  3 12:47:46.897: INFO: Created: latency-svc-f5t2g
Dec  3 12:47:46.930: INFO: Got endpoints: latency-svc-zxtzj [747.09331ms]
Dec  3 12:47:46.945: INFO: Created: latency-svc-2gfhq
Dec  3 12:47:46.981: INFO: Got endpoints: latency-svc-8tn5h [748.705043ms]
Dec  3 12:47:46.992: INFO: Created: latency-svc-rfl85
Dec  3 12:47:47.031: INFO: Got endpoints: latency-svc-xvzjp [747.024446ms]
Dec  3 12:47:47.042: INFO: Created: latency-svc-n8d6d
Dec  3 12:47:47.083: INFO: Got endpoints: latency-svc-8ltth [750.860965ms]
Dec  3 12:47:47.095: INFO: Created: latency-svc-sx926
Dec  3 12:47:47.133: INFO: Got endpoints: latency-svc-xvqcs [752.118146ms]
Dec  3 12:47:47.147: INFO: Created: latency-svc-v6wch
Dec  3 12:47:47.182: INFO: Got endpoints: latency-svc-k5pmq [750.859896ms]
Dec  3 12:47:47.196: INFO: Created: latency-svc-btkd6
Dec  3 12:47:47.242: INFO: Got endpoints: latency-svc-fzn4j [761.451426ms]
Dec  3 12:47:47.266: INFO: Created: latency-svc-77xlc
Dec  3 12:47:47.280: INFO: Got endpoints: latency-svc-thxnp [747.536653ms]
Dec  3 12:47:47.293: INFO: Created: latency-svc-69snp
Dec  3 12:47:47.331: INFO: Got endpoints: latency-svc-bk5jn [748.979492ms]
Dec  3 12:47:47.342: INFO: Created: latency-svc-n2pxg
Dec  3 12:47:47.384: INFO: Got endpoints: latency-svc-cwt4m [752.167736ms]
Dec  3 12:47:47.395: INFO: Created: latency-svc-rvrvz
Dec  3 12:47:47.431: INFO: Got endpoints: latency-svc-fxw6b [745.989633ms]
Dec  3 12:47:47.443: INFO: Created: latency-svc-fzljs
Dec  3 12:47:47.480: INFO: Got endpoints: latency-svc-gk24w [749.078082ms]
Dec  3 12:47:47.491: INFO: Created: latency-svc-tzgjd
Dec  3 12:47:47.531: INFO: Got endpoints: latency-svc-2jrxg [745.347884ms]
Dec  3 12:47:47.582: INFO: Got endpoints: latency-svc-d2wjs [751.48606ms]
Dec  3 12:47:47.631: INFO: Got endpoints: latency-svc-f5t2g [745.635884ms]
Dec  3 12:47:47.682: INFO: Got endpoints: latency-svc-2gfhq [751.34674ms]
Dec  3 12:47:47.731: INFO: Got endpoints: latency-svc-rfl85 [749.849894ms]
Dec  3 12:47:47.782: INFO: Got endpoints: latency-svc-n8d6d [751.183957ms]
Dec  3 12:47:47.830: INFO: Got endpoints: latency-svc-sx926 [747.612018ms]
Dec  3 12:47:47.882: INFO: Got endpoints: latency-svc-v6wch [749.626394ms]
Dec  3 12:47:47.931: INFO: Got endpoints: latency-svc-btkd6 [748.424505ms]
Dec  3 12:47:47.981: INFO: Got endpoints: latency-svc-77xlc [739.192188ms]
Dec  3 12:47:48.031: INFO: Got endpoints: latency-svc-69snp [749.321448ms]
Dec  3 12:47:48.083: INFO: Got endpoints: latency-svc-n2pxg [752.667002ms]
Dec  3 12:47:48.130: INFO: Got endpoints: latency-svc-rvrvz [746.119446ms]
Dec  3 12:47:48.183: INFO: Got endpoints: latency-svc-fzljs [751.611077ms]
Dec  3 12:47:48.231: INFO: Got endpoints: latency-svc-tzgjd [750.324338ms]
Dec  3 12:47:48.231: INFO: Latencies: [39.894634ms 49.816431ms 50.153978ms 55.258036ms 64.138779ms 77.032036ms 89.247574ms 93.121961ms 95.979355ms 118.469865ms 121.859216ms 122.206645ms 125.875561ms 129.152213ms 132.737552ms 134.504335ms 139.787025ms 144.150302ms 146.293965ms 147.020989ms 148.708852ms 149.968433ms 152.891666ms 159.269182ms 159.409117ms 165.436939ms 167.802677ms 217.820678ms 217.899725ms 236.059616ms 256.899074ms 264.978808ms 287.437649ms 290.422926ms 293.87325ms 311.352282ms 311.852809ms 313.928758ms 324.981293ms 327.256123ms 329.351298ms 330.530168ms 346.964791ms 350.45553ms 371.200108ms 382.442752ms 398.874593ms 444.829653ms 491.843766ms 545.608709ms 580.16747ms 625.396912ms 673.920597ms 723.252559ms 727.035584ms 739.192188ms 740.952572ms 745.347884ms 745.635884ms 745.827452ms 745.989633ms 746.119446ms 746.422319ms 746.498276ms 746.564737ms 746.768613ms 747.024446ms 747.09331ms 747.100719ms 747.327406ms 747.536653ms 747.571312ms 747.612018ms 747.692319ms 747.876802ms 747.879368ms 747.998714ms 748.01416ms 748.015408ms 748.039015ms 748.081766ms 748.147522ms 748.236357ms 748.279157ms 748.316923ms 748.33815ms 748.34677ms 748.424505ms 748.454416ms 748.528145ms 748.547305ms 748.559035ms 748.591511ms 748.624058ms 748.644357ms 748.661045ms 748.666716ms 748.668252ms 748.687233ms 748.705043ms 748.815308ms 748.8259ms 748.875956ms 748.915918ms 748.931519ms 748.937063ms 748.979492ms 749.046315ms 749.047539ms 749.078082ms 749.321448ms 749.33342ms 749.35825ms 749.40817ms 749.416366ms 749.430584ms 749.48115ms 749.611853ms 749.626394ms 749.637632ms 749.657935ms 749.694001ms 749.701851ms 749.744929ms 749.849894ms 750.03842ms 750.122476ms 750.144157ms 750.285983ms 750.324338ms 750.346975ms 750.389597ms 750.451207ms 750.463592ms 750.480489ms 750.54834ms 750.587495ms 750.602457ms 750.632251ms 750.656264ms 750.690591ms 750.707387ms 750.722653ms 750.859896ms 750.860965ms 750.921001ms 751.15056ms 751.172482ms 751.183957ms 751.185257ms 751.282812ms 751.34674ms 751.48606ms 751.519617ms 751.59237ms 751.611077ms 751.660881ms 751.693208ms 751.727845ms 751.756453ms 751.974892ms 752.041688ms 752.085618ms 752.106899ms 752.118146ms 752.150265ms 752.167736ms 752.325967ms 752.41507ms 752.426285ms 752.563204ms 752.667002ms 752.714794ms 752.807861ms 752.81304ms 752.900453ms 753.085472ms 753.093914ms 753.094002ms 753.628352ms 754.110214ms 757.303353ms 757.344735ms 761.451426ms 772.464815ms 795.443134ms 796.665341ms 796.896667ms 798.224437ms 798.710581ms 798.888476ms 799.318145ms 799.751647ms 799.814978ms 800.113026ms 800.680084ms 800.814999ms 801.012805ms 802.11792ms 803.543382ms]
Dec  3 12:47:48.231: INFO: 50 %ile: 748.815308ms
Dec  3 12:47:48.231: INFO: 90 %ile: 754.110214ms
Dec  3 12:47:48.231: INFO: 99 %ile: 802.11792ms
Dec  3 12:47:48.231: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Dec  3 12:47:48.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8851" for this suite. 12/03/22 12:47:48.237
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":143,"skipped":2742,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.828 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:47:37.417
    Dec  3 12:47:37.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svc-latency 12/03/22 12:47:37.418
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:37.442
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:37.445
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Dec  3 12:47:37.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-8851 12/03/22 12:47:37.453
    I1203 12:47:37.460242      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8851, replica count: 1
    I1203 12:47:38.510961      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 12:47:39.511136      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 12:47:39.623: INFO: Created: latency-svc-6kdhb
    Dec  3 12:47:39.636: INFO: Got endpoints: latency-svc-6kdhb [24.246721ms]
    Dec  3 12:47:39.668: INFO: Created: latency-svc-lv65p
    Dec  3 12:47:39.674: INFO: Created: latency-svc-nb4bh
    Dec  3 12:47:39.676: INFO: Got endpoints: latency-svc-lv65p [39.894634ms]
    Dec  3 12:47:39.683: INFO: Created: latency-svc-tn95t
    Dec  3 12:47:39.687: INFO: Got endpoints: latency-svc-nb4bh [50.153978ms]
    Dec  3 12:47:39.692: INFO: Created: latency-svc-8v8k8
    Dec  3 12:47:39.696: INFO: Created: latency-svc-n7vsg
    Dec  3 12:47:39.700: INFO: Got endpoints: latency-svc-tn95t [64.138779ms]
    Dec  3 12:47:39.704: INFO: Created: latency-svc-h45wk
    Dec  3 12:47:39.713: INFO: Created: latency-svc-frpxf
    Dec  3 12:47:39.719: INFO: Created: latency-svc-vn74f
    Dec  3 12:47:39.726: INFO: Got endpoints: latency-svc-n7vsg [89.247574ms]
    Dec  3 12:47:39.729: INFO: Got endpoints: latency-svc-8v8k8 [93.121961ms]
    Dec  3 12:47:39.732: INFO: Got endpoints: latency-svc-h45wk [95.979355ms]
    Dec  3 12:47:39.736: INFO: Created: latency-svc-96crt
    Dec  3 12:47:39.743: INFO: Created: latency-svc-2khsr
    Dec  3 12:47:39.757: INFO: Created: latency-svc-dpbl6
    Dec  3 12:47:39.761: INFO: Created: latency-svc-884hd
    Dec  3 12:47:39.762: INFO: Got endpoints: latency-svc-frpxf [125.875561ms]
    Dec  3 12:47:39.765: INFO: Got endpoints: latency-svc-vn74f [129.152213ms]
    Dec  3 12:47:39.769: INFO: Got endpoints: latency-svc-96crt [132.737552ms]
    Dec  3 12:47:39.777: INFO: Created: latency-svc-wb76f
    Dec  3 12:47:39.783: INFO: Got endpoints: latency-svc-2khsr [146.293965ms]
    Dec  3 12:47:39.786: INFO: Created: latency-svc-fxt56
    Dec  3 12:47:39.786: INFO: Got endpoints: latency-svc-dpbl6 [149.968433ms]
    Dec  3 12:47:39.790: INFO: Got endpoints: latency-svc-884hd [152.891666ms]
    Dec  3 12:47:39.791: INFO: Created: latency-svc-m9zvz
    Dec  3 12:47:39.796: INFO: Got endpoints: latency-svc-wb76f [159.409117ms]
    Dec  3 12:47:39.796: INFO: Got endpoints: latency-svc-fxt56 [159.269182ms]
    Dec  3 12:47:39.802: INFO: Got endpoints: latency-svc-m9zvz [165.436939ms]
    Dec  3 12:47:39.811: INFO: Created: latency-svc-k5hw4
    Dec  3 12:47:39.819: INFO: Created: latency-svc-tk5g5
    Dec  3 12:47:39.820: INFO: Got endpoints: latency-svc-k5hw4 [144.150302ms]
    Dec  3 12:47:39.827: INFO: Got endpoints: latency-svc-tk5g5 [139.787025ms]
    Dec  3 12:47:39.828: INFO: Created: latency-svc-4lmsr
    Dec  3 12:47:39.834: INFO: Created: latency-svc-zkl9q
    Dec  3 12:47:39.847: INFO: Got endpoints: latency-svc-4lmsr [147.020989ms]
    Dec  3 12:47:39.848: INFO: Got endpoints: latency-svc-zkl9q [122.206645ms]
    Dec  3 12:47:39.855: INFO: Created: latency-svc-hnghf
    Dec  3 12:47:39.863: INFO: Got endpoints: latency-svc-hnghf [134.504335ms]
    Dec  3 12:47:39.865: INFO: Created: latency-svc-z59qx
    Dec  3 12:47:39.869: INFO: Created: latency-svc-8n78v
    Dec  3 12:47:39.881: INFO: Got endpoints: latency-svc-z59qx [148.708852ms]
    Dec  3 12:47:39.881: INFO: Got endpoints: latency-svc-8n78v [118.469865ms]
    Dec  3 12:47:40.080: INFO: Created: latency-svc-mdt9q
    Dec  3 12:47:40.083: INFO: Created: latency-svc-p2nps
    Dec  3 12:47:40.085: INFO: Created: latency-svc-hnzck
    Dec  3 12:47:40.085: INFO: Created: latency-svc-m8k9x
    Dec  3 12:47:40.089: INFO: Created: latency-svc-lq7c6
    Dec  3 12:47:40.089: INFO: Created: latency-svc-nmvst
    Dec  3 12:47:40.089: INFO: Created: latency-svc-89glx
    Dec  3 12:47:40.089: INFO: Created: latency-svc-hpqrf
    Dec  3 12:47:40.092: INFO: Created: latency-svc-ffsbs
    Dec  3 12:47:40.093: INFO: Created: latency-svc-ldgbx
    Dec  3 12:47:40.093: INFO: Created: latency-svc-95sqs
    Dec  3 12:47:40.093: INFO: Created: latency-svc-fvfn7
    Dec  3 12:47:40.093: INFO: Created: latency-svc-dw6hc
    Dec  3 12:47:40.094: INFO: Created: latency-svc-59gpl
    Dec  3 12:47:40.094: INFO: Created: latency-svc-xzqqj
    Dec  3 12:47:40.099: INFO: Got endpoints: latency-svc-mdt9q [217.820678ms]
    Dec  3 12:47:40.104: INFO: Got endpoints: latency-svc-p2nps [256.899074ms]
    Dec  3 12:47:40.107: INFO: Got endpoints: latency-svc-hnzck [287.437649ms]
    Dec  3 12:47:40.110: INFO: Got endpoints: latency-svc-hpqrf [313.928758ms]
    Dec  3 12:47:40.114: INFO: Got endpoints: latency-svc-dw6hc [330.530168ms]
    Dec  3 12:47:40.115: INFO: Got endpoints: latency-svc-95sqs [324.981293ms]
    Dec  3 12:47:40.117: INFO: Got endpoints: latency-svc-ldgbx [236.059616ms]
    Dec  3 12:47:40.120: INFO: Created: latency-svc-lrt4b
    Dec  3 12:47:40.123: INFO: Got endpoints: latency-svc-89glx [327.256123ms]
    Dec  3 12:47:40.130: INFO: Created: latency-svc-j762k
    Dec  3 12:47:40.131: INFO: Got endpoints: latency-svc-ffsbs [329.351298ms]
    Dec  3 12:47:40.133: INFO: Got endpoints: latency-svc-m8k9x [346.964791ms]
    Dec  3 12:47:40.137: INFO: Got endpoints: latency-svc-fvfn7 [371.200108ms]
    Dec  3 12:47:40.138: INFO: Got endpoints: latency-svc-nmvst [311.352282ms]
    Dec  3 12:47:40.139: INFO: Got endpoints: latency-svc-lq7c6 [290.422926ms]
    Dec  3 12:47:40.139: INFO: Created: latency-svc-j6gx7
    Dec  3 12:47:40.147: INFO: Created: latency-svc-cnl9j
    Dec  3 12:47:40.151: INFO: Got endpoints: latency-svc-xzqqj [382.442752ms]
    Dec  3 12:47:40.154: INFO: Got endpoints: latency-svc-lrt4b [55.258036ms]
    Dec  3 12:47:40.156: INFO: Created: latency-svc-k5qf9
    Dec  3 12:47:40.157: INFO: Got endpoints: latency-svc-j762k [49.816431ms]
    Dec  3 12:47:40.157: INFO: Got endpoints: latency-svc-59gpl [293.87325ms]
    Dec  3 12:47:40.171: INFO: Created: latency-svc-cppck
    Dec  3 12:47:40.175: INFO: Created: latency-svc-vfhhl
    Dec  3 12:47:40.181: INFO: Created: latency-svc-qfwvg
    Dec  3 12:47:40.181: INFO: Got endpoints: latency-svc-j6gx7 [77.032036ms]
    Dec  3 12:47:40.190: INFO: Created: latency-svc-2tw9x
    Dec  3 12:47:40.195: INFO: Created: latency-svc-qb5gk
    Dec  3 12:47:40.203: INFO: Created: latency-svc-hvs8j
    Dec  3 12:47:40.215: INFO: Created: latency-svc-s9jnm
    Dec  3 12:47:40.220: INFO: Created: latency-svc-457w8
    Dec  3 12:47:40.224: INFO: Created: latency-svc-7fm87
    Dec  3 12:47:40.232: INFO: Got endpoints: latency-svc-cnl9j [121.859216ms]
    Dec  3 12:47:40.233: INFO: Created: latency-svc-x8wds
    Dec  3 12:47:40.239: INFO: Created: latency-svc-xrb9f
    Dec  3 12:47:40.245: INFO: Created: latency-svc-wh77p
    Dec  3 12:47:40.256: INFO: Created: latency-svc-hknvc
    Dec  3 12:47:40.260: INFO: Created: latency-svc-4x6sz
    Dec  3 12:47:40.281: INFO: Got endpoints: latency-svc-k5qf9 [167.802677ms]
    Dec  3 12:47:40.294: INFO: Created: latency-svc-mqk7r
    Dec  3 12:47:40.332: INFO: Got endpoints: latency-svc-cppck [217.899725ms]
    Dec  3 12:47:40.347: INFO: Created: latency-svc-ll2t4
    Dec  3 12:47:40.382: INFO: Got endpoints: latency-svc-vfhhl [264.978808ms]
    Dec  3 12:47:40.393: INFO: Created: latency-svc-hhv2k
    Dec  3 12:47:40.435: INFO: Got endpoints: latency-svc-qfwvg [311.852809ms]
    Dec  3 12:47:40.449: INFO: Created: latency-svc-xtd4p
    Dec  3 12:47:40.482: INFO: Got endpoints: latency-svc-2tw9x [350.45553ms]
    Dec  3 12:47:40.496: INFO: Created: latency-svc-vhwr2
    Dec  3 12:47:40.532: INFO: Got endpoints: latency-svc-qb5gk [398.874593ms]
    Dec  3 12:47:40.544: INFO: Created: latency-svc-8tdm9
    Dec  3 12:47:40.581: INFO: Got endpoints: latency-svc-hvs8j [444.829653ms]
    Dec  3 12:47:40.593: INFO: Created: latency-svc-jngfq
    Dec  3 12:47:40.630: INFO: Got endpoints: latency-svc-s9jnm [491.843766ms]
    Dec  3 12:47:40.644: INFO: Created: latency-svc-q2mfx
    Dec  3 12:47:40.684: INFO: Got endpoints: latency-svc-457w8 [545.608709ms]
    Dec  3 12:47:40.696: INFO: Created: latency-svc-dk5ls
    Dec  3 12:47:40.732: INFO: Got endpoints: latency-svc-7fm87 [580.16747ms]
    Dec  3 12:47:40.750: INFO: Created: latency-svc-tf6r9
    Dec  3 12:47:40.780: INFO: Got endpoints: latency-svc-x8wds [625.396912ms]
    Dec  3 12:47:40.793: INFO: Created: latency-svc-f88dp
    Dec  3 12:47:40.831: INFO: Got endpoints: latency-svc-xrb9f [673.920597ms]
    Dec  3 12:47:40.843: INFO: Created: latency-svc-cn4fz
    Dec  3 12:47:40.881: INFO: Got endpoints: latency-svc-wh77p [723.252559ms]
    Dec  3 12:47:40.890: INFO: Created: latency-svc-tr2cg
    Dec  3 12:47:40.932: INFO: Got endpoints: latency-svc-hknvc [750.144157ms]
    Dec  3 12:47:40.943: INFO: Created: latency-svc-v64ll
    Dec  3 12:47:40.983: INFO: Got endpoints: latency-svc-4x6sz [750.690591ms]
    Dec  3 12:47:40.993: INFO: Created: latency-svc-p2wxn
    Dec  3 12:47:41.032: INFO: Got endpoints: latency-svc-mqk7r [750.285983ms]
    Dec  3 12:47:41.042: INFO: Created: latency-svc-5np4q
    Dec  3 12:47:41.081: INFO: Got endpoints: latency-svc-ll2t4 [748.015408ms]
    Dec  3 12:47:41.093: INFO: Created: latency-svc-c5hqd
    Dec  3 12:47:41.130: INFO: Got endpoints: latency-svc-hhv2k [747.876802ms]
    Dec  3 12:47:41.140: INFO: Created: latency-svc-2w78b
    Dec  3 12:47:41.183: INFO: Got endpoints: latency-svc-xtd4p [747.998714ms]
    Dec  3 12:47:41.193: INFO: Created: latency-svc-fvbhh
    Dec  3 12:47:41.230: INFO: Got endpoints: latency-svc-vhwr2 [748.147522ms]
    Dec  3 12:47:41.245: INFO: Created: latency-svc-7jcch
    Dec  3 12:47:41.281: INFO: Got endpoints: latency-svc-8tdm9 [748.33815ms]
    Dec  3 12:47:41.291: INFO: Created: latency-svc-k9sxp
    Dec  3 12:47:41.331: INFO: Got endpoints: latency-svc-jngfq [749.416366ms]
    Dec  3 12:47:41.343: INFO: Created: latency-svc-rfngx
    Dec  3 12:47:41.381: INFO: Got endpoints: latency-svc-q2mfx [750.03842ms]
    Dec  3 12:47:41.393: INFO: Created: latency-svc-wkf4n
    Dec  3 12:47:41.434: INFO: Got endpoints: latency-svc-dk5ls [749.657935ms]
    Dec  3 12:47:41.504: INFO: Got endpoints: latency-svc-tf6r9 [772.464815ms]
    Dec  3 12:47:41.513: INFO: Created: latency-svc-dzpzh
    Dec  3 12:47:41.518: INFO: Created: latency-svc-7ccrl
    Dec  3 12:47:41.531: INFO: Got endpoints: latency-svc-f88dp [751.660881ms]
    Dec  3 12:47:41.544: INFO: Created: latency-svc-xp8kz
    Dec  3 12:47:41.580: INFO: Got endpoints: latency-svc-cn4fz [748.34677ms]
    Dec  3 12:47:41.592: INFO: Created: latency-svc-pv86k
    Dec  3 12:47:41.633: INFO: Got endpoints: latency-svc-tr2cg [752.41507ms]
    Dec  3 12:47:41.644: INFO: Created: latency-svc-mrhqb
    Dec  3 12:47:41.685: INFO: Got endpoints: latency-svc-v64ll [752.900453ms]
    Dec  3 12:47:41.696: INFO: Created: latency-svc-j2gnn
    Dec  3 12:47:41.731: INFO: Got endpoints: latency-svc-p2wxn [748.081766ms]
    Dec  3 12:47:41.742: INFO: Created: latency-svc-tv4gc
    Dec  3 12:47:41.785: INFO: Got endpoints: latency-svc-5np4q [753.093914ms]
    Dec  3 12:47:41.796: INFO: Created: latency-svc-snx99
    Dec  3 12:47:41.830: INFO: Got endpoints: latency-svc-c5hqd [748.915918ms]
    Dec  3 12:47:41.842: INFO: Created: latency-svc-984nq
    Dec  3 12:47:41.881: INFO: Got endpoints: latency-svc-2w78b [750.632251ms]
    Dec  3 12:47:41.892: INFO: Created: latency-svc-z4mfb
    Dec  3 12:47:41.932: INFO: Got endpoints: latency-svc-fvbhh [748.875956ms]
    Dec  3 12:47:41.943: INFO: Created: latency-svc-jh7xh
    Dec  3 12:47:41.982: INFO: Got endpoints: latency-svc-7jcch [751.282812ms]
    Dec  3 12:47:41.994: INFO: Created: latency-svc-v4m7v
    Dec  3 12:47:42.033: INFO: Got endpoints: latency-svc-k9sxp [752.106899ms]
    Dec  3 12:47:42.045: INFO: Created: latency-svc-c9lng
    Dec  3 12:47:42.080: INFO: Got endpoints: latency-svc-rfngx [749.40817ms]
    Dec  3 12:47:42.090: INFO: Created: latency-svc-587nf
    Dec  3 12:47:42.130: INFO: Got endpoints: latency-svc-wkf4n [749.701851ms]
    Dec  3 12:47:42.143: INFO: Created: latency-svc-zlwqh
    Dec  3 12:47:42.181: INFO: Got endpoints: latency-svc-dzpzh [746.422319ms]
    Dec  3 12:47:42.198: INFO: Created: latency-svc-sdfw8
    Dec  3 12:47:42.231: INFO: Got endpoints: latency-svc-7ccrl [727.035584ms]
    Dec  3 12:47:42.244: INFO: Created: latency-svc-jcdt2
    Dec  3 12:47:42.280: INFO: Got endpoints: latency-svc-xp8kz [748.668252ms]
    Dec  3 12:47:42.293: INFO: Created: latency-svc-lqrbz
    Dec  3 12:47:42.330: INFO: Got endpoints: latency-svc-pv86k [750.346975ms]
    Dec  3 12:47:42.342: INFO: Created: latency-svc-czs8c
    Dec  3 12:47:42.382: INFO: Got endpoints: latency-svc-mrhqb [748.528145ms]
    Dec  3 12:47:42.392: INFO: Created: latency-svc-c6zg8
    Dec  3 12:47:42.442: INFO: Got endpoints: latency-svc-j2gnn [757.303353ms]
    Dec  3 12:47:42.454: INFO: Created: latency-svc-pd7qr
    Dec  3 12:47:42.480: INFO: Got endpoints: latency-svc-tv4gc [749.35825ms]
    Dec  3 12:47:42.491: INFO: Created: latency-svc-xh8b4
    Dec  3 12:47:42.532: INFO: Got endpoints: latency-svc-snx99 [746.768613ms]
    Dec  3 12:47:42.542: INFO: Created: latency-svc-4sckl
    Dec  3 12:47:42.580: INFO: Got endpoints: latency-svc-984nq [750.54834ms]
    Dec  3 12:47:42.593: INFO: Created: latency-svc-p67d6
    Dec  3 12:47:42.632: INFO: Got endpoints: latency-svc-z4mfb [751.693208ms]
    Dec  3 12:47:42.653: INFO: Created: latency-svc-qwrgd
    Dec  3 12:47:42.683: INFO: Got endpoints: latency-svc-jh7xh [751.15056ms]
    Dec  3 12:47:42.700: INFO: Created: latency-svc-lqv5d
    Dec  3 12:47:42.733: INFO: Got endpoints: latency-svc-v4m7v [750.451207ms]
    Dec  3 12:47:42.747: INFO: Created: latency-svc-nrt2c
    Dec  3 12:47:42.783: INFO: Got endpoints: latency-svc-c9lng [750.463592ms]
    Dec  3 12:47:42.797: INFO: Created: latency-svc-ql66v
    Dec  3 12:47:42.833: INFO: Got endpoints: latency-svc-587nf [752.085618ms]
    Dec  3 12:47:42.842: INFO: Created: latency-svc-x4lqd
    Dec  3 12:47:42.880: INFO: Got endpoints: latency-svc-zlwqh [749.611853ms]
    Dec  3 12:47:42.891: INFO: Created: latency-svc-h896c
    Dec  3 12:47:42.931: INFO: Got endpoints: latency-svc-sdfw8 [749.744929ms]
    Dec  3 12:47:42.960: INFO: Created: latency-svc-bmvjf
    Dec  3 12:47:42.980: INFO: Got endpoints: latency-svc-jcdt2 [748.559035ms]
    Dec  3 12:47:42.991: INFO: Created: latency-svc-q5cqr
    Dec  3 12:47:43.038: INFO: Got endpoints: latency-svc-lqrbz [757.344735ms]
    Dec  3 12:47:43.050: INFO: Created: latency-svc-rt6kj
    Dec  3 12:47:43.085: INFO: Got endpoints: latency-svc-czs8c [754.110214ms]
    Dec  3 12:47:43.098: INFO: Created: latency-svc-t42jg
    Dec  3 12:47:43.131: INFO: Got endpoints: latency-svc-c6zg8 [748.661045ms]
    Dec  3 12:47:43.143: INFO: Created: latency-svc-mlc4b
    Dec  3 12:47:43.183: INFO: Got endpoints: latency-svc-pd7qr [740.952572ms]
    Dec  3 12:47:43.197: INFO: Created: latency-svc-629b2
    Dec  3 12:47:43.281: INFO: Got endpoints: latency-svc-xh8b4 [800.814999ms]
    Dec  3 12:47:43.300: INFO: Created: latency-svc-tm78w
    Dec  3 12:47:43.331: INFO: Got endpoints: latency-svc-4sckl [798.888476ms]
    Dec  3 12:47:43.340: INFO: Created: latency-svc-kbnxz
    Dec  3 12:47:43.381: INFO: Got endpoints: latency-svc-p67d6 [801.012805ms]
    Dec  3 12:47:43.392: INFO: Created: latency-svc-tjkvg
    Dec  3 12:47:43.433: INFO: Got endpoints: latency-svc-qwrgd [800.113026ms]
    Dec  3 12:47:43.446: INFO: Created: latency-svc-pnkjn
    Dec  3 12:47:43.480: INFO: Got endpoints: latency-svc-lqv5d [796.665341ms]
    Dec  3 12:47:43.493: INFO: Created: latency-svc-xfvmp
    Dec  3 12:47:43.535: INFO: Got endpoints: latency-svc-nrt2c [802.11792ms]
    Dec  3 12:47:43.547: INFO: Created: latency-svc-dp65d
    Dec  3 12:47:43.584: INFO: Got endpoints: latency-svc-ql66v [799.751647ms]
    Dec  3 12:47:43.596: INFO: Created: latency-svc-7xlx5
    Dec  3 12:47:43.632: INFO: Got endpoints: latency-svc-x4lqd [799.318145ms]
    Dec  3 12:47:43.646: INFO: Created: latency-svc-k5288
    Dec  3 12:47:43.684: INFO: Got endpoints: latency-svc-h896c [803.543382ms]
    Dec  3 12:47:43.696: INFO: Created: latency-svc-v2s2m
    Dec  3 12:47:43.730: INFO: Got endpoints: latency-svc-bmvjf [798.710581ms]
    Dec  3 12:47:43.741: INFO: Created: latency-svc-ljs8z
    Dec  3 12:47:43.780: INFO: Got endpoints: latency-svc-q5cqr [799.814978ms]
    Dec  3 12:47:43.792: INFO: Created: latency-svc-4ktlx
    Dec  3 12:47:43.833: INFO: Got endpoints: latency-svc-rt6kj [795.443134ms]
    Dec  3 12:47:43.847: INFO: Created: latency-svc-xmww8
    Dec  3 12:47:43.882: INFO: Got endpoints: latency-svc-t42jg [796.896667ms]
    Dec  3 12:47:43.893: INFO: Created: latency-svc-49hq7
    Dec  3 12:47:43.931: INFO: Got endpoints: latency-svc-mlc4b [800.680084ms]
    Dec  3 12:47:43.941: INFO: Created: latency-svc-xqlc8
    Dec  3 12:47:43.982: INFO: Got endpoints: latency-svc-629b2 [798.224437ms]
    Dec  3 12:47:43.994: INFO: Created: latency-svc-htq4s
    Dec  3 12:47:44.031: INFO: Got endpoints: latency-svc-tm78w [749.48115ms]
    Dec  3 12:47:44.041: INFO: Created: latency-svc-26vck
    Dec  3 12:47:44.084: INFO: Got endpoints: latency-svc-kbnxz [752.81304ms]
    Dec  3 12:47:44.097: INFO: Created: latency-svc-9rqlm
    Dec  3 12:47:44.132: INFO: Got endpoints: latency-svc-tjkvg [750.602457ms]
    Dec  3 12:47:44.144: INFO: Created: latency-svc-vk9k4
    Dec  3 12:47:44.182: INFO: Got endpoints: latency-svc-pnkjn [749.430584ms]
    Dec  3 12:47:44.197: INFO: Created: latency-svc-xxkxz
    Dec  3 12:47:44.231: INFO: Got endpoints: latency-svc-xfvmp [750.122476ms]
    Dec  3 12:47:44.241: INFO: Created: latency-svc-s9fps
    Dec  3 12:47:44.283: INFO: Got endpoints: latency-svc-dp65d [747.692319ms]
    Dec  3 12:47:44.294: INFO: Created: latency-svc-9rp9f
    Dec  3 12:47:44.333: INFO: Got endpoints: latency-svc-7xlx5 [748.591511ms]
    Dec  3 12:47:44.356: INFO: Created: latency-svc-q9226
    Dec  3 12:47:44.380: INFO: Got endpoints: latency-svc-k5288 [747.879368ms]
    Dec  3 12:47:44.391: INFO: Created: latency-svc-knhxb
    Dec  3 12:47:44.432: INFO: Got endpoints: latency-svc-v2s2m [748.316923ms]
    Dec  3 12:47:44.448: INFO: Created: latency-svc-4cdc6
    Dec  3 12:47:44.482: INFO: Got endpoints: latency-svc-ljs8z [752.041688ms]
    Dec  3 12:47:44.493: INFO: Created: latency-svc-9h228
    Dec  3 12:47:44.533: INFO: Got endpoints: latency-svc-4ktlx [752.325967ms]
    Dec  3 12:47:44.543: INFO: Created: latency-svc-c9z59
    Dec  3 12:47:44.580: INFO: Got endpoints: latency-svc-xmww8 [747.100719ms]
    Dec  3 12:47:44.593: INFO: Created: latency-svc-dzqlk
    Dec  3 12:47:44.633: INFO: Got endpoints: latency-svc-49hq7 [750.921001ms]
    Dec  3 12:47:44.650: INFO: Created: latency-svc-wclf7
    Dec  3 12:47:44.683: INFO: Got endpoints: latency-svc-xqlc8 [751.727845ms]
    Dec  3 12:47:44.696: INFO: Created: latency-svc-wcvc5
    Dec  3 12:47:44.733: INFO: Got endpoints: latency-svc-htq4s [751.519617ms]
    Dec  3 12:47:44.747: INFO: Created: latency-svc-s54tc
    Dec  3 12:47:44.784: INFO: Got endpoints: latency-svc-26vck [752.714794ms]
    Dec  3 12:47:44.796: INFO: Created: latency-svc-5258r
    Dec  3 12:47:44.833: INFO: Got endpoints: latency-svc-9rqlm [749.046315ms]
    Dec  3 12:47:44.843: INFO: Created: latency-svc-6m2wq
    Dec  3 12:47:44.882: INFO: Got endpoints: latency-svc-vk9k4 [749.637632ms]
    Dec  3 12:47:44.896: INFO: Created: latency-svc-v2jsr
    Dec  3 12:47:44.931: INFO: Got endpoints: latency-svc-xxkxz [749.33342ms]
    Dec  3 12:47:44.943: INFO: Created: latency-svc-slbw2
    Dec  3 12:47:44.981: INFO: Got endpoints: latency-svc-s9fps [750.587495ms]
    Dec  3 12:47:44.991: INFO: Created: latency-svc-wbdqt
    Dec  3 12:47:45.032: INFO: Got endpoints: latency-svc-9rp9f [748.236357ms]
    Dec  3 12:47:45.045: INFO: Created: latency-svc-5wwmq
    Dec  3 12:47:45.082: INFO: Got endpoints: latency-svc-q9226 [748.454416ms]
    Dec  3 12:47:45.094: INFO: Created: latency-svc-9hdlz
    Dec  3 12:47:45.131: INFO: Got endpoints: latency-svc-knhxb [750.480489ms]
    Dec  3 12:47:45.143: INFO: Created: latency-svc-ngb8r
    Dec  3 12:47:45.181: INFO: Got endpoints: latency-svc-4cdc6 [748.937063ms]
    Dec  3 12:47:45.194: INFO: Created: latency-svc-n8nmh
    Dec  3 12:47:45.230: INFO: Got endpoints: latency-svc-9h228 [747.327406ms]
    Dec  3 12:47:45.244: INFO: Created: latency-svc-mf76c
    Dec  3 12:47:45.281: INFO: Got endpoints: latency-svc-c9z59 [748.039015ms]
    Dec  3 12:47:45.290: INFO: Created: latency-svc-b52k9
    Dec  3 12:47:45.333: INFO: Got endpoints: latency-svc-dzqlk [751.59237ms]
    Dec  3 12:47:45.350: INFO: Created: latency-svc-hk6xd
    Dec  3 12:47:45.381: INFO: Got endpoints: latency-svc-wclf7 [748.279157ms]
    Dec  3 12:47:45.394: INFO: Created: latency-svc-b9gd9
    Dec  3 12:47:45.432: INFO: Got endpoints: latency-svc-wcvc5 [748.547305ms]
    Dec  3 12:47:45.442: INFO: Created: latency-svc-7gvb6
    Dec  3 12:47:45.483: INFO: Got endpoints: latency-svc-s54tc [749.694001ms]
    Dec  3 12:47:45.499: INFO: Created: latency-svc-tztb2
    Dec  3 12:47:45.530: INFO: Got endpoints: latency-svc-5258r [746.564737ms]
    Dec  3 12:47:45.542: INFO: Created: latency-svc-xkj87
    Dec  3 12:47:45.585: INFO: Got endpoints: latency-svc-6m2wq [751.974892ms]
    Dec  3 12:47:45.594: INFO: Created: latency-svc-m2dxb
    Dec  3 12:47:45.634: INFO: Got endpoints: latency-svc-v2jsr [752.426285ms]
    Dec  3 12:47:45.652: INFO: Created: latency-svc-6nbns
    Dec  3 12:47:45.683: INFO: Got endpoints: latency-svc-slbw2 [751.172482ms]
    Dec  3 12:47:45.695: INFO: Created: latency-svc-js6hr
    Dec  3 12:47:45.732: INFO: Got endpoints: latency-svc-wbdqt [750.389597ms]
    Dec  3 12:47:45.743: INFO: Created: latency-svc-lf9gl
    Dec  3 12:47:45.780: INFO: Got endpoints: latency-svc-5wwmq [748.644357ms]
    Dec  3 12:47:45.793: INFO: Created: latency-svc-krftk
    Dec  3 12:47:45.834: INFO: Got endpoints: latency-svc-9hdlz [751.756453ms]
    Dec  3 12:47:45.849: INFO: Created: latency-svc-zwnx6
    Dec  3 12:47:45.881: INFO: Got endpoints: latency-svc-ngb8r [750.722653ms]
    Dec  3 12:47:45.898: INFO: Created: latency-svc-2w4m5
    Dec  3 12:47:45.930: INFO: Got endpoints: latency-svc-n8nmh [748.8259ms]
    Dec  3 12:47:45.944: INFO: Created: latency-svc-w9fht
    Dec  3 12:47:45.982: INFO: Got endpoints: latency-svc-mf76c [752.150265ms]
    Dec  3 12:47:45.998: INFO: Created: latency-svc-c6lzs
    Dec  3 12:47:46.032: INFO: Got endpoints: latency-svc-b52k9 [751.185257ms]
    Dec  3 12:47:46.043: INFO: Created: latency-svc-x4qlj
    Dec  3 12:47:46.082: INFO: Got endpoints: latency-svc-hk6xd [748.815308ms]
    Dec  3 12:47:46.094: INFO: Created: latency-svc-89pmm
    Dec  3 12:47:46.132: INFO: Got endpoints: latency-svc-b9gd9 [750.656264ms]
    Dec  3 12:47:46.149: INFO: Created: latency-svc-vbcxt
    Dec  3 12:47:46.183: INFO: Got endpoints: latency-svc-7gvb6 [750.707387ms]
    Dec  3 12:47:46.196: INFO: Created: latency-svc-zxtzj
    Dec  3 12:47:46.232: INFO: Got endpoints: latency-svc-tztb2 [748.624058ms]
    Dec  3 12:47:46.246: INFO: Created: latency-svc-8tn5h
    Dec  3 12:47:46.284: INFO: Got endpoints: latency-svc-xkj87 [753.094002ms]
    Dec  3 12:47:46.296: INFO: Created: latency-svc-xvzjp
    Dec  3 12:47:46.332: INFO: Got endpoints: latency-svc-m2dxb [746.498276ms]
    Dec  3 12:47:46.345: INFO: Created: latency-svc-8ltth
    Dec  3 12:47:46.381: INFO: Got endpoints: latency-svc-6nbns [745.827452ms]
    Dec  3 12:47:46.396: INFO: Created: latency-svc-xvqcs
    Dec  3 12:47:46.431: INFO: Got endpoints: latency-svc-js6hr [748.01416ms]
    Dec  3 12:47:46.444: INFO: Created: latency-svc-k5pmq
    Dec  3 12:47:46.481: INFO: Got endpoints: latency-svc-lf9gl [748.666716ms]
    Dec  3 12:47:46.493: INFO: Created: latency-svc-fzn4j
    Dec  3 12:47:46.533: INFO: Got endpoints: latency-svc-krftk [752.563204ms]
    Dec  3 12:47:46.554: INFO: Created: latency-svc-thxnp
    Dec  3 12:47:46.581: INFO: Got endpoints: latency-svc-zwnx6 [747.571312ms]
    Dec  3 12:47:46.594: INFO: Created: latency-svc-bk5jn
    Dec  3 12:47:46.631: INFO: Got endpoints: latency-svc-2w4m5 [748.931519ms]
    Dec  3 12:47:46.650: INFO: Created: latency-svc-cwt4m
    Dec  3 12:47:46.683: INFO: Got endpoints: latency-svc-w9fht [753.085472ms]
    Dec  3 12:47:46.702: INFO: Created: latency-svc-fxw6b
    Dec  3 12:47:46.731: INFO: Got endpoints: latency-svc-c6lzs [749.047539ms]
    Dec  3 12:47:46.749: INFO: Created: latency-svc-gk24w
    Dec  3 12:47:46.786: INFO: Got endpoints: latency-svc-x4qlj [753.628352ms]
    Dec  3 12:47:46.800: INFO: Created: latency-svc-2jrxg
    Dec  3 12:47:46.830: INFO: Got endpoints: latency-svc-89pmm [748.687233ms]
    Dec  3 12:47:46.847: INFO: Created: latency-svc-d2wjs
    Dec  3 12:47:46.885: INFO: Got endpoints: latency-svc-vbcxt [752.807861ms]
    Dec  3 12:47:46.897: INFO: Created: latency-svc-f5t2g
    Dec  3 12:47:46.930: INFO: Got endpoints: latency-svc-zxtzj [747.09331ms]
    Dec  3 12:47:46.945: INFO: Created: latency-svc-2gfhq
    Dec  3 12:47:46.981: INFO: Got endpoints: latency-svc-8tn5h [748.705043ms]
    Dec  3 12:47:46.992: INFO: Created: latency-svc-rfl85
    Dec  3 12:47:47.031: INFO: Got endpoints: latency-svc-xvzjp [747.024446ms]
    Dec  3 12:47:47.042: INFO: Created: latency-svc-n8d6d
    Dec  3 12:47:47.083: INFO: Got endpoints: latency-svc-8ltth [750.860965ms]
    Dec  3 12:47:47.095: INFO: Created: latency-svc-sx926
    Dec  3 12:47:47.133: INFO: Got endpoints: latency-svc-xvqcs [752.118146ms]
    Dec  3 12:47:47.147: INFO: Created: latency-svc-v6wch
    Dec  3 12:47:47.182: INFO: Got endpoints: latency-svc-k5pmq [750.859896ms]
    Dec  3 12:47:47.196: INFO: Created: latency-svc-btkd6
    Dec  3 12:47:47.242: INFO: Got endpoints: latency-svc-fzn4j [761.451426ms]
    Dec  3 12:47:47.266: INFO: Created: latency-svc-77xlc
    Dec  3 12:47:47.280: INFO: Got endpoints: latency-svc-thxnp [747.536653ms]
    Dec  3 12:47:47.293: INFO: Created: latency-svc-69snp
    Dec  3 12:47:47.331: INFO: Got endpoints: latency-svc-bk5jn [748.979492ms]
    Dec  3 12:47:47.342: INFO: Created: latency-svc-n2pxg
    Dec  3 12:47:47.384: INFO: Got endpoints: latency-svc-cwt4m [752.167736ms]
    Dec  3 12:47:47.395: INFO: Created: latency-svc-rvrvz
    Dec  3 12:47:47.431: INFO: Got endpoints: latency-svc-fxw6b [745.989633ms]
    Dec  3 12:47:47.443: INFO: Created: latency-svc-fzljs
    Dec  3 12:47:47.480: INFO: Got endpoints: latency-svc-gk24w [749.078082ms]
    Dec  3 12:47:47.491: INFO: Created: latency-svc-tzgjd
    Dec  3 12:47:47.531: INFO: Got endpoints: latency-svc-2jrxg [745.347884ms]
    Dec  3 12:47:47.582: INFO: Got endpoints: latency-svc-d2wjs [751.48606ms]
    Dec  3 12:47:47.631: INFO: Got endpoints: latency-svc-f5t2g [745.635884ms]
    Dec  3 12:47:47.682: INFO: Got endpoints: latency-svc-2gfhq [751.34674ms]
    Dec  3 12:47:47.731: INFO: Got endpoints: latency-svc-rfl85 [749.849894ms]
    Dec  3 12:47:47.782: INFO: Got endpoints: latency-svc-n8d6d [751.183957ms]
    Dec  3 12:47:47.830: INFO: Got endpoints: latency-svc-sx926 [747.612018ms]
    Dec  3 12:47:47.882: INFO: Got endpoints: latency-svc-v6wch [749.626394ms]
    Dec  3 12:47:47.931: INFO: Got endpoints: latency-svc-btkd6 [748.424505ms]
    Dec  3 12:47:47.981: INFO: Got endpoints: latency-svc-77xlc [739.192188ms]
    Dec  3 12:47:48.031: INFO: Got endpoints: latency-svc-69snp [749.321448ms]
    Dec  3 12:47:48.083: INFO: Got endpoints: latency-svc-n2pxg [752.667002ms]
    Dec  3 12:47:48.130: INFO: Got endpoints: latency-svc-rvrvz [746.119446ms]
    Dec  3 12:47:48.183: INFO: Got endpoints: latency-svc-fzljs [751.611077ms]
    Dec  3 12:47:48.231: INFO: Got endpoints: latency-svc-tzgjd [750.324338ms]
    Dec  3 12:47:48.231: INFO: Latencies: [39.894634ms 49.816431ms 50.153978ms 55.258036ms 64.138779ms 77.032036ms 89.247574ms 93.121961ms 95.979355ms 118.469865ms 121.859216ms 122.206645ms 125.875561ms 129.152213ms 132.737552ms 134.504335ms 139.787025ms 144.150302ms 146.293965ms 147.020989ms 148.708852ms 149.968433ms 152.891666ms 159.269182ms 159.409117ms 165.436939ms 167.802677ms 217.820678ms 217.899725ms 236.059616ms 256.899074ms 264.978808ms 287.437649ms 290.422926ms 293.87325ms 311.352282ms 311.852809ms 313.928758ms 324.981293ms 327.256123ms 329.351298ms 330.530168ms 346.964791ms 350.45553ms 371.200108ms 382.442752ms 398.874593ms 444.829653ms 491.843766ms 545.608709ms 580.16747ms 625.396912ms 673.920597ms 723.252559ms 727.035584ms 739.192188ms 740.952572ms 745.347884ms 745.635884ms 745.827452ms 745.989633ms 746.119446ms 746.422319ms 746.498276ms 746.564737ms 746.768613ms 747.024446ms 747.09331ms 747.100719ms 747.327406ms 747.536653ms 747.571312ms 747.612018ms 747.692319ms 747.876802ms 747.879368ms 747.998714ms 748.01416ms 748.015408ms 748.039015ms 748.081766ms 748.147522ms 748.236357ms 748.279157ms 748.316923ms 748.33815ms 748.34677ms 748.424505ms 748.454416ms 748.528145ms 748.547305ms 748.559035ms 748.591511ms 748.624058ms 748.644357ms 748.661045ms 748.666716ms 748.668252ms 748.687233ms 748.705043ms 748.815308ms 748.8259ms 748.875956ms 748.915918ms 748.931519ms 748.937063ms 748.979492ms 749.046315ms 749.047539ms 749.078082ms 749.321448ms 749.33342ms 749.35825ms 749.40817ms 749.416366ms 749.430584ms 749.48115ms 749.611853ms 749.626394ms 749.637632ms 749.657935ms 749.694001ms 749.701851ms 749.744929ms 749.849894ms 750.03842ms 750.122476ms 750.144157ms 750.285983ms 750.324338ms 750.346975ms 750.389597ms 750.451207ms 750.463592ms 750.480489ms 750.54834ms 750.587495ms 750.602457ms 750.632251ms 750.656264ms 750.690591ms 750.707387ms 750.722653ms 750.859896ms 750.860965ms 750.921001ms 751.15056ms 751.172482ms 751.183957ms 751.185257ms 751.282812ms 751.34674ms 751.48606ms 751.519617ms 751.59237ms 751.611077ms 751.660881ms 751.693208ms 751.727845ms 751.756453ms 751.974892ms 752.041688ms 752.085618ms 752.106899ms 752.118146ms 752.150265ms 752.167736ms 752.325967ms 752.41507ms 752.426285ms 752.563204ms 752.667002ms 752.714794ms 752.807861ms 752.81304ms 752.900453ms 753.085472ms 753.093914ms 753.094002ms 753.628352ms 754.110214ms 757.303353ms 757.344735ms 761.451426ms 772.464815ms 795.443134ms 796.665341ms 796.896667ms 798.224437ms 798.710581ms 798.888476ms 799.318145ms 799.751647ms 799.814978ms 800.113026ms 800.680084ms 800.814999ms 801.012805ms 802.11792ms 803.543382ms]
    Dec  3 12:47:48.231: INFO: 50 %ile: 748.815308ms
    Dec  3 12:47:48.231: INFO: 90 %ile: 754.110214ms
    Dec  3 12:47:48.231: INFO: 99 %ile: 802.11792ms
    Dec  3 12:47:48.231: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Dec  3 12:47:48.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-8851" for this suite. 12/03/22 12:47:48.237
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:47:48.246
Dec  3 12:47:48.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:47:48.247
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:48.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:48.272
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:47:48.278
Dec  3 12:47:48.287: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4406" to be "running and ready"
Dec  3 12:47:48.290: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157896ms
Dec  3 12:47:48.290: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:47:50.295: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008213513s
Dec  3 12:47:50.295: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec  3 12:47:50.295: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 12/03/22 12:47:50.299
Dec  3 12:47:50.307: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4406" to be "running and ready"
Dec  3 12:47:50.312: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235279ms
Dec  3 12:47:50.312: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:47:52.317: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009981826s
Dec  3 12:47:52.317: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Dec  3 12:47:52.317: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/03/22 12:47:52.321
Dec  3 12:47:52.330: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 12:47:52.334: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 12:47:54.334: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 12:47:54.338: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 12:47:56.334: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 12:47:56.339: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 12/03/22 12:47:56.34
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec  3 12:47:56.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4406" for this suite. 12/03/22 12:47:56.372
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":144,"skipped":2743,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.136 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:47:48.246
    Dec  3 12:47:48.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 12:47:48.247
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:48.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:48.272
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/03/22 12:47:48.278
    Dec  3 12:47:48.287: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4406" to be "running and ready"
    Dec  3 12:47:48.290: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157896ms
    Dec  3 12:47:48.290: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:47:50.295: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008213513s
    Dec  3 12:47:50.295: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec  3 12:47:50.295: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 12/03/22 12:47:50.299
    Dec  3 12:47:50.307: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4406" to be "running and ready"
    Dec  3 12:47:50.312: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235279ms
    Dec  3 12:47:50.312: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:47:52.317: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009981826s
    Dec  3 12:47:52.317: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Dec  3 12:47:52.317: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/03/22 12:47:52.321
    Dec  3 12:47:52.330: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec  3 12:47:52.334: INFO: Pod pod-with-prestop-http-hook still exists
    Dec  3 12:47:54.334: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec  3 12:47:54.338: INFO: Pod pod-with-prestop-http-hook still exists
    Dec  3 12:47:56.334: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec  3 12:47:56.339: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 12/03/22 12:47:56.34
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec  3 12:47:56.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4406" for this suite. 12/03/22 12:47:56.372
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:47:56.383
Dec  3 12:47:56.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:47:56.384
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:56.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:56.411
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ce0f6d52-3200-4c01-88da-9bd9491b0313 12/03/22 12:47:56.418
STEP: Creating the pod 12/03/22 12:47:56.423
Dec  3 12:47:56.433: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a" in namespace "projected-3317" to be "running and ready"
Dec  3 12:47:56.438: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.695085ms
Dec  3 12:47:56.438: INFO: The phase of Pod pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:47:58.442: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009812496s
Dec  3 12:47:58.442: INFO: The phase of Pod pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a is Running (Ready = true)
Dec  3 12:47:58.442: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-ce0f6d52-3200-4c01-88da-9bd9491b0313 12/03/22 12:47:58.452
STEP: waiting to observe update in volume 12/03/22 12:47:58.457
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 12:48:00.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3317" for this suite. 12/03/22 12:48:00.477
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":145,"skipped":2754,"failed":0}
------------------------------
â€¢ [4.102 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:47:56.383
    Dec  3 12:47:56.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:47:56.384
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:47:56.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:47:56.411
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-ce0f6d52-3200-4c01-88da-9bd9491b0313 12/03/22 12:47:56.418
    STEP: Creating the pod 12/03/22 12:47:56.423
    Dec  3 12:47:56.433: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a" in namespace "projected-3317" to be "running and ready"
    Dec  3 12:47:56.438: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.695085ms
    Dec  3 12:47:56.438: INFO: The phase of Pod pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:47:58.442: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009812496s
    Dec  3 12:47:58.442: INFO: The phase of Pod pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a is Running (Ready = true)
    Dec  3 12:47:58.442: INFO: Pod "pod-projected-configmaps-192da87d-1c86-4482-92dd-4dc718bbb30a" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-ce0f6d52-3200-4c01-88da-9bd9491b0313 12/03/22 12:47:58.452
    STEP: waiting to observe update in volume 12/03/22 12:47:58.457
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 12:48:00.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3317" for this suite. 12/03/22 12:48:00.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:00.488
Dec  3 12:48:00.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:48:00.488
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:00.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:00.518
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Dec  3 12:48:00.529: INFO: Waiting up to 5m0s for pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030" in namespace "pods-7363" to be "running and ready"
Dec  3 12:48:00.534: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030": Phase="Pending", Reason="", readiness=false. Elapsed: 4.593367ms
Dec  3 12:48:00.534: INFO: The phase of Pod server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:48:02.538: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030": Phase="Running", Reason="", readiness=true. Elapsed: 2.00882822s
Dec  3 12:48:02.538: INFO: The phase of Pod server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030 is Running (Ready = true)
Dec  3 12:48:02.538: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030" satisfied condition "running and ready"
Dec  3 12:48:02.564: INFO: Waiting up to 5m0s for pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a" in namespace "pods-7363" to be "Succeeded or Failed"
Dec  3 12:48:02.571: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.844986ms
Dec  3 12:48:04.576: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011495279s
Dec  3 12:48:06.577: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012848255s
STEP: Saw pod success 12/03/22 12:48:06.577
Dec  3 12:48:06.578: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a" satisfied condition "Succeeded or Failed"
Dec  3 12:48:06.582: INFO: Trying to get logs from node ip-172-31-38-234 pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a container env3cont: <nil>
STEP: delete the pod 12/03/22 12:48:06.59
Dec  3 12:48:06.602: INFO: Waiting for pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a to disappear
Dec  3 12:48:06.605: INFO: Pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:48:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7363" for this suite. 12/03/22 12:48:06.611
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":146,"skipped":2796,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.131 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:00.488
    Dec  3 12:48:00.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:48:00.488
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:00.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:00.518
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Dec  3 12:48:00.529: INFO: Waiting up to 5m0s for pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030" in namespace "pods-7363" to be "running and ready"
    Dec  3 12:48:00.534: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030": Phase="Pending", Reason="", readiness=false. Elapsed: 4.593367ms
    Dec  3 12:48:00.534: INFO: The phase of Pod server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:48:02.538: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030": Phase="Running", Reason="", readiness=true. Elapsed: 2.00882822s
    Dec  3 12:48:02.538: INFO: The phase of Pod server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030 is Running (Ready = true)
    Dec  3 12:48:02.538: INFO: Pod "server-envvars-4ac50158-52e2-4f5f-b63e-b6fb3e350030" satisfied condition "running and ready"
    Dec  3 12:48:02.564: INFO: Waiting up to 5m0s for pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a" in namespace "pods-7363" to be "Succeeded or Failed"
    Dec  3 12:48:02.571: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.844986ms
    Dec  3 12:48:04.576: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011495279s
    Dec  3 12:48:06.577: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012848255s
    STEP: Saw pod success 12/03/22 12:48:06.577
    Dec  3 12:48:06.578: INFO: Pod "client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a" satisfied condition "Succeeded or Failed"
    Dec  3 12:48:06.582: INFO: Trying to get logs from node ip-172-31-38-234 pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a container env3cont: <nil>
    STEP: delete the pod 12/03/22 12:48:06.59
    Dec  3 12:48:06.602: INFO: Waiting for pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a to disappear
    Dec  3 12:48:06.605: INFO: Pod client-envvars-165c5c29-71b5-4d74-bab8-f5eb4053ec0a no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:48:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7363" for this suite. 12/03/22 12:48:06.611
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:06.622
Dec  3 12:48:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:48:06.624
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:06.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:06.652
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6169-delete-me 12/03/22 12:48:06.664
STEP: Waiting for the RuntimeClass to disappear 12/03/22 12:48:06.67
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec  3 12:48:06.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6169" for this suite. 12/03/22 12:48:06.687
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":147,"skipped":2839,"failed":0}
------------------------------
â€¢ [0.074 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:06.622
    Dec  3 12:48:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:48:06.624
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:06.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:06.652
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6169-delete-me 12/03/22 12:48:06.664
    STEP: Waiting for the RuntimeClass to disappear 12/03/22 12:48:06.67
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec  3 12:48:06.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6169" for this suite. 12/03/22 12:48:06.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:06.701
Dec  3 12:48:06.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 12:48:06.702
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:06.727
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:06.735
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-d8af5739-0a01-423f-9bb0-55f28db6fb2f 12/03/22 12:48:06.742
STEP: Creating secret with name s-test-opt-upd-90b4add0-4f79-46f0-b919-d0294c1330c2 12/03/22 12:48:06.747
STEP: Creating the pod 12/03/22 12:48:06.753
Dec  3 12:48:06.766: INFO: Waiting up to 5m0s for pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc" in namespace "secrets-3334" to be "running and ready"
Dec  3 12:48:06.837: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc": Phase="Pending", Reason="", readiness=false. Elapsed: 71.580851ms
Dec  3 12:48:06.837: INFO: The phase of Pod pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:48:08.843: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.077317802s
Dec  3 12:48:08.843: INFO: The phase of Pod pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc is Running (Ready = true)
Dec  3 12:48:08.843: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-d8af5739-0a01-423f-9bb0-55f28db6fb2f 12/03/22 12:48:08.871
STEP: Updating secret s-test-opt-upd-90b4add0-4f79-46f0-b919-d0294c1330c2 12/03/22 12:48:08.879
STEP: Creating secret with name s-test-opt-create-c5baffb2-9943-43ba-9a1a-82106e6c38fa 12/03/22 12:48:08.886
STEP: waiting to observe update in volume 12/03/22 12:48:08.892
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 12:48:10.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3334" for this suite. 12/03/22 12:48:10.928
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":148,"skipped":2891,"failed":0}
------------------------------
â€¢ [4.235 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:06.701
    Dec  3 12:48:06.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 12:48:06.702
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:06.727
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:06.735
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-d8af5739-0a01-423f-9bb0-55f28db6fb2f 12/03/22 12:48:06.742
    STEP: Creating secret with name s-test-opt-upd-90b4add0-4f79-46f0-b919-d0294c1330c2 12/03/22 12:48:06.747
    STEP: Creating the pod 12/03/22 12:48:06.753
    Dec  3 12:48:06.766: INFO: Waiting up to 5m0s for pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc" in namespace "secrets-3334" to be "running and ready"
    Dec  3 12:48:06.837: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc": Phase="Pending", Reason="", readiness=false. Elapsed: 71.580851ms
    Dec  3 12:48:06.837: INFO: The phase of Pod pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:48:08.843: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.077317802s
    Dec  3 12:48:08.843: INFO: The phase of Pod pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc is Running (Ready = true)
    Dec  3 12:48:08.843: INFO: Pod "pod-secrets-cbee4119-94f5-4e00-8aa4-55fbbc6d1dfc" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-d8af5739-0a01-423f-9bb0-55f28db6fb2f 12/03/22 12:48:08.871
    STEP: Updating secret s-test-opt-upd-90b4add0-4f79-46f0-b919-d0294c1330c2 12/03/22 12:48:08.879
    STEP: Creating secret with name s-test-opt-create-c5baffb2-9943-43ba-9a1a-82106e6c38fa 12/03/22 12:48:08.886
    STEP: waiting to observe update in volume 12/03/22 12:48:08.892
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 12:48:10.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3334" for this suite. 12/03/22 12:48:10.928
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:10.937
Dec  3 12:48:10.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename certificates 12/03/22 12:48:10.938
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:10.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:10.967
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 12/03/22 12:48:12.037
STEP: getting /apis/certificates.k8s.io 12/03/22 12:48:12.041
STEP: getting /apis/certificates.k8s.io/v1 12/03/22 12:48:12.042
STEP: creating 12/03/22 12:48:12.043
STEP: getting 12/03/22 12:48:12.063
STEP: listing 12/03/22 12:48:12.069
STEP: watching 12/03/22 12:48:12.072
Dec  3 12:48:12.072: INFO: starting watch
STEP: patching 12/03/22 12:48:12.074
STEP: updating 12/03/22 12:48:12.082
Dec  3 12:48:12.089: INFO: waiting for watch events with expected annotations
Dec  3 12:48:12.089: INFO: saw patched and updated annotations
STEP: getting /approval 12/03/22 12:48:12.089
STEP: patching /approval 12/03/22 12:48:12.092
STEP: updating /approval 12/03/22 12:48:12.099
STEP: getting /status 12/03/22 12:48:12.108
STEP: patching /status 12/03/22 12:48:12.111
STEP: updating /status 12/03/22 12:48:12.122
STEP: deleting 12/03/22 12:48:12.136
STEP: deleting a collection 12/03/22 12:48:12.157
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:48:12.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-7809" for this suite. 12/03/22 12:48:12.187
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":149,"skipped":2905,"failed":0}
------------------------------
â€¢ [1.263 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:10.937
    Dec  3 12:48:10.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename certificates 12/03/22 12:48:10.938
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:10.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:10.967
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 12/03/22 12:48:12.037
    STEP: getting /apis/certificates.k8s.io 12/03/22 12:48:12.041
    STEP: getting /apis/certificates.k8s.io/v1 12/03/22 12:48:12.042
    STEP: creating 12/03/22 12:48:12.043
    STEP: getting 12/03/22 12:48:12.063
    STEP: listing 12/03/22 12:48:12.069
    STEP: watching 12/03/22 12:48:12.072
    Dec  3 12:48:12.072: INFO: starting watch
    STEP: patching 12/03/22 12:48:12.074
    STEP: updating 12/03/22 12:48:12.082
    Dec  3 12:48:12.089: INFO: waiting for watch events with expected annotations
    Dec  3 12:48:12.089: INFO: saw patched and updated annotations
    STEP: getting /approval 12/03/22 12:48:12.089
    STEP: patching /approval 12/03/22 12:48:12.092
    STEP: updating /approval 12/03/22 12:48:12.099
    STEP: getting /status 12/03/22 12:48:12.108
    STEP: patching /status 12/03/22 12:48:12.111
    STEP: updating /status 12/03/22 12:48:12.122
    STEP: deleting 12/03/22 12:48:12.136
    STEP: deleting a collection 12/03/22 12:48:12.157
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:48:12.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-7809" for this suite. 12/03/22 12:48:12.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:12.204
Dec  3 12:48:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:48:12.205
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:12.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:12.238
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-3116 12/03/22 12:48:12.241
STEP: creating a selector 12/03/22 12:48:12.241
STEP: Creating the service pods in kubernetes 12/03/22 12:48:12.241
Dec  3 12:48:12.241: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec  3 12:48:12.285: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3116" to be "running and ready"
Dec  3 12:48:12.298: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.43623ms
Dec  3 12:48:12.298: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:48:14.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018283933s
Dec  3 12:48:14.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:16.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018228493s
Dec  3 12:48:16.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:18.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017410248s
Dec  3 12:48:18.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:20.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017877579s
Dec  3 12:48:20.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:22.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017164597s
Dec  3 12:48:22.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:24.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018156334s
Dec  3 12:48:24.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:26.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.017168925s
Dec  3 12:48:26.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:28.304: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.018574405s
Dec  3 12:48:28.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:30.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.018134214s
Dec  3 12:48:30.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:32.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.018365705s
Dec  3 12:48:32.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 12:48:34.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018237028s
Dec  3 12:48:34.303: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec  3 12:48:34.303: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec  3 12:48:34.310: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3116" to be "running and ready"
Dec  3 12:48:34.315: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.940452ms
Dec  3 12:48:34.316: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec  3 12:48:34.316: INFO: Pod "netserver-1" satisfied condition "running and ready"
Dec  3 12:48:34.319: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3116" to be "running and ready"
Dec  3 12:48:34.322: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.653124ms
Dec  3 12:48:34.322: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Dec  3 12:48:34.322: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 12/03/22 12:48:34.325
Dec  3 12:48:34.348: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3116" to be "running"
Dec  3 12:48:34.351: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.928372ms
Dec  3 12:48:36.356: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008767657s
Dec  3 12:48:36.357: INFO: Pod "test-container-pod" satisfied condition "running"
Dec  3 12:48:36.362: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Dec  3 12:48:36.362: INFO: Breadth first check of 192.168.197.71 on host 172.31.38.234...
Dec  3 12:48:36.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.197.71&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:48:36.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:48:36.366: INFO: ExecWithOptions: Clientset creation
Dec  3 12:48:36.366: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.197.71%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 12:48:36.439: INFO: Waiting for responses: map[]
Dec  3 12:48:36.440: INFO: reached 192.168.197.71 after 0/1 tries
Dec  3 12:48:36.440: INFO: Breadth first check of 192.168.197.49 on host 172.31.4.162...
Dec  3 12:48:36.444: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.197.49&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:48:36.445: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:48:36.445: INFO: ExecWithOptions: Clientset creation
Dec  3 12:48:36.445: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.197.49%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 12:48:36.512: INFO: Waiting for responses: map[]
Dec  3 12:48:36.512: INFO: reached 192.168.197.49 after 0/1 tries
Dec  3 12:48:36.512: INFO: Breadth first check of 192.168.71.249 on host 172.31.76.203...
Dec  3 12:48:36.516: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.71.249&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 12:48:36.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 12:48:36.516: INFO: ExecWithOptions: Clientset creation
Dec  3 12:48:36.516: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.71.249%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 12:48:36.593: INFO: Waiting for responses: map[]
Dec  3 12:48:36.593: INFO: reached 192.168.71.249 after 0/1 tries
Dec  3 12:48:36.593: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec  3 12:48:36.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3116" for this suite. 12/03/22 12:48:36.598
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":150,"skipped":2931,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.403 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:12.204
    Dec  3 12:48:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pod-network-test 12/03/22 12:48:12.205
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:12.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:12.238
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-3116 12/03/22 12:48:12.241
    STEP: creating a selector 12/03/22 12:48:12.241
    STEP: Creating the service pods in kubernetes 12/03/22 12:48:12.241
    Dec  3 12:48:12.241: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec  3 12:48:12.285: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3116" to be "running and ready"
    Dec  3 12:48:12.298: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.43623ms
    Dec  3 12:48:12.298: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:48:14.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018283933s
    Dec  3 12:48:14.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:16.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018228493s
    Dec  3 12:48:16.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:18.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017410248s
    Dec  3 12:48:18.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:20.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017877579s
    Dec  3 12:48:20.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:22.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017164597s
    Dec  3 12:48:22.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:24.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018156334s
    Dec  3 12:48:24.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:26.302: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.017168925s
    Dec  3 12:48:26.302: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:28.304: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.018574405s
    Dec  3 12:48:28.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:30.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.018134214s
    Dec  3 12:48:30.303: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:32.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.018365705s
    Dec  3 12:48:32.304: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 12:48:34.303: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018237028s
    Dec  3 12:48:34.303: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec  3 12:48:34.303: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec  3 12:48:34.310: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3116" to be "running and ready"
    Dec  3 12:48:34.315: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.940452ms
    Dec  3 12:48:34.316: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec  3 12:48:34.316: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Dec  3 12:48:34.319: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3116" to be "running and ready"
    Dec  3 12:48:34.322: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.653124ms
    Dec  3 12:48:34.322: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Dec  3 12:48:34.322: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 12/03/22 12:48:34.325
    Dec  3 12:48:34.348: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3116" to be "running"
    Dec  3 12:48:34.351: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.928372ms
    Dec  3 12:48:36.356: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008767657s
    Dec  3 12:48:36.357: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec  3 12:48:36.362: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Dec  3 12:48:36.362: INFO: Breadth first check of 192.168.197.71 on host 172.31.38.234...
    Dec  3 12:48:36.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.197.71&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:48:36.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:48:36.366: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:48:36.366: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.197.71%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 12:48:36.439: INFO: Waiting for responses: map[]
    Dec  3 12:48:36.440: INFO: reached 192.168.197.71 after 0/1 tries
    Dec  3 12:48:36.440: INFO: Breadth first check of 192.168.197.49 on host 172.31.4.162...
    Dec  3 12:48:36.444: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.197.49&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:48:36.445: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:48:36.445: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:48:36.445: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.197.49%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 12:48:36.512: INFO: Waiting for responses: map[]
    Dec  3 12:48:36.512: INFO: reached 192.168.197.49 after 0/1 tries
    Dec  3 12:48:36.512: INFO: Breadth first check of 192.168.71.249 on host 172.31.76.203...
    Dec  3 12:48:36.516: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.72:9080/dial?request=hostname&protocol=http&host=192.168.71.249&port=8083&tries=1'] Namespace:pod-network-test-3116 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 12:48:36.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 12:48:36.516: INFO: ExecWithOptions: Clientset creation
    Dec  3 12:48:36.516: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3116/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.72%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.71.249%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 12:48:36.593: INFO: Waiting for responses: map[]
    Dec  3 12:48:36.593: INFO: reached 192.168.71.249 after 0/1 tries
    Dec  3 12:48:36.593: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec  3 12:48:36.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3116" for this suite. 12/03/22 12:48:36.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:36.609
Dec  3 12:48:36.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename events 12/03/22 12:48:36.61
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:36.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:36.639
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 12/03/22 12:48:36.643
STEP: listing events in all namespaces 12/03/22 12:48:36.659
STEP: listing events in test namespace 12/03/22 12:48:36.67
STEP: listing events with field selection filtering on source 12/03/22 12:48:36.676
STEP: listing events with field selection filtering on reportingController 12/03/22 12:48:36.679
STEP: getting the test event 12/03/22 12:48:36.682
STEP: patching the test event 12/03/22 12:48:36.688
STEP: getting the test event 12/03/22 12:48:36.698
STEP: updating the test event 12/03/22 12:48:36.711
STEP: getting the test event 12/03/22 12:48:36.721
STEP: deleting the test event 12/03/22 12:48:36.725
STEP: listing events in all namespaces 12/03/22 12:48:36.735
STEP: listing events in test namespace 12/03/22 12:48:36.746
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec  3 12:48:36.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8331" for this suite. 12/03/22 12:48:36.753
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":151,"skipped":2936,"failed":0}
------------------------------
â€¢ [0.152 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:36.609
    Dec  3 12:48:36.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename events 12/03/22 12:48:36.61
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:36.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:36.639
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 12/03/22 12:48:36.643
    STEP: listing events in all namespaces 12/03/22 12:48:36.659
    STEP: listing events in test namespace 12/03/22 12:48:36.67
    STEP: listing events with field selection filtering on source 12/03/22 12:48:36.676
    STEP: listing events with field selection filtering on reportingController 12/03/22 12:48:36.679
    STEP: getting the test event 12/03/22 12:48:36.682
    STEP: patching the test event 12/03/22 12:48:36.688
    STEP: getting the test event 12/03/22 12:48:36.698
    STEP: updating the test event 12/03/22 12:48:36.711
    STEP: getting the test event 12/03/22 12:48:36.721
    STEP: deleting the test event 12/03/22 12:48:36.725
    STEP: listing events in all namespaces 12/03/22 12:48:36.735
    STEP: listing events in test namespace 12/03/22 12:48:36.746
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec  3 12:48:36.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8331" for this suite. 12/03/22 12:48:36.753
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:48:36.761
Dec  3 12:48:36.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename cronjob 12/03/22 12:48:36.762
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:36.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:36.793
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 12/03/22 12:48:36.798
STEP: Ensuring no jobs are scheduled 12/03/22 12:48:36.808
STEP: Ensuring no job exists by listing jobs explicitly 12/03/22 12:53:36.818
STEP: Removing cronjob 12/03/22 12:53:36.821
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec  3 12:53:36.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3962" for this suite. 12/03/22 12:53:36.835
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":152,"skipped":2938,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.081 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:48:36.761
    Dec  3 12:48:36.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename cronjob 12/03/22 12:48:36.762
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:48:36.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:48:36.793
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 12/03/22 12:48:36.798
    STEP: Ensuring no jobs are scheduled 12/03/22 12:48:36.808
    STEP: Ensuring no job exists by listing jobs explicitly 12/03/22 12:53:36.818
    STEP: Removing cronjob 12/03/22 12:53:36.821
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec  3 12:53:36.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3962" for this suite. 12/03/22 12:53:36.835
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:53:36.842
Dec  3 12:53:36.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:53:36.843
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:36.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:36.88
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 12/03/22 12:53:36.883
Dec  3 12:53:36.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-4924 create -f -'
Dec  3 12:53:37.124: INFO: stderr: ""
Dec  3 12:53:37.124: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/03/22 12:53:37.125
Dec  3 12:53:38.130: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 12:53:38.130: INFO: Found 0 / 1
Dec  3 12:53:39.130: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 12:53:39.130: INFO: Found 1 / 1
Dec  3 12:53:39.130: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 12/03/22 12:53:39.13
Dec  3 12:53:39.135: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 12:53:39.135: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 12:53:39.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-4924 patch pod agnhost-primary-jvs88 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 12:53:39.213: INFO: stderr: ""
Dec  3 12:53:39.213: INFO: stdout: "pod/agnhost-primary-jvs88 patched\n"
STEP: checking annotations 12/03/22 12:53:39.213
Dec  3 12:53:39.217: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 12:53:39.217: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:53:39.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4924" for this suite. 12/03/22 12:53:39.221
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":153,"skipped":2938,"failed":0}
------------------------------
â€¢ [2.385 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:53:36.842
    Dec  3 12:53:36.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:53:36.843
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:36.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:36.88
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 12/03/22 12:53:36.883
    Dec  3 12:53:36.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-4924 create -f -'
    Dec  3 12:53:37.124: INFO: stderr: ""
    Dec  3 12:53:37.124: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/03/22 12:53:37.125
    Dec  3 12:53:38.130: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 12:53:38.130: INFO: Found 0 / 1
    Dec  3 12:53:39.130: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 12:53:39.130: INFO: Found 1 / 1
    Dec  3 12:53:39.130: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 12/03/22 12:53:39.13
    Dec  3 12:53:39.135: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 12:53:39.135: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec  3 12:53:39.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-4924 patch pod agnhost-primary-jvs88 -p {"metadata":{"annotations":{"x":"y"}}}'
    Dec  3 12:53:39.213: INFO: stderr: ""
    Dec  3 12:53:39.213: INFO: stdout: "pod/agnhost-primary-jvs88 patched\n"
    STEP: checking annotations 12/03/22 12:53:39.213
    Dec  3 12:53:39.217: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 12:53:39.217: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:53:39.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4924" for this suite. 12/03/22 12:53:39.221
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:53:39.228
Dec  3 12:53:39.228: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:53:39.229
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:39.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:39.263
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Dec  3 12:53:39.283: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5611 to be scheduled
Dec  3 12:53:39.286: INFO: 1 pods are not scheduled: [runtimeclass-5611/test-runtimeclass-runtimeclass-5611-preconfigured-handler-vnsv7(629b03ed-eae0-4424-89d9-0d6b89efdb5a)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec  3 12:53:41.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5611" for this suite. 12/03/22 12:53:41.303
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":154,"skipped":2939,"failed":0}
------------------------------
â€¢ [2.081 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:53:39.228
    Dec  3 12:53:39.228: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename runtimeclass 12/03/22 12:53:39.229
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:39.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:39.263
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Dec  3 12:53:39.283: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5611 to be scheduled
    Dec  3 12:53:39.286: INFO: 1 pods are not scheduled: [runtimeclass-5611/test-runtimeclass-runtimeclass-5611-preconfigured-handler-vnsv7(629b03ed-eae0-4424-89d9-0d6b89efdb5a)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec  3 12:53:41.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5611" for this suite. 12/03/22 12:53:41.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:53:41.311
Dec  3 12:53:41.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename taint-single-pod 12/03/22 12:53:41.312
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:41.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:41.334
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Dec  3 12:53:41.337: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 12:54:41.354: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Dec  3 12:54:41.358: INFO: Starting informer...
STEP: Starting pod... 12/03/22 12:54:41.358
Dec  3 12:54:41.583: INFO: Pod is running on ip-172-31-38-234. Tainting Node
STEP: Trying to apply a taint on the Node 12/03/22 12:54:41.583
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:54:41.598
STEP: Waiting short time to make sure Pod is queued for deletion 12/03/22 12:54:41.857
Dec  3 12:54:41.857: INFO: Pod wasn't evicted. Proceeding
Dec  3 12:54:41.857: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:54:41.877
STEP: Waiting some time to make sure that toleration time passed. 12/03/22 12:54:41.882
Dec  3 12:55:56.882: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:55:56.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5196" for this suite. 12/03/22 12:55:56.889
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":155,"skipped":2948,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.586 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:53:41.311
    Dec  3 12:53:41.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename taint-single-pod 12/03/22 12:53:41.312
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:53:41.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:53:41.334
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Dec  3 12:53:41.337: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 12:54:41.354: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Dec  3 12:54:41.358: INFO: Starting informer...
    STEP: Starting pod... 12/03/22 12:54:41.358
    Dec  3 12:54:41.583: INFO: Pod is running on ip-172-31-38-234. Tainting Node
    STEP: Trying to apply a taint on the Node 12/03/22 12:54:41.583
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:54:41.598
    STEP: Waiting short time to make sure Pod is queued for deletion 12/03/22 12:54:41.857
    Dec  3 12:54:41.857: INFO: Pod wasn't evicted. Proceeding
    Dec  3 12:54:41.857: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/03/22 12:54:41.877
    STEP: Waiting some time to make sure that toleration time passed. 12/03/22 12:54:41.882
    Dec  3 12:55:56.882: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:55:56.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-5196" for this suite. 12/03/22 12:55:56.889
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:55:56.9
Dec  3 12:55:56.901: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:55:56.903
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:55:56.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:55:56.925
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:55:56.948
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:55:57.686
STEP: Deploying the webhook pod 12/03/22 12:55:57.699
STEP: Wait for the deployment to be ready 12/03/22 12:55:57.712
Dec  3 12:55:57.726: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 12:55:59.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/03/22 12:56:01.744
STEP: Verifying the service has paired with the endpoint 12/03/22 12:56:01.755
Dec  3 12:56:02.755: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Dec  3 12:56:02.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7088-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 12:56:03.271
STEP: Creating a custom resource that should be mutated by the webhook 12/03/22 12:56:03.291
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:56:05.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3577" for this suite. 12/03/22 12:56:05.864
STEP: Destroying namespace "webhook-3577-markers" for this suite. 12/03/22 12:56:05.876
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":156,"skipped":2951,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.035 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:55:56.9
    Dec  3 12:55:56.901: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:55:56.903
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:55:56.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:55:56.925
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:55:56.948
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:55:57.686
    STEP: Deploying the webhook pod 12/03/22 12:55:57.699
    STEP: Wait for the deployment to be ready 12/03/22 12:55:57.712
    Dec  3 12:55:57.726: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Dec  3 12:55:59.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/03/22 12:56:01.744
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:56:01.755
    Dec  3 12:56:02.755: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Dec  3 12:56:02.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7088-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 12:56:03.271
    STEP: Creating a custom resource that should be mutated by the webhook 12/03/22 12:56:03.291
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:56:05.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3577" for this suite. 12/03/22 12:56:05.864
    STEP: Destroying namespace "webhook-3577-markers" for this suite. 12/03/22 12:56:05.876
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:05.94
Dec  3 12:56:05.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 12:56:05.94
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:05.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:05.998
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 12/03/22 12:56:06
STEP: Wait for the Deployment to create new ReplicaSet 12/03/22 12:56:06.009
STEP: delete the deployment 12/03/22 12:56:06.523
STEP: wait for all rs to be garbage collected 12/03/22 12:56:06.531
STEP: expected 0 rs, got 1 rs 12/03/22 12:56:06.539
STEP: expected 0 pods, got 2 pods 12/03/22 12:56:06.544
STEP: Gathering metrics 12/03/22 12:56:07.056
W1203 12:56:07.061222      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 12:56:07.061: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 12:56:07.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9112" for this suite. 12/03/22 12:56:07.066
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":157,"skipped":2978,"failed":0}
------------------------------
â€¢ [1.134 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:05.94
    Dec  3 12:56:05.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 12:56:05.94
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:05.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:05.998
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 12/03/22 12:56:06
    STEP: Wait for the Deployment to create new ReplicaSet 12/03/22 12:56:06.009
    STEP: delete the deployment 12/03/22 12:56:06.523
    STEP: wait for all rs to be garbage collected 12/03/22 12:56:06.531
    STEP: expected 0 rs, got 1 rs 12/03/22 12:56:06.539
    STEP: expected 0 pods, got 2 pods 12/03/22 12:56:06.544
    STEP: Gathering metrics 12/03/22 12:56:07.056
    W1203 12:56:07.061222      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 12:56:07.061: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 12:56:07.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9112" for this suite. 12/03/22 12:56:07.066
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:07.075
Dec  3 12:56:07.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 12:56:07.076
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:07.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:07.101
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 12/03/22 12:56:07.105
Dec  3 12:56:07.105: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7189 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 12/03/22 12:56:07.153
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 12:56:07.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7189" for this suite. 12/03/22 12:56:07.167
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":158,"skipped":2980,"failed":0}
------------------------------
â€¢ [0.101 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:07.075
    Dec  3 12:56:07.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 12:56:07.076
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:07.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:07.101
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 12/03/22 12:56:07.105
    Dec  3 12:56:07.105: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7189 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 12/03/22 12:56:07.153
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 12:56:07.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7189" for this suite. 12/03/22 12:56:07.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:07.177
Dec  3 12:56:07.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:56:07.178
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:07.203
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:07.209
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:56:07.234
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:56:07.847
STEP: Deploying the webhook pod 12/03/22 12:56:07.853
STEP: Wait for the deployment to be ready 12/03/22 12:56:07.869
Dec  3 12:56:07.878: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 12:56:09.892
STEP: Verifying the service has paired with the endpoint 12/03/22 12:56:09.906
Dec  3 12:56:10.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/03/22 12:56:10.911
STEP: create a namespace for the webhook 12/03/22 12:56:10.931
STEP: create a configmap should be unconditionally rejected by the webhook 12/03/22 12:56:10.944
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:56:11.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8535" for this suite. 12/03/22 12:56:11.038
STEP: Destroying namespace "webhook-8535-markers" for this suite. 12/03/22 12:56:11.045
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":159,"skipped":2988,"failed":0}
------------------------------
â€¢ [3.926 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:07.177
    Dec  3 12:56:07.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:56:07.178
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:07.203
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:07.209
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:56:07.234
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:56:07.847
    STEP: Deploying the webhook pod 12/03/22 12:56:07.853
    STEP: Wait for the deployment to be ready 12/03/22 12:56:07.869
    Dec  3 12:56:07.878: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 12:56:09.892
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:56:09.906
    Dec  3 12:56:10.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/03/22 12:56:10.911
    STEP: create a namespace for the webhook 12/03/22 12:56:10.931
    STEP: create a configmap should be unconditionally rejected by the webhook 12/03/22 12:56:10.944
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:56:11.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8535" for this suite. 12/03/22 12:56:11.038
    STEP: Destroying namespace "webhook-8535-markers" for this suite. 12/03/22 12:56:11.045
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:11.103
Dec  3 12:56:11.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:56:11.104
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:11.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:11.145
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Dec  3 12:56:11.228: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 12:56:14.211
Dec  3 12:56:14.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 create -f -'
Dec  3 12:56:15.062: INFO: stderr: ""
Dec  3 12:56:15.062: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 12:56:15.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 delete e2e-test-crd-publish-openapi-2084-crds test-cr'
Dec  3 12:56:15.167: INFO: stderr: ""
Dec  3 12:56:15.167: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec  3 12:56:15.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 apply -f -'
Dec  3 12:56:15.724: INFO: stderr: ""
Dec  3 12:56:15.724: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 12:56:15.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 delete e2e-test-crd-publish-openapi-2084-crds test-cr'
Dec  3 12:56:15.791: INFO: stderr: ""
Dec  3 12:56:15.791: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/03/22 12:56:15.791
Dec  3 12:56:15.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 explain e2e-test-crd-publish-openapi-2084-crds'
Dec  3 12:56:15.981: INFO: stderr: ""
Dec  3 12:56:15.981: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2084-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:56:18.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3238" for this suite. 12/03/22 12:56:18.353
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":160,"skipped":3001,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.258 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:11.103
    Dec  3 12:56:11.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 12:56:11.104
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:11.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:11.145
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Dec  3 12:56:11.228: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 12:56:14.211
    Dec  3 12:56:14.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 create -f -'
    Dec  3 12:56:15.062: INFO: stderr: ""
    Dec  3 12:56:15.062: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec  3 12:56:15.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 delete e2e-test-crd-publish-openapi-2084-crds test-cr'
    Dec  3 12:56:15.167: INFO: stderr: ""
    Dec  3 12:56:15.167: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Dec  3 12:56:15.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 apply -f -'
    Dec  3 12:56:15.724: INFO: stderr: ""
    Dec  3 12:56:15.724: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec  3 12:56:15.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 --namespace=crd-publish-openapi-3238 delete e2e-test-crd-publish-openapi-2084-crds test-cr'
    Dec  3 12:56:15.791: INFO: stderr: ""
    Dec  3 12:56:15.791: INFO: stdout: "e2e-test-crd-publish-openapi-2084-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/03/22 12:56:15.791
    Dec  3 12:56:15.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-3238 explain e2e-test-crd-publish-openapi-2084-crds'
    Dec  3 12:56:15.981: INFO: stderr: ""
    Dec  3 12:56:15.981: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2084-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:56:18.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3238" for this suite. 12/03/22 12:56:18.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:18.365
Dec  3 12:56:18.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 12:56:18.366
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:18.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:18.393
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 12/03/22 12:56:18.397
STEP: submitting the pod to kubernetes 12/03/22 12:56:18.398
Dec  3 12:56:18.412: INFO: Waiting up to 5m0s for pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" in namespace "pods-5780" to be "running and ready"
Dec  3 12:56:18.418: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Pending", Reason="", readiness=false. Elapsed: 6.123384ms
Dec  3 12:56:18.418: INFO: The phase of Pod pod-update-49d334a8-c072-4399-98df-e8893c411d00 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 12:56:20.424: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Running", Reason="", readiness=true. Elapsed: 2.012514194s
Dec  3 12:56:20.425: INFO: The phase of Pod pod-update-49d334a8-c072-4399-98df-e8893c411d00 is Running (Ready = true)
Dec  3 12:56:20.425: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/03/22 12:56:20.429
STEP: updating the pod 12/03/22 12:56:20.436
Dec  3 12:56:20.951: INFO: Successfully updated pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00"
Dec  3 12:56:20.951: INFO: Waiting up to 5m0s for pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" in namespace "pods-5780" to be "running"
Dec  3 12:56:20.956: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Running", Reason="", readiness=true. Elapsed: 5.400269ms
Dec  3 12:56:20.956: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 12/03/22 12:56:20.956
Dec  3 12:56:20.962: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 12:56:20.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5780" for this suite. 12/03/22 12:56:20.972
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":161,"skipped":3061,"failed":0}
------------------------------
â€¢ [2.618 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:18.365
    Dec  3 12:56:18.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 12:56:18.366
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:18.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:18.393
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 12/03/22 12:56:18.397
    STEP: submitting the pod to kubernetes 12/03/22 12:56:18.398
    Dec  3 12:56:18.412: INFO: Waiting up to 5m0s for pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" in namespace "pods-5780" to be "running and ready"
    Dec  3 12:56:18.418: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Pending", Reason="", readiness=false. Elapsed: 6.123384ms
    Dec  3 12:56:18.418: INFO: The phase of Pod pod-update-49d334a8-c072-4399-98df-e8893c411d00 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 12:56:20.424: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Running", Reason="", readiness=true. Elapsed: 2.012514194s
    Dec  3 12:56:20.425: INFO: The phase of Pod pod-update-49d334a8-c072-4399-98df-e8893c411d00 is Running (Ready = true)
    Dec  3 12:56:20.425: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/03/22 12:56:20.429
    STEP: updating the pod 12/03/22 12:56:20.436
    Dec  3 12:56:20.951: INFO: Successfully updated pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00"
    Dec  3 12:56:20.951: INFO: Waiting up to 5m0s for pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" in namespace "pods-5780" to be "running"
    Dec  3 12:56:20.956: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00": Phase="Running", Reason="", readiness=true. Elapsed: 5.400269ms
    Dec  3 12:56:20.956: INFO: Pod "pod-update-49d334a8-c072-4399-98df-e8893c411d00" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 12/03/22 12:56:20.956
    Dec  3 12:56:20.962: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 12:56:20.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5780" for this suite. 12/03/22 12:56:20.972
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:20.986
Dec  3 12:56:20.986: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 12:56:20.987
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:21.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:21.018
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/03/22 12:56:21.023
Dec  3 12:56:21.037: INFO: Waiting up to 5m0s for pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c" in namespace "emptydir-5543" to be "Succeeded or Failed"
Dec  3 12:56:21.045: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.217654ms
Dec  3 12:56:23.052: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014903498s
Dec  3 12:56:25.051: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013810978s
STEP: Saw pod success 12/03/22 12:56:25.051
Dec  3 12:56:25.051: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c" satisfied condition "Succeeded or Failed"
Dec  3 12:56:25.056: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c container test-container: <nil>
STEP: delete the pod 12/03/22 12:56:25.074
Dec  3 12:56:25.091: INFO: Waiting for pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c to disappear
Dec  3 12:56:25.096: INFO: Pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 12:56:25.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5543" for this suite. 12/03/22 12:56:25.102
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":162,"skipped":3083,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:20.986
    Dec  3 12:56:20.986: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 12:56:20.987
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:21.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:21.018
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/03/22 12:56:21.023
    Dec  3 12:56:21.037: INFO: Waiting up to 5m0s for pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c" in namespace "emptydir-5543" to be "Succeeded or Failed"
    Dec  3 12:56:21.045: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.217654ms
    Dec  3 12:56:23.052: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014903498s
    Dec  3 12:56:25.051: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013810978s
    STEP: Saw pod success 12/03/22 12:56:25.051
    Dec  3 12:56:25.051: INFO: Pod "pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c" satisfied condition "Succeeded or Failed"
    Dec  3 12:56:25.056: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c container test-container: <nil>
    STEP: delete the pod 12/03/22 12:56:25.074
    Dec  3 12:56:25.091: INFO: Waiting for pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c to disappear
    Dec  3 12:56:25.096: INFO: Pod pod-8c4eacac-0ce8-4a71-ad36-5a5abaad1a2c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 12:56:25.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5543" for this suite. 12/03/22 12:56:25.102
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:56:25.114
Dec  3 12:56:25.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 12:56:25.115
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:25.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:25.134
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-431 12/03/22 12:56:25.138
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 12/03/22 12:56:25.144
Dec  3 12:56:25.163: INFO: Found 0 stateful pods, waiting for 3
Dec  3 12:56:35.170: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:56:35.170: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:56:35.170: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/03/22 12:56:35.19
Dec  3 12:56:35.213: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/03/22 12:56:35.213
STEP: Not applying an update when the partition is greater than the number of replicas 12/03/22 12:56:45.238
STEP: Performing a canary update 12/03/22 12:56:45.238
Dec  3 12:56:45.262: INFO: Updating stateful set ss2
Dec  3 12:56:45.282: INFO: Waiting for Pod statefulset-431/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 12/03/22 12:56:55.294
Dec  3 12:56:55.363: INFO: Found 2 stateful pods, waiting for 3
Dec  3 12:57:05.372: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:57:05.372: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 12:57:05.372: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 12/03/22 12:57:05.382
Dec  3 12:57:05.410: INFO: Updating stateful set ss2
Dec  3 12:57:05.427: INFO: Waiting for Pod statefulset-431/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Dec  3 12:57:15.463: INFO: Updating stateful set ss2
Dec  3 12:57:15.477: INFO: Waiting for StatefulSet statefulset-431/ss2 to complete update
Dec  3 12:57:15.477: INFO: Waiting for Pod statefulset-431/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 12:57:25.493: INFO: Deleting all statefulset in ns statefulset-431
Dec  3 12:57:25.499: INFO: Scaling statefulset ss2 to 0
Dec  3 12:57:35.528: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 12:57:35.537: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 12:57:35.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-431" for this suite. 12/03/22 12:57:35.575
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":163,"skipped":3129,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.474 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:56:25.114
    Dec  3 12:56:25.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 12:56:25.115
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:56:25.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:56:25.134
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-431 12/03/22 12:56:25.138
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 12/03/22 12:56:25.144
    Dec  3 12:56:25.163: INFO: Found 0 stateful pods, waiting for 3
    Dec  3 12:56:35.170: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:56:35.170: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:56:35.170: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/03/22 12:56:35.19
    Dec  3 12:56:35.213: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/03/22 12:56:35.213
    STEP: Not applying an update when the partition is greater than the number of replicas 12/03/22 12:56:45.238
    STEP: Performing a canary update 12/03/22 12:56:45.238
    Dec  3 12:56:45.262: INFO: Updating stateful set ss2
    Dec  3 12:56:45.282: INFO: Waiting for Pod statefulset-431/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 12/03/22 12:56:55.294
    Dec  3 12:56:55.363: INFO: Found 2 stateful pods, waiting for 3
    Dec  3 12:57:05.372: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:57:05.372: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 12:57:05.372: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 12/03/22 12:57:05.382
    Dec  3 12:57:05.410: INFO: Updating stateful set ss2
    Dec  3 12:57:05.427: INFO: Waiting for Pod statefulset-431/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Dec  3 12:57:15.463: INFO: Updating stateful set ss2
    Dec  3 12:57:15.477: INFO: Waiting for StatefulSet statefulset-431/ss2 to complete update
    Dec  3 12:57:15.477: INFO: Waiting for Pod statefulset-431/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 12:57:25.493: INFO: Deleting all statefulset in ns statefulset-431
    Dec  3 12:57:25.499: INFO: Scaling statefulset ss2 to 0
    Dec  3 12:57:35.528: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 12:57:35.537: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 12:57:35.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-431" for this suite. 12/03/22 12:57:35.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:57:35.591
Dec  3 12:57:35.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename namespaces 12/03/22 12:57:35.592
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:35.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:35.627
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 12/03/22 12:57:35.632
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:35.654
STEP: Creating a pod in the namespace 12/03/22 12:57:35.658
STEP: Waiting for the pod to have running status 12/03/22 12:57:35.669
Dec  3 12:57:35.669: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1081" to be "running"
Dec  3 12:57:35.680: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.950536ms
Dec  3 12:57:37.686: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01696669s
Dec  3 12:57:37.686: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 12/03/22 12:57:37.686
STEP: Waiting for the namespace to be removed. 12/03/22 12:57:37.695
STEP: Recreating the namespace 12/03/22 12:57:48.701
STEP: Verifying there are no pods in the namespace 12/03/22 12:57:48.718
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec  3 12:57:48.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4693" for this suite. 12/03/22 12:57:48.732
STEP: Destroying namespace "nsdeletetest-1081" for this suite. 12/03/22 12:57:48.742
Dec  3 12:57:48.746: INFO: Namespace nsdeletetest-1081 was already deleted
STEP: Destroying namespace "nsdeletetest-4253" for this suite. 12/03/22 12:57:48.746
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":164,"skipped":3167,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.169 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:57:35.591
    Dec  3 12:57:35.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename namespaces 12/03/22 12:57:35.592
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:35.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:35.627
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 12/03/22 12:57:35.632
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:35.654
    STEP: Creating a pod in the namespace 12/03/22 12:57:35.658
    STEP: Waiting for the pod to have running status 12/03/22 12:57:35.669
    Dec  3 12:57:35.669: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1081" to be "running"
    Dec  3 12:57:35.680: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.950536ms
    Dec  3 12:57:37.686: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01696669s
    Dec  3 12:57:37.686: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 12/03/22 12:57:37.686
    STEP: Waiting for the namespace to be removed. 12/03/22 12:57:37.695
    STEP: Recreating the namespace 12/03/22 12:57:48.701
    STEP: Verifying there are no pods in the namespace 12/03/22 12:57:48.718
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 12:57:48.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4693" for this suite. 12/03/22 12:57:48.732
    STEP: Destroying namespace "nsdeletetest-1081" for this suite. 12/03/22 12:57:48.742
    Dec  3 12:57:48.746: INFO: Namespace nsdeletetest-1081 was already deleted
    STEP: Destroying namespace "nsdeletetest-4253" for this suite. 12/03/22 12:57:48.746
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:57:48.763
Dec  3 12:57:48.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:57:48.764
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:48.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:48.791
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:57:48.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6608" for this suite. 12/03/22 12:57:48.806
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":165,"skipped":3186,"failed":0}
------------------------------
â€¢ [0.055 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:57:48.763
    Dec  3 12:57:48.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:57:48.764
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:48.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:48.791
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:57:48.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6608" for this suite. 12/03/22 12:57:48.806
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:57:48.822
Dec  3 12:57:48.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:57:48.823
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:48.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:48.854
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9491 12/03/22 12:57:48.858
STEP: changing the ExternalName service to type=ClusterIP 12/03/22 12:57:48.865
STEP: creating replication controller externalname-service in namespace services-9491 12/03/22 12:57:48.886
I1203 12:57:48.896279      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9491, replica count: 2
I1203 12:57:51.947295      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 12:57:51.947: INFO: Creating new exec pod
Dec  3 12:57:51.957: INFO: Waiting up to 5m0s for pod "execpod26fr4" in namespace "services-9491" to be "running"
Dec  3 12:57:51.965: INFO: Pod "execpod26fr4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.419925ms
Dec  3 12:57:53.971: INFO: Pod "execpod26fr4": Phase="Running", Reason="", readiness=true. Elapsed: 2.0145628s
Dec  3 12:57:53.971: INFO: Pod "execpod26fr4" satisfied condition "running"
Dec  3 12:57:54.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 12:57:55.159: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:55.159: INFO: stdout: ""
Dec  3 12:57:56.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 12:57:56.303: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:56.303: INFO: stdout: ""
Dec  3 12:57:57.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 12:57:57.337: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:57.337: INFO: stdout: ""
Dec  3 12:57:58.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 12:57:58.345: INFO: stderr: "+ + echonc -v hostName\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:58.345: INFO: stdout: ""
Dec  3 12:57:59.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 12:57:59.310: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:59.310: INFO: stdout: "externalname-service-hdhbs"
Dec  3 12:57:59.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
Dec  3 12:57:59.473: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [tcp/http] succeeded!\n"
Dec  3 12:57:59.473: INFO: stdout: "externalname-service-f9fl2"
Dec  3 12:57:59.473: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:57:59.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9491" for this suite. 12/03/22 12:57:59.531
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":166,"skipped":3216,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.719 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:57:48.822
    Dec  3 12:57:48.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:57:48.823
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:48.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:48.854
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-9491 12/03/22 12:57:48.858
    STEP: changing the ExternalName service to type=ClusterIP 12/03/22 12:57:48.865
    STEP: creating replication controller externalname-service in namespace services-9491 12/03/22 12:57:48.886
    I1203 12:57:48.896279      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9491, replica count: 2
    I1203 12:57:51.947295      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 12:57:51.947: INFO: Creating new exec pod
    Dec  3 12:57:51.957: INFO: Waiting up to 5m0s for pod "execpod26fr4" in namespace "services-9491" to be "running"
    Dec  3 12:57:51.965: INFO: Pod "execpod26fr4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.419925ms
    Dec  3 12:57:53.971: INFO: Pod "execpod26fr4": Phase="Running", Reason="", readiness=true. Elapsed: 2.0145628s
    Dec  3 12:57:53.971: INFO: Pod "execpod26fr4" satisfied condition "running"
    Dec  3 12:57:54.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 12:57:55.159: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:55.159: INFO: stdout: ""
    Dec  3 12:57:56.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 12:57:56.303: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:56.303: INFO: stdout: ""
    Dec  3 12:57:57.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 12:57:57.337: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:57.337: INFO: stdout: ""
    Dec  3 12:57:58.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 12:57:58.345: INFO: stderr: "+ + echonc -v hostName\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:58.345: INFO: stdout: ""
    Dec  3 12:57:59.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 12:57:59.310: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:59.310: INFO: stdout: "externalname-service-hdhbs"
    Dec  3 12:57:59.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-9491 exec execpod26fr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
    Dec  3 12:57:59.473: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [tcp/http] succeeded!\n"
    Dec  3 12:57:59.473: INFO: stdout: "externalname-service-f9fl2"
    Dec  3 12:57:59.473: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:57:59.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9491" for this suite. 12/03/22 12:57:59.531
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:57:59.544
Dec  3 12:57:59.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:57:59.545
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:59.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:59.575
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b in namespace container-probe-9751 12/03/22 12:57:59.579
Dec  3 12:57:59.602: INFO: Waiting up to 5m0s for pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b" in namespace "container-probe-9751" to be "not pending"
Dec  3 12:57:59.610: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.838818ms
Dec  3 12:58:01.616: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014111911s
Dec  3 12:58:01.616: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b" satisfied condition "not pending"
Dec  3 12:58:01.616: INFO: Started pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b in namespace container-probe-9751
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:58:01.616
Dec  3 12:58:01.621: INFO: Initial restart count of pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b is 0
Dec  3 12:58:21.693: INFO: Restart count of pod container-probe-9751/liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b is now 1 (20.071365576s elapsed)
STEP: deleting the pod 12/03/22 12:58:21.693
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 12:58:21.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9751" for this suite. 12/03/22 12:58:21.717
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":167,"skipped":3271,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.182 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:57:59.544
    Dec  3 12:57:59.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:57:59.545
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:57:59.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:57:59.575
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b in namespace container-probe-9751 12/03/22 12:57:59.579
    Dec  3 12:57:59.602: INFO: Waiting up to 5m0s for pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b" in namespace "container-probe-9751" to be "not pending"
    Dec  3 12:57:59.610: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.838818ms
    Dec  3 12:58:01.616: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014111911s
    Dec  3 12:58:01.616: INFO: Pod "liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b" satisfied condition "not pending"
    Dec  3 12:58:01.616: INFO: Started pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b in namespace container-probe-9751
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:58:01.616
    Dec  3 12:58:01.621: INFO: Initial restart count of pod liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b is 0
    Dec  3 12:58:21.693: INFO: Restart count of pod container-probe-9751/liveness-2b112a3f-674a-4f0b-a1dc-53894f44443b is now 1 (20.071365576s elapsed)
    STEP: deleting the pod 12/03/22 12:58:21.693
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 12:58:21.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9751" for this suite. 12/03/22 12:58:21.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:58:21.728
Dec  3 12:58:21.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 12:58:21.729
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:21.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:21.763
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 12/03/22 12:58:21.771
STEP: create the rc2 12/03/22 12:58:21.782
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/03/22 12:58:26.806
STEP: delete the rc simpletest-rc-to-be-deleted 12/03/22 12:58:27.334
STEP: wait for the rc to be deleted 12/03/22 12:58:27.345
Dec  3 12:58:32.361: INFO: 69 pods remaining
Dec  3 12:58:32.361: INFO: 69 pods has nil DeletionTimestamp
Dec  3 12:58:32.361: INFO: 
STEP: Gathering metrics 12/03/22 12:58:37.362
W1203 12:58:37.368729      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 12:58:37.368: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec  3 12:58:37.368: INFO: Deleting pod "simpletest-rc-to-be-deleted-25dhb" in namespace "gc-7223"
Dec  3 12:58:37.387: INFO: Deleting pod "simpletest-rc-to-be-deleted-286hj" in namespace "gc-7223"
Dec  3 12:58:37.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f79v" in namespace "gc-7223"
Dec  3 12:58:37.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s8gq" in namespace "gc-7223"
Dec  3 12:58:37.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-455tt" in namespace "gc-7223"
Dec  3 12:58:37.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-4x4vm" in namespace "gc-7223"
Dec  3 12:58:37.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dd5p" in namespace "gc-7223"
Dec  3 12:58:37.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jgrs" in namespace "gc-7223"
Dec  3 12:58:37.524: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qkcg" in namespace "gc-7223"
Dec  3 12:58:37.545: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rds4" in namespace "gc-7223"
Dec  3 12:58:37.562: INFO: Deleting pod "simpletest-rc-to-be-deleted-69b8v" in namespace "gc-7223"
Dec  3 12:58:37.578: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gk5s" in namespace "gc-7223"
Dec  3 12:58:37.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kvgc" in namespace "gc-7223"
Dec  3 12:58:37.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mqj8" in namespace "gc-7223"
Dec  3 12:58:37.641: INFO: Deleting pod "simpletest-rc-to-be-deleted-794q4" in namespace "gc-7223"
Dec  3 12:58:37.671: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ck69" in namespace "gc-7223"
Dec  3 12:58:37.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-7krg7" in namespace "gc-7223"
Dec  3 12:58:37.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-7q579" in namespace "gc-7223"
Dec  3 12:58:37.798: INFO: Deleting pod "simpletest-rc-to-be-deleted-85jq9" in namespace "gc-7223"
Dec  3 12:58:37.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-8h5qn" in namespace "gc-7223"
Dec  3 12:58:37.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mcdq" in namespace "gc-7223"
Dec  3 12:58:37.859: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nb42" in namespace "gc-7223"
Dec  3 12:58:37.876: INFO: Deleting pod "simpletest-rc-to-be-deleted-8w59w" in namespace "gc-7223"
Dec  3 12:58:37.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-98m52" in namespace "gc-7223"
Dec  3 12:58:37.912: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hwr5" in namespace "gc-7223"
Dec  3 12:58:37.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qfqf" in namespace "gc-7223"
Dec  3 12:58:37.943: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xtwz" in namespace "gc-7223"
Dec  3 12:58:37.958: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkdf7" in namespace "gc-7223"
Dec  3 12:58:37.977: INFO: Deleting pod "simpletest-rc-to-be-deleted-bltb9" in namespace "gc-7223"
Dec  3 12:58:37.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-btpqs" in namespace "gc-7223"
Dec  3 12:58:38.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2xx5" in namespace "gc-7223"
Dec  3 12:58:38.028: INFO: Deleting pod "simpletest-rc-to-be-deleted-cb6c7" in namespace "gc-7223"
Dec  3 12:58:38.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmh7n" in namespace "gc-7223"
Dec  3 12:58:38.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-d24j6" in namespace "gc-7223"
Dec  3 12:58:38.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6zt2" in namespace "gc-7223"
Dec  3 12:58:38.115: INFO: Deleting pod "simpletest-rc-to-be-deleted-db8wr" in namespace "gc-7223"
Dec  3 12:58:38.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhq68" in namespace "gc-7223"
Dec  3 12:58:38.158: INFO: Deleting pod "simpletest-rc-to-be-deleted-dj8vf" in namespace "gc-7223"
Dec  3 12:58:38.182: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlplg" in namespace "gc-7223"
Dec  3 12:58:38.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-dpnfp" in namespace "gc-7223"
Dec  3 12:58:38.223: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqfqn" in namespace "gc-7223"
Dec  3 12:58:38.241: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvhr7" in namespace "gc-7223"
Dec  3 12:58:38.254: INFO: Deleting pod "simpletest-rc-to-be-deleted-dwrzs" in namespace "gc-7223"
Dec  3 12:58:38.270: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7nsj" in namespace "gc-7223"
Dec  3 12:58:38.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8bjw" in namespace "gc-7223"
Dec  3 12:58:38.303: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffqp7" in namespace "gc-7223"
Dec  3 12:58:38.319: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj8wl" in namespace "gc-7223"
Dec  3 12:58:38.334: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpxvc" in namespace "gc-7223"
Dec  3 12:58:38.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8bwd" in namespace "gc-7223"
Dec  3 12:58:38.367: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbrbh" in namespace "gc-7223"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 12:58:38.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7223" for this suite. 12/03/22 12:58:38.391
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":168,"skipped":3279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.676 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:58:21.728
    Dec  3 12:58:21.729: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 12:58:21.729
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:21.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:21.763
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 12/03/22 12:58:21.771
    STEP: create the rc2 12/03/22 12:58:21.782
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/03/22 12:58:26.806
    STEP: delete the rc simpletest-rc-to-be-deleted 12/03/22 12:58:27.334
    STEP: wait for the rc to be deleted 12/03/22 12:58:27.345
    Dec  3 12:58:32.361: INFO: 69 pods remaining
    Dec  3 12:58:32.361: INFO: 69 pods has nil DeletionTimestamp
    Dec  3 12:58:32.361: INFO: 
    STEP: Gathering metrics 12/03/22 12:58:37.362
    W1203 12:58:37.368729      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 12:58:37.368: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec  3 12:58:37.368: INFO: Deleting pod "simpletest-rc-to-be-deleted-25dhb" in namespace "gc-7223"
    Dec  3 12:58:37.387: INFO: Deleting pod "simpletest-rc-to-be-deleted-286hj" in namespace "gc-7223"
    Dec  3 12:58:37.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f79v" in namespace "gc-7223"
    Dec  3 12:58:37.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s8gq" in namespace "gc-7223"
    Dec  3 12:58:37.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-455tt" in namespace "gc-7223"
    Dec  3 12:58:37.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-4x4vm" in namespace "gc-7223"
    Dec  3 12:58:37.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dd5p" in namespace "gc-7223"
    Dec  3 12:58:37.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jgrs" in namespace "gc-7223"
    Dec  3 12:58:37.524: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qkcg" in namespace "gc-7223"
    Dec  3 12:58:37.545: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rds4" in namespace "gc-7223"
    Dec  3 12:58:37.562: INFO: Deleting pod "simpletest-rc-to-be-deleted-69b8v" in namespace "gc-7223"
    Dec  3 12:58:37.578: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gk5s" in namespace "gc-7223"
    Dec  3 12:58:37.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kvgc" in namespace "gc-7223"
    Dec  3 12:58:37.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mqj8" in namespace "gc-7223"
    Dec  3 12:58:37.641: INFO: Deleting pod "simpletest-rc-to-be-deleted-794q4" in namespace "gc-7223"
    Dec  3 12:58:37.671: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ck69" in namespace "gc-7223"
    Dec  3 12:58:37.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-7krg7" in namespace "gc-7223"
    Dec  3 12:58:37.761: INFO: Deleting pod "simpletest-rc-to-be-deleted-7q579" in namespace "gc-7223"
    Dec  3 12:58:37.798: INFO: Deleting pod "simpletest-rc-to-be-deleted-85jq9" in namespace "gc-7223"
    Dec  3 12:58:37.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-8h5qn" in namespace "gc-7223"
    Dec  3 12:58:37.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mcdq" in namespace "gc-7223"
    Dec  3 12:58:37.859: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nb42" in namespace "gc-7223"
    Dec  3 12:58:37.876: INFO: Deleting pod "simpletest-rc-to-be-deleted-8w59w" in namespace "gc-7223"
    Dec  3 12:58:37.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-98m52" in namespace "gc-7223"
    Dec  3 12:58:37.912: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hwr5" in namespace "gc-7223"
    Dec  3 12:58:37.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qfqf" in namespace "gc-7223"
    Dec  3 12:58:37.943: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xtwz" in namespace "gc-7223"
    Dec  3 12:58:37.958: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkdf7" in namespace "gc-7223"
    Dec  3 12:58:37.977: INFO: Deleting pod "simpletest-rc-to-be-deleted-bltb9" in namespace "gc-7223"
    Dec  3 12:58:37.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-btpqs" in namespace "gc-7223"
    Dec  3 12:58:38.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2xx5" in namespace "gc-7223"
    Dec  3 12:58:38.028: INFO: Deleting pod "simpletest-rc-to-be-deleted-cb6c7" in namespace "gc-7223"
    Dec  3 12:58:38.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmh7n" in namespace "gc-7223"
    Dec  3 12:58:38.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-d24j6" in namespace "gc-7223"
    Dec  3 12:58:38.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6zt2" in namespace "gc-7223"
    Dec  3 12:58:38.115: INFO: Deleting pod "simpletest-rc-to-be-deleted-db8wr" in namespace "gc-7223"
    Dec  3 12:58:38.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhq68" in namespace "gc-7223"
    Dec  3 12:58:38.158: INFO: Deleting pod "simpletest-rc-to-be-deleted-dj8vf" in namespace "gc-7223"
    Dec  3 12:58:38.182: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlplg" in namespace "gc-7223"
    Dec  3 12:58:38.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-dpnfp" in namespace "gc-7223"
    Dec  3 12:58:38.223: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqfqn" in namespace "gc-7223"
    Dec  3 12:58:38.241: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvhr7" in namespace "gc-7223"
    Dec  3 12:58:38.254: INFO: Deleting pod "simpletest-rc-to-be-deleted-dwrzs" in namespace "gc-7223"
    Dec  3 12:58:38.270: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7nsj" in namespace "gc-7223"
    Dec  3 12:58:38.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8bjw" in namespace "gc-7223"
    Dec  3 12:58:38.303: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffqp7" in namespace "gc-7223"
    Dec  3 12:58:38.319: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj8wl" in namespace "gc-7223"
    Dec  3 12:58:38.334: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpxvc" in namespace "gc-7223"
    Dec  3 12:58:38.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8bwd" in namespace "gc-7223"
    Dec  3 12:58:38.367: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbrbh" in namespace "gc-7223"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 12:58:38.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7223" for this suite. 12/03/22 12:58:38.391
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:58:38.408
Dec  3 12:58:38.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename csistoragecapacity 12/03/22 12:58:38.409
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:38.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:38.434
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 12/03/22 12:58:38.439
STEP: getting /apis/storage.k8s.io 12/03/22 12:58:38.442
STEP: getting /apis/storage.k8s.io/v1 12/03/22 12:58:38.444
STEP: creating 12/03/22 12:58:38.446
STEP: watching 12/03/22 12:58:38.471
Dec  3 12:58:38.471: INFO: starting watch
STEP: getting 12/03/22 12:58:38.481
STEP: listing in namespace 12/03/22 12:58:38.485
STEP: listing across namespaces 12/03/22 12:58:38.49
STEP: patching 12/03/22 12:58:38.496
STEP: updating 12/03/22 12:58:38.503
Dec  3 12:58:38.511: INFO: waiting for watch events with expected annotations in namespace
Dec  3 12:58:38.511: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 12/03/22 12:58:38.512
STEP: deleting a collection 12/03/22 12:58:38.53
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Dec  3 12:58:38.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-9779" for this suite. 12/03/22 12:58:38.557
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":169,"skipped":3299,"failed":0}
------------------------------
â€¢ [0.158 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:58:38.408
    Dec  3 12:58:38.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename csistoragecapacity 12/03/22 12:58:38.409
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:38.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:38.434
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 12/03/22 12:58:38.439
    STEP: getting /apis/storage.k8s.io 12/03/22 12:58:38.442
    STEP: getting /apis/storage.k8s.io/v1 12/03/22 12:58:38.444
    STEP: creating 12/03/22 12:58:38.446
    STEP: watching 12/03/22 12:58:38.471
    Dec  3 12:58:38.471: INFO: starting watch
    STEP: getting 12/03/22 12:58:38.481
    STEP: listing in namespace 12/03/22 12:58:38.485
    STEP: listing across namespaces 12/03/22 12:58:38.49
    STEP: patching 12/03/22 12:58:38.496
    STEP: updating 12/03/22 12:58:38.503
    Dec  3 12:58:38.511: INFO: waiting for watch events with expected annotations in namespace
    Dec  3 12:58:38.511: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 12/03/22 12:58:38.512
    STEP: deleting a collection 12/03/22 12:58:38.53
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Dec  3 12:58:38.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-9779" for this suite. 12/03/22 12:58:38.557
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:58:38.567
Dec  3 12:58:38.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 12:58:38.568
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:38.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:38.59
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8755 12/03/22 12:58:38.595
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/03/22 12:58:38.61
STEP: creating service externalsvc in namespace services-8755 12/03/22 12:58:38.611
STEP: creating replication controller externalsvc in namespace services-8755 12/03/22 12:58:38.632
I1203 12:58:38.648896      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8755, replica count: 2
I1203 12:58:41.699513      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 12:58:44.699647      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 12:58:47.700662      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 12:58:50.701703      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 12/03/22 12:58:50.707
Dec  3 12:58:50.727: INFO: Creating new exec pod
Dec  3 12:58:50.742: INFO: Waiting up to 5m0s for pod "execpodx4bkg" in namespace "services-8755" to be "running"
Dec  3 12:58:50.754: INFO: Pod "execpodx4bkg": Phase="Pending", Reason="", readiness=false. Elapsed: 12.583739ms
Dec  3 12:58:52.760: INFO: Pod "execpodx4bkg": Phase="Running", Reason="", readiness=true. Elapsed: 2.018898262s
Dec  3 12:58:52.761: INFO: Pod "execpodx4bkg" satisfied condition "running"
Dec  3 12:58:52.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-8755 exec execpodx4bkg -- /bin/sh -x -c nslookup clusterip-service.services-8755.svc.cluster.local'
Dec  3 12:58:52.960: INFO: stderr: "+ nslookup clusterip-service.services-8755.svc.cluster.local\n"
Dec  3 12:58:52.960: INFO: stdout: "Server:\t\t10.152.183.238\nAddress:\t10.152.183.238#53\n\nclusterip-service.services-8755.svc.cluster.local\tcanonical name = externalsvc.services-8755.svc.cluster.local.\nName:\texternalsvc.services-8755.svc.cluster.local\nAddress: 10.152.183.206\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8755, will wait for the garbage collector to delete the pods 12/03/22 12:58:52.96
Dec  3 12:58:53.035: INFO: Deleting ReplicationController externalsvc took: 18.15668ms
Dec  3 12:58:53.136: INFO: Terminating ReplicationController externalsvc pods took: 101.073519ms
Dec  3 12:58:55.469: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 12:58:55.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8755" for this suite. 12/03/22 12:58:55.495
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":170,"skipped":3309,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.943 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:58:38.567
    Dec  3 12:58:38.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 12:58:38.568
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:38.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:38.59
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8755 12/03/22 12:58:38.595
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/03/22 12:58:38.61
    STEP: creating service externalsvc in namespace services-8755 12/03/22 12:58:38.611
    STEP: creating replication controller externalsvc in namespace services-8755 12/03/22 12:58:38.632
    I1203 12:58:38.648896      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8755, replica count: 2
    I1203 12:58:41.699513      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 12:58:44.699647      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 12:58:47.700662      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 12:58:50.701703      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 12/03/22 12:58:50.707
    Dec  3 12:58:50.727: INFO: Creating new exec pod
    Dec  3 12:58:50.742: INFO: Waiting up to 5m0s for pod "execpodx4bkg" in namespace "services-8755" to be "running"
    Dec  3 12:58:50.754: INFO: Pod "execpodx4bkg": Phase="Pending", Reason="", readiness=false. Elapsed: 12.583739ms
    Dec  3 12:58:52.760: INFO: Pod "execpodx4bkg": Phase="Running", Reason="", readiness=true. Elapsed: 2.018898262s
    Dec  3 12:58:52.761: INFO: Pod "execpodx4bkg" satisfied condition "running"
    Dec  3 12:58:52.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-8755 exec execpodx4bkg -- /bin/sh -x -c nslookup clusterip-service.services-8755.svc.cluster.local'
    Dec  3 12:58:52.960: INFO: stderr: "+ nslookup clusterip-service.services-8755.svc.cluster.local\n"
    Dec  3 12:58:52.960: INFO: stdout: "Server:\t\t10.152.183.238\nAddress:\t10.152.183.238#53\n\nclusterip-service.services-8755.svc.cluster.local\tcanonical name = externalsvc.services-8755.svc.cluster.local.\nName:\texternalsvc.services-8755.svc.cluster.local\nAddress: 10.152.183.206\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-8755, will wait for the garbage collector to delete the pods 12/03/22 12:58:52.96
    Dec  3 12:58:53.035: INFO: Deleting ReplicationController externalsvc took: 18.15668ms
    Dec  3 12:58:53.136: INFO: Terminating ReplicationController externalsvc pods took: 101.073519ms
    Dec  3 12:58:55.469: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 12:58:55.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8755" for this suite. 12/03/22 12:58:55.495
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:58:55.515
Dec  3 12:58:55.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 12:58:55.515
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:55.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:55.54
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-391d9830-e1ac-4a1e-a538-86d27cbaada4 12/03/22 12:58:55.553
STEP: Creating a pod to test consume secrets 12/03/22 12:58:55.56
Dec  3 12:58:55.573: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539" in namespace "projected-5379" to be "Succeeded or Failed"
Dec  3 12:58:55.582: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Pending", Reason="", readiness=false. Elapsed: 9.039558ms
Dec  3 12:58:57.587: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014123864s
Dec  3 12:58:59.588: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014983669s
STEP: Saw pod success 12/03/22 12:58:59.588
Dec  3 12:58:59.588: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539" satisfied condition "Succeeded or Failed"
Dec  3 12:58:59.595: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/03/22 12:58:59.61
Dec  3 12:58:59.629: INFO: Waiting for pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 to disappear
Dec  3 12:58:59.637: INFO: Pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 12:58:59.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5379" for this suite. 12/03/22 12:58:59.644
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":171,"skipped":3412,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:58:55.515
    Dec  3 12:58:55.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 12:58:55.515
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:55.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:55.54
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-391d9830-e1ac-4a1e-a538-86d27cbaada4 12/03/22 12:58:55.553
    STEP: Creating a pod to test consume secrets 12/03/22 12:58:55.56
    Dec  3 12:58:55.573: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539" in namespace "projected-5379" to be "Succeeded or Failed"
    Dec  3 12:58:55.582: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Pending", Reason="", readiness=false. Elapsed: 9.039558ms
    Dec  3 12:58:57.587: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014123864s
    Dec  3 12:58:59.588: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014983669s
    STEP: Saw pod success 12/03/22 12:58:59.588
    Dec  3 12:58:59.588: INFO: Pod "pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539" satisfied condition "Succeeded or Failed"
    Dec  3 12:58:59.595: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 12:58:59.61
    Dec  3 12:58:59.629: INFO: Waiting for pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 to disappear
    Dec  3 12:58:59.637: INFO: Pod pod-projected-secrets-b63ea9d1-eb78-4919-82f6-c9438367f539 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 12:58:59.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5379" for this suite. 12/03/22 12:58:59.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:58:59.656
Dec  3 12:58:59.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 12:58:59.658
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:59.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:59.701
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 12/03/22 12:58:59.718
Dec  3 12:58:59.718: INFO: Creating simple deployment test-deployment-w7lx2
Dec  3 12:58:59.751: INFO: deployment "test-deployment-w7lx2" doesn't have the required revision set
STEP: Getting /status 12/03/22 12:59:01.771
Dec  3 12:59:01.777: INFO: Deployment test-deployment-w7lx2 has Conditions: [{Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 12/03/22 12:59:01.777
Dec  3 12:59:01.794: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 58, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-w7lx2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 12/03/22 12:59:01.794
Dec  3 12:59:01.798: INFO: Observed &Deployment event: ADDED
Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
Dec  3 12:59:01.798: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec  3 12:59:01.798: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w7lx2-777898ffcc" is progressing.}
Dec  3 12:59:01.799: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
Dec  3 12:59:01.799: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
Dec  3 12:59:01.799: INFO: Found Deployment test-deployment-w7lx2 in namespace deployment-3994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec  3 12:59:01.799: INFO: Deployment test-deployment-w7lx2 has an updated status
STEP: patching the Statefulset Status 12/03/22 12:59:01.799
Dec  3 12:59:01.800: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec  3 12:59:01.811: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 12/03/22 12:59:01.811
Dec  3 12:59:01.815: INFO: Observed &Deployment event: ADDED
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w7lx2-777898ffcc" is progressing.}
Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
Dec  3 12:59:01.815: INFO: Found deployment test-deployment-w7lx2 in namespace deployment-3994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Dec  3 12:59:01.816: INFO: Deployment test-deployment-w7lx2 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 12:59:01.829: INFO: Deployment "test-deployment-w7lx2":
&Deployment{ObjectMeta:{test-deployment-w7lx2  deployment-3994  ece083df-2acb-45ec-9cff-9df854dbddba 23973 1 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00391bb68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-w7lx2-777898ffcc",LastUpdateTime:2022-12-03 12:59:01 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 12:59:01.835: INFO: New ReplicaSet "test-deployment-w7lx2-777898ffcc" of Deployment "test-deployment-w7lx2":
&ReplicaSet{ObjectMeta:{test-deployment-w7lx2-777898ffcc  deployment-3994  6470ce2f-0285-46cc-ab78-500a22ba2e40 23968 1 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-w7lx2 ece083df-2acb-45ec-9cff-9df854dbddba 0xc00391bf80 0xc00391bf81}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ece083df-2acb-45ec-9cff-9df854dbddba\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002496238 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 12:59:01.839: INFO: Pod "test-deployment-w7lx2-777898ffcc-86p46" is available:
&Pod{ObjectMeta:{test-deployment-w7lx2-777898ffcc-86p46 test-deployment-w7lx2-777898ffcc- deployment-3994  4491b93d-e5a5-4ac6-9138-e223a8cfbb17 23967 0 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-w7lx2-777898ffcc 6470ce2f-0285-46cc-ab78-500a22ba2e40 0xc002b536e0 0xc002b536e1}] [] [{kube-controller-manager Update v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6470ce2f-0285-46cc-ab78-500a22ba2e40\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.122\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-45lvc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-45lvc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:58:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:58:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.122,StartTime:2022-12-03 12:58:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:59:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://53a2dbe6c7f5be3daaaffe29a9adfd591b08836a5035846162a102dd1fb6978e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 12:59:01.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3994" for this suite. 12/03/22 12:59:01.846
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":172,"skipped":3448,"failed":0}
------------------------------
â€¢ [2.206 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:58:59.656
    Dec  3 12:58:59.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 12:58:59.658
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:58:59.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:58:59.701
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 12/03/22 12:58:59.718
    Dec  3 12:58:59.718: INFO: Creating simple deployment test-deployment-w7lx2
    Dec  3 12:58:59.751: INFO: deployment "test-deployment-w7lx2" doesn't have the required revision set
    STEP: Getting /status 12/03/22 12:59:01.771
    Dec  3 12:59:01.777: INFO: Deployment test-deployment-w7lx2 has Conditions: [{Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 12/03/22 12:59:01.777
    Dec  3 12:59:01.794: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 12, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 12, 58, 59, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-w7lx2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 12/03/22 12:59:01.794
    Dec  3 12:59:01.798: INFO: Observed &Deployment event: ADDED
    Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
    Dec  3 12:59:01.798: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
    Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec  3 12:59:01.798: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.798: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w7lx2-777898ffcc" is progressing.}
    Dec  3 12:59:01.799: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
    Dec  3 12:59:01.799: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec  3 12:59:01.799: INFO: Observed Deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
    Dec  3 12:59:01.799: INFO: Found Deployment test-deployment-w7lx2 in namespace deployment-3994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec  3 12:59:01.799: INFO: Deployment test-deployment-w7lx2 has an updated status
    STEP: patching the Statefulset Status 12/03/22 12:59:01.799
    Dec  3 12:59:01.800: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec  3 12:59:01.811: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 12/03/22 12:59:01.811
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: ADDED
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-w7lx2-777898ffcc"}
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:58:59 +0000 UTC 2022-12-03 12:58:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-w7lx2-777898ffcc" is progressing.}
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:59:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-03 12:59:01 +0000 UTC 2022-12-03 12:58:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-w7lx2-777898ffcc" has successfully progressed.}
    Dec  3 12:59:01.815: INFO: Observed deployment test-deployment-w7lx2 in namespace deployment-3994 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec  3 12:59:01.815: INFO: Observed &Deployment event: MODIFIED
    Dec  3 12:59:01.815: INFO: Found deployment test-deployment-w7lx2 in namespace deployment-3994 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Dec  3 12:59:01.816: INFO: Deployment test-deployment-w7lx2 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 12:59:01.829: INFO: Deployment "test-deployment-w7lx2":
    &Deployment{ObjectMeta:{test-deployment-w7lx2  deployment-3994  ece083df-2acb-45ec-9cff-9df854dbddba 23973 1 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00391bb68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-w7lx2-777898ffcc",LastUpdateTime:2022-12-03 12:59:01 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec  3 12:59:01.835: INFO: New ReplicaSet "test-deployment-w7lx2-777898ffcc" of Deployment "test-deployment-w7lx2":
    &ReplicaSet{ObjectMeta:{test-deployment-w7lx2-777898ffcc  deployment-3994  6470ce2f-0285-46cc-ab78-500a22ba2e40 23968 1 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-w7lx2 ece083df-2acb-45ec-9cff-9df854dbddba 0xc00391bf80 0xc00391bf81}] [] [{kube-controller-manager Update apps/v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ece083df-2acb-45ec-9cff-9df854dbddba\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002496238 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 12:59:01.839: INFO: Pod "test-deployment-w7lx2-777898ffcc-86p46" is available:
    &Pod{ObjectMeta:{test-deployment-w7lx2-777898ffcc-86p46 test-deployment-w7lx2-777898ffcc- deployment-3994  4491b93d-e5a5-4ac6-9138-e223a8cfbb17 23967 0 2022-12-03 12:58:59 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-w7lx2-777898ffcc 6470ce2f-0285-46cc-ab78-500a22ba2e40 0xc002b536e0 0xc002b536e1}] [] [{kube-controller-manager Update v1 2022-12-03 12:58:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6470ce2f-0285-46cc-ab78-500a22ba2e40\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 12:59:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.122\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-45lvc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-45lvc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:58:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:59:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 12:58:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.122,StartTime:2022-12-03 12:58:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 12:59:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://53a2dbe6c7f5be3daaaffe29a9adfd591b08836a5035846162a102dd1fb6978e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 12:59:01.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3994" for this suite. 12/03/22 12:59:01.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:59:01.875
Dec  3 12:59:01.875: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename subpath 12/03/22 12:59:01.88
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:01.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:01.907
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/03/22 12:59:01.911
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-vcwv 12/03/22 12:59:01.925
STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:59:01.925
Dec  3 12:59:01.939: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vcwv" in namespace "subpath-7406" to be "Succeeded or Failed"
Dec  3 12:59:01.946: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Pending", Reason="", readiness=false. Elapsed: 7.279154ms
Dec  3 12:59:03.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 2.013039731s
Dec  3 12:59:05.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 4.01340233s
Dec  3 12:59:07.956: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 6.016994263s
Dec  3 12:59:09.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 8.014204601s
Dec  3 12:59:11.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 10.013565919s
Dec  3 12:59:13.954: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 12.015188265s
Dec  3 12:59:15.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 14.013664807s
Dec  3 12:59:17.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 16.013675405s
Dec  3 12:59:19.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 18.013160615s
Dec  3 12:59:21.958: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 20.019021992s
Dec  3 12:59:23.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=false. Elapsed: 22.013245991s
Dec  3 12:59:25.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012718819s
STEP: Saw pod success 12/03/22 12:59:25.952
Dec  3 12:59:25.952: INFO: Pod "pod-subpath-test-configmap-vcwv" satisfied condition "Succeeded or Failed"
Dec  3 12:59:25.956: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-configmap-vcwv container test-container-subpath-configmap-vcwv: <nil>
STEP: delete the pod 12/03/22 12:59:25.965
Dec  3 12:59:25.981: INFO: Waiting for pod pod-subpath-test-configmap-vcwv to disappear
Dec  3 12:59:25.987: INFO: Pod pod-subpath-test-configmap-vcwv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vcwv 12/03/22 12:59:25.987
Dec  3 12:59:25.987: INFO: Deleting pod "pod-subpath-test-configmap-vcwv" in namespace "subpath-7406"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec  3 12:59:25.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7406" for this suite. 12/03/22 12:59:25.997
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":173,"skipped":3497,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.132 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:59:01.875
    Dec  3 12:59:01.875: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename subpath 12/03/22 12:59:01.88
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:01.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:01.907
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/03/22 12:59:01.911
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-vcwv 12/03/22 12:59:01.925
    STEP: Creating a pod to test atomic-volume-subpath 12/03/22 12:59:01.925
    Dec  3 12:59:01.939: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vcwv" in namespace "subpath-7406" to be "Succeeded or Failed"
    Dec  3 12:59:01.946: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Pending", Reason="", readiness=false. Elapsed: 7.279154ms
    Dec  3 12:59:03.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 2.013039731s
    Dec  3 12:59:05.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 4.01340233s
    Dec  3 12:59:07.956: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 6.016994263s
    Dec  3 12:59:09.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 8.014204601s
    Dec  3 12:59:11.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 10.013565919s
    Dec  3 12:59:13.954: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 12.015188265s
    Dec  3 12:59:15.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 14.013664807s
    Dec  3 12:59:17.953: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 16.013675405s
    Dec  3 12:59:19.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 18.013160615s
    Dec  3 12:59:21.958: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=true. Elapsed: 20.019021992s
    Dec  3 12:59:23.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Running", Reason="", readiness=false. Elapsed: 22.013245991s
    Dec  3 12:59:25.952: INFO: Pod "pod-subpath-test-configmap-vcwv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012718819s
    STEP: Saw pod success 12/03/22 12:59:25.952
    Dec  3 12:59:25.952: INFO: Pod "pod-subpath-test-configmap-vcwv" satisfied condition "Succeeded or Failed"
    Dec  3 12:59:25.956: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-configmap-vcwv container test-container-subpath-configmap-vcwv: <nil>
    STEP: delete the pod 12/03/22 12:59:25.965
    Dec  3 12:59:25.981: INFO: Waiting for pod pod-subpath-test-configmap-vcwv to disappear
    Dec  3 12:59:25.987: INFO: Pod pod-subpath-test-configmap-vcwv no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-vcwv 12/03/22 12:59:25.987
    Dec  3 12:59:25.987: INFO: Deleting pod "pod-subpath-test-configmap-vcwv" in namespace "subpath-7406"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec  3 12:59:25.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7406" for this suite. 12/03/22 12:59:25.997
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:59:26.008
Dec  3 12:59:26.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 12:59:26.009
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:26.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:26.031
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 12/03/22 12:59:26.036
Dec  3 12:59:26.051: INFO: Waiting up to 5m0s for pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520" in namespace "var-expansion-7693" to be "Succeeded or Failed"
Dec  3 12:59:26.061: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Pending", Reason="", readiness=false. Elapsed: 9.260543ms
Dec  3 12:59:28.067: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015403655s
Dec  3 12:59:30.069: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017914173s
STEP: Saw pod success 12/03/22 12:59:30.069
Dec  3 12:59:30.070: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520" satisfied condition "Succeeded or Failed"
Dec  3 12:59:30.074: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 container dapi-container: <nil>
STEP: delete the pod 12/03/22 12:59:30.084
Dec  3 12:59:30.105: INFO: Waiting for pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 to disappear
Dec  3 12:59:30.109: INFO: Pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 12:59:30.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7693" for this suite. 12/03/22 12:59:30.116
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":174,"skipped":3507,"failed":0}
------------------------------
â€¢ [4.116 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:59:26.008
    Dec  3 12:59:26.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 12:59:26.009
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:26.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:26.031
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 12/03/22 12:59:26.036
    Dec  3 12:59:26.051: INFO: Waiting up to 5m0s for pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520" in namespace "var-expansion-7693" to be "Succeeded or Failed"
    Dec  3 12:59:26.061: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Pending", Reason="", readiness=false. Elapsed: 9.260543ms
    Dec  3 12:59:28.067: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015403655s
    Dec  3 12:59:30.069: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017914173s
    STEP: Saw pod success 12/03/22 12:59:30.069
    Dec  3 12:59:30.070: INFO: Pod "var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520" satisfied condition "Succeeded or Failed"
    Dec  3 12:59:30.074: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 12:59:30.084
    Dec  3 12:59:30.105: INFO: Waiting for pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 to disappear
    Dec  3 12:59:30.109: INFO: Pod var-expansion-221aa197-3e69-44aa-8474-37e5c6c70520 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 12:59:30.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7693" for this suite. 12/03/22 12:59:30.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:59:30.128
Dec  3 12:59:30.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 12:59:30.129
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:30.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:30.156
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 12:59:30.183
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:59:31.037
STEP: Deploying the webhook pod 12/03/22 12:59:31.049
STEP: Wait for the deployment to be ready 12/03/22 12:59:31.073
Dec  3 12:59:31.094: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 12:59:33.113
STEP: Verifying the service has paired with the endpoint 12/03/22 12:59:33.134
Dec  3 12:59:34.135: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 12/03/22 12:59:34.23
STEP: Creating a configMap that should be mutated 12/03/22 12:59:34.254
STEP: Deleting the collection of validation webhooks 12/03/22 12:59:34.304
STEP: Creating a configMap that should not be mutated 12/03/22 12:59:34.374
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 12:59:34.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4743" for this suite. 12/03/22 12:59:34.397
STEP: Destroying namespace "webhook-4743-markers" for this suite. 12/03/22 12:59:34.412
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":175,"skipped":3528,"failed":0}
------------------------------
â€¢ [4.411 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:59:30.128
    Dec  3 12:59:30.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 12:59:30.129
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:30.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:30.156
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 12:59:30.183
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 12:59:31.037
    STEP: Deploying the webhook pod 12/03/22 12:59:31.049
    STEP: Wait for the deployment to be ready 12/03/22 12:59:31.073
    Dec  3 12:59:31.094: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 12:59:33.113
    STEP: Verifying the service has paired with the endpoint 12/03/22 12:59:33.134
    Dec  3 12:59:34.135: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 12/03/22 12:59:34.23
    STEP: Creating a configMap that should be mutated 12/03/22 12:59:34.254
    STEP: Deleting the collection of validation webhooks 12/03/22 12:59:34.304
    STEP: Creating a configMap that should not be mutated 12/03/22 12:59:34.374
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 12:59:34.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4743" for this suite. 12/03/22 12:59:34.397
    STEP: Destroying namespace "webhook-4743-markers" for this suite. 12/03/22 12:59:34.412
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 12:59:34.541
Dec  3 12:59:34.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 12:59:34.543
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:34.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:34.57
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab in namespace container-probe-9855 12/03/22 12:59:34.575
Dec  3 12:59:34.587: INFO: Waiting up to 5m0s for pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab" in namespace "container-probe-9855" to be "not pending"
Dec  3 12:59:34.596: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.096917ms
Dec  3 12:59:36.601: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab": Phase="Running", Reason="", readiness=true. Elapsed: 2.014734936s
Dec  3 12:59:36.602: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab" satisfied condition "not pending"
Dec  3 12:59:36.602: INFO: Started pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab in namespace container-probe-9855
STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:59:36.602
Dec  3 12:59:36.607: INFO: Initial restart count of pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab is 0
STEP: deleting the pod 12/03/22 13:03:37.417
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 13:03:37.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9855" for this suite. 12/03/22 13:03:37.441
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":176,"skipped":3549,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.909 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 12:59:34.541
    Dec  3 12:59:34.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 12:59:34.543
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 12:59:34.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 12:59:34.57
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab in namespace container-probe-9855 12/03/22 12:59:34.575
    Dec  3 12:59:34.587: INFO: Waiting up to 5m0s for pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab" in namespace "container-probe-9855" to be "not pending"
    Dec  3 12:59:34.596: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.096917ms
    Dec  3 12:59:36.601: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab": Phase="Running", Reason="", readiness=true. Elapsed: 2.014734936s
    Dec  3 12:59:36.602: INFO: Pod "test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab" satisfied condition "not pending"
    Dec  3 12:59:36.602: INFO: Started pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab in namespace container-probe-9855
    STEP: checking the pod's current state and verifying that restartCount is present 12/03/22 12:59:36.602
    Dec  3 12:59:36.607: INFO: Initial restart count of pod test-webserver-eaba89fe-c015-4da1-ae87-136ab6be0dab is 0
    STEP: deleting the pod 12/03/22 13:03:37.417
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 13:03:37.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9855" for this suite. 12/03/22 13:03:37.441
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:37.453
Dec  3 13:03:37.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:03:37.454
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:37.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:37.48
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:03:37.485
Dec  3 13:03:37.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6" in namespace "downward-api-5489" to be "Succeeded or Failed"
Dec  3 13:03:37.509: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.564403ms
Dec  3 13:03:39.516: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01296784s
Dec  3 13:03:41.521: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01805215s
STEP: Saw pod success 12/03/22 13:03:41.521
Dec  3 13:03:41.521: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6" satisfied condition "Succeeded or Failed"
Dec  3 13:03:41.529: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 container client-container: <nil>
STEP: delete the pod 12/03/22 13:03:41.57
Dec  3 13:03:41.588: INFO: Waiting for pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 to disappear
Dec  3 13:03:41.593: INFO: Pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:03:41.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5489" for this suite. 12/03/22 13:03:41.599
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":177,"skipped":3571,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:37.453
    Dec  3 13:03:37.453: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:03:37.454
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:37.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:37.48
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:03:37.485
    Dec  3 13:03:37.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6" in namespace "downward-api-5489" to be "Succeeded or Failed"
    Dec  3 13:03:37.509: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.564403ms
    Dec  3 13:03:39.516: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01296784s
    Dec  3 13:03:41.521: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01805215s
    STEP: Saw pod success 12/03/22 13:03:41.521
    Dec  3 13:03:41.521: INFO: Pod "downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6" satisfied condition "Succeeded or Failed"
    Dec  3 13:03:41.529: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:03:41.57
    Dec  3 13:03:41.588: INFO: Waiting for pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 to disappear
    Dec  3 13:03:41.593: INFO: Pod downwardapi-volume-40671b4d-c000-43c1-af7c-57c2de2dd7e6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:03:41.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5489" for this suite. 12/03/22 13:03:41.599
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:41.616
Dec  3 13:03:41.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename ephemeral-containers-test 12/03/22 13:03:41.617
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:41.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:41.651
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 12/03/22 13:03:41.656
Dec  3 13:03:41.673: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1500" to be "running and ready"
Dec  3 13:03:41.678: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.006462ms
Dec  3 13:03:41.678: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:03:43.684: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010837792s
Dec  3 13:03:43.684: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Dec  3 13:03:43.684: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 12/03/22 13:03:43.689
Dec  3 13:03:43.702: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1500" to be "container debugger running"
Dec  3 13:03:43.707: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.657215ms
Dec  3 13:03:45.715: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012358052s
Dec  3 13:03:47.713: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010400646s
Dec  3 13:03:47.713: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 12/03/22 13:03:47.713
Dec  3 13:03:47.713: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1500 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 13:03:47.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:03:47.714: INFO: ExecWithOptions: Clientset creation
Dec  3 13:03:47.714: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-1500/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Dec  3 13:03:47.815: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 13:03:47.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-1500" for this suite. 12/03/22 13:03:47.83
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":178,"skipped":3601,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.223 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:41.616
    Dec  3 13:03:41.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename ephemeral-containers-test 12/03/22 13:03:41.617
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:41.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:41.651
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 12/03/22 13:03:41.656
    Dec  3 13:03:41.673: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1500" to be "running and ready"
    Dec  3 13:03:41.678: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.006462ms
    Dec  3 13:03:41.678: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:03:43.684: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010837792s
    Dec  3 13:03:43.684: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Dec  3 13:03:43.684: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 12/03/22 13:03:43.689
    Dec  3 13:03:43.702: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1500" to be "container debugger running"
    Dec  3 13:03:43.707: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.657215ms
    Dec  3 13:03:45.715: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012358052s
    Dec  3 13:03:47.713: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010400646s
    Dec  3 13:03:47.713: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 12/03/22 13:03:47.713
    Dec  3 13:03:47.713: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1500 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 13:03:47.713: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:03:47.714: INFO: ExecWithOptions: Clientset creation
    Dec  3 13:03:47.714: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-1500/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Dec  3 13:03:47.815: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 13:03:47.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-1500" for this suite. 12/03/22 13:03:47.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:47.84
Dec  3 13:03:47.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:03:47.841
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:47.864
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:47.868
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:03:47.893
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:03:48.395
STEP: Deploying the webhook pod 12/03/22 13:03:48.406
STEP: Wait for the deployment to be ready 12/03/22 13:03:48.421
Dec  3 13:03:48.443: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:03:50.461
STEP: Verifying the service has paired with the endpoint 12/03/22 13:03:50.477
Dec  3 13:03:51.478: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 12/03/22 13:03:51.483
STEP: Creating a custom resource definition that should be denied by the webhook 12/03/22 13:03:51.503
Dec  3 13:03:51.503: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:03:51.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8129" for this suite. 12/03/22 13:03:51.527
STEP: Destroying namespace "webhook-8129-markers" for this suite. 12/03/22 13:03:51.536
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":179,"skipped":3608,"failed":0}
------------------------------
â€¢ [3.850 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:47.84
    Dec  3 13:03:47.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:03:47.841
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:47.864
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:47.868
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:03:47.893
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:03:48.395
    STEP: Deploying the webhook pod 12/03/22 13:03:48.406
    STEP: Wait for the deployment to be ready 12/03/22 13:03:48.421
    Dec  3 13:03:48.443: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:03:50.461
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:03:50.477
    Dec  3 13:03:51.478: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 12/03/22 13:03:51.483
    STEP: Creating a custom resource definition that should be denied by the webhook 12/03/22 13:03:51.503
    Dec  3 13:03:51.503: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:03:51.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8129" for this suite. 12/03/22 13:03:51.527
    STEP: Destroying namespace "webhook-8129-markers" for this suite. 12/03/22 13:03:51.536
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:51.691
Dec  3 13:03:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:03:51.692
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:51.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:51.842
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 12/03/22 13:03:51.853
Dec  3 13:03:51.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-9374 cluster-info'
Dec  3 13:03:51.921: INFO: stderr: ""
Dec  3 13:03:51.921: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:03:51.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9374" for this suite. 12/03/22 13:03:51.929
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":180,"skipped":3619,"failed":0}
------------------------------
â€¢ [0.249 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:51.691
    Dec  3 13:03:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:03:51.692
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:51.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:51.842
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 12/03/22 13:03:51.853
    Dec  3 13:03:51.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-9374 cluster-info'
    Dec  3 13:03:51.921: INFO: stderr: ""
    Dec  3 13:03:51.921: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:03:51.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9374" for this suite. 12/03/22 13:03:51.929
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:51.94
Dec  3 13:03:51.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 13:03:51.941
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:51.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:51.974
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:03:52.011
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:03:52.021
Dec  3 13:03:52.028: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:52.028: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:52.036: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:03:52.036: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:03:53.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:53.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:53.047: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:03:53.047: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:03:54.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:54.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:54.047: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:03:54.047: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:03:55.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:55.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:55.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:03:55.048: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:03:56.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:56.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:03:56.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:03:56.049: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 12/03/22 13:03:56.053
STEP: DeleteCollection of the DaemonSets 12/03/22 13:03:56.058
STEP: Verify that ReplicaSets have been deleted 12/03/22 13:03:56.075
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Dec  3 13:03:56.105: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24934"},"items":null}

Dec  3 13:03:56.115: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24936"},"items":[{"metadata":{"name":"daemon-set-6nsvf","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"9101265a-f4e1-4cfd-bbeb-c35bdcfc7a04","resourceVersion":"24935","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-qnzsc","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-qnzsc","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-4-162","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-4-162"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.4.162","podIP":"192.168.197.27","podIPs":[{"ip":"192.168.197.27"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://27dd1d2315639c4540023727c4ce81d4a68a48697c04335cf36caf189a0c41a2","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-kh248","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"f8359948-8e20-4722-9ecf-e9a5ce8025a9","resourceVersion":"24934","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.226\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ldhvb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ldhvb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-76-203","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-76-203"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:55Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:55Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.76.203","podIP":"192.168.71.226","podIPs":[{"ip":"192.168.71.226"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1258e45b13075082ccb564b243a776fbf26ec61284870e42091a58f7658c17e4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-xgdgj","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"bf2b2c14-c4ea-4b09-a295-5582e558f93c","resourceVersion":"24936","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-4ttw5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-4ttw5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-38-234","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-38-234"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.38.234","podIP":"192.168.197.69","podIPs":[{"ip":"192.168.197.69"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://048d4da94f483e53c9409158bef58c4c7f139ee0f55915e5185a16a278eaf08d","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:03:56.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1371" for this suite. 12/03/22 13:03:56.141
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":181,"skipped":3621,"failed":0}
------------------------------
â€¢ [4.210 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:51.94
    Dec  3 13:03:51.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 13:03:51.941
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:51.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:51.974
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:03:52.011
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:03:52.021
    Dec  3 13:03:52.028: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:52.028: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:52.036: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:03:52.036: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:03:53.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:53.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:53.047: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:03:53.047: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:03:54.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:54.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:54.047: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:03:54.047: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:03:55.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:55.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:55.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:03:55.048: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:03:56.042: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:56.042: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:03:56.049: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:03:56.049: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 12/03/22 13:03:56.053
    STEP: DeleteCollection of the DaemonSets 12/03/22 13:03:56.058
    STEP: Verify that ReplicaSets have been deleted 12/03/22 13:03:56.075
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Dec  3 13:03:56.105: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24934"},"items":null}

    Dec  3 13:03:56.115: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24936"},"items":[{"metadata":{"name":"daemon-set-6nsvf","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"9101265a-f4e1-4cfd-bbeb-c35bdcfc7a04","resourceVersion":"24935","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-qnzsc","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-qnzsc","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-4-162","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-4-162"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.4.162","podIP":"192.168.197.27","podIPs":[{"ip":"192.168.197.27"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://27dd1d2315639c4540023727c4ce81d4a68a48697c04335cf36caf189a0c41a2","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-kh248","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"f8359948-8e20-4722-9ecf-e9a5ce8025a9","resourceVersion":"24934","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.226\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ldhvb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ldhvb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-76-203","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-76-203"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:55Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:55Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.76.203","podIP":"192.168.71.226","podIPs":[{"ip":"192.168.71.226"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1258e45b13075082ccb564b243a776fbf26ec61284870e42091a58f7658c17e4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-xgdgj","generateName":"daemon-set-","namespace":"daemonsets-1371","uid":"bf2b2c14-c4ea-4b09-a295-5582e558f93c","resourceVersion":"24936","creationTimestamp":"2022-12-03T13:03:52Z","deletionTimestamp":"2022-12-03T13:04:26Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"042f251d-4702-4404-bc52-8f47cb769016","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"042f251d-4702-4404-bc52-8f47cb769016\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-03T13:03:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-4ttw5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-4ttw5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-38-234","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-38-234"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-03T13:03:52Z"}],"hostIP":"172.31.38.234","podIP":"192.168.197.69","podIPs":[{"ip":"192.168.197.69"}],"startTime":"2022-12-03T13:03:52Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-03T13:03:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://048d4da94f483e53c9409158bef58c4c7f139ee0f55915e5185a16a278eaf08d","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:03:56.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1371" for this suite. 12/03/22 13:03:56.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:56.151
Dec  3 13:03:56.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 13:03:56.152
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:56.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:56.18
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 12/03/22 13:03:56.185
STEP: Getting a ResourceQuota 12/03/22 13:03:56.191
STEP: Listing all ResourceQuotas with LabelSelector 12/03/22 13:03:56.196
STEP: Patching the ResourceQuota 12/03/22 13:03:56.201
STEP: Deleting a Collection of ResourceQuotas 12/03/22 13:03:56.211
STEP: Verifying the deleted ResourceQuota 12/03/22 13:03:56.223
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 13:03:56.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8141" for this suite. 12/03/22 13:03:56.232
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":182,"skipped":3626,"failed":0}
------------------------------
â€¢ [0.091 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:56.151
    Dec  3 13:03:56.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 13:03:56.152
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:56.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:56.18
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 12/03/22 13:03:56.185
    STEP: Getting a ResourceQuota 12/03/22 13:03:56.191
    STEP: Listing all ResourceQuotas with LabelSelector 12/03/22 13:03:56.196
    STEP: Patching the ResourceQuota 12/03/22 13:03:56.201
    STEP: Deleting a Collection of ResourceQuotas 12/03/22 13:03:56.211
    STEP: Verifying the deleted ResourceQuota 12/03/22 13:03:56.223
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 13:03:56.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8141" for this suite. 12/03/22 13:03:56.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:03:56.245
Dec  3 13:03:56.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:03:56.246
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:56.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:56.281
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:03:56.303
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:03:57.103
STEP: Deploying the webhook pod 12/03/22 13:03:57.112
STEP: Wait for the deployment to be ready 12/03/22 13:03:57.129
Dec  3 13:03:57.144: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:03:59.168
STEP: Verifying the service has paired with the endpoint 12/03/22 13:03:59.182
Dec  3 13:04:00.182: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 12/03/22 13:04:00.189
STEP: create a pod that should be denied by the webhook 12/03/22 13:04:00.206
STEP: create a pod that causes the webhook to hang 12/03/22 13:04:00.216
STEP: create a configmap that should be denied by the webhook 12/03/22 13:04:10.237
STEP: create a configmap that should be admitted by the webhook 12/03/22 13:04:10.247
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/03/22 13:04:10.258
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/03/22 13:04:10.271
STEP: create a namespace that bypass the webhook 12/03/22 13:04:10.278
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/03/22 13:04:10.291
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:04:10.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8896" for this suite. 12/03/22 13:04:10.353
STEP: Destroying namespace "webhook-8896-markers" for this suite. 12/03/22 13:04:10.364
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":183,"skipped":3668,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.224 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:03:56.245
    Dec  3 13:03:56.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:03:56.246
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:03:56.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:03:56.281
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:03:56.303
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:03:57.103
    STEP: Deploying the webhook pod 12/03/22 13:03:57.112
    STEP: Wait for the deployment to be ready 12/03/22 13:03:57.129
    Dec  3 13:03:57.144: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:03:59.168
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:03:59.182
    Dec  3 13:04:00.182: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 12/03/22 13:04:00.189
    STEP: create a pod that should be denied by the webhook 12/03/22 13:04:00.206
    STEP: create a pod that causes the webhook to hang 12/03/22 13:04:00.216
    STEP: create a configmap that should be denied by the webhook 12/03/22 13:04:10.237
    STEP: create a configmap that should be admitted by the webhook 12/03/22 13:04:10.247
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/03/22 13:04:10.258
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/03/22 13:04:10.271
    STEP: create a namespace that bypass the webhook 12/03/22 13:04:10.278
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/03/22 13:04:10.291
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:04:10.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8896" for this suite. 12/03/22 13:04:10.353
    STEP: Destroying namespace "webhook-8896-markers" for this suite. 12/03/22 13:04:10.364
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:10.47
Dec  3 13:04:10.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 13:04:10.471
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:10.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:10.508
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/03/22 13:04:10.518
Dec  3 13:04:10.534: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6516" to be "running and ready"
Dec  3 13:04:10.541: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.417201ms
Dec  3 13:04:10.541: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:04:12.547: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013007985s
Dec  3 13:04:12.548: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec  3 13:04:12.548: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 12/03/22 13:04:12.552
Dec  3 13:04:12.558: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-6516" to be "running and ready"
Dec  3 13:04:12.563: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.960785ms
Dec  3 13:04:12.563: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:04:14.570: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012043735s
Dec  3 13:04:14.570: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Dec  3 13:04:14.570: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/03/22 13:04:14.582
STEP: delete the pod with lifecycle hook 12/03/22 13:04:14.606
Dec  3 13:04:14.618: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 13:04:14.623: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 13:04:16.623: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 13:04:16.629: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 13:04:18.624: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 13:04:18.632: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec  3 13:04:18.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6516" for this suite. 12/03/22 13:04:18.637
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":184,"skipped":3684,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.176 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:10.47
    Dec  3 13:04:10.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/03/22 13:04:10.471
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:10.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:10.508
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/03/22 13:04:10.518
    Dec  3 13:04:10.534: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6516" to be "running and ready"
    Dec  3 13:04:10.541: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.417201ms
    Dec  3 13:04:10.541: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:04:12.547: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013007985s
    Dec  3 13:04:12.548: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec  3 13:04:12.548: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 12/03/22 13:04:12.552
    Dec  3 13:04:12.558: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-6516" to be "running and ready"
    Dec  3 13:04:12.563: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.960785ms
    Dec  3 13:04:12.563: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:04:14.570: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012043735s
    Dec  3 13:04:14.570: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Dec  3 13:04:14.570: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/03/22 13:04:14.582
    STEP: delete the pod with lifecycle hook 12/03/22 13:04:14.606
    Dec  3 13:04:14.618: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec  3 13:04:14.623: INFO: Pod pod-with-poststart-exec-hook still exists
    Dec  3 13:04:16.623: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec  3 13:04:16.629: INFO: Pod pod-with-poststart-exec-hook still exists
    Dec  3 13:04:18.624: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec  3 13:04:18.632: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec  3 13:04:18.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6516" for this suite. 12/03/22 13:04:18.637
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:18.648
Dec  3 13:04:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:04:18.649
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:18.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:18.671
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-526 12/03/22 13:04:18.675
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[] 12/03/22 13:04:18.709
Dec  3 13:04:18.738: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-526 12/03/22 13:04:18.738
Dec  3 13:04:18.754: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-526" to be "running and ready"
Dec  3 13:04:18.760: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.341755ms
Dec  3 13:04:18.761: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:04:20.769: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014901406s
Dec  3 13:04:20.769: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec  3 13:04:20.769: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod1:[100]] 12/03/22 13:04:20.78
Dec  3 13:04:20.799: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-526 12/03/22 13:04:20.799
Dec  3 13:04:20.807: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-526" to be "running and ready"
Dec  3 13:04:20.812: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153441ms
Dec  3 13:04:20.812: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:04:22.817: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010259417s
Dec  3 13:04:22.817: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec  3 13:04:22.817: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod1:[100] pod2:[101]] 12/03/22 13:04:22.823
Dec  3 13:04:22.853: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 12/03/22 13:04:22.854
Dec  3 13:04:22.854: INFO: Creating new exec pod
Dec  3 13:04:22.867: INFO: Waiting up to 5m0s for pod "execpod7ffjb" in namespace "services-526" to be "running"
Dec  3 13:04:22.874: INFO: Pod "execpod7ffjb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.931031ms
Dec  3 13:04:24.880: INFO: Pod "execpod7ffjb": Phase="Running", Reason="", readiness=true. Elapsed: 2.013262938s
Dec  3 13:04:24.881: INFO: Pod "execpod7ffjb" satisfied condition "running"
Dec  3 13:04:25.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Dec  3 13:04:26.040: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Dec  3 13:04:26.040: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:04:26.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.168 80'
Dec  3 13:04:26.228: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.168 80\nConnection to 10.152.183.168 80 port [tcp/http] succeeded!\n"
Dec  3 13:04:26.228: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:04:26.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Dec  3 13:04:26.384: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Dec  3 13:04:26.384: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:04:26.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.168 81'
Dec  3 13:04:26.577: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.168 81\nConnection to 10.152.183.168 81 port [tcp/*] succeeded!\n"
Dec  3 13:04:26.577: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-526 12/03/22 13:04:26.577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod2:[101]] 12/03/22 13:04:26.6
Dec  3 13:04:26.618: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-526 12/03/22 13:04:26.618
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[] 12/03/22 13:04:26.664
Dec  3 13:04:26.688: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:04:26.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-526" for this suite. 12/03/22 13:04:26.735
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":185,"skipped":3711,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.096 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:18.648
    Dec  3 13:04:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:04:18.649
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:18.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:18.671
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-526 12/03/22 13:04:18.675
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[] 12/03/22 13:04:18.709
    Dec  3 13:04:18.738: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-526 12/03/22 13:04:18.738
    Dec  3 13:04:18.754: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-526" to be "running and ready"
    Dec  3 13:04:18.760: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.341755ms
    Dec  3 13:04:18.761: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:04:20.769: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014901406s
    Dec  3 13:04:20.769: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec  3 13:04:20.769: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod1:[100]] 12/03/22 13:04:20.78
    Dec  3 13:04:20.799: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-526 12/03/22 13:04:20.799
    Dec  3 13:04:20.807: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-526" to be "running and ready"
    Dec  3 13:04:20.812: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153441ms
    Dec  3 13:04:20.812: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:04:22.817: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010259417s
    Dec  3 13:04:22.817: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec  3 13:04:22.817: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod1:[100] pod2:[101]] 12/03/22 13:04:22.823
    Dec  3 13:04:22.853: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 12/03/22 13:04:22.854
    Dec  3 13:04:22.854: INFO: Creating new exec pod
    Dec  3 13:04:22.867: INFO: Waiting up to 5m0s for pod "execpod7ffjb" in namespace "services-526" to be "running"
    Dec  3 13:04:22.874: INFO: Pod "execpod7ffjb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.931031ms
    Dec  3 13:04:24.880: INFO: Pod "execpod7ffjb": Phase="Running", Reason="", readiness=true. Elapsed: 2.013262938s
    Dec  3 13:04:24.881: INFO: Pod "execpod7ffjb" satisfied condition "running"
    Dec  3 13:04:25.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Dec  3 13:04:26.040: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Dec  3 13:04:26.040: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:04:26.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.168 80'
    Dec  3 13:04:26.228: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.168 80\nConnection to 10.152.183.168 80 port [tcp/http] succeeded!\n"
    Dec  3 13:04:26.228: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:04:26.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Dec  3 13:04:26.384: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Dec  3 13:04:26.384: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:04:26.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-526 exec execpod7ffjb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.168 81'
    Dec  3 13:04:26.577: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.168 81\nConnection to 10.152.183.168 81 port [tcp/*] succeeded!\n"
    Dec  3 13:04:26.577: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-526 12/03/22 13:04:26.577
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[pod2:[101]] 12/03/22 13:04:26.6
    Dec  3 13:04:26.618: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-526 12/03/22 13:04:26.618
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-526 to expose endpoints map[] 12/03/22 13:04:26.664
    Dec  3 13:04:26.688: INFO: successfully validated that service multi-endpoint-test in namespace services-526 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:04:26.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-526" for this suite. 12/03/22 13:04:26.735
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:26.745
Dec  3 13:04:26.745: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:04:26.746
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:26.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:26.77
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 12/03/22 13:04:26.774
Dec  3 13:04:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: rename a version 12/03/22 13:04:33.656
STEP: check the new version name is served 12/03/22 13:04:33.676
STEP: check the old version name is removed 12/03/22 13:04:36.545
STEP: check the other version is not changed 12/03/22 13:04:37.817
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:04:42.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7829" for this suite. 12/03/22 13:04:42.839
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":186,"skipped":3720,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.103 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:26.745
    Dec  3 13:04:26.745: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:04:26.746
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:26.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:26.77
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 12/03/22 13:04:26.774
    Dec  3 13:04:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: rename a version 12/03/22 13:04:33.656
    STEP: check the new version name is served 12/03/22 13:04:33.676
    STEP: check the old version name is removed 12/03/22 13:04:36.545
    STEP: check the other version is not changed 12/03/22 13:04:37.817
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:04:42.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7829" for this suite. 12/03/22 13:04:42.839
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:42.85
Dec  3 13:04:42.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 13:04:42.851
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:42.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:42.88
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Dec  3 13:04:42.883: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:04:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6519" for this suite. 12/03/22 13:04:49.216
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":187,"skipped":3724,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.375 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:42.85
    Dec  3 13:04:42.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename custom-resource-definition 12/03/22 13:04:42.851
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:42.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:42.88
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Dec  3 13:04:42.883: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:04:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6519" for this suite. 12/03/22 13:04:49.216
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:49.226
Dec  3 13:04:49.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:04:49.227
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:49.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:49.25
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-2319 12/03/22 13:04:49.254
STEP: creating replication controller nodeport-test in namespace services-2319 12/03/22 13:04:49.277
I1203 13:04:49.307801      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2319, replica count: 2
I1203 13:04:52.358953      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:04:52.359: INFO: Creating new exec pod
Dec  3 13:04:52.371: INFO: Waiting up to 5m0s for pod "execpod7t2lw" in namespace "services-2319" to be "running"
Dec  3 13:04:52.377: INFO: Pod "execpod7t2lw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.001604ms
Dec  3 13:04:54.382: INFO: Pod "execpod7t2lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.011327307s
Dec  3 13:04:54.383: INFO: Pod "execpod7t2lw" satisfied condition "running"
Dec  3 13:04:55.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec  3 13:04:55.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec  3 13:04:55.538: INFO: stdout: "nodeport-test-9n26d"
Dec  3 13:04:55.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.155 80'
Dec  3 13:04:55.699: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.155 80\nConnection to 10.152.183.155 80 port [tcp/http] succeeded!\n"
Dec  3 13:04:55.699: INFO: stdout: "nodeport-test-9n26d"
Dec  3 13:04:55.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 31955'
Dec  3 13:04:55.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.4.162 31955\nConnection to 172.31.4.162 31955 port [tcp/*] succeeded!\n"
Dec  3 13:04:55.861: INFO: stdout: "nodeport-test-dg2sv"
Dec  3 13:04:55.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 31955'
Dec  3 13:04:56.022: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.76.203 31955\nConnection to 172.31.76.203 31955 port [tcp/*] succeeded!\n"
Dec  3 13:04:56.022: INFO: stdout: "nodeport-test-9n26d"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:04:56.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2319" for this suite. 12/03/22 13:04:56.027
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":188,"skipped":3728,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.808 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:49.226
    Dec  3 13:04:49.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:04:49.227
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:49.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:49.25
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-2319 12/03/22 13:04:49.254
    STEP: creating replication controller nodeport-test in namespace services-2319 12/03/22 13:04:49.277
    I1203 13:04:49.307801      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2319, replica count: 2
    I1203 13:04:52.358953      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:04:52.359: INFO: Creating new exec pod
    Dec  3 13:04:52.371: INFO: Waiting up to 5m0s for pod "execpod7t2lw" in namespace "services-2319" to be "running"
    Dec  3 13:04:52.377: INFO: Pod "execpod7t2lw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.001604ms
    Dec  3 13:04:54.382: INFO: Pod "execpod7t2lw": Phase="Running", Reason="", readiness=true. Elapsed: 2.011327307s
    Dec  3 13:04:54.383: INFO: Pod "execpod7t2lw" satisfied condition "running"
    Dec  3 13:04:55.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec  3 13:04:55.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec  3 13:04:55.538: INFO: stdout: "nodeport-test-9n26d"
    Dec  3 13:04:55.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.155 80'
    Dec  3 13:04:55.699: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.155 80\nConnection to 10.152.183.155 80 port [tcp/http] succeeded!\n"
    Dec  3 13:04:55.699: INFO: stdout: "nodeport-test-9n26d"
    Dec  3 13:04:55.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 31955'
    Dec  3 13:04:55.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.4.162 31955\nConnection to 172.31.4.162 31955 port [tcp/*] succeeded!\n"
    Dec  3 13:04:55.861: INFO: stdout: "nodeport-test-dg2sv"
    Dec  3 13:04:55.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2319 exec execpod7t2lw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 31955'
    Dec  3 13:04:56.022: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.76.203 31955\nConnection to 172.31.76.203 31955 port [tcp/*] succeeded!\n"
    Dec  3 13:04:56.022: INFO: stdout: "nodeport-test-9n26d"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:04:56.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2319" for this suite. 12/03/22 13:04:56.027
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:04:56.035
Dec  3 13:04:56.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 13:04:56.036
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:56.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:56.065
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 12/03/22 13:04:56.069
STEP: Ensuring job reaches completions 12/03/22 13:04:56.079
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 13:05:10.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2323" for this suite. 12/03/22 13:05:10.094
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":189,"skipped":3749,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.072 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:04:56.035
    Dec  3 13:04:56.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 13:04:56.036
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:04:56.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:04:56.065
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 12/03/22 13:04:56.069
    STEP: Ensuring job reaches completions 12/03/22 13:04:56.079
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 13:05:10.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2323" for this suite. 12/03/22 13:05:10.094
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:05:10.108
Dec  3 13:05:10.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context-test 12/03/22 13:05:10.109
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:10.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:10.14
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Dec  3 13:05:10.155: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f" in namespace "security-context-test-7423" to be "Succeeded or Failed"
Dec  3 13:05:10.160: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.756011ms
Dec  3 13:05:12.167: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011649717s
Dec  3 13:05:14.168: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012960126s
Dec  3 13:05:16.166: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011010975s
Dec  3 13:05:16.166: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 13:05:16.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7423" for this suite. 12/03/22 13:05:16.181
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":190,"skipped":3752,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.083 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:05:10.108
    Dec  3 13:05:10.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context-test 12/03/22 13:05:10.109
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:10.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:10.14
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Dec  3 13:05:10.155: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f" in namespace "security-context-test-7423" to be "Succeeded or Failed"
    Dec  3 13:05:10.160: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.756011ms
    Dec  3 13:05:12.167: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011649717s
    Dec  3 13:05:14.168: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012960126s
    Dec  3 13:05:16.166: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011010975s
    Dec  3 13:05:16.166: INFO: Pod "alpine-nnp-false-12e4c893-5072-4f07-aa41-564eec34265f" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 13:05:16.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7423" for this suite. 12/03/22 13:05:16.181
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:05:16.194
Dec  3 13:05:16.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:05:16.194
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:16.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:16.268
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:05:16.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1347" for this suite. 12/03/22 13:05:16.335
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":191,"skipped":3782,"failed":0}
------------------------------
â€¢ [0.151 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:05:16.194
    Dec  3 13:05:16.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:05:16.194
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:16.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:16.268
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:05:16.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1347" for this suite. 12/03/22 13:05:16.335
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:05:16.345
Dec  3 13:05:16.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-probe 12/03/22 13:05:16.346
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:16.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:16.379
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec  3 13:06:16.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4998" for this suite. 12/03/22 13:06:16.421
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":192,"skipped":3802,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.085 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:05:16.345
    Dec  3 13:05:16.345: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-probe 12/03/22 13:05:16.346
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:05:16.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:05:16.379
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec  3 13:06:16.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4998" for this suite. 12/03/22 13:06:16.421
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:06:16.433
Dec  3 13:06:16.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-runtime 12/03/22 13:06:16.434
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:16.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:16.461
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 12/03/22 13:06:16.465
STEP: wait for the container to reach Failed 12/03/22 13:06:16.482
STEP: get the container status 12/03/22 13:06:20.519
STEP: the container should be terminated 12/03/22 13:06:20.524
STEP: the termination message should be set 12/03/22 13:06:20.524
Dec  3 13:06:20.524: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/03/22 13:06:20.524
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec  3 13:06:20.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3349" for this suite. 12/03/22 13:06:20.559
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":193,"skipped":3848,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:06:16.433
    Dec  3 13:06:16.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-runtime 12/03/22 13:06:16.434
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:16.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:16.461
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 12/03/22 13:06:16.465
    STEP: wait for the container to reach Failed 12/03/22 13:06:16.482
    STEP: get the container status 12/03/22 13:06:20.519
    STEP: the container should be terminated 12/03/22 13:06:20.524
    STEP: the termination message should be set 12/03/22 13:06:20.524
    Dec  3 13:06:20.524: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/03/22 13:06:20.524
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec  3 13:06:20.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3349" for this suite. 12/03/22 13:06:20.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:06:20.573
Dec  3 13:06:20.574: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 13:06:20.578
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:20.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:20.615
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 12/03/22 13:06:20.625
STEP: Patching the Job 12/03/22 13:06:20.637
STEP: Watching for Job to be patched 12/03/22 13:06:20.665
Dec  3 13:06:20.668: INFO: Event ADDED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec  3 13:06:20.668: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec  3 13:06:20.668: INFO: Event MODIFIED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 12/03/22 13:06:20.668
STEP: Watching for Job to be updated 12/03/22 13:06:20.69
Dec  3 13:06:20.693: INFO: Event MODIFIED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:20.693: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 12/03/22 13:06:20.693
Dec  3 13:06:20.700: INFO: Job: e2e-9vbhz as labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz]
STEP: Waiting for job to complete 12/03/22 13:06:20.701
STEP: Delete a job collection with a labelselector 12/03/22 13:06:30.706
STEP: Watching for Job to be deleted 12/03/22 13:06:30.717
Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:30.720: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec  3 13:06:30.724: INFO: Event DELETED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 12/03/22 13:06:30.724
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 13:06:30.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4030" for this suite. 12/03/22 13:06:30.742
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":194,"skipped":3856,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.187 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:06:20.573
    Dec  3 13:06:20.574: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 13:06:20.578
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:20.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:20.615
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 12/03/22 13:06:20.625
    STEP: Patching the Job 12/03/22 13:06:20.637
    STEP: Watching for Job to be patched 12/03/22 13:06:20.665
    Dec  3 13:06:20.668: INFO: Event ADDED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec  3 13:06:20.668: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec  3 13:06:20.668: INFO: Event MODIFIED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 12/03/22 13:06:20.668
    STEP: Watching for Job to be updated 12/03/22 13:06:20.69
    Dec  3 13:06:20.693: INFO: Event MODIFIED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:20.693: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 12/03/22 13:06:20.693
    Dec  3 13:06:20.700: INFO: Job: e2e-9vbhz as labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz]
    STEP: Waiting for job to complete 12/03/22 13:06:20.701
    STEP: Delete a job collection with a labelselector 12/03/22 13:06:30.706
    STEP: Watching for Job to be deleted 12/03/22 13:06:30.717
    Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:30.719: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:30.720: INFO: Event MODIFIED observed for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec  3 13:06:30.724: INFO: Event DELETED found for Job e2e-9vbhz in namespace job-4030 with labels: map[e2e-9vbhz:patched e2e-job-label:e2e-9vbhz] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 12/03/22 13:06:30.724
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 13:06:30.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4030" for this suite. 12/03/22 13:06:30.742
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:06:30.762
Dec  3 13:06:30.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:06:30.763
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:30.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:30.811
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-c6463ace-6c5d-4aa5-8a80-d0f40f0c1ead 12/03/22 13:06:30.815
STEP: Creating a pod to test consume configMaps 12/03/22 13:06:30.825
Dec  3 13:06:30.843: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813" in namespace "projected-3429" to be "Succeeded or Failed"
Dec  3 13:06:30.850: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Pending", Reason="", readiness=false. Elapsed: 7.732072ms
Dec  3 13:06:32.856: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013048104s
Dec  3 13:06:34.857: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014403713s
STEP: Saw pod success 12/03/22 13:06:34.857
Dec  3 13:06:34.857: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813" satisfied condition "Succeeded or Failed"
Dec  3 13:06:34.862: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:06:34.871
Dec  3 13:06:34.892: INFO: Waiting for pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 to disappear
Dec  3 13:06:34.897: INFO: Pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:06:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3429" for this suite. 12/03/22 13:06:34.904
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":195,"skipped":3861,"failed":0}
------------------------------
â€¢ [4.150 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:06:30.762
    Dec  3 13:06:30.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:06:30.763
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:30.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:30.811
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-c6463ace-6c5d-4aa5-8a80-d0f40f0c1ead 12/03/22 13:06:30.815
    STEP: Creating a pod to test consume configMaps 12/03/22 13:06:30.825
    Dec  3 13:06:30.843: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813" in namespace "projected-3429" to be "Succeeded or Failed"
    Dec  3 13:06:30.850: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Pending", Reason="", readiness=false. Elapsed: 7.732072ms
    Dec  3 13:06:32.856: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013048104s
    Dec  3 13:06:34.857: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014403713s
    STEP: Saw pod success 12/03/22 13:06:34.857
    Dec  3 13:06:34.857: INFO: Pod "pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813" satisfied condition "Succeeded or Failed"
    Dec  3 13:06:34.862: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:06:34.871
    Dec  3 13:06:34.892: INFO: Waiting for pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 to disappear
    Dec  3 13:06:34.897: INFO: Pod pod-projected-configmaps-ef22558e-af54-44f1-ab22-41ac8a218813 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:06:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3429" for this suite. 12/03/22 13:06:34.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:06:34.918
Dec  3 13:06:34.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:06:34.919
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:34.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:35.003
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 12/03/22 13:06:35.008
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6018;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6018;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +notcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_udp@PTR;check="$$(dig +tcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_tcp@PTR;sleep 1; done
 12/03/22 13:06:35.039
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6018;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6018;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +notcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_udp@PTR;check="$$(dig +tcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_tcp@PTR;sleep 1; done
 12/03/22 13:06:35.039
STEP: creating a pod to probe DNS 12/03/22 13:06:35.039
STEP: submitting the pod to kubernetes 12/03/22 13:06:35.039
Dec  3 13:06:35.058: INFO: Waiting up to 15m0s for pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6" in namespace "dns-6018" to be "running"
Dec  3 13:06:35.067: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.436398ms
Dec  3 13:06:37.073: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.013129318s
Dec  3 13:06:37.073: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:06:37.073
STEP: looking for the results for each expected name from probers 12/03/22 13:06:37.078
Dec  3 13:06:37.085: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.089: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.094: INFO: Unable to read wheezy_udp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.111: INFO: Unable to read wheezy_udp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.119: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.125: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.130: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.166: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.171: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.176: INFO: Unable to read jessie_udp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.182: INFO: Unable to read jessie_tcp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.187: INFO: Unable to read jessie_udp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.191: INFO: Unable to read jessie_tcp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.196: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.200: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
Dec  3 13:06:37.220: INFO: Lookups using dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6018 wheezy_tcp@dns-test-service.dns-6018 wheezy_udp@dns-test-service.dns-6018.svc wheezy_tcp@dns-test-service.dns-6018.svc wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6018 jessie_tcp@dns-test-service.dns-6018 jessie_udp@dns-test-service.dns-6018.svc jessie_tcp@dns-test-service.dns-6018.svc jessie_udp@_http._tcp.dns-test-service.dns-6018.svc jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc]

Dec  3 13:06:42.375: INFO: DNS probes using dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6 succeeded

STEP: deleting the pod 12/03/22 13:06:42.375
STEP: deleting the test service 12/03/22 13:06:42.391
STEP: deleting the test headless service 12/03/22 13:06:42.432
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:06:42.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6018" for this suite. 12/03/22 13:06:42.479
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":196,"skipped":3926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.572 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:06:34.918
    Dec  3 13:06:34.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:06:34.919
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:34.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:35.003
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 12/03/22 13:06:35.008
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6018;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6018;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +notcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_udp@PTR;check="$$(dig +tcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_tcp@PTR;sleep 1; done
     12/03/22 13:06:35.039
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6018;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6018;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6018.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6018.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6018.svc;check="$$(dig +notcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_udp@PTR;check="$$(dig +tcp +noall +answer +search 135.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.135_tcp@PTR;sleep 1; done
     12/03/22 13:06:35.039
    STEP: creating a pod to probe DNS 12/03/22 13:06:35.039
    STEP: submitting the pod to kubernetes 12/03/22 13:06:35.039
    Dec  3 13:06:35.058: INFO: Waiting up to 15m0s for pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6" in namespace "dns-6018" to be "running"
    Dec  3 13:06:35.067: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.436398ms
    Dec  3 13:06:37.073: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.013129318s
    Dec  3 13:06:37.073: INFO: Pod "dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:06:37.073
    STEP: looking for the results for each expected name from probers 12/03/22 13:06:37.078
    Dec  3 13:06:37.085: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.089: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.094: INFO: Unable to read wheezy_udp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.111: INFO: Unable to read wheezy_udp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.119: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.125: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.130: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.166: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.171: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.176: INFO: Unable to read jessie_udp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.182: INFO: Unable to read jessie_tcp@dns-test-service.dns-6018 from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.187: INFO: Unable to read jessie_udp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.191: INFO: Unable to read jessie_tcp@dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.196: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.200: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc from pod dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6: the server could not find the requested resource (get pods dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6)
    Dec  3 13:06:37.220: INFO: Lookups using dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6018 wheezy_tcp@dns-test-service.dns-6018 wheezy_udp@dns-test-service.dns-6018.svc wheezy_tcp@dns-test-service.dns-6018.svc wheezy_udp@_http._tcp.dns-test-service.dns-6018.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6018.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6018 jessie_tcp@dns-test-service.dns-6018 jessie_udp@dns-test-service.dns-6018.svc jessie_tcp@dns-test-service.dns-6018.svc jessie_udp@_http._tcp.dns-test-service.dns-6018.svc jessie_tcp@_http._tcp.dns-test-service.dns-6018.svc]

    Dec  3 13:06:42.375: INFO: DNS probes using dns-6018/dns-test-0a37e877-0d89-4849-8ca8-c9e96bc6d1b6 succeeded

    STEP: deleting the pod 12/03/22 13:06:42.375
    STEP: deleting the test service 12/03/22 13:06:42.391
    STEP: deleting the test headless service 12/03/22 13:06:42.432
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:06:42.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6018" for this suite. 12/03/22 13:06:42.479
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:06:42.491
Dec  3 13:06:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename watch 12/03/22 13:06:42.491
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:42.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:42.538
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 12/03/22 13:06:42.543
STEP: creating a watch on configmaps with label B 12/03/22 13:06:42.545
STEP: creating a watch on configmaps with label A or B 12/03/22 13:06:42.547
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.549
Dec  3 13:06:42.557: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26258 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:42.557: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26258 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.557
Dec  3 13:06:42.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26259 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:42.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26259 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/03/22 13:06:42.572
Dec  3 13:06:42.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26260 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:42.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26260 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.586
Dec  3 13:06:42.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26261 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:42.600: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26261 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/03/22 13:06:42.6
Dec  3 13:06:42.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26262 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:42.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26262 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/03/22 13:06:52.609
Dec  3 13:06:52.622: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26305 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec  3 13:06:52.622: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26305 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec  3 13:07:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8394" for this suite. 12/03/22 13:07:02.631
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":197,"skipped":3927,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.158 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:06:42.491
    Dec  3 13:06:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename watch 12/03/22 13:06:42.491
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:06:42.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:06:42.538
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 12/03/22 13:06:42.543
    STEP: creating a watch on configmaps with label B 12/03/22 13:06:42.545
    STEP: creating a watch on configmaps with label A or B 12/03/22 13:06:42.547
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.549
    Dec  3 13:06:42.557: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26258 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:42.557: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26258 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.557
    Dec  3 13:06:42.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26259 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:42.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26259 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/03/22 13:06:42.572
    Dec  3 13:06:42.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26260 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:42.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26260 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/03/22 13:06:42.586
    Dec  3 13:06:42.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26261 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:42.600: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8394  700e3e2e-290e-4f75-b2f0-7c78e70633cb 26261 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/03/22 13:06:42.6
    Dec  3 13:06:42.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26262 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:42.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26262 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/03/22 13:06:52.609
    Dec  3 13:06:52.622: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26305 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec  3 13:06:52.622: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8394  b2e06beb-188e-40a1-b571-bfe9e5effdf9 26305 0 2022-12-03 13:06:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-03 13:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec  3 13:07:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8394" for this suite. 12/03/22 13:07:02.631
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:02.649
Dec  3 13:07:02.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 13:07:02.65
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:02.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:02.683
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 12/03/22 13:07:02.689
STEP: Creating a ResourceQuota 12/03/22 13:07:07.694
STEP: Ensuring resource quota status is calculated 12/03/22 13:07:07.704
STEP: Creating a Pod that fits quota 12/03/22 13:07:09.711
STEP: Ensuring ResourceQuota status captures the pod usage 12/03/22 13:07:09.73
STEP: Not allowing a pod to be created that exceeds remaining quota 12/03/22 13:07:11.737
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/03/22 13:07:11.741
STEP: Ensuring a pod cannot update its resource requirements 12/03/22 13:07:11.744
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/03/22 13:07:11.751
STEP: Deleting the pod 12/03/22 13:07:13.757
STEP: Ensuring resource quota status released the pod usage 12/03/22 13:07:13.773
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 13:07:15.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6807" for this suite. 12/03/22 13:07:15.787
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":198,"skipped":3931,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.147 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:02.649
    Dec  3 13:07:02.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 13:07:02.65
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:02.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:02.683
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 12/03/22 13:07:02.689
    STEP: Creating a ResourceQuota 12/03/22 13:07:07.694
    STEP: Ensuring resource quota status is calculated 12/03/22 13:07:07.704
    STEP: Creating a Pod that fits quota 12/03/22 13:07:09.711
    STEP: Ensuring ResourceQuota status captures the pod usage 12/03/22 13:07:09.73
    STEP: Not allowing a pod to be created that exceeds remaining quota 12/03/22 13:07:11.737
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/03/22 13:07:11.741
    STEP: Ensuring a pod cannot update its resource requirements 12/03/22 13:07:11.744
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/03/22 13:07:11.751
    STEP: Deleting the pod 12/03/22 13:07:13.757
    STEP: Ensuring resource quota status released the pod usage 12/03/22 13:07:13.773
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 13:07:15.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6807" for this suite. 12/03/22 13:07:15.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:15.797
Dec  3 13:07:15.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:07:15.798
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:15.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:15.823
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:07:15.827
Dec  3 13:07:15.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65" in namespace "projected-752" to be "Succeeded or Failed"
Dec  3 13:07:15.846: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Pending", Reason="", readiness=false. Elapsed: 6.295203ms
Dec  3 13:07:17.852: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012535217s
Dec  3 13:07:19.852: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012598627s
STEP: Saw pod success 12/03/22 13:07:19.853
Dec  3 13:07:19.853: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65" satisfied condition "Succeeded or Failed"
Dec  3 13:07:19.857: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 container client-container: <nil>
STEP: delete the pod 12/03/22 13:07:19.866
Dec  3 13:07:19.886: INFO: Waiting for pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 to disappear
Dec  3 13:07:19.892: INFO: Pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:07:19.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-752" for this suite. 12/03/22 13:07:19.898
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":199,"skipped":3943,"failed":0}
------------------------------
â€¢ [4.111 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:15.797
    Dec  3 13:07:15.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:07:15.798
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:15.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:15.823
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:07:15.827
    Dec  3 13:07:15.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65" in namespace "projected-752" to be "Succeeded or Failed"
    Dec  3 13:07:15.846: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Pending", Reason="", readiness=false. Elapsed: 6.295203ms
    Dec  3 13:07:17.852: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012535217s
    Dec  3 13:07:19.852: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012598627s
    STEP: Saw pod success 12/03/22 13:07:19.853
    Dec  3 13:07:19.853: INFO: Pod "downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65" satisfied condition "Succeeded or Failed"
    Dec  3 13:07:19.857: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:07:19.866
    Dec  3 13:07:19.886: INFO: Waiting for pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 to disappear
    Dec  3 13:07:19.892: INFO: Pod downwardapi-volume-23e64959-ae80-4087-a2b9-7c92ecff2f65 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:07:19.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-752" for this suite. 12/03/22 13:07:19.898
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:19.91
Dec  3 13:07:19.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 13:07:19.911
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:19.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:19.947
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 12/03/22 13:07:19.952
STEP: Creating a ResourceQuota 12/03/22 13:07:24.959
STEP: Ensuring resource quota status is calculated 12/03/22 13:07:24.969
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 13:07:26.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7395" for this suite. 12/03/22 13:07:26.981
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":200,"skipped":3951,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.080 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:19.91
    Dec  3 13:07:19.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 13:07:19.911
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:19.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:19.947
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 12/03/22 13:07:19.952
    STEP: Creating a ResourceQuota 12/03/22 13:07:24.959
    STEP: Ensuring resource quota status is calculated 12/03/22 13:07:24.969
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 13:07:26.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7395" for this suite. 12/03/22 13:07:26.981
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:26.99
Dec  3 13:07:26.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:07:26.992
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:27.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:27.032
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 12/03/22 13:07:27.04
Dec  3 13:07:27.040: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Dec  3 13:07:27.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:27.308: INFO: stderr: ""
Dec  3 13:07:27.308: INFO: stdout: "service/agnhost-replica created\n"
Dec  3 13:07:27.308: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Dec  3 13:07:27.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:28.218: INFO: stderr: ""
Dec  3 13:07:28.218: INFO: stdout: "service/agnhost-primary created\n"
Dec  3 13:07:28.218: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 13:07:28.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:28.502: INFO: stderr: ""
Dec  3 13:07:28.502: INFO: stdout: "service/frontend created\n"
Dec  3 13:07:28.502: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec  3 13:07:28.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:28.691: INFO: stderr: ""
Dec  3 13:07:28.691: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 13:07:28.691: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 13:07:28.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:28.893: INFO: stderr: ""
Dec  3 13:07:28.893: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Dec  3 13:07:28.893: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 13:07:28.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
Dec  3 13:07:29.141: INFO: stderr: ""
Dec  3 13:07:29.141: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 12/03/22 13:07:29.141
Dec  3 13:07:29.141: INFO: Waiting for all frontend pods to be Running.
Dec  3 13:07:34.194: INFO: Waiting for frontend to serve content.
Dec  3 13:07:34.208: INFO: Trying to add a new entry to the guestbook.
Dec  3 13:07:34.223: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 12/03/22 13:07:34.243
Dec  3 13:07:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.363: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.363: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 12/03/22 13:07:34.363
Dec  3 13:07:34.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.468: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.468: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/03/22 13:07:34.468
Dec  3 13:07:34.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.561: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.561: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/03/22 13:07:34.561
Dec  3 13:07:34.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.637: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.637: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/03/22 13:07:34.637
Dec  3 13:07:34.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.717: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.717: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/03/22 13:07:34.717
Dec  3 13:07:34.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
Dec  3 13:07:34.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:07:34.926: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:07:34.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1515" for this suite. 12/03/22 13:07:34.939
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":201,"skipped":3953,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.971 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:26.99
    Dec  3 13:07:26.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:07:26.992
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:27.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:27.032
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 12/03/22 13:07:27.04
    Dec  3 13:07:27.040: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Dec  3 13:07:27.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:27.308: INFO: stderr: ""
    Dec  3 13:07:27.308: INFO: stdout: "service/agnhost-replica created\n"
    Dec  3 13:07:27.308: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Dec  3 13:07:27.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:28.218: INFO: stderr: ""
    Dec  3 13:07:28.218: INFO: stdout: "service/agnhost-primary created\n"
    Dec  3 13:07:28.218: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Dec  3 13:07:28.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:28.502: INFO: stderr: ""
    Dec  3 13:07:28.502: INFO: stdout: "service/frontend created\n"
    Dec  3 13:07:28.502: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Dec  3 13:07:28.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:28.691: INFO: stderr: ""
    Dec  3 13:07:28.691: INFO: stdout: "deployment.apps/frontend created\n"
    Dec  3 13:07:28.691: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec  3 13:07:28.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:28.893: INFO: stderr: ""
    Dec  3 13:07:28.893: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Dec  3 13:07:28.893: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec  3 13:07:28.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 create -f -'
    Dec  3 13:07:29.141: INFO: stderr: ""
    Dec  3 13:07:29.141: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 12/03/22 13:07:29.141
    Dec  3 13:07:29.141: INFO: Waiting for all frontend pods to be Running.
    Dec  3 13:07:34.194: INFO: Waiting for frontend to serve content.
    Dec  3 13:07:34.208: INFO: Trying to add a new entry to the guestbook.
    Dec  3 13:07:34.223: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 12/03/22 13:07:34.243
    Dec  3 13:07:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.363: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.363: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 12/03/22 13:07:34.363
    Dec  3 13:07:34.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.468: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.468: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/03/22 13:07:34.468
    Dec  3 13:07:34.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.561: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.561: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/03/22 13:07:34.561
    Dec  3 13:07:34.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.637: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.637: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/03/22 13:07:34.637
    Dec  3 13:07:34.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.717: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.717: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/03/22 13:07:34.717
    Dec  3 13:07:34.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1515 delete --grace-period=0 --force -f -'
    Dec  3 13:07:34.926: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:07:34.926: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:07:34.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1515" for this suite. 12/03/22 13:07:34.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:34.964
Dec  3 13:07:34.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:07:34.973
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:35.035
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-a608a4ed-26e8-428a-8cfc-6d2194668024 12/03/22 13:07:35.043
STEP: Creating a pod to test consume configMaps 12/03/22 13:07:35.053
Dec  3 13:07:35.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82" in namespace "configmap-7461" to be "Succeeded or Failed"
Dec  3 13:07:35.078: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Pending", Reason="", readiness=false. Elapsed: 6.704501ms
Dec  3 13:07:37.085: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013682632s
Dec  3 13:07:39.086: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014391645s
STEP: Saw pod success 12/03/22 13:07:39.086
Dec  3 13:07:39.086: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82" satisfied condition "Succeeded or Failed"
Dec  3 13:07:39.092: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:07:39.101
Dec  3 13:07:39.121: INFO: Waiting for pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 to disappear
Dec  3 13:07:39.127: INFO: Pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:07:39.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7461" for this suite. 12/03/22 13:07:39.133
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":202,"skipped":3964,"failed":0}
------------------------------
â€¢ [4.184 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:34.964
    Dec  3 13:07:34.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:07:34.973
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:35.035
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-a608a4ed-26e8-428a-8cfc-6d2194668024 12/03/22 13:07:35.043
    STEP: Creating a pod to test consume configMaps 12/03/22 13:07:35.053
    Dec  3 13:07:35.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82" in namespace "configmap-7461" to be "Succeeded or Failed"
    Dec  3 13:07:35.078: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Pending", Reason="", readiness=false. Elapsed: 6.704501ms
    Dec  3 13:07:37.085: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013682632s
    Dec  3 13:07:39.086: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014391645s
    STEP: Saw pod success 12/03/22 13:07:39.086
    Dec  3 13:07:39.086: INFO: Pod "pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82" satisfied condition "Succeeded or Failed"
    Dec  3 13:07:39.092: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:07:39.101
    Dec  3 13:07:39.121: INFO: Waiting for pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 to disappear
    Dec  3 13:07:39.127: INFO: Pod pod-configmaps-48622953-2bdb-4076-b386-6ece81c99f82 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:07:39.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7461" for this suite. 12/03/22 13:07:39.133
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:39.149
Dec  3 13:07:39.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption 12/03/22 13:07:39.15
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:39.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:39.179
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 12/03/22 13:07:39.193
STEP: Updating PodDisruptionBudget status 12/03/22 13:07:41.209
STEP: Waiting for all pods to be running 12/03/22 13:07:41.228
Dec  3 13:07:41.236: INFO: running pods: 0 < 1
STEP: locating a running pod 12/03/22 13:07:43.246
STEP: Waiting for the pdb to be processed 12/03/22 13:07:43.269
STEP: Patching PodDisruptionBudget status 12/03/22 13:07:43.283
STEP: Waiting for the pdb to be processed 12/03/22 13:07:43.296
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec  3 13:07:43.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8918" for this suite. 12/03/22 13:07:43.309
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":203,"skipped":3995,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:39.149
    Dec  3 13:07:39.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption 12/03/22 13:07:39.15
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:39.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:39.179
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 12/03/22 13:07:39.193
    STEP: Updating PodDisruptionBudget status 12/03/22 13:07:41.209
    STEP: Waiting for all pods to be running 12/03/22 13:07:41.228
    Dec  3 13:07:41.236: INFO: running pods: 0 < 1
    STEP: locating a running pod 12/03/22 13:07:43.246
    STEP: Waiting for the pdb to be processed 12/03/22 13:07:43.269
    STEP: Patching PodDisruptionBudget status 12/03/22 13:07:43.283
    STEP: Waiting for the pdb to be processed 12/03/22 13:07:43.296
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec  3 13:07:43.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8918" for this suite. 12/03/22 13:07:43.309
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:43.318
Dec  3 13:07:43.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:07:43.32
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:43.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:43.349
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 12/03/22 13:07:43.357
STEP: watching for the Service to be added 12/03/22 13:07:43.368
Dec  3 13:07:43.372: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Dec  3 13:07:43.372: INFO: Service test-service-chhg9 created
STEP: Getting /status 12/03/22 13:07:43.372
Dec  3 13:07:43.379: INFO: Service test-service-chhg9 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 12/03/22 13:07:43.379
STEP: watching for the Service to be patched 12/03/22 13:07:43.391
Dec  3 13:07:43.394: INFO: observed Service test-service-chhg9 in namespace services-9992 with annotations: map[] & LoadBalancer: {[]}
Dec  3 13:07:43.394: INFO: Found Service test-service-chhg9 in namespace services-9992 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Dec  3 13:07:43.394: INFO: Service test-service-chhg9 has service status patched
STEP: updating the ServiceStatus 12/03/22 13:07:43.394
Dec  3 13:07:43.411: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 12/03/22 13:07:43.411
Dec  3 13:07:43.414: INFO: Observed Service test-service-chhg9 in namespace services-9992 with annotations: map[] & Conditions: {[]}
Dec  3 13:07:43.414: INFO: Observed event: &Service{ObjectMeta:{test-service-chhg9  services-9992  217ab87d-9f13-4035-a558-d730b1de39f9 26785 0 2022-12-03 13:07:43 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-03 13:07:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-03 13:07:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.212,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.212],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Dec  3 13:07:43.414: INFO: Found Service test-service-chhg9 in namespace services-9992 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec  3 13:07:43.414: INFO: Service test-service-chhg9 has service status updated
STEP: patching the service 12/03/22 13:07:43.414
STEP: watching for the Service to be patched 12/03/22 13:07:43.435
Dec  3 13:07:43.438: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
Dec  3 13:07:43.438: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
Dec  3 13:07:43.439: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
Dec  3 13:07:43.439: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service:patched test-service-static:true]
Dec  3 13:07:43.439: INFO: Service test-service-chhg9 patched
STEP: deleting the service 12/03/22 13:07:43.439
STEP: watching for the Service to be deleted 12/03/22 13:07:43.464
Dec  3 13:07:43.467: INFO: Observed event: ADDED
Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
Dec  3 13:07:43.467: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Dec  3 13:07:43.467: INFO: Service test-service-chhg9 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:07:43.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9992" for this suite. 12/03/22 13:07:43.473
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":204,"skipped":3995,"failed":0}
------------------------------
â€¢ [0.164 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:43.318
    Dec  3 13:07:43.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:07:43.32
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:43.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:43.349
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 12/03/22 13:07:43.357
    STEP: watching for the Service to be added 12/03/22 13:07:43.368
    Dec  3 13:07:43.372: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Dec  3 13:07:43.372: INFO: Service test-service-chhg9 created
    STEP: Getting /status 12/03/22 13:07:43.372
    Dec  3 13:07:43.379: INFO: Service test-service-chhg9 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 12/03/22 13:07:43.379
    STEP: watching for the Service to be patched 12/03/22 13:07:43.391
    Dec  3 13:07:43.394: INFO: observed Service test-service-chhg9 in namespace services-9992 with annotations: map[] & LoadBalancer: {[]}
    Dec  3 13:07:43.394: INFO: Found Service test-service-chhg9 in namespace services-9992 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Dec  3 13:07:43.394: INFO: Service test-service-chhg9 has service status patched
    STEP: updating the ServiceStatus 12/03/22 13:07:43.394
    Dec  3 13:07:43.411: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 12/03/22 13:07:43.411
    Dec  3 13:07:43.414: INFO: Observed Service test-service-chhg9 in namespace services-9992 with annotations: map[] & Conditions: {[]}
    Dec  3 13:07:43.414: INFO: Observed event: &Service{ObjectMeta:{test-service-chhg9  services-9992  217ab87d-9f13-4035-a558-d730b1de39f9 26785 0 2022-12-03 13:07:43 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-03 13:07:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-03 13:07:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.212,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.212],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Dec  3 13:07:43.414: INFO: Found Service test-service-chhg9 in namespace services-9992 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec  3 13:07:43.414: INFO: Service test-service-chhg9 has service status updated
    STEP: patching the service 12/03/22 13:07:43.414
    STEP: watching for the Service to be patched 12/03/22 13:07:43.435
    Dec  3 13:07:43.438: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
    Dec  3 13:07:43.438: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
    Dec  3 13:07:43.439: INFO: observed Service test-service-chhg9 in namespace services-9992 with labels: map[test-service-static:true]
    Dec  3 13:07:43.439: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service:patched test-service-static:true]
    Dec  3 13:07:43.439: INFO: Service test-service-chhg9 patched
    STEP: deleting the service 12/03/22 13:07:43.439
    STEP: watching for the Service to be deleted 12/03/22 13:07:43.464
    Dec  3 13:07:43.467: INFO: Observed event: ADDED
    Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
    Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
    Dec  3 13:07:43.467: INFO: Observed event: MODIFIED
    Dec  3 13:07:43.467: INFO: Found Service test-service-chhg9 in namespace services-9992 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Dec  3 13:07:43.467: INFO: Service test-service-chhg9 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:07:43.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9992" for this suite. 12/03/22 13:07:43.473
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:43.484
Dec  3 13:07:43.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 13:07:43.485
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:43.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:43.511
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2883 12/03/22 13:07:43.515
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 12/03/22 13:07:43.524
STEP: Creating pod with conflicting port in namespace statefulset-2883 12/03/22 13:07:43.53
STEP: Waiting until pod test-pod will start running in namespace statefulset-2883 12/03/22 13:07:43.542
Dec  3 13:07:43.542: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2883" to be "running"
Dec  3 13:07:43.547: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.036161ms
Dec  3 13:07:45.555: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012839483s
Dec  3 13:07:45.555: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-2883 12/03/22 13:07:45.555
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2883 12/03/22 13:07:45.564
Dec  3 13:07:45.582: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Pending. Waiting for statefulset controller to delete.
Dec  3 13:07:45.604: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 13:07:45.625: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 13:07:45.630: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2883
STEP: Removing pod with conflicting port in namespace statefulset-2883 12/03/22 13:07:45.63
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2883 and will be in running state 12/03/22 13:07:45.65
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 13:07:47.663: INFO: Deleting all statefulset in ns statefulset-2883
Dec  3 13:07:47.668: INFO: Scaling statefulset ss to 0
Dec  3 13:07:57.692: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:07:57.698: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 13:07:57.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2883" for this suite. 12/03/22 13:07:57.723
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":205,"skipped":4002,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.256 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:43.484
    Dec  3 13:07:43.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 13:07:43.485
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:43.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:43.511
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2883 12/03/22 13:07:43.515
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 12/03/22 13:07:43.524
    STEP: Creating pod with conflicting port in namespace statefulset-2883 12/03/22 13:07:43.53
    STEP: Waiting until pod test-pod will start running in namespace statefulset-2883 12/03/22 13:07:43.542
    Dec  3 13:07:43.542: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2883" to be "running"
    Dec  3 13:07:43.547: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.036161ms
    Dec  3 13:07:45.555: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012839483s
    Dec  3 13:07:45.555: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-2883 12/03/22 13:07:45.555
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2883 12/03/22 13:07:45.564
    Dec  3 13:07:45.582: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Pending. Waiting for statefulset controller to delete.
    Dec  3 13:07:45.604: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Failed. Waiting for statefulset controller to delete.
    Dec  3 13:07:45.625: INFO: Observed stateful pod in namespace: statefulset-2883, name: ss-0, uid: d6730485-5c14-4509-b15c-07f140f337b7, status phase: Failed. Waiting for statefulset controller to delete.
    Dec  3 13:07:45.630: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2883
    STEP: Removing pod with conflicting port in namespace statefulset-2883 12/03/22 13:07:45.63
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2883 and will be in running state 12/03/22 13:07:45.65
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 13:07:47.663: INFO: Deleting all statefulset in ns statefulset-2883
    Dec  3 13:07:47.668: INFO: Scaling statefulset ss to 0
    Dec  3 13:07:57.692: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:07:57.698: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 13:07:57.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2883" for this suite. 12/03/22 13:07:57.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:07:57.744
Dec  3 13:07:57.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:07:57.745
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:57.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:57.782
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 12/03/22 13:07:57.789
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local;sleep 1; done
 12/03/22 13:07:57.8
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local;sleep 1; done
 12/03/22 13:07:57.8
STEP: creating a pod to probe DNS 12/03/22 13:07:57.8
STEP: submitting the pod to kubernetes 12/03/22 13:07:57.8
Dec  3 13:07:57.824: INFO: Waiting up to 15m0s for pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9" in namespace "dns-2938" to be "running"
Dec  3 13:07:57.834: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.117648ms
Dec  3 13:07:59.841: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016651445s
Dec  3 13:07:59.841: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:07:59.841
STEP: looking for the results for each expected name from probers 12/03/22 13:07:59.847
Dec  3 13:07:59.859: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.868: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.880: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.888: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.900: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.912: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.927: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.933: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
Dec  3 13:07:59.933: INFO: Lookups using dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local]

Dec  3 13:08:04.978: INFO: DNS probes using dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9 succeeded

STEP: deleting the pod 12/03/22 13:08:04.978
STEP: deleting the test headless service 12/03/22 13:08:04.997
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:08:05.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2938" for this suite. 12/03/22 13:08:05.026
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":206,"skipped":4039,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.292 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:07:57.744
    Dec  3 13:07:57.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:07:57.745
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:07:57.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:07:57.782
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 12/03/22 13:07:57.789
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local;sleep 1; done
     12/03/22 13:07:57.8
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2938.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local;sleep 1; done
     12/03/22 13:07:57.8
    STEP: creating a pod to probe DNS 12/03/22 13:07:57.8
    STEP: submitting the pod to kubernetes 12/03/22 13:07:57.8
    Dec  3 13:07:57.824: INFO: Waiting up to 15m0s for pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9" in namespace "dns-2938" to be "running"
    Dec  3 13:07:57.834: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.117648ms
    Dec  3 13:07:59.841: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016651445s
    Dec  3 13:07:59.841: INFO: Pod "dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:07:59.841
    STEP: looking for the results for each expected name from probers 12/03/22 13:07:59.847
    Dec  3 13:07:59.859: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.868: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.880: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.888: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.900: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.912: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.927: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.933: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local from pod dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9: the server could not find the requested resource (get pods dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9)
    Dec  3 13:07:59.933: INFO: Lookups using dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2938.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2938.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2938.svc.cluster.local jessie_udp@dns-test-service-2.dns-2938.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2938.svc.cluster.local]

    Dec  3 13:08:04.978: INFO: DNS probes using dns-2938/dns-test-fca423ce-7e61-4da0-a9f7-16394d481bf9 succeeded

    STEP: deleting the pod 12/03/22 13:08:04.978
    STEP: deleting the test headless service 12/03/22 13:08:04.997
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:08:05.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2938" for this suite. 12/03/22 13:08:05.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:05.037
Dec  3 13:08:05.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:08:05.038
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:05.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:05.069
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-e74cb3a2-1a00-4bac-b922-5d24877787a3 12/03/22 13:08:05.079
STEP: Creating configMap with name cm-test-opt-upd-e9f0ae40-70f9-4747-b67c-cf391dafa164 12/03/22 13:08:05.087
STEP: Creating the pod 12/03/22 13:08:05.093
Dec  3 13:08:05.107: INFO: Waiting up to 5m0s for pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2" in namespace "configmap-3291" to be "running and ready"
Dec  3 13:08:05.116: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.403336ms
Dec  3 13:08:05.116: INFO: The phase of Pod pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:08:07.122: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015641344s
Dec  3 13:08:07.123: INFO: The phase of Pod pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2 is Running (Ready = true)
Dec  3 13:08:07.123: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-e74cb3a2-1a00-4bac-b922-5d24877787a3 12/03/22 13:08:07.157
STEP: Updating configmap cm-test-opt-upd-e9f0ae40-70f9-4747-b67c-cf391dafa164 12/03/22 13:08:07.167
STEP: Creating configMap with name cm-test-opt-create-940324cd-1a02-4c1d-b662-29df2dd92e4f 12/03/22 13:08:07.174
STEP: waiting to observe update in volume 12/03/22 13:08:07.186
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:08:09.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3291" for this suite. 12/03/22 13:08:09.231
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":207,"skipped":4051,"failed":0}
------------------------------
â€¢ [4.205 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:05.037
    Dec  3 13:08:05.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:08:05.038
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:05.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:05.069
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-e74cb3a2-1a00-4bac-b922-5d24877787a3 12/03/22 13:08:05.079
    STEP: Creating configMap with name cm-test-opt-upd-e9f0ae40-70f9-4747-b67c-cf391dafa164 12/03/22 13:08:05.087
    STEP: Creating the pod 12/03/22 13:08:05.093
    Dec  3 13:08:05.107: INFO: Waiting up to 5m0s for pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2" in namespace "configmap-3291" to be "running and ready"
    Dec  3 13:08:05.116: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.403336ms
    Dec  3 13:08:05.116: INFO: The phase of Pod pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:08:07.122: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015641344s
    Dec  3 13:08:07.123: INFO: The phase of Pod pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2 is Running (Ready = true)
    Dec  3 13:08:07.123: INFO: Pod "pod-configmaps-4aefeb5b-8537-4417-b620-bb396fde35e2" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-e74cb3a2-1a00-4bac-b922-5d24877787a3 12/03/22 13:08:07.157
    STEP: Updating configmap cm-test-opt-upd-e9f0ae40-70f9-4747-b67c-cf391dafa164 12/03/22 13:08:07.167
    STEP: Creating configMap with name cm-test-opt-create-940324cd-1a02-4c1d-b662-29df2dd92e4f 12/03/22 13:08:07.174
    STEP: waiting to observe update in volume 12/03/22 13:08:07.186
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:08:09.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3291" for this suite. 12/03/22 13:08:09.231
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:09.244
Dec  3 13:08:09.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:08:09.245
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:09.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:09.278
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Dec  3 13:08:09.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 13:08:11.899
Dec  3 13:08:11.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 create -f -'
Dec  3 13:08:12.495: INFO: stderr: ""
Dec  3 13:08:12.495: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 13:08:12.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 delete e2e-test-crd-publish-openapi-7524-crds test-cr'
Dec  3 13:08:12.591: INFO: stderr: ""
Dec  3 13:08:12.591: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec  3 13:08:12.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 apply -f -'
Dec  3 13:08:12.787: INFO: stderr: ""
Dec  3 13:08:12.787: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 13:08:12.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 delete e2e-test-crd-publish-openapi-7524-crds test-cr'
Dec  3 13:08:12.861: INFO: stderr: ""
Dec  3 13:08:12.861: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 12/03/22 13:08:12.861
Dec  3 13:08:12.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 explain e2e-test-crd-publish-openapi-7524-crds'
Dec  3 13:08:13.391: INFO: stderr: ""
Dec  3 13:08:13.391: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7524-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:08:15.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-992" for this suite. 12/03/22 13:08:15.789
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":208,"skipped":4066,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.552 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:09.244
    Dec  3 13:08:09.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:08:09.245
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:09.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:09.278
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Dec  3 13:08:09.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/03/22 13:08:11.899
    Dec  3 13:08:11.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 create -f -'
    Dec  3 13:08:12.495: INFO: stderr: ""
    Dec  3 13:08:12.495: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec  3 13:08:12.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 delete e2e-test-crd-publish-openapi-7524-crds test-cr'
    Dec  3 13:08:12.591: INFO: stderr: ""
    Dec  3 13:08:12.591: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Dec  3 13:08:12.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 apply -f -'
    Dec  3 13:08:12.787: INFO: stderr: ""
    Dec  3 13:08:12.787: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec  3 13:08:12.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 --namespace=crd-publish-openapi-992 delete e2e-test-crd-publish-openapi-7524-crds test-cr'
    Dec  3 13:08:12.861: INFO: stderr: ""
    Dec  3 13:08:12.861: INFO: stdout: "e2e-test-crd-publish-openapi-7524-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 12/03/22 13:08:12.861
    Dec  3 13:08:12.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=crd-publish-openapi-992 explain e2e-test-crd-publish-openapi-7524-crds'
    Dec  3 13:08:13.391: INFO: stderr: ""
    Dec  3 13:08:13.391: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7524-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:08:15.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-992" for this suite. 12/03/22 13:08:15.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:15.797
Dec  3 13:08:15.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:08:15.798
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:15.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:15.821
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:08:15.825
Dec  3 13:08:15.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b" in namespace "projected-4637" to be "Succeeded or Failed"
Dec  3 13:08:15.839: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.188388ms
Dec  3 13:08:17.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010297566s
Dec  3 13:08:19.845: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009403518s
Dec  3 13:08:21.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010654376s
STEP: Saw pod success 12/03/22 13:08:21.846
Dec  3 13:08:21.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b" satisfied condition "Succeeded or Failed"
Dec  3 13:08:21.850: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b container client-container: <nil>
STEP: delete the pod 12/03/22 13:08:21.865
Dec  3 13:08:21.877: INFO: Waiting for pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b to disappear
Dec  3 13:08:21.881: INFO: Pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:08:21.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4637" for this suite. 12/03/22 13:08:21.886
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":209,"skipped":4072,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.097 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:15.797
    Dec  3 13:08:15.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:08:15.798
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:15.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:15.821
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:08:15.825
    Dec  3 13:08:15.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b" in namespace "projected-4637" to be "Succeeded or Failed"
    Dec  3 13:08:15.839: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.188388ms
    Dec  3 13:08:17.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010297566s
    Dec  3 13:08:19.845: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009403518s
    Dec  3 13:08:21.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010654376s
    STEP: Saw pod success 12/03/22 13:08:21.846
    Dec  3 13:08:21.846: INFO: Pod "downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b" satisfied condition "Succeeded or Failed"
    Dec  3 13:08:21.850: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b container client-container: <nil>
    STEP: delete the pod 12/03/22 13:08:21.865
    Dec  3 13:08:21.877: INFO: Waiting for pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b to disappear
    Dec  3 13:08:21.881: INFO: Pod downwardapi-volume-278f109d-9c8b-4da7-b4eb-81cecb7fc45b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:08:21.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4637" for this suite. 12/03/22 13:08:21.886
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:21.897
Dec  3 13:08:21.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 13:08:21.898
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:21.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:21.92
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:08:21.945
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:08:21.954
Dec  3 13:08:21.957: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:21.958: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:21.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:08:21.961: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:08:22.967: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:22.967: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:22.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:08:22.971: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:08:23.967: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:23.967: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:23.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:08:23.970: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 12/03/22 13:08:23.973
Dec  3 13:08:23.992: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:23.992: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:24.007: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:08:24.007: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 13:08:25.014: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:25.014: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:25.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:08:25.017: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 13:08:26.013: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:26.013: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:26.018: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:08:26.018: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 13:08:27.012: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:27.013: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:27.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec  3 13:08:27.016: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
Dec  3 13:08:28.016: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:28.016: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:08:28.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:08:28.022: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:08:28.027
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9184, will wait for the garbage collector to delete the pods 12/03/22 13:08:28.027
Dec  3 13:08:28.089: INFO: Deleting DaemonSet.extensions daemon-set took: 7.603196ms
Dec  3 13:08:28.190: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.43768ms
Dec  3 13:08:30.894: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:08:30.894: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 13:08:30.898: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27285"},"items":null}

Dec  3 13:08:30.903: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27285"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:08:30.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9184" for this suite. 12/03/22 13:08:30.921
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":210,"skipped":4085,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.033 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:21.897
    Dec  3 13:08:21.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 13:08:21.898
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:21.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:21.92
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:08:21.945
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:08:21.954
    Dec  3 13:08:21.957: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:21.958: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:21.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:08:21.961: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:08:22.967: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:22.967: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:22.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:08:22.971: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:08:23.967: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:23.967: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:23.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:08:23.970: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 12/03/22 13:08:23.973
    Dec  3 13:08:23.992: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:23.992: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:24.007: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:08:24.007: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 13:08:25.014: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:25.014: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:25.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:08:25.017: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 13:08:26.013: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:26.013: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:26.018: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:08:26.018: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 13:08:27.012: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:27.013: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:27.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec  3 13:08:27.016: INFO: Node ip-172-31-4-162 is running 0 daemon pod, expected 1
    Dec  3 13:08:28.016: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:28.016: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:08:28.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:08:28.022: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:08:28.027
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9184, will wait for the garbage collector to delete the pods 12/03/22 13:08:28.027
    Dec  3 13:08:28.089: INFO: Deleting DaemonSet.extensions daemon-set took: 7.603196ms
    Dec  3 13:08:28.190: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.43768ms
    Dec  3 13:08:30.894: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:08:30.894: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 13:08:30.898: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27285"},"items":null}

    Dec  3 13:08:30.903: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27285"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:08:30.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9184" for this suite. 12/03/22 13:08:30.921
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:30.931
Dec  3 13:08:30.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename proxy 12/03/22 13:08:30.932
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:30.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:30.96
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Dec  3 13:08:30.964: INFO: Creating pod...
Dec  3 13:08:30.974: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-8383" to be "running"
Dec  3 13:08:30.977: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951972ms
Dec  3 13:08:32.982: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.007915148s
Dec  3 13:08:32.982: INFO: Pod "agnhost" satisfied condition "running"
Dec  3 13:08:32.982: INFO: Creating service...
Dec  3 13:08:32.997: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/DELETE
Dec  3 13:08:33.007: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec  3 13:08:33.007: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/GET
Dec  3 13:08:33.013: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec  3 13:08:33.013: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/HEAD
Dec  3 13:08:33.019: INFO: http.Client request:HEAD | StatusCode:200
Dec  3 13:08:33.019: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/OPTIONS
Dec  3 13:08:33.026: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec  3 13:08:33.026: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/PATCH
Dec  3 13:08:33.033: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec  3 13:08:33.033: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/POST
Dec  3 13:08:33.039: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec  3 13:08:33.039: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/PUT
Dec  3 13:08:33.044: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec  3 13:08:33.044: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/DELETE
Dec  3 13:08:33.054: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec  3 13:08:33.054: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/GET
Dec  3 13:08:33.063: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec  3 13:08:33.063: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/HEAD
Dec  3 13:08:33.082: INFO: http.Client request:HEAD | StatusCode:200
Dec  3 13:08:33.082: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/OPTIONS
Dec  3 13:08:33.092: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec  3 13:08:33.092: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/PATCH
Dec  3 13:08:33.099: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec  3 13:08:33.099: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/POST
Dec  3 13:08:33.105: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec  3 13:08:33.105: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/PUT
Dec  3 13:08:33.112: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec  3 13:08:33.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8383" for this suite. 12/03/22 13:08:33.125
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":211,"skipped":4086,"failed":0}
------------------------------
â€¢ [2.205 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:30.931
    Dec  3 13:08:30.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename proxy 12/03/22 13:08:30.932
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:30.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:30.96
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Dec  3 13:08:30.964: INFO: Creating pod...
    Dec  3 13:08:30.974: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-8383" to be "running"
    Dec  3 13:08:30.977: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951972ms
    Dec  3 13:08:32.982: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.007915148s
    Dec  3 13:08:32.982: INFO: Pod "agnhost" satisfied condition "running"
    Dec  3 13:08:32.982: INFO: Creating service...
    Dec  3 13:08:32.997: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/DELETE
    Dec  3 13:08:33.007: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec  3 13:08:33.007: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/GET
    Dec  3 13:08:33.013: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec  3 13:08:33.013: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/HEAD
    Dec  3 13:08:33.019: INFO: http.Client request:HEAD | StatusCode:200
    Dec  3 13:08:33.019: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/OPTIONS
    Dec  3 13:08:33.026: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec  3 13:08:33.026: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/PATCH
    Dec  3 13:08:33.033: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec  3 13:08:33.033: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/POST
    Dec  3 13:08:33.039: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec  3 13:08:33.039: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/pods/agnhost/proxy/some/path/with/PUT
    Dec  3 13:08:33.044: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec  3 13:08:33.044: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/DELETE
    Dec  3 13:08:33.054: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec  3 13:08:33.054: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/GET
    Dec  3 13:08:33.063: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec  3 13:08:33.063: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/HEAD
    Dec  3 13:08:33.082: INFO: http.Client request:HEAD | StatusCode:200
    Dec  3 13:08:33.082: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/OPTIONS
    Dec  3 13:08:33.092: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec  3 13:08:33.092: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/PATCH
    Dec  3 13:08:33.099: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec  3 13:08:33.099: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/POST
    Dec  3 13:08:33.105: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec  3 13:08:33.105: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8383/services/test-service/proxy/some/path/with/PUT
    Dec  3 13:08:33.112: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec  3 13:08:33.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-8383" for this suite. 12/03/22 13:08:33.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:33.138
Dec  3 13:08:33.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:08:33.139
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:33.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:33.17
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-fa20c9d1-2b75-4bee-b201-36865f101c85 12/03/22 13:08:33.176
STEP: Creating a pod to test consume secrets 12/03/22 13:08:33.183
Dec  3 13:08:33.196: INFO: Waiting up to 5m0s for pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a" in namespace "secrets-6881" to be "Succeeded or Failed"
Dec  3 13:08:33.202: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.902058ms
Dec  3 13:08:35.207: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010798707s
Dec  3 13:08:37.208: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012306427s
STEP: Saw pod success 12/03/22 13:08:37.208
Dec  3 13:08:37.208: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a" satisfied condition "Succeeded or Failed"
Dec  3 13:08:37.213: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:08:37.221
Dec  3 13:08:37.236: INFO: Waiting for pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a to disappear
Dec  3 13:08:37.243: INFO: Pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:08:37.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6881" for this suite. 12/03/22 13:08:37.248
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":212,"skipped":4095,"failed":0}
------------------------------
â€¢ [4.116 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:33.138
    Dec  3 13:08:33.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:08:33.139
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:33.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:33.17
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-fa20c9d1-2b75-4bee-b201-36865f101c85 12/03/22 13:08:33.176
    STEP: Creating a pod to test consume secrets 12/03/22 13:08:33.183
    Dec  3 13:08:33.196: INFO: Waiting up to 5m0s for pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a" in namespace "secrets-6881" to be "Succeeded or Failed"
    Dec  3 13:08:33.202: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.902058ms
    Dec  3 13:08:35.207: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010798707s
    Dec  3 13:08:37.208: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012306427s
    STEP: Saw pod success 12/03/22 13:08:37.208
    Dec  3 13:08:37.208: INFO: Pod "pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a" satisfied condition "Succeeded or Failed"
    Dec  3 13:08:37.213: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:08:37.221
    Dec  3 13:08:37.236: INFO: Waiting for pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a to disappear
    Dec  3 13:08:37.243: INFO: Pod pod-secrets-722ae1f9-ce4b-40b8-8df6-4b7a9cd9116a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:08:37.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6881" for this suite. 12/03/22 13:08:37.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:37.254
Dec  3 13:08:37.255: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:08:37.256
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:37.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:37.29
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:08:37.294
Dec  3 13:08:37.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367" in namespace "projected-2997" to be "Succeeded or Failed"
Dec  3 13:08:37.324: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Pending", Reason="", readiness=false. Elapsed: 5.329244ms
Dec  3 13:08:39.333: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013989196s
Dec  3 13:08:41.329: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010434948s
STEP: Saw pod success 12/03/22 13:08:41.329
Dec  3 13:08:41.330: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367" satisfied condition "Succeeded or Failed"
Dec  3 13:08:41.334: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 container client-container: <nil>
STEP: delete the pod 12/03/22 13:08:41.343
Dec  3 13:08:41.358: INFO: Waiting for pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 to disappear
Dec  3 13:08:41.361: INFO: Pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:08:41.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2997" for this suite. 12/03/22 13:08:41.365
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":213,"skipped":4101,"failed":0}
------------------------------
â€¢ [4.118 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:37.254
    Dec  3 13:08:37.255: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:08:37.256
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:37.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:37.29
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:08:37.294
    Dec  3 13:08:37.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367" in namespace "projected-2997" to be "Succeeded or Failed"
    Dec  3 13:08:37.324: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Pending", Reason="", readiness=false. Elapsed: 5.329244ms
    Dec  3 13:08:39.333: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013989196s
    Dec  3 13:08:41.329: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010434948s
    STEP: Saw pod success 12/03/22 13:08:41.329
    Dec  3 13:08:41.330: INFO: Pod "downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367" satisfied condition "Succeeded or Failed"
    Dec  3 13:08:41.334: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:08:41.343
    Dec  3 13:08:41.358: INFO: Waiting for pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 to disappear
    Dec  3 13:08:41.361: INFO: Pod downwardapi-volume-41b0b11f-0813-497a-a9f0-2f67a57b4367 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:08:41.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2997" for this suite. 12/03/22 13:08:41.365
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:41.384
Dec  3 13:08:41.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:08:41.385
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:41.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:41.421
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-4260/configmap-test-03610d34-4c7b-47ea-acdd-4019e3332dbc 12/03/22 13:08:41.425
STEP: Creating a pod to test consume configMaps 12/03/22 13:08:41.434
Dec  3 13:08:41.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116" in namespace "configmap-4260" to be "Succeeded or Failed"
Dec  3 13:08:41.455: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Pending", Reason="", readiness=false. Elapsed: 7.596678ms
Dec  3 13:08:43.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013528758s
Dec  3 13:08:45.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012871535s
STEP: Saw pod success 12/03/22 13:08:45.461
Dec  3 13:08:45.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116" satisfied condition "Succeeded or Failed"
Dec  3 13:08:45.464: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 container env-test: <nil>
STEP: delete the pod 12/03/22 13:08:45.478
Dec  3 13:08:45.491: INFO: Waiting for pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 to disappear
Dec  3 13:08:45.495: INFO: Pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:08:45.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4260" for this suite. 12/03/22 13:08:45.499
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":214,"skipped":4118,"failed":0}
------------------------------
â€¢ [4.122 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:41.384
    Dec  3 13:08:41.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:08:41.385
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:41.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:41.421
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-4260/configmap-test-03610d34-4c7b-47ea-acdd-4019e3332dbc 12/03/22 13:08:41.425
    STEP: Creating a pod to test consume configMaps 12/03/22 13:08:41.434
    Dec  3 13:08:41.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116" in namespace "configmap-4260" to be "Succeeded or Failed"
    Dec  3 13:08:41.455: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Pending", Reason="", readiness=false. Elapsed: 7.596678ms
    Dec  3 13:08:43.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013528758s
    Dec  3 13:08:45.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012871535s
    STEP: Saw pod success 12/03/22 13:08:45.461
    Dec  3 13:08:45.461: INFO: Pod "pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116" satisfied condition "Succeeded or Failed"
    Dec  3 13:08:45.464: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 container env-test: <nil>
    STEP: delete the pod 12/03/22 13:08:45.478
    Dec  3 13:08:45.491: INFO: Waiting for pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 to disappear
    Dec  3 13:08:45.495: INFO: Pod pod-configmaps-a9c93a5c-f36a-4caa-ba53-086771cf4116 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:08:45.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4260" for this suite. 12/03/22 13:08:45.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:45.508
Dec  3 13:08:45.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 13:08:45.509
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:45.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:45.535
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 12/03/22 13:08:45.54
STEP: Creating a ResourceQuota 12/03/22 13:08:50.548
STEP: Ensuring resource quota status is calculated 12/03/22 13:08:50.555
STEP: Creating a ReplicationController 12/03/22 13:08:52.561
STEP: Ensuring resource quota status captures replication controller creation 12/03/22 13:08:52.576
STEP: Deleting a ReplicationController 12/03/22 13:08:54.58
STEP: Ensuring resource quota status released usage 12/03/22 13:08:54.586
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 13:08:56.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-43" for this suite. 12/03/22 13:08:56.597
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":215,"skipped":4138,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.096 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:45.508
    Dec  3 13:08:45.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 13:08:45.509
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:45.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:45.535
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 12/03/22 13:08:45.54
    STEP: Creating a ResourceQuota 12/03/22 13:08:50.548
    STEP: Ensuring resource quota status is calculated 12/03/22 13:08:50.555
    STEP: Creating a ReplicationController 12/03/22 13:08:52.561
    STEP: Ensuring resource quota status captures replication controller creation 12/03/22 13:08:52.576
    STEP: Deleting a ReplicationController 12/03/22 13:08:54.58
    STEP: Ensuring resource quota status released usage 12/03/22 13:08:54.586
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 13:08:56.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-43" for this suite. 12/03/22 13:08:56.597
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:08:56.606
Dec  3 13:08:56.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:08:56.607
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:56.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:56.637
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-7409cca7-4b2d-401e-9fc3-8d33751c4be8 12/03/22 13:08:56.641
STEP: Creating a pod to test consume configMaps 12/03/22 13:08:56.647
Dec  3 13:08:56.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9" in namespace "configmap-4412" to be "Succeeded or Failed"
Dec  3 13:08:56.663: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092429ms
Dec  3 13:08:58.670: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01092545s
Dec  3 13:09:00.669: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009657969s
STEP: Saw pod success 12/03/22 13:09:00.669
Dec  3 13:09:00.669: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9" satisfied condition "Succeeded or Failed"
Dec  3 13:09:00.678: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:09:00.693
Dec  3 13:09:00.703: INFO: Waiting for pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 to disappear
Dec  3 13:09:00.711: INFO: Pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:09:00.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4412" for this suite. 12/03/22 13:09:00.716
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":216,"skipped":4139,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:08:56.606
    Dec  3 13:08:56.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:08:56.607
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:08:56.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:08:56.637
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-7409cca7-4b2d-401e-9fc3-8d33751c4be8 12/03/22 13:08:56.641
    STEP: Creating a pod to test consume configMaps 12/03/22 13:08:56.647
    Dec  3 13:08:56.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9" in namespace "configmap-4412" to be "Succeeded or Failed"
    Dec  3 13:08:56.663: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092429ms
    Dec  3 13:08:58.670: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01092545s
    Dec  3 13:09:00.669: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009657969s
    STEP: Saw pod success 12/03/22 13:09:00.669
    Dec  3 13:09:00.669: INFO: Pod "pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9" satisfied condition "Succeeded or Failed"
    Dec  3 13:09:00.678: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:09:00.693
    Dec  3 13:09:00.703: INFO: Waiting for pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 to disappear
    Dec  3 13:09:00.711: INFO: Pod pod-configmaps-126931db-2af8-4481-a5c0-e91e39e5d0a9 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:09:00.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4412" for this suite. 12/03/22 13:09:00.716
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:09:00.725
Dec  3 13:09:00.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename conformance-tests 12/03/22 13:09:00.726
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:00.747
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:00.758
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 12/03/22 13:09:00.769
Dec  3 13:09:00.769: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Dec  3 13:09:00.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-2891" for this suite. 12/03/22 13:09:00.781
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":217,"skipped":4140,"failed":0}
------------------------------
â€¢ [0.066 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:09:00.725
    Dec  3 13:09:00.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename conformance-tests 12/03/22 13:09:00.726
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:00.747
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:00.758
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 12/03/22 13:09:00.769
    Dec  3 13:09:00.769: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Dec  3 13:09:00.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-2891" for this suite. 12/03/22 13:09:00.781
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:09:00.795
Dec  3 13:09:00.795: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 13:09:00.802
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:00.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:00.83
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 12/03/22 13:09:00.843
Dec  3 13:09:00.853: INFO: Waiting up to 5m0s for pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60" in namespace "var-expansion-5276" to be "Succeeded or Failed"
Dec  3 13:09:00.857: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 3.905868ms
Dec  3 13:09:02.864: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010430261s
Dec  3 13:09:04.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009869743s
Dec  3 13:09:06.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009895774s
STEP: Saw pod success 12/03/22 13:09:06.863
Dec  3 13:09:06.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60" satisfied condition "Succeeded or Failed"
Dec  3 13:09:06.867: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 container dapi-container: <nil>
STEP: delete the pod 12/03/22 13:09:06.878
Dec  3 13:09:06.893: INFO: Waiting for pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 to disappear
Dec  3 13:09:06.897: INFO: Pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 13:09:06.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5276" for this suite. 12/03/22 13:09:06.902
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":218,"skipped":4200,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.115 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:09:00.795
    Dec  3 13:09:00.795: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 13:09:00.802
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:00.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:00.83
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 12/03/22 13:09:00.843
    Dec  3 13:09:00.853: INFO: Waiting up to 5m0s for pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60" in namespace "var-expansion-5276" to be "Succeeded or Failed"
    Dec  3 13:09:00.857: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 3.905868ms
    Dec  3 13:09:02.864: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010430261s
    Dec  3 13:09:04.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009869743s
    Dec  3 13:09:06.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009895774s
    STEP: Saw pod success 12/03/22 13:09:06.863
    Dec  3 13:09:06.863: INFO: Pod "var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60" satisfied condition "Succeeded or Failed"
    Dec  3 13:09:06.867: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 13:09:06.878
    Dec  3 13:09:06.893: INFO: Waiting for pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 to disappear
    Dec  3 13:09:06.897: INFO: Pod var-expansion-09d64c57-b4b3-47a5-8070-fcba86ceaf60 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 13:09:06.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5276" for this suite. 12/03/22 13:09:06.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:09:06.913
Dec  3 13:09:06.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 13:09:06.914
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:06.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:06.945
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 12/03/22 13:09:06.953
STEP: delete the rc 12/03/22 13:09:11.965
STEP: wait for the rc to be deleted 12/03/22 13:09:11.973
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/03/22 13:09:16.977
STEP: Gathering metrics 12/03/22 13:09:46.991
W1203 13:09:46.997025      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 13:09:46.997: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec  3 13:09:46.997: INFO: Deleting pod "simpletest.rc-2dtsn" in namespace "gc-4599"
Dec  3 13:09:47.017: INFO: Deleting pod "simpletest.rc-2ldsx" in namespace "gc-4599"
Dec  3 13:09:47.034: INFO: Deleting pod "simpletest.rc-2lnzx" in namespace "gc-4599"
Dec  3 13:09:47.053: INFO: Deleting pod "simpletest.rc-2qbr8" in namespace "gc-4599"
Dec  3 13:09:47.089: INFO: Deleting pod "simpletest.rc-2tblx" in namespace "gc-4599"
Dec  3 13:09:47.118: INFO: Deleting pod "simpletest.rc-2zvqf" in namespace "gc-4599"
Dec  3 13:09:47.136: INFO: Deleting pod "simpletest.rc-47kh5" in namespace "gc-4599"
Dec  3 13:09:47.175: INFO: Deleting pod "simpletest.rc-4jtmr" in namespace "gc-4599"
Dec  3 13:09:47.193: INFO: Deleting pod "simpletest.rc-4nplm" in namespace "gc-4599"
Dec  3 13:09:47.208: INFO: Deleting pod "simpletest.rc-4vdpw" in namespace "gc-4599"
Dec  3 13:09:47.225: INFO: Deleting pod "simpletest.rc-56mk7" in namespace "gc-4599"
Dec  3 13:09:47.253: INFO: Deleting pod "simpletest.rc-5kdgq" in namespace "gc-4599"
Dec  3 13:09:47.266: INFO: Deleting pod "simpletest.rc-6f4hp" in namespace "gc-4599"
Dec  3 13:09:47.287: INFO: Deleting pod "simpletest.rc-6gmgq" in namespace "gc-4599"
Dec  3 13:09:47.300: INFO: Deleting pod "simpletest.rc-7fbxw" in namespace "gc-4599"
Dec  3 13:09:47.312: INFO: Deleting pod "simpletest.rc-7gkhb" in namespace "gc-4599"
Dec  3 13:09:47.325: INFO: Deleting pod "simpletest.rc-7qfb8" in namespace "gc-4599"
Dec  3 13:09:47.339: INFO: Deleting pod "simpletest.rc-858zt" in namespace "gc-4599"
Dec  3 13:09:47.352: INFO: Deleting pod "simpletest.rc-8lkgx" in namespace "gc-4599"
Dec  3 13:09:47.372: INFO: Deleting pod "simpletest.rc-8m79d" in namespace "gc-4599"
Dec  3 13:09:47.388: INFO: Deleting pod "simpletest.rc-8vlfr" in namespace "gc-4599"
Dec  3 13:09:47.401: INFO: Deleting pod "simpletest.rc-98xvm" in namespace "gc-4599"
Dec  3 13:09:47.414: INFO: Deleting pod "simpletest.rc-99klg" in namespace "gc-4599"
Dec  3 13:09:47.424: INFO: Deleting pod "simpletest.rc-9c9pb" in namespace "gc-4599"
Dec  3 13:09:47.439: INFO: Deleting pod "simpletest.rc-9gwtw" in namespace "gc-4599"
Dec  3 13:09:47.455: INFO: Deleting pod "simpletest.rc-9vwr5" in namespace "gc-4599"
Dec  3 13:09:47.469: INFO: Deleting pod "simpletest.rc-c6cnn" in namespace "gc-4599"
Dec  3 13:09:47.482: INFO: Deleting pod "simpletest.rc-c8tgc" in namespace "gc-4599"
Dec  3 13:09:47.497: INFO: Deleting pod "simpletest.rc-cqrfp" in namespace "gc-4599"
Dec  3 13:09:47.511: INFO: Deleting pod "simpletest.rc-dcjsw" in namespace "gc-4599"
Dec  3 13:09:47.525: INFO: Deleting pod "simpletest.rc-dpjxs" in namespace "gc-4599"
Dec  3 13:09:47.540: INFO: Deleting pod "simpletest.rc-f4bzx" in namespace "gc-4599"
Dec  3 13:09:47.565: INFO: Deleting pod "simpletest.rc-f5wkj" in namespace "gc-4599"
Dec  3 13:09:47.586: INFO: Deleting pod "simpletest.rc-ffrjt" in namespace "gc-4599"
Dec  3 13:09:47.604: INFO: Deleting pod "simpletest.rc-fmbqd" in namespace "gc-4599"
Dec  3 13:09:47.618: INFO: Deleting pod "simpletest.rc-fqccf" in namespace "gc-4599"
Dec  3 13:09:47.632: INFO: Deleting pod "simpletest.rc-fr9hq" in namespace "gc-4599"
Dec  3 13:09:47.643: INFO: Deleting pod "simpletest.rc-fs6v5" in namespace "gc-4599"
Dec  3 13:09:47.655: INFO: Deleting pod "simpletest.rc-g6fhw" in namespace "gc-4599"
Dec  3 13:09:47.669: INFO: Deleting pod "simpletest.rc-gbdtt" in namespace "gc-4599"
Dec  3 13:09:47.687: INFO: Deleting pod "simpletest.rc-gdx44" in namespace "gc-4599"
Dec  3 13:09:47.698: INFO: Deleting pod "simpletest.rc-hdwqb" in namespace "gc-4599"
Dec  3 13:09:47.709: INFO: Deleting pod "simpletest.rc-hh6rd" in namespace "gc-4599"
Dec  3 13:09:47.720: INFO: Deleting pod "simpletest.rc-hlsmm" in namespace "gc-4599"
Dec  3 13:09:47.732: INFO: Deleting pod "simpletest.rc-jlx9l" in namespace "gc-4599"
Dec  3 13:09:47.764: INFO: Deleting pod "simpletest.rc-jz6mn" in namespace "gc-4599"
Dec  3 13:09:47.777: INFO: Deleting pod "simpletest.rc-ktflh" in namespace "gc-4599"
Dec  3 13:09:47.788: INFO: Deleting pod "simpletest.rc-kztr7" in namespace "gc-4599"
Dec  3 13:09:47.807: INFO: Deleting pod "simpletest.rc-lwvb6" in namespace "gc-4599"
Dec  3 13:09:47.821: INFO: Deleting pod "simpletest.rc-m756z" in namespace "gc-4599"
Dec  3 13:09:47.835: INFO: Deleting pod "simpletest.rc-mbpmp" in namespace "gc-4599"
Dec  3 13:09:47.850: INFO: Deleting pod "simpletest.rc-mw5qs" in namespace "gc-4599"
Dec  3 13:09:47.861: INFO: Deleting pod "simpletest.rc-nc9rm" in namespace "gc-4599"
Dec  3 13:09:47.874: INFO: Deleting pod "simpletest.rc-nd46x" in namespace "gc-4599"
Dec  3 13:09:47.971: INFO: Deleting pod "simpletest.rc-nfcfn" in namespace "gc-4599"
Dec  3 13:09:47.982: INFO: Deleting pod "simpletest.rc-nhqlt" in namespace "gc-4599"
Dec  3 13:09:47.994: INFO: Deleting pod "simpletest.rc-nk22w" in namespace "gc-4599"
Dec  3 13:09:48.008: INFO: Deleting pod "simpletest.rc-nkkk9" in namespace "gc-4599"
Dec  3 13:09:48.021: INFO: Deleting pod "simpletest.rc-nkwzh" in namespace "gc-4599"
Dec  3 13:09:48.031: INFO: Deleting pod "simpletest.rc-ntpkx" in namespace "gc-4599"
Dec  3 13:09:48.042: INFO: Deleting pod "simpletest.rc-p94dg" in namespace "gc-4599"
Dec  3 13:09:48.056: INFO: Deleting pod "simpletest.rc-p9npg" in namespace "gc-4599"
Dec  3 13:09:48.070: INFO: Deleting pod "simpletest.rc-pbhw6" in namespace "gc-4599"
Dec  3 13:09:48.081: INFO: Deleting pod "simpletest.rc-pmrwl" in namespace "gc-4599"
Dec  3 13:09:48.093: INFO: Deleting pod "simpletest.rc-q45zv" in namespace "gc-4599"
Dec  3 13:09:48.104: INFO: Deleting pod "simpletest.rc-qlq68" in namespace "gc-4599"
Dec  3 13:09:48.118: INFO: Deleting pod "simpletest.rc-qnjh5" in namespace "gc-4599"
Dec  3 13:09:48.130: INFO: Deleting pod "simpletest.rc-qsx6f" in namespace "gc-4599"
Dec  3 13:09:48.141: INFO: Deleting pod "simpletest.rc-rgnrl" in namespace "gc-4599"
Dec  3 13:09:48.154: INFO: Deleting pod "simpletest.rc-rmjph" in namespace "gc-4599"
Dec  3 13:09:48.165: INFO: Deleting pod "simpletest.rc-rq584" in namespace "gc-4599"
Dec  3 13:09:48.177: INFO: Deleting pod "simpletest.rc-s6drp" in namespace "gc-4599"
Dec  3 13:09:48.191: INFO: Deleting pod "simpletest.rc-s6rqc" in namespace "gc-4599"
Dec  3 13:09:48.241: INFO: Deleting pod "simpletest.rc-sg4xx" in namespace "gc-4599"
Dec  3 13:09:48.291: INFO: Deleting pod "simpletest.rc-sqtqf" in namespace "gc-4599"
Dec  3 13:09:48.342: INFO: Deleting pod "simpletest.rc-tpswf" in namespace "gc-4599"
Dec  3 13:09:48.394: INFO: Deleting pod "simpletest.rc-v6528" in namespace "gc-4599"
Dec  3 13:09:48.440: INFO: Deleting pod "simpletest.rc-vfdmv" in namespace "gc-4599"
Dec  3 13:09:48.489: INFO: Deleting pod "simpletest.rc-vllxn" in namespace "gc-4599"
Dec  3 13:09:48.543: INFO: Deleting pod "simpletest.rc-vpnnl" in namespace "gc-4599"
Dec  3 13:09:48.591: INFO: Deleting pod "simpletest.rc-vvmbq" in namespace "gc-4599"
Dec  3 13:09:48.643: INFO: Deleting pod "simpletest.rc-w2x5k" in namespace "gc-4599"
Dec  3 13:09:48.691: INFO: Deleting pod "simpletest.rc-w4tvp" in namespace "gc-4599"
Dec  3 13:09:48.741: INFO: Deleting pod "simpletest.rc-whjzs" in namespace "gc-4599"
Dec  3 13:09:48.791: INFO: Deleting pod "simpletest.rc-wqv5m" in namespace "gc-4599"
Dec  3 13:09:48.844: INFO: Deleting pod "simpletest.rc-wwk75" in namespace "gc-4599"
Dec  3 13:09:48.890: INFO: Deleting pod "simpletest.rc-wzs4f" in namespace "gc-4599"
Dec  3 13:09:48.941: INFO: Deleting pod "simpletest.rc-x6sbh" in namespace "gc-4599"
Dec  3 13:09:48.993: INFO: Deleting pod "simpletest.rc-x75dd" in namespace "gc-4599"
Dec  3 13:09:49.047: INFO: Deleting pod "simpletest.rc-x8sjt" in namespace "gc-4599"
Dec  3 13:09:49.093: INFO: Deleting pod "simpletest.rc-x96bc" in namespace "gc-4599"
Dec  3 13:09:49.142: INFO: Deleting pod "simpletest.rc-xc2rj" in namespace "gc-4599"
Dec  3 13:09:49.191: INFO: Deleting pod "simpletest.rc-xsrkx" in namespace "gc-4599"
Dec  3 13:09:49.246: INFO: Deleting pod "simpletest.rc-xv5dt" in namespace "gc-4599"
Dec  3 13:09:49.290: INFO: Deleting pod "simpletest.rc-xws48" in namespace "gc-4599"
Dec  3 13:09:49.340: INFO: Deleting pod "simpletest.rc-z4k8p" in namespace "gc-4599"
Dec  3 13:09:49.392: INFO: Deleting pod "simpletest.rc-z57kc" in namespace "gc-4599"
Dec  3 13:09:49.443: INFO: Deleting pod "simpletest.rc-z7978" in namespace "gc-4599"
Dec  3 13:09:49.494: INFO: Deleting pod "simpletest.rc-zpls6" in namespace "gc-4599"
Dec  3 13:09:49.542: INFO: Deleting pod "simpletest.rc-zst5b" in namespace "gc-4599"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 13:09:49.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4599" for this suite. 12/03/22 13:09:49.635
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":219,"skipped":4213,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.772 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:09:06.913
    Dec  3 13:09:06.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 13:09:06.914
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:06.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:06.945
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 12/03/22 13:09:06.953
    STEP: delete the rc 12/03/22 13:09:11.965
    STEP: wait for the rc to be deleted 12/03/22 13:09:11.973
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/03/22 13:09:16.977
    STEP: Gathering metrics 12/03/22 13:09:46.991
    W1203 13:09:46.997025      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 13:09:46.997: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec  3 13:09:46.997: INFO: Deleting pod "simpletest.rc-2dtsn" in namespace "gc-4599"
    Dec  3 13:09:47.017: INFO: Deleting pod "simpletest.rc-2ldsx" in namespace "gc-4599"
    Dec  3 13:09:47.034: INFO: Deleting pod "simpletest.rc-2lnzx" in namespace "gc-4599"
    Dec  3 13:09:47.053: INFO: Deleting pod "simpletest.rc-2qbr8" in namespace "gc-4599"
    Dec  3 13:09:47.089: INFO: Deleting pod "simpletest.rc-2tblx" in namespace "gc-4599"
    Dec  3 13:09:47.118: INFO: Deleting pod "simpletest.rc-2zvqf" in namespace "gc-4599"
    Dec  3 13:09:47.136: INFO: Deleting pod "simpletest.rc-47kh5" in namespace "gc-4599"
    Dec  3 13:09:47.175: INFO: Deleting pod "simpletest.rc-4jtmr" in namespace "gc-4599"
    Dec  3 13:09:47.193: INFO: Deleting pod "simpletest.rc-4nplm" in namespace "gc-4599"
    Dec  3 13:09:47.208: INFO: Deleting pod "simpletest.rc-4vdpw" in namespace "gc-4599"
    Dec  3 13:09:47.225: INFO: Deleting pod "simpletest.rc-56mk7" in namespace "gc-4599"
    Dec  3 13:09:47.253: INFO: Deleting pod "simpletest.rc-5kdgq" in namespace "gc-4599"
    Dec  3 13:09:47.266: INFO: Deleting pod "simpletest.rc-6f4hp" in namespace "gc-4599"
    Dec  3 13:09:47.287: INFO: Deleting pod "simpletest.rc-6gmgq" in namespace "gc-4599"
    Dec  3 13:09:47.300: INFO: Deleting pod "simpletest.rc-7fbxw" in namespace "gc-4599"
    Dec  3 13:09:47.312: INFO: Deleting pod "simpletest.rc-7gkhb" in namespace "gc-4599"
    Dec  3 13:09:47.325: INFO: Deleting pod "simpletest.rc-7qfb8" in namespace "gc-4599"
    Dec  3 13:09:47.339: INFO: Deleting pod "simpletest.rc-858zt" in namespace "gc-4599"
    Dec  3 13:09:47.352: INFO: Deleting pod "simpletest.rc-8lkgx" in namespace "gc-4599"
    Dec  3 13:09:47.372: INFO: Deleting pod "simpletest.rc-8m79d" in namespace "gc-4599"
    Dec  3 13:09:47.388: INFO: Deleting pod "simpletest.rc-8vlfr" in namespace "gc-4599"
    Dec  3 13:09:47.401: INFO: Deleting pod "simpletest.rc-98xvm" in namespace "gc-4599"
    Dec  3 13:09:47.414: INFO: Deleting pod "simpletest.rc-99klg" in namespace "gc-4599"
    Dec  3 13:09:47.424: INFO: Deleting pod "simpletest.rc-9c9pb" in namespace "gc-4599"
    Dec  3 13:09:47.439: INFO: Deleting pod "simpletest.rc-9gwtw" in namespace "gc-4599"
    Dec  3 13:09:47.455: INFO: Deleting pod "simpletest.rc-9vwr5" in namespace "gc-4599"
    Dec  3 13:09:47.469: INFO: Deleting pod "simpletest.rc-c6cnn" in namespace "gc-4599"
    Dec  3 13:09:47.482: INFO: Deleting pod "simpletest.rc-c8tgc" in namespace "gc-4599"
    Dec  3 13:09:47.497: INFO: Deleting pod "simpletest.rc-cqrfp" in namespace "gc-4599"
    Dec  3 13:09:47.511: INFO: Deleting pod "simpletest.rc-dcjsw" in namespace "gc-4599"
    Dec  3 13:09:47.525: INFO: Deleting pod "simpletest.rc-dpjxs" in namespace "gc-4599"
    Dec  3 13:09:47.540: INFO: Deleting pod "simpletest.rc-f4bzx" in namespace "gc-4599"
    Dec  3 13:09:47.565: INFO: Deleting pod "simpletest.rc-f5wkj" in namespace "gc-4599"
    Dec  3 13:09:47.586: INFO: Deleting pod "simpletest.rc-ffrjt" in namespace "gc-4599"
    Dec  3 13:09:47.604: INFO: Deleting pod "simpletest.rc-fmbqd" in namespace "gc-4599"
    Dec  3 13:09:47.618: INFO: Deleting pod "simpletest.rc-fqccf" in namespace "gc-4599"
    Dec  3 13:09:47.632: INFO: Deleting pod "simpletest.rc-fr9hq" in namespace "gc-4599"
    Dec  3 13:09:47.643: INFO: Deleting pod "simpletest.rc-fs6v5" in namespace "gc-4599"
    Dec  3 13:09:47.655: INFO: Deleting pod "simpletest.rc-g6fhw" in namespace "gc-4599"
    Dec  3 13:09:47.669: INFO: Deleting pod "simpletest.rc-gbdtt" in namespace "gc-4599"
    Dec  3 13:09:47.687: INFO: Deleting pod "simpletest.rc-gdx44" in namespace "gc-4599"
    Dec  3 13:09:47.698: INFO: Deleting pod "simpletest.rc-hdwqb" in namespace "gc-4599"
    Dec  3 13:09:47.709: INFO: Deleting pod "simpletest.rc-hh6rd" in namespace "gc-4599"
    Dec  3 13:09:47.720: INFO: Deleting pod "simpletest.rc-hlsmm" in namespace "gc-4599"
    Dec  3 13:09:47.732: INFO: Deleting pod "simpletest.rc-jlx9l" in namespace "gc-4599"
    Dec  3 13:09:47.764: INFO: Deleting pod "simpletest.rc-jz6mn" in namespace "gc-4599"
    Dec  3 13:09:47.777: INFO: Deleting pod "simpletest.rc-ktflh" in namespace "gc-4599"
    Dec  3 13:09:47.788: INFO: Deleting pod "simpletest.rc-kztr7" in namespace "gc-4599"
    Dec  3 13:09:47.807: INFO: Deleting pod "simpletest.rc-lwvb6" in namespace "gc-4599"
    Dec  3 13:09:47.821: INFO: Deleting pod "simpletest.rc-m756z" in namespace "gc-4599"
    Dec  3 13:09:47.835: INFO: Deleting pod "simpletest.rc-mbpmp" in namespace "gc-4599"
    Dec  3 13:09:47.850: INFO: Deleting pod "simpletest.rc-mw5qs" in namespace "gc-4599"
    Dec  3 13:09:47.861: INFO: Deleting pod "simpletest.rc-nc9rm" in namespace "gc-4599"
    Dec  3 13:09:47.874: INFO: Deleting pod "simpletest.rc-nd46x" in namespace "gc-4599"
    Dec  3 13:09:47.971: INFO: Deleting pod "simpletest.rc-nfcfn" in namespace "gc-4599"
    Dec  3 13:09:47.982: INFO: Deleting pod "simpletest.rc-nhqlt" in namespace "gc-4599"
    Dec  3 13:09:47.994: INFO: Deleting pod "simpletest.rc-nk22w" in namespace "gc-4599"
    Dec  3 13:09:48.008: INFO: Deleting pod "simpletest.rc-nkkk9" in namespace "gc-4599"
    Dec  3 13:09:48.021: INFO: Deleting pod "simpletest.rc-nkwzh" in namespace "gc-4599"
    Dec  3 13:09:48.031: INFO: Deleting pod "simpletest.rc-ntpkx" in namespace "gc-4599"
    Dec  3 13:09:48.042: INFO: Deleting pod "simpletest.rc-p94dg" in namespace "gc-4599"
    Dec  3 13:09:48.056: INFO: Deleting pod "simpletest.rc-p9npg" in namespace "gc-4599"
    Dec  3 13:09:48.070: INFO: Deleting pod "simpletest.rc-pbhw6" in namespace "gc-4599"
    Dec  3 13:09:48.081: INFO: Deleting pod "simpletest.rc-pmrwl" in namespace "gc-4599"
    Dec  3 13:09:48.093: INFO: Deleting pod "simpletest.rc-q45zv" in namespace "gc-4599"
    Dec  3 13:09:48.104: INFO: Deleting pod "simpletest.rc-qlq68" in namespace "gc-4599"
    Dec  3 13:09:48.118: INFO: Deleting pod "simpletest.rc-qnjh5" in namespace "gc-4599"
    Dec  3 13:09:48.130: INFO: Deleting pod "simpletest.rc-qsx6f" in namespace "gc-4599"
    Dec  3 13:09:48.141: INFO: Deleting pod "simpletest.rc-rgnrl" in namespace "gc-4599"
    Dec  3 13:09:48.154: INFO: Deleting pod "simpletest.rc-rmjph" in namespace "gc-4599"
    Dec  3 13:09:48.165: INFO: Deleting pod "simpletest.rc-rq584" in namespace "gc-4599"
    Dec  3 13:09:48.177: INFO: Deleting pod "simpletest.rc-s6drp" in namespace "gc-4599"
    Dec  3 13:09:48.191: INFO: Deleting pod "simpletest.rc-s6rqc" in namespace "gc-4599"
    Dec  3 13:09:48.241: INFO: Deleting pod "simpletest.rc-sg4xx" in namespace "gc-4599"
    Dec  3 13:09:48.291: INFO: Deleting pod "simpletest.rc-sqtqf" in namespace "gc-4599"
    Dec  3 13:09:48.342: INFO: Deleting pod "simpletest.rc-tpswf" in namespace "gc-4599"
    Dec  3 13:09:48.394: INFO: Deleting pod "simpletest.rc-v6528" in namespace "gc-4599"
    Dec  3 13:09:48.440: INFO: Deleting pod "simpletest.rc-vfdmv" in namespace "gc-4599"
    Dec  3 13:09:48.489: INFO: Deleting pod "simpletest.rc-vllxn" in namespace "gc-4599"
    Dec  3 13:09:48.543: INFO: Deleting pod "simpletest.rc-vpnnl" in namespace "gc-4599"
    Dec  3 13:09:48.591: INFO: Deleting pod "simpletest.rc-vvmbq" in namespace "gc-4599"
    Dec  3 13:09:48.643: INFO: Deleting pod "simpletest.rc-w2x5k" in namespace "gc-4599"
    Dec  3 13:09:48.691: INFO: Deleting pod "simpletest.rc-w4tvp" in namespace "gc-4599"
    Dec  3 13:09:48.741: INFO: Deleting pod "simpletest.rc-whjzs" in namespace "gc-4599"
    Dec  3 13:09:48.791: INFO: Deleting pod "simpletest.rc-wqv5m" in namespace "gc-4599"
    Dec  3 13:09:48.844: INFO: Deleting pod "simpletest.rc-wwk75" in namespace "gc-4599"
    Dec  3 13:09:48.890: INFO: Deleting pod "simpletest.rc-wzs4f" in namespace "gc-4599"
    Dec  3 13:09:48.941: INFO: Deleting pod "simpletest.rc-x6sbh" in namespace "gc-4599"
    Dec  3 13:09:48.993: INFO: Deleting pod "simpletest.rc-x75dd" in namespace "gc-4599"
    Dec  3 13:09:49.047: INFO: Deleting pod "simpletest.rc-x8sjt" in namespace "gc-4599"
    Dec  3 13:09:49.093: INFO: Deleting pod "simpletest.rc-x96bc" in namespace "gc-4599"
    Dec  3 13:09:49.142: INFO: Deleting pod "simpletest.rc-xc2rj" in namespace "gc-4599"
    Dec  3 13:09:49.191: INFO: Deleting pod "simpletest.rc-xsrkx" in namespace "gc-4599"
    Dec  3 13:09:49.246: INFO: Deleting pod "simpletest.rc-xv5dt" in namespace "gc-4599"
    Dec  3 13:09:49.290: INFO: Deleting pod "simpletest.rc-xws48" in namespace "gc-4599"
    Dec  3 13:09:49.340: INFO: Deleting pod "simpletest.rc-z4k8p" in namespace "gc-4599"
    Dec  3 13:09:49.392: INFO: Deleting pod "simpletest.rc-z57kc" in namespace "gc-4599"
    Dec  3 13:09:49.443: INFO: Deleting pod "simpletest.rc-z7978" in namespace "gc-4599"
    Dec  3 13:09:49.494: INFO: Deleting pod "simpletest.rc-zpls6" in namespace "gc-4599"
    Dec  3 13:09:49.542: INFO: Deleting pod "simpletest.rc-zst5b" in namespace "gc-4599"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 13:09:49.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4599" for this suite. 12/03/22 13:09:49.635
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:09:49.688
Dec  3 13:09:49.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:09:49.69
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:49.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:49.713
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 12/03/22 13:09:49.726
Dec  3 13:09:49.726: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed" in namespace "kubelet-test-5415" to be "completed"
Dec  3 13:09:49.731: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497259ms
Dec  3 13:09:51.738: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012079512s
Dec  3 13:09:53.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010167895s
Dec  3 13:09:55.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011397016s
Dec  3 13:09:57.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Running", Reason="", readiness=true. Elapsed: 8.010758081s
Dec  3 13:09:59.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Running", Reason="", readiness=true. Elapsed: 10.010503935s
Dec  3 13:10:01.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.010196829s
Dec  3 13:10:01.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec  3 13:10:01.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5415" for this suite. 12/03/22 13:10:01.756
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":220,"skipped":4228,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.078 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:09:49.688
    Dec  3 13:09:49.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:09:49.69
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:09:49.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:09:49.713
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 12/03/22 13:09:49.726
    Dec  3 13:09:49.726: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed" in namespace "kubelet-test-5415" to be "completed"
    Dec  3 13:09:49.731: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497259ms
    Dec  3 13:09:51.738: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012079512s
    Dec  3 13:09:53.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010167895s
    Dec  3 13:09:55.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011397016s
    Dec  3 13:09:57.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Running", Reason="", readiness=true. Elapsed: 8.010758081s
    Dec  3 13:09:59.737: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Running", Reason="", readiness=true. Elapsed: 10.010503935s
    Dec  3 13:10:01.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.010196829s
    Dec  3 13:10:01.736: INFO: Pod "agnhost-host-aliases750fba36-330d-4200-a2a8-c6e67c063eed" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec  3 13:10:01.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5415" for this suite. 12/03/22 13:10:01.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:01.767
Dec  3 13:10:01.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename containers 12/03/22 13:10:01.769
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:01.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:01.816
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Dec  3 13:10:01.840: INFO: Waiting up to 5m0s for pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df" in namespace "containers-6796" to be "running"
Dec  3 13:10:01.852: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df": Phase="Pending", Reason="", readiness=false. Elapsed: 11.823595ms
Dec  3 13:10:03.859: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df": Phase="Running", Reason="", readiness=true. Elapsed: 2.019030125s
Dec  3 13:10:03.859: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec  3 13:10:03.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6796" for this suite. 12/03/22 13:10:03.871
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":221,"skipped":4233,"failed":0}
------------------------------
â€¢ [2.112 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:01.767
    Dec  3 13:10:01.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename containers 12/03/22 13:10:01.769
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:01.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:01.816
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Dec  3 13:10:01.840: INFO: Waiting up to 5m0s for pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df" in namespace "containers-6796" to be "running"
    Dec  3 13:10:01.852: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df": Phase="Pending", Reason="", readiness=false. Elapsed: 11.823595ms
    Dec  3 13:10:03.859: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df": Phase="Running", Reason="", readiness=true. Elapsed: 2.019030125s
    Dec  3 13:10:03.859: INFO: Pod "client-containers-b8698969-6b83-41fd-857e-6a430cb943df" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec  3 13:10:03.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6796" for this suite. 12/03/22 13:10:03.871
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:03.881
Dec  3 13:10:03.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:10:03.882
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:03.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:03.903
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-b8138d7c-56bd-4e45-9ae6-72852466aaeb 12/03/22 13:10:03.906
STEP: Creating a pod to test consume configMaps 12/03/22 13:10:03.911
Dec  3 13:10:03.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd" in namespace "configmap-3042" to be "Succeeded or Failed"
Dec  3 13:10:03.927: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136837ms
Dec  3 13:10:05.935: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014106646s
Dec  3 13:10:07.932: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458023s
STEP: Saw pod success 12/03/22 13:10:07.932
Dec  3 13:10:07.932: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd" satisfied condition "Succeeded or Failed"
Dec  3 13:10:07.936: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:10:07.944
Dec  3 13:10:07.963: INFO: Waiting for pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd to disappear
Dec  3 13:10:07.968: INFO: Pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:10:07.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3042" for this suite. 12/03/22 13:10:07.973
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":222,"skipped":4243,"failed":0}
------------------------------
â€¢ [4.098 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:03.881
    Dec  3 13:10:03.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:10:03.882
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:03.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:03.903
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-b8138d7c-56bd-4e45-9ae6-72852466aaeb 12/03/22 13:10:03.906
    STEP: Creating a pod to test consume configMaps 12/03/22 13:10:03.911
    Dec  3 13:10:03.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd" in namespace "configmap-3042" to be "Succeeded or Failed"
    Dec  3 13:10:03.927: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136837ms
    Dec  3 13:10:05.935: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014106646s
    Dec  3 13:10:07.932: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458023s
    STEP: Saw pod success 12/03/22 13:10:07.932
    Dec  3 13:10:07.932: INFO: Pod "pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:07.936: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:10:07.944
    Dec  3 13:10:07.963: INFO: Waiting for pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd to disappear
    Dec  3 13:10:07.968: INFO: Pod pod-configmaps-93c80697-8845-4abb-905b-f5c35674b4fd no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:10:07.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3042" for this suite. 12/03/22 13:10:07.973
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:07.982
Dec  3 13:10:07.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename containers 12/03/22 13:10:07.984
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:08.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:08.007
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 12/03/22 13:10:08.013
Dec  3 13:10:08.025: INFO: Waiting up to 5m0s for pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7" in namespace "containers-721" to be "Succeeded or Failed"
Dec  3 13:10:08.028: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.560863ms
Dec  3 13:10:10.033: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526682s
Dec  3 13:10:12.034: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009177191s
STEP: Saw pod success 12/03/22 13:10:12.034
Dec  3 13:10:12.035: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7" satisfied condition "Succeeded or Failed"
Dec  3 13:10:12.039: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:10:12.047
Dec  3 13:10:12.070: INFO: Waiting for pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 to disappear
Dec  3 13:10:12.073: INFO: Pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec  3 13:10:12.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-721" for this suite. 12/03/22 13:10:12.08
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":223,"skipped":4278,"failed":0}
------------------------------
â€¢ [4.105 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:07.982
    Dec  3 13:10:07.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename containers 12/03/22 13:10:07.984
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:08.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:08.007
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 12/03/22 13:10:08.013
    Dec  3 13:10:08.025: INFO: Waiting up to 5m0s for pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7" in namespace "containers-721" to be "Succeeded or Failed"
    Dec  3 13:10:08.028: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.560863ms
    Dec  3 13:10:10.033: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526682s
    Dec  3 13:10:12.034: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009177191s
    STEP: Saw pod success 12/03/22 13:10:12.034
    Dec  3 13:10:12.035: INFO: Pod "client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:12.039: INFO: Trying to get logs from node ip-172-31-38-234 pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:10:12.047
    Dec  3 13:10:12.070: INFO: Waiting for pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 to disappear
    Dec  3 13:10:12.073: INFO: Pod client-containers-72a28709-c3a5-41aa-a444-3894ab8490a7 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec  3 13:10:12.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-721" for this suite. 12/03/22 13:10:12.08
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:12.091
Dec  3 13:10:12.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename ingressclass 12/03/22 13:10:12.093
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:12.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:12.131
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 12/03/22 13:10:12.135
STEP: getting /apis/networking.k8s.io 12/03/22 13:10:12.14
STEP: getting /apis/networking.k8s.iov1 12/03/22 13:10:12.141
STEP: creating 12/03/22 13:10:12.142
STEP: getting 12/03/22 13:10:12.161
STEP: listing 12/03/22 13:10:12.164
STEP: watching 12/03/22 13:10:12.167
Dec  3 13:10:12.168: INFO: starting watch
STEP: patching 12/03/22 13:10:12.168
STEP: updating 12/03/22 13:10:12.174
Dec  3 13:10:12.182: INFO: waiting for watch events with expected annotations
Dec  3 13:10:12.182: INFO: saw patched and updated annotations
STEP: deleting 12/03/22 13:10:12.183
STEP: deleting a collection 12/03/22 13:10:12.196
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Dec  3 13:10:12.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-9844" for this suite. 12/03/22 13:10:12.229
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":224,"skipped":4303,"failed":0}
------------------------------
â€¢ [0.147 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:12.091
    Dec  3 13:10:12.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename ingressclass 12/03/22 13:10:12.093
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:12.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:12.131
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 12/03/22 13:10:12.135
    STEP: getting /apis/networking.k8s.io 12/03/22 13:10:12.14
    STEP: getting /apis/networking.k8s.iov1 12/03/22 13:10:12.141
    STEP: creating 12/03/22 13:10:12.142
    STEP: getting 12/03/22 13:10:12.161
    STEP: listing 12/03/22 13:10:12.164
    STEP: watching 12/03/22 13:10:12.167
    Dec  3 13:10:12.168: INFO: starting watch
    STEP: patching 12/03/22 13:10:12.168
    STEP: updating 12/03/22 13:10:12.174
    Dec  3 13:10:12.182: INFO: waiting for watch events with expected annotations
    Dec  3 13:10:12.182: INFO: saw patched and updated annotations
    STEP: deleting 12/03/22 13:10:12.183
    STEP: deleting a collection 12/03/22 13:10:12.196
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Dec  3 13:10:12.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-9844" for this suite. 12/03/22 13:10:12.229
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:12.241
Dec  3 13:10:12.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 13:10:12.242
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:12.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:12.273
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 12/03/22 13:10:12.282
STEP: waiting for Deployment to be created 12/03/22 13:10:12.289
STEP: waiting for all Replicas to be Ready 12/03/22 13:10:12.292
Dec  3 13:10:12.294: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.294: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.320: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.321: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.359: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.359: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.396: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:12.397: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec  3 13:10:13.755: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec  3 13:10:13.755: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec  3 13:10:13.919: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 12/03/22 13:10:13.919
W1203 13:10:13.937667      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec  3 13:10:13.940: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 12/03/22 13:10:13.94
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:13.970: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:13.970: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:14.034: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:14.034: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:14.060: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:14.061: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:14.076: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:14.076: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:15.810: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:15.810: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:15.841: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
STEP: listing Deployments 12/03/22 13:10:15.841
Dec  3 13:10:15.846: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 12/03/22 13:10:15.847
Dec  3 13:10:15.862: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 12/03/22 13:10:15.863
Dec  3 13:10:15.880: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:15.880: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:15.915: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:15.941: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:15.962: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:16.927: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:17.799: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:17.834: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:17.919: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec  3 13:10:18.947: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 12/03/22 13:10:18.984
STEP: fetching the DeploymentStatus 12/03/22 13:10:18.992
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3
Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3
STEP: deleting the Deployment 12/03/22 13:10:18.998
Dec  3 13:10:19.010: INFO: observed event type MODIFIED
Dec  3 13:10:19.010: INFO: observed event type MODIFIED
Dec  3 13:10:19.010: INFO: observed event type MODIFIED
Dec  3 13:10:19.010: INFO: observed event type MODIFIED
Dec  3 13:10:19.010: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
Dec  3 13:10:19.011: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 13:10:19.018: INFO: Log out all the ReplicaSets if there is no deployment created
Dec  3 13:10:19.024: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-5053  4a2ebc62-6451-4fee-a807-41ce2f193b74 30405 4 2022-12-03 13:10:13 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51447 0xc005b51448}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b514d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Dec  3 13:10:19.029: INFO: pod: "test-deployment-54cc775c4b-jln9g":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-jln9g test-deployment-54cc775c4b- deployment-5053  979d306c-141f-4bfa-b041-5c007be6d4ed 30401 0 2022-12-03 13:10:15 +0000 UTC 2022-12-03 13:10:19 +0000 UTC 0xc005b51928 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4a2ebc62-6451-4fee-a807-41ce2f193b74 0xc005b51957 0xc005b51958}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a2ebc62-6451-4fee-a807-41ce2f193b74\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wslv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wslv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.213,StartTime:2022-12-03 13:10:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://a68e6347a86c7e6350871c0c52693015376265ab266b884666b65552082bf287,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec  3 13:10:19.029: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-5053  ba82afe7-7286-48a1-82f9-6e25a25c18fd 30397 2 2022-12-03 13:10:15 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51537 0xc005b51538}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b515c0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Dec  3 13:10:19.033: INFO: pod: "test-deployment-7c7d8d58c8-rplgv":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-rplgv test-deployment-7c7d8d58c8- deployment-5053  e2559919-50da-4092-b5f9-a4416cd6cf0f 30396 0 2022-12-03 13:10:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 ba82afe7-7286-48a1-82f9-6e25a25c18fd 0xc005baa567 0xc005baa568}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba82afe7-7286-48a1-82f9-6e25a25c18fd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.221\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2trdf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2trdf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.221,StartTime:2022-12-03 13:10:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e6eb5c45a9c8332de0c9b0b38a8a6bb2037b03344228026ce3e54c4255e84f40,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.221,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec  3 13:10:19.033: INFO: pod: "test-deployment-7c7d8d58c8-vv8kb":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-vv8kb test-deployment-7c7d8d58c8- deployment-5053  783e1466-487b-46cc-aa02-2997acdd9e90 30359 0 2022-12-03 13:10:15 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 ba82afe7-7286-48a1-82f9-6e25a25c18fd 0xc005baa757 0xc005baa758}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba82afe7-7286-48a1-82f9-6e25a25c18fd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.77\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rghss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rghss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.77,StartTime:2022-12-03 13:10:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5b7b0b9a13be329c021930071e8e2fd9bb2add75c14fcb5db1245f607eff6080,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec  3 13:10:19.034: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-5053  610e0d0a-cbbd-408a-b11e-f31c7f1f5028 30286 3 2022-12-03 13:10:12 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51627 0xc005b51628}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b516b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 13:10:19.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5053" for this suite. 12/03/22 13:10:19.045
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":225,"skipped":4308,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.811 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:12.241
    Dec  3 13:10:12.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 13:10:12.242
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:12.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:12.273
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 12/03/22 13:10:12.282
    STEP: waiting for Deployment to be created 12/03/22 13:10:12.289
    STEP: waiting for all Replicas to be Ready 12/03/22 13:10:12.292
    Dec  3 13:10:12.294: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.294: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.320: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.321: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.359: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.359: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.396: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:12.397: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec  3 13:10:13.755: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec  3 13:10:13.755: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec  3 13:10:13.919: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 12/03/22 13:10:13.919
    W1203 13:10:13.937667      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec  3 13:10:13.940: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 12/03/22 13:10:13.94
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 0
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:13.942: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:13.970: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:13.970: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:14.034: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:14.034: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:14.060: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:14.061: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:14.076: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:14.076: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:15.810: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:15.810: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:15.841: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    STEP: listing Deployments 12/03/22 13:10:15.841
    Dec  3 13:10:15.846: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 12/03/22 13:10:15.847
    Dec  3 13:10:15.862: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 12/03/22 13:10:15.863
    Dec  3 13:10:15.880: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:15.880: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:15.915: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:15.941: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:15.962: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:16.927: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:17.799: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:17.834: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:17.919: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec  3 13:10:18.947: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 12/03/22 13:10:18.984
    STEP: fetching the DeploymentStatus 12/03/22 13:10:18.992
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 1
    Dec  3 13:10:18.997: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3
    Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 2
    Dec  3 13:10:18.998: INFO: observed Deployment test-deployment in namespace deployment-5053 with ReadyReplicas 3
    STEP: deleting the Deployment 12/03/22 13:10:18.998
    Dec  3 13:10:19.010: INFO: observed event type MODIFIED
    Dec  3 13:10:19.010: INFO: observed event type MODIFIED
    Dec  3 13:10:19.010: INFO: observed event type MODIFIED
    Dec  3 13:10:19.010: INFO: observed event type MODIFIED
    Dec  3 13:10:19.010: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    Dec  3 13:10:19.011: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 13:10:19.018: INFO: Log out all the ReplicaSets if there is no deployment created
    Dec  3 13:10:19.024: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-5053  4a2ebc62-6451-4fee-a807-41ce2f193b74 30405 4 2022-12-03 13:10:13 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51447 0xc005b51448}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b514d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Dec  3 13:10:19.029: INFO: pod: "test-deployment-54cc775c4b-jln9g":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-jln9g test-deployment-54cc775c4b- deployment-5053  979d306c-141f-4bfa-b041-5c007be6d4ed 30401 0 2022-12-03 13:10:15 +0000 UTC 2022-12-03 13:10:19 +0000 UTC 0xc005b51928 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4a2ebc62-6451-4fee-a807-41ce2f193b74 0xc005b51957 0xc005b51958}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a2ebc62-6451-4fee-a807-41ce2f193b74\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wslv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wslv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.213,StartTime:2022-12-03 13:10:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://a68e6347a86c7e6350871c0c52693015376265ab266b884666b65552082bf287,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Dec  3 13:10:19.029: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-5053  ba82afe7-7286-48a1-82f9-6e25a25c18fd 30397 2 2022-12-03 13:10:15 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51537 0xc005b51538}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b515c0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Dec  3 13:10:19.033: INFO: pod: "test-deployment-7c7d8d58c8-rplgv":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-rplgv test-deployment-7c7d8d58c8- deployment-5053  e2559919-50da-4092-b5f9-a4416cd6cf0f 30396 0 2022-12-03 13:10:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 ba82afe7-7286-48a1-82f9-6e25a25c18fd 0xc005baa567 0xc005baa568}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba82afe7-7286-48a1-82f9-6e25a25c18fd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.71.221\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2trdf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2trdf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-76-203,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.76.203,PodIP:192.168.71.221,StartTime:2022-12-03 13:10:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e6eb5c45a9c8332de0c9b0b38a8a6bb2037b03344228026ce3e54c4255e84f40,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.71.221,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Dec  3 13:10:19.033: INFO: pod: "test-deployment-7c7d8d58c8-vv8kb":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-vv8kb test-deployment-7c7d8d58c8- deployment-5053  783e1466-487b-46cc-aa02-2997acdd9e90 30359 0 2022-12-03 13:10:15 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 ba82afe7-7286-48a1-82f9-6e25a25c18fd 0xc005baa757 0xc005baa758}] [] [{kube-controller-manager Update v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba82afe7-7286-48a1-82f9-6e25a25c18fd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:10:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.197.77\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rghss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rghss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:10:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:192.168.197.77,StartTime:2022-12-03 13:10:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-03 13:10:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5b7b0b9a13be329c021930071e8e2fd9bb2add75c14fcb5db1245f607eff6080,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.197.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Dec  3 13:10:19.034: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-5053  610e0d0a-cbbd-408a-b11e-f31c7f1f5028 30286 3 2022-12-03 13:10:12 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment fa97ef77-33a9-481c-857c-4fabc278b787 0xc005b51627 0xc005b51628}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fa97ef77-33a9-481c-857c-4fabc278b787\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:10:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b516b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 13:10:19.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5053" for this suite. 12/03/22 13:10:19.045
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:19.054
Dec  3 13:10:19.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename proxy 12/03/22 13:10:19.055
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:19.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:19.087
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 12/03/22 13:10:19.112
STEP: creating replication controller proxy-service-zws7g in namespace proxy-5167 12/03/22 13:10:19.112
I1203 13:10:19.132910      19 runners.go:193] Created replication controller with name: proxy-service-zws7g, namespace: proxy-5167, replica count: 1
I1203 13:10:20.185078      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:10:21.185374      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 13:10:22.186071      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:10:22.189: INFO: setup took 3.089742223s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/03/22 13:10:22.189
Dec  3 13:10:22.199: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.417271ms)
Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 24.068708ms)
Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 23.949594ms)
Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 24.245197ms)
Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 29.432111ms)
Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 29.832794ms)
Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 29.822846ms)
Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 30.743688ms)
Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 30.757801ms)
Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 30.91181ms)
Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 31.269041ms)
Dec  3 13:10:22.222: INFO: (0) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 31.484293ms)
Dec  3 13:10:22.222: INFO: (0) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 32.138864ms)
Dec  3 13:10:22.223: INFO: (0) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 33.328791ms)
Dec  3 13:10:22.224: INFO: (0) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 34.033778ms)
Dec  3 13:10:22.224: INFO: (0) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 33.909188ms)
Dec  3 13:10:22.231: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 7.226636ms)
Dec  3 13:10:22.235: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.122663ms)
Dec  3 13:10:22.235: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 10.302714ms)
Dec  3 13:10:22.236: INFO: (1) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 12.320071ms)
Dec  3 13:10:22.236: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.855402ms)
Dec  3 13:10:22.238: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 13.467458ms)
Dec  3 13:10:22.238: INFO: (1) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.641945ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.278842ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.601437ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.152287ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 14.126581ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.119129ms)
Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 13.941125ms)
Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 16.099633ms)
Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.22896ms)
Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 15.682224ms)
Dec  3 13:10:22.248: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.175208ms)
Dec  3 13:10:22.248: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.855946ms)
Dec  3 13:10:22.250: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 8.693922ms)
Dec  3 13:10:22.250: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.435445ms)
Dec  3 13:10:22.252: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.637485ms)
Dec  3 13:10:22.253: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.30281ms)
Dec  3 13:10:22.253: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 12.03071ms)
Dec  3 13:10:22.254: INFO: (2) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 13.249264ms)
Dec  3 13:10:22.254: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 13.204148ms)
Dec  3 13:10:22.255: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.942355ms)
Dec  3 13:10:22.255: INFO: (2) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.101958ms)
Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.216654ms)
Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 16.875029ms)
Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 17.177964ms)
Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.883779ms)
Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 16.885495ms)
Dec  3 13:10:22.265: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.276221ms)
Dec  3 13:10:22.268: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.343354ms)
Dec  3 13:10:22.269: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.004002ms)
Dec  3 13:10:22.270: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.697607ms)
Dec  3 13:10:22.270: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 11.631013ms)
Dec  3 13:10:22.281: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 22.377776ms)
Dec  3 13:10:22.282: INFO: (3) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 22.902522ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 25.399195ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 25.161464ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 24.749928ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 25.43202ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 25.023ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 25.133185ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 25.641376ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 25.631616ms)
Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 25.970696ms)
Dec  3 13:10:22.291: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 6.751058ms)
Dec  3 13:10:22.292: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 7.146207ms)
Dec  3 13:10:22.292: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.518871ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.031584ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.481565ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.702379ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 14.181658ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.242957ms)
Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.733604ms)
Dec  3 13:10:22.300: INFO: (4) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 15.171776ms)
Dec  3 13:10:22.300: INFO: (4) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 15.377666ms)
Dec  3 13:10:22.301: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.197782ms)
Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.694355ms)
Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 16.8893ms)
Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.031902ms)
Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 17.016886ms)
Dec  3 13:10:22.310: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 7.839188ms)
Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 9.607624ms)
Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.445126ms)
Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.851233ms)
Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 10.049674ms)
Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.188125ms)
Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 10.488581ms)
Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.61211ms)
Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.759474ms)
Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 12.48566ms)
Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 12.51088ms)
Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 14.459625ms)
Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 14.645486ms)
Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.528285ms)
Dec  3 13:10:22.320: INFO: (5) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.095961ms)
Dec  3 13:10:22.320: INFO: (5) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.163892ms)
Dec  3 13:10:22.329: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 8.894253ms)
Dec  3 13:10:22.330: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.032513ms)
Dec  3 13:10:22.331: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.243822ms)
Dec  3 13:10:22.332: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 12.010658ms)
Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.534927ms)
Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 13.799326ms)
Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 14.343418ms)
Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 13.927457ms)
Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.36886ms)
Dec  3 13:10:22.335: INFO: (6) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.993895ms)
Dec  3 13:10:22.339: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 18.672415ms)
Dec  3 13:10:22.340: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 19.461215ms)
Dec  3 13:10:22.341: INFO: (6) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 20.495822ms)
Dec  3 13:10:22.341: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 20.409851ms)
Dec  3 13:10:22.342: INFO: (6) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 21.342304ms)
Dec  3 13:10:22.342: INFO: (6) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 22.060926ms)
Dec  3 13:10:22.350: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.9447ms)
Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 9.230694ms)
Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.04888ms)
Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 9.728416ms)
Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.765251ms)
Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 10.17161ms)
Dec  3 13:10:22.353: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 10.108976ms)
Dec  3 13:10:22.353: INFO: (7) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 10.745183ms)
Dec  3 13:10:22.354: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.618492ms)
Dec  3 13:10:22.354: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.510569ms)
Dec  3 13:10:22.355: INFO: (7) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.317611ms)
Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 14.143431ms)
Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 14.522902ms)
Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.408819ms)
Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 14.503583ms)
Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.606514ms)
Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.529116ms)
Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.661598ms)
Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 7.521276ms)
Dec  3 13:10:22.366: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.943929ms)
Dec  3 13:10:22.366: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 8.1575ms)
Dec  3 13:10:22.368: INFO: (8) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 9.618725ms)
Dec  3 13:10:22.368: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 9.794715ms)
Dec  3 13:10:22.369: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 11.560085ms)
Dec  3 13:10:22.369: INFO: (8) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 11.342353ms)
Dec  3 13:10:22.370: INFO: (8) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.175128ms)
Dec  3 13:10:22.371: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.282493ms)
Dec  3 13:10:22.377: INFO: (8) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 18.903339ms)
Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 19.893387ms)
Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 20.235327ms)
Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 20.313235ms)
Dec  3 13:10:22.381: INFO: (8) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 22.742083ms)
Dec  3 13:10:22.389: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.80871ms)
Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 8.784036ms)
Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 9.146317ms)
Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 8.636104ms)
Dec  3 13:10:22.391: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 9.750449ms)
Dec  3 13:10:22.393: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.939274ms)
Dec  3 13:10:22.393: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.751909ms)
Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 12.778442ms)
Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.63219ms)
Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 13.12232ms)
Dec  3 13:10:22.395: INFO: (9) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.826679ms)
Dec  3 13:10:22.395: INFO: (9) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.001812ms)
Dec  3 13:10:22.396: INFO: (9) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 15.075772ms)
Dec  3 13:10:22.396: INFO: (9) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 15.006063ms)
Dec  3 13:10:22.398: INFO: (9) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 16.340954ms)
Dec  3 13:10:22.398: INFO: (9) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.323972ms)
Dec  3 13:10:22.409: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 10.333457ms)
Dec  3 13:10:22.410: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 11.47262ms)
Dec  3 13:10:22.411: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.212101ms)
Dec  3 13:10:22.411: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.016919ms)
Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 14.773122ms)
Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.848459ms)
Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.107084ms)
Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.876021ms)
Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 15.397463ms)
Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.212018ms)
Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.13664ms)
Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.20674ms)
Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 16.65821ms)
Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.761479ms)
Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 16.637606ms)
Dec  3 13:10:22.417: INFO: (10) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 18.373759ms)
Dec  3 13:10:22.423: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 5.199576ms)
Dec  3 13:10:22.423: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 5.675952ms)
Dec  3 13:10:22.425: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.972194ms)
Dec  3 13:10:22.425: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 7.180465ms)
Dec  3 13:10:22.427: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.045098ms)
Dec  3 13:10:22.428: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 10.22265ms)
Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 10.626352ms)
Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 11.150448ms)
Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.297081ms)
Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.686343ms)
Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 13.391348ms)
Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.057395ms)
Dec  3 13:10:22.433: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.654038ms)
Dec  3 13:10:22.433: INFO: (11) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.317207ms)
Dec  3 13:10:22.434: INFO: (11) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 15.481054ms)
Dec  3 13:10:22.434: INFO: (11) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.017971ms)
Dec  3 13:10:22.442: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.684531ms)
Dec  3 13:10:22.446: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 11.562108ms)
Dec  3 13:10:22.446: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 11.961673ms)
Dec  3 13:10:22.447: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.605898ms)
Dec  3 13:10:22.447: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 12.489366ms)
Dec  3 13:10:22.448: INFO: (12) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 13.679767ms)
Dec  3 13:10:22.448: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.649718ms)
Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 14.260598ms)
Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 14.069069ms)
Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 13.821203ms)
Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.023498ms)
Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.4719ms)
Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.846276ms)
Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.240673ms)
Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.406802ms)
Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.18448ms)
Dec  3 13:10:22.463: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 10.194384ms)
Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 14.764089ms)
Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.652264ms)
Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.97851ms)
Dec  3 13:10:22.468: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 15.104981ms)
Dec  3 13:10:22.468: INFO: (13) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 15.314202ms)
Dec  3 13:10:22.469: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.812622ms)
Dec  3 13:10:22.469: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 16.401958ms)
Dec  3 13:10:22.470: INFO: (13) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.688254ms)
Dec  3 13:10:22.470: INFO: (13) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.186406ms)
Dec  3 13:10:22.471: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 18.398713ms)
Dec  3 13:10:22.471: INFO: (13) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 18.68431ms)
Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 18.983906ms)
Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 19.054636ms)
Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 19.583077ms)
Dec  3 13:10:22.473: INFO: (13) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 21.217885ms)
Dec  3 13:10:22.479: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 5.29694ms)
Dec  3 13:10:22.479: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.920758ms)
Dec  3 13:10:22.480: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 6.118865ms)
Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 9.065953ms)
Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 8.945778ms)
Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 8.944845ms)
Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 10.451662ms)
Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.983904ms)
Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.072017ms)
Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.580781ms)
Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 12.903693ms)
Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 12.790272ms)
Dec  3 13:10:22.487: INFO: (14) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.202759ms)
Dec  3 13:10:22.488: INFO: (14) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.185339ms)
Dec  3 13:10:22.488: INFO: (14) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.030791ms)
Dec  3 13:10:22.490: INFO: (14) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 15.861354ms)
Dec  3 13:10:22.498: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 8.024776ms)
Dec  3 13:10:22.502: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.790588ms)
Dec  3 13:10:22.503: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.190252ms)
Dec  3 13:10:22.503: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.366951ms)
Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.854399ms)
Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.735524ms)
Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.813083ms)
Dec  3 13:10:22.509: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 17.578625ms)
Dec  3 13:10:22.510: INFO: (15) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 18.871373ms)
Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 20.772921ms)
Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 21.940954ms)
Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 21.620336ms)
Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 23.233854ms)
Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 22.878538ms)
Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 23.69064ms)
Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 23.018581ms)
Dec  3 13:10:22.529: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.429914ms)
Dec  3 13:10:22.529: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.564383ms)
Dec  3 13:10:22.530: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 15.605888ms)
Dec  3 13:10:22.531: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.40195ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 16.997821ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 17.304143ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.863287ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 17.409245ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 17.125606ms)
Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 17.965401ms)
Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 17.537987ms)
Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 17.675374ms)
Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.948124ms)
Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 18.882173ms)
Dec  3 13:10:22.534: INFO: (16) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 18.713369ms)
Dec  3 13:10:22.534: INFO: (16) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 19.021275ms)
Dec  3 13:10:22.539: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.178935ms)
Dec  3 13:10:22.541: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.860896ms)
Dec  3 13:10:22.542: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.820985ms)
Dec  3 13:10:22.542: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 7.398026ms)
Dec  3 13:10:22.543: INFO: (17) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 8.985963ms)
Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 10.262042ms)
Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.99966ms)
Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 10.604252ms)
Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.134645ms)
Dec  3 13:10:22.547: INFO: (17) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 12.000959ms)
Dec  3 13:10:22.547: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.726324ms)
Dec  3 13:10:22.548: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.341303ms)
Dec  3 13:10:22.548: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.616748ms)
Dec  3 13:10:22.549: INFO: (17) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.736214ms)
Dec  3 13:10:22.549: INFO: (17) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 14.783438ms)
Dec  3 13:10:22.550: INFO: (17) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.791026ms)
Dec  3 13:10:22.556: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 5.70859ms)
Dec  3 13:10:22.558: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.910554ms)
Dec  3 13:10:22.565: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 14.751067ms)
Dec  3 13:10:22.565: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 14.937085ms)
Dec  3 13:10:22.566: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 15.526975ms)
Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.468555ms)
Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.312937ms)
Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 17.623217ms)
Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 17.937684ms)
Dec  3 13:10:22.569: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 18.577207ms)
Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 19.488572ms)
Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 19.374684ms)
Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 20.204797ms)
Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 20.218142ms)
Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 19.778865ms)
Dec  3 13:10:22.571: INFO: (18) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 20.250081ms)
Dec  3 13:10:22.576: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.255642ms)
Dec  3 13:10:22.577: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 6.534068ms)
Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 10.20486ms)
Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.599193ms)
Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.891988ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.048828ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.745801ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.604438ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.693427ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 16.99749ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 16.714069ms)
Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 16.884604ms)
Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.135093ms)
Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.192329ms)
Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.236437ms)
Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.921488ms)
STEP: deleting ReplicationController proxy-service-zws7g in namespace proxy-5167, will wait for the garbage collector to delete the pods 12/03/22 13:10:22.589
Dec  3 13:10:22.654: INFO: Deleting ReplicationController proxy-service-zws7g took: 10.760878ms
Dec  3 13:10:22.755: INFO: Terminating ReplicationController proxy-service-zws7g pods took: 100.640639ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec  3 13:10:24.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5167" for this suite. 12/03/22 13:10:24.97
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":226,"skipped":4309,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.928 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:19.054
    Dec  3 13:10:19.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename proxy 12/03/22 13:10:19.055
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:19.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:19.087
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 12/03/22 13:10:19.112
    STEP: creating replication controller proxy-service-zws7g in namespace proxy-5167 12/03/22 13:10:19.112
    I1203 13:10:19.132910      19 runners.go:193] Created replication controller with name: proxy-service-zws7g, namespace: proxy-5167, replica count: 1
    I1203 13:10:20.185078      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:10:21.185374      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I1203 13:10:22.186071      19 runners.go:193] proxy-service-zws7g Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:10:22.189: INFO: setup took 3.089742223s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/03/22 13:10:22.189
    Dec  3 13:10:22.199: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.417271ms)
    Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 24.068708ms)
    Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 23.949594ms)
    Dec  3 13:10:22.214: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 24.245197ms)
    Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 29.432111ms)
    Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 29.832794ms)
    Dec  3 13:10:22.220: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 29.822846ms)
    Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 30.743688ms)
    Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 30.757801ms)
    Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 30.91181ms)
    Dec  3 13:10:22.221: INFO: (0) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 31.269041ms)
    Dec  3 13:10:22.222: INFO: (0) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 31.484293ms)
    Dec  3 13:10:22.222: INFO: (0) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 32.138864ms)
    Dec  3 13:10:22.223: INFO: (0) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 33.328791ms)
    Dec  3 13:10:22.224: INFO: (0) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 34.033778ms)
    Dec  3 13:10:22.224: INFO: (0) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 33.909188ms)
    Dec  3 13:10:22.231: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 7.226636ms)
    Dec  3 13:10:22.235: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.122663ms)
    Dec  3 13:10:22.235: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 10.302714ms)
    Dec  3 13:10:22.236: INFO: (1) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 12.320071ms)
    Dec  3 13:10:22.236: INFO: (1) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.855402ms)
    Dec  3 13:10:22.238: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 13.467458ms)
    Dec  3 13:10:22.238: INFO: (1) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.641945ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.278842ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.601437ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.152287ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 14.126581ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.119129ms)
    Dec  3 13:10:22.239: INFO: (1) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 13.941125ms)
    Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 16.099633ms)
    Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.22896ms)
    Dec  3 13:10:22.240: INFO: (1) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 15.682224ms)
    Dec  3 13:10:22.248: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.175208ms)
    Dec  3 13:10:22.248: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.855946ms)
    Dec  3 13:10:22.250: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 8.693922ms)
    Dec  3 13:10:22.250: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.435445ms)
    Dec  3 13:10:22.252: INFO: (2) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.637485ms)
    Dec  3 13:10:22.253: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.30281ms)
    Dec  3 13:10:22.253: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 12.03071ms)
    Dec  3 13:10:22.254: INFO: (2) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 13.249264ms)
    Dec  3 13:10:22.254: INFO: (2) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 13.204148ms)
    Dec  3 13:10:22.255: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.942355ms)
    Dec  3 13:10:22.255: INFO: (2) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.101958ms)
    Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.216654ms)
    Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 16.875029ms)
    Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 17.177964ms)
    Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.883779ms)
    Dec  3 13:10:22.258: INFO: (2) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 16.885495ms)
    Dec  3 13:10:22.265: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.276221ms)
    Dec  3 13:10:22.268: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.343354ms)
    Dec  3 13:10:22.269: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.004002ms)
    Dec  3 13:10:22.270: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.697607ms)
    Dec  3 13:10:22.270: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 11.631013ms)
    Dec  3 13:10:22.281: INFO: (3) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 22.377776ms)
    Dec  3 13:10:22.282: INFO: (3) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 22.902522ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 25.399195ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 25.161464ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 24.749928ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 25.43202ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 25.023ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 25.133185ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 25.641376ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 25.631616ms)
    Dec  3 13:10:22.284: INFO: (3) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 25.970696ms)
    Dec  3 13:10:22.291: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 6.751058ms)
    Dec  3 13:10:22.292: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 7.146207ms)
    Dec  3 13:10:22.292: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.518871ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.031584ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.481565ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.702379ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 14.181658ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.242957ms)
    Dec  3 13:10:22.299: INFO: (4) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.733604ms)
    Dec  3 13:10:22.300: INFO: (4) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 15.171776ms)
    Dec  3 13:10:22.300: INFO: (4) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 15.377666ms)
    Dec  3 13:10:22.301: INFO: (4) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.197782ms)
    Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.694355ms)
    Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 16.8893ms)
    Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.031902ms)
    Dec  3 13:10:22.302: INFO: (4) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 17.016886ms)
    Dec  3 13:10:22.310: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 7.839188ms)
    Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 9.607624ms)
    Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.445126ms)
    Dec  3 13:10:22.312: INFO: (5) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.851233ms)
    Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 10.049674ms)
    Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.188125ms)
    Dec  3 13:10:22.313: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 10.488581ms)
    Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.61211ms)
    Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.759474ms)
    Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 12.48566ms)
    Dec  3 13:10:22.315: INFO: (5) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 12.51088ms)
    Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 14.459625ms)
    Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 14.645486ms)
    Dec  3 13:10:22.317: INFO: (5) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.528285ms)
    Dec  3 13:10:22.320: INFO: (5) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.095961ms)
    Dec  3 13:10:22.320: INFO: (5) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.163892ms)
    Dec  3 13:10:22.329: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 8.894253ms)
    Dec  3 13:10:22.330: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.032513ms)
    Dec  3 13:10:22.331: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.243822ms)
    Dec  3 13:10:22.332: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 12.010658ms)
    Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.534927ms)
    Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 13.799326ms)
    Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 14.343418ms)
    Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 13.927457ms)
    Dec  3 13:10:22.334: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.36886ms)
    Dec  3 13:10:22.335: INFO: (6) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.993895ms)
    Dec  3 13:10:22.339: INFO: (6) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 18.672415ms)
    Dec  3 13:10:22.340: INFO: (6) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 19.461215ms)
    Dec  3 13:10:22.341: INFO: (6) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 20.495822ms)
    Dec  3 13:10:22.341: INFO: (6) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 20.409851ms)
    Dec  3 13:10:22.342: INFO: (6) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 21.342304ms)
    Dec  3 13:10:22.342: INFO: (6) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 22.060926ms)
    Dec  3 13:10:22.350: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.9447ms)
    Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 9.230694ms)
    Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.04888ms)
    Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 9.728416ms)
    Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 9.765251ms)
    Dec  3 13:10:22.352: INFO: (7) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 10.17161ms)
    Dec  3 13:10:22.353: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 10.108976ms)
    Dec  3 13:10:22.353: INFO: (7) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 10.745183ms)
    Dec  3 13:10:22.354: INFO: (7) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.618492ms)
    Dec  3 13:10:22.354: INFO: (7) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.510569ms)
    Dec  3 13:10:22.355: INFO: (7) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.317611ms)
    Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 14.143431ms)
    Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 14.522902ms)
    Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.408819ms)
    Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 14.503583ms)
    Dec  3 13:10:22.357: INFO: (7) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.606514ms)
    Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.529116ms)
    Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.661598ms)
    Dec  3 13:10:22.365: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 7.521276ms)
    Dec  3 13:10:22.366: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.943929ms)
    Dec  3 13:10:22.366: INFO: (8) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 8.1575ms)
    Dec  3 13:10:22.368: INFO: (8) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 9.618725ms)
    Dec  3 13:10:22.368: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 9.794715ms)
    Dec  3 13:10:22.369: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 11.560085ms)
    Dec  3 13:10:22.369: INFO: (8) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 11.342353ms)
    Dec  3 13:10:22.370: INFO: (8) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.175128ms)
    Dec  3 13:10:22.371: INFO: (8) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.282493ms)
    Dec  3 13:10:22.377: INFO: (8) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 18.903339ms)
    Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 19.893387ms)
    Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 20.235327ms)
    Dec  3 13:10:22.378: INFO: (8) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 20.313235ms)
    Dec  3 13:10:22.381: INFO: (8) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 22.742083ms)
    Dec  3 13:10:22.389: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.80871ms)
    Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 8.784036ms)
    Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 9.146317ms)
    Dec  3 13:10:22.390: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 8.636104ms)
    Dec  3 13:10:22.391: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 9.750449ms)
    Dec  3 13:10:22.393: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 11.939274ms)
    Dec  3 13:10:22.393: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.751909ms)
    Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 12.778442ms)
    Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.63219ms)
    Dec  3 13:10:22.394: INFO: (9) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 13.12232ms)
    Dec  3 13:10:22.395: INFO: (9) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.826679ms)
    Dec  3 13:10:22.395: INFO: (9) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.001812ms)
    Dec  3 13:10:22.396: INFO: (9) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 15.075772ms)
    Dec  3 13:10:22.396: INFO: (9) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 15.006063ms)
    Dec  3 13:10:22.398: INFO: (9) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 16.340954ms)
    Dec  3 13:10:22.398: INFO: (9) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.323972ms)
    Dec  3 13:10:22.409: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 10.333457ms)
    Dec  3 13:10:22.410: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 11.47262ms)
    Dec  3 13:10:22.411: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.212101ms)
    Dec  3 13:10:22.411: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.016919ms)
    Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 14.773122ms)
    Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.848459ms)
    Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.107084ms)
    Dec  3 13:10:22.414: INFO: (10) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.876021ms)
    Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 15.397463ms)
    Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.212018ms)
    Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.13664ms)
    Dec  3 13:10:22.415: INFO: (10) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.20674ms)
    Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 16.65821ms)
    Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.761479ms)
    Dec  3 13:10:22.416: INFO: (10) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 16.637606ms)
    Dec  3 13:10:22.417: INFO: (10) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 18.373759ms)
    Dec  3 13:10:22.423: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 5.199576ms)
    Dec  3 13:10:22.423: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 5.675952ms)
    Dec  3 13:10:22.425: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.972194ms)
    Dec  3 13:10:22.425: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 7.180465ms)
    Dec  3 13:10:22.427: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.045098ms)
    Dec  3 13:10:22.428: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 10.22265ms)
    Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 10.626352ms)
    Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 11.150448ms)
    Dec  3 13:10:22.429: INFO: (11) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.297081ms)
    Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 12.686343ms)
    Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 13.391348ms)
    Dec  3 13:10:22.431: INFO: (11) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.057395ms)
    Dec  3 13:10:22.433: INFO: (11) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.654038ms)
    Dec  3 13:10:22.433: INFO: (11) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.317207ms)
    Dec  3 13:10:22.434: INFO: (11) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 15.481054ms)
    Dec  3 13:10:22.434: INFO: (11) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.017971ms)
    Dec  3 13:10:22.442: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 7.684531ms)
    Dec  3 13:10:22.446: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 11.562108ms)
    Dec  3 13:10:22.446: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 11.961673ms)
    Dec  3 13:10:22.447: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.605898ms)
    Dec  3 13:10:22.447: INFO: (12) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 12.489366ms)
    Dec  3 13:10:22.448: INFO: (12) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 13.679767ms)
    Dec  3 13:10:22.448: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.649718ms)
    Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 14.260598ms)
    Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 14.069069ms)
    Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 13.821203ms)
    Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 14.023498ms)
    Dec  3 13:10:22.449: INFO: (12) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.4719ms)
    Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 16.846276ms)
    Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.240673ms)
    Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.406802ms)
    Dec  3 13:10:22.452: INFO: (12) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.18448ms)
    Dec  3 13:10:22.463: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 10.194384ms)
    Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 14.764089ms)
    Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 14.652264ms)
    Dec  3 13:10:22.467: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.97851ms)
    Dec  3 13:10:22.468: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 15.104981ms)
    Dec  3 13:10:22.468: INFO: (13) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 15.314202ms)
    Dec  3 13:10:22.469: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.812622ms)
    Dec  3 13:10:22.469: INFO: (13) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 16.401958ms)
    Dec  3 13:10:22.470: INFO: (13) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.688254ms)
    Dec  3 13:10:22.470: INFO: (13) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.186406ms)
    Dec  3 13:10:22.471: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 18.398713ms)
    Dec  3 13:10:22.471: INFO: (13) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 18.68431ms)
    Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 18.983906ms)
    Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 19.054636ms)
    Dec  3 13:10:22.472: INFO: (13) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 19.583077ms)
    Dec  3 13:10:22.473: INFO: (13) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 21.217885ms)
    Dec  3 13:10:22.479: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 5.29694ms)
    Dec  3 13:10:22.479: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.920758ms)
    Dec  3 13:10:22.480: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 6.118865ms)
    Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 9.065953ms)
    Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 8.945778ms)
    Dec  3 13:10:22.483: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 8.944845ms)
    Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 10.451662ms)
    Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 10.983904ms)
    Dec  3 13:10:22.485: INFO: (14) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.072017ms)
    Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 11.580781ms)
    Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 12.903693ms)
    Dec  3 13:10:22.486: INFO: (14) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 12.790272ms)
    Dec  3 13:10:22.487: INFO: (14) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 13.202759ms)
    Dec  3 13:10:22.488: INFO: (14) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 14.185339ms)
    Dec  3 13:10:22.488: INFO: (14) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 14.030791ms)
    Dec  3 13:10:22.490: INFO: (14) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 15.861354ms)
    Dec  3 13:10:22.498: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 8.024776ms)
    Dec  3 13:10:22.502: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.790588ms)
    Dec  3 13:10:22.503: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.190252ms)
    Dec  3 13:10:22.503: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.366951ms)
    Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 12.854399ms)
    Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.735524ms)
    Dec  3 13:10:22.504: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 12.813083ms)
    Dec  3 13:10:22.509: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 17.578625ms)
    Dec  3 13:10:22.510: INFO: (15) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 18.871373ms)
    Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 20.772921ms)
    Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 21.940954ms)
    Dec  3 13:10:22.512: INFO: (15) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 21.620336ms)
    Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 23.233854ms)
    Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 22.878538ms)
    Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 23.69064ms)
    Dec  3 13:10:22.514: INFO: (15) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 23.018581ms)
    Dec  3 13:10:22.529: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.429914ms)
    Dec  3 13:10:22.529: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 14.564383ms)
    Dec  3 13:10:22.530: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 15.605888ms)
    Dec  3 13:10:22.531: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 16.40195ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 16.997821ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 17.304143ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.863287ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 17.409245ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 17.125606ms)
    Dec  3 13:10:22.532: INFO: (16) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 17.965401ms)
    Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 17.537987ms)
    Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 17.675374ms)
    Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.948124ms)
    Dec  3 13:10:22.533: INFO: (16) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 18.882173ms)
    Dec  3 13:10:22.534: INFO: (16) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 18.713369ms)
    Dec  3 13:10:22.534: INFO: (16) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 19.021275ms)
    Dec  3 13:10:22.539: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.178935ms)
    Dec  3 13:10:22.541: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 6.860896ms)
    Dec  3 13:10:22.542: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 7.820985ms)
    Dec  3 13:10:22.542: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 7.398026ms)
    Dec  3 13:10:22.543: INFO: (17) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 8.985963ms)
    Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 10.262042ms)
    Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 10.99966ms)
    Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 10.604252ms)
    Dec  3 13:10:22.545: INFO: (17) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 11.134645ms)
    Dec  3 13:10:22.547: INFO: (17) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 12.000959ms)
    Dec  3 13:10:22.547: INFO: (17) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 12.726324ms)
    Dec  3 13:10:22.548: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 13.341303ms)
    Dec  3 13:10:22.548: INFO: (17) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 13.616748ms)
    Dec  3 13:10:22.549: INFO: (17) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 14.736214ms)
    Dec  3 13:10:22.549: INFO: (17) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 14.783438ms)
    Dec  3 13:10:22.550: INFO: (17) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 15.791026ms)
    Dec  3 13:10:22.556: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 5.70859ms)
    Dec  3 13:10:22.558: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 7.910554ms)
    Dec  3 13:10:22.565: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 14.751067ms)
    Dec  3 13:10:22.565: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 14.937085ms)
    Dec  3 13:10:22.566: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 15.526975ms)
    Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.468555ms)
    Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.312937ms)
    Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 17.623217ms)
    Dec  3 13:10:22.568: INFO: (18) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 17.937684ms)
    Dec  3 13:10:22.569: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 18.577207ms)
    Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 19.488572ms)
    Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 19.374684ms)
    Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 20.204797ms)
    Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 20.218142ms)
    Dec  3 13:10:22.570: INFO: (18) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 19.778865ms)
    Dec  3 13:10:22.571: INFO: (18) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 20.250081ms)
    Dec  3 13:10:22.576: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld/proxy/rewriteme">test</a> (200; 5.255642ms)
    Dec  3 13:10:22.577: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:1080/proxy/rewriteme">... (200; 6.534068ms)
    Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:462/proxy/: tls qux (200; 10.20486ms)
    Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.599193ms)
    Dec  3 13:10:22.581: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:160/proxy/: foo (200; 9.891988ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:443/proxy/tlsrewritem... (200; 16.048828ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname2/proxy/: tls qux (200; 16.745801ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.604438ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/http:proxy-service-zws7g-lvxld:162/proxy/: bar (200; 16.693427ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/: <a href="/api/v1/namespaces/proxy-5167/pods/proxy-service-zws7g-lvxld:1080/proxy/rewriteme">test<... (200; 16.99749ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/services/https:proxy-service-zws7g:tlsportname1/proxy/: tls baz (200; 16.714069ms)
    Dec  3 13:10:22.588: INFO: (19) /api/v1/namespaces/proxy-5167/pods/https:proxy-service-zws7g-lvxld:460/proxy/: tls baz (200; 16.884604ms)
    Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname2/proxy/: bar (200; 17.135093ms)
    Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname2/proxy/: bar (200; 17.192329ms)
    Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/http:proxy-service-zws7g:portname1/proxy/: foo (200; 17.236437ms)
    Dec  3 13:10:22.589: INFO: (19) /api/v1/namespaces/proxy-5167/services/proxy-service-zws7g:portname1/proxy/: foo (200; 17.921488ms)
    STEP: deleting ReplicationController proxy-service-zws7g in namespace proxy-5167, will wait for the garbage collector to delete the pods 12/03/22 13:10:22.589
    Dec  3 13:10:22.654: INFO: Deleting ReplicationController proxy-service-zws7g took: 10.760878ms
    Dec  3 13:10:22.755: INFO: Terminating ReplicationController proxy-service-zws7g pods took: 100.640639ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec  3 13:10:24.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-5167" for this suite. 12/03/22 13:10:24.97
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:24.989
Dec  3 13:10:24.989: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:10:24.996
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:25.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:25.037
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-80279807-78ca-4cc8-bd2c-f8e1e8441b5d 12/03/22 13:10:25.044
STEP: Creating the pod 12/03/22 13:10:25.049
Dec  3 13:10:25.060: INFO: Waiting up to 5m0s for pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01" in namespace "configmap-5898" to be "running and ready"
Dec  3 13:10:25.068: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01": Phase="Pending", Reason="", readiness=false. Elapsed: 7.443047ms
Dec  3 13:10:25.068: INFO: The phase of Pod pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:10:27.073: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01": Phase="Running", Reason="", readiness=true. Elapsed: 2.012721747s
Dec  3 13:10:27.073: INFO: The phase of Pod pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01 is Running (Ready = true)
Dec  3 13:10:27.073: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-80279807-78ca-4cc8-bd2c-f8e1e8441b5d 12/03/22 13:10:27.084
STEP: waiting to observe update in volume 12/03/22 13:10:27.09
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:10:29.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5898" for this suite. 12/03/22 13:10:29.119
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":227,"skipped":4317,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:24.989
    Dec  3 13:10:24.989: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:10:24.996
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:25.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:25.037
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-80279807-78ca-4cc8-bd2c-f8e1e8441b5d 12/03/22 13:10:25.044
    STEP: Creating the pod 12/03/22 13:10:25.049
    Dec  3 13:10:25.060: INFO: Waiting up to 5m0s for pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01" in namespace "configmap-5898" to be "running and ready"
    Dec  3 13:10:25.068: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01": Phase="Pending", Reason="", readiness=false. Elapsed: 7.443047ms
    Dec  3 13:10:25.068: INFO: The phase of Pod pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:10:27.073: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01": Phase="Running", Reason="", readiness=true. Elapsed: 2.012721747s
    Dec  3 13:10:27.073: INFO: The phase of Pod pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01 is Running (Ready = true)
    Dec  3 13:10:27.073: INFO: Pod "pod-configmaps-8afa85a1-945e-4ed3-a60e-aa2ce01baa01" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-80279807-78ca-4cc8-bd2c-f8e1e8441b5d 12/03/22 13:10:27.084
    STEP: waiting to observe update in volume 12/03/22 13:10:27.09
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:10:29.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5898" for this suite. 12/03/22 13:10:29.119
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:29.13
Dec  3 13:10:29.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 13:10:29.134
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:29.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:29.171
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:10:29.212
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:10:29.222
Dec  3 13:10:29.229: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:29.230: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:29.236: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:10:29.236: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:10:30.240: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:30.241: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:30.246: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:10:30.246: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:10:31.244: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:31.244: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:10:31.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:10:31.247: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 12/03/22 13:10:31.251
Dec  3 13:10:31.256: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 12/03/22 13:10:31.256
Dec  3 13:10:31.267: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 12/03/22 13:10:31.268
Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: ADDED
Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.271: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.271: INFO: Found daemon set daemon-set in namespace daemonsets-1219 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec  3 13:10:31.271: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 12/03/22 13:10:31.271
STEP: watching for the daemon set status to be patched 12/03/22 13:10:31.28
Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: ADDED
Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.283: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.283: INFO: Observed daemon set daemon-set in namespace daemonsets-1219 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec  3 13:10:31.283: INFO: Observed &DaemonSet event: MODIFIED
Dec  3 13:10:31.283: INFO: Found daemon set daemon-set in namespace daemonsets-1219 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Dec  3 13:10:31.283: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:10:31.285
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1219, will wait for the garbage collector to delete the pods 12/03/22 13:10:31.286
Dec  3 13:10:31.350: INFO: Deleting DaemonSet.extensions daemon-set took: 10.135836ms
Dec  3 13:10:31.451: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.173693ms
Dec  3 13:10:34.058: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:10:34.058: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 13:10:34.072: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30668"},"items":null}

Dec  3 13:10:34.081: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30668"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:10:34.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1219" for this suite. 12/03/22 13:10:34.131
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":228,"skipped":4317,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.012 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:29.13
    Dec  3 13:10:29.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 13:10:29.134
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:29.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:29.171
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 12/03/22 13:10:29.212
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:10:29.222
    Dec  3 13:10:29.229: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:29.230: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:29.236: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:10:29.236: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:10:30.240: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:30.241: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:30.246: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:10:30.246: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:10:31.244: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:31.244: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:10:31.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:10:31.247: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 12/03/22 13:10:31.251
    Dec  3 13:10:31.256: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 12/03/22 13:10:31.256
    Dec  3 13:10:31.267: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 12/03/22 13:10:31.268
    Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: ADDED
    Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.270: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.271: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.271: INFO: Found daemon set daemon-set in namespace daemonsets-1219 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec  3 13:10:31.271: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 12/03/22 13:10:31.271
    STEP: watching for the daemon set status to be patched 12/03/22 13:10:31.28
    Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: ADDED
    Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.282: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.283: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.283: INFO: Observed daemon set daemon-set in namespace daemonsets-1219 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec  3 13:10:31.283: INFO: Observed &DaemonSet event: MODIFIED
    Dec  3 13:10:31.283: INFO: Found daemon set daemon-set in namespace daemonsets-1219 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Dec  3 13:10:31.283: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:10:31.285
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1219, will wait for the garbage collector to delete the pods 12/03/22 13:10:31.286
    Dec  3 13:10:31.350: INFO: Deleting DaemonSet.extensions daemon-set took: 10.135836ms
    Dec  3 13:10:31.451: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.173693ms
    Dec  3 13:10:34.058: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:10:34.058: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 13:10:34.072: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30668"},"items":null}

    Dec  3 13:10:34.081: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30668"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:10:34.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1219" for this suite. 12/03/22 13:10:34.131
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:34.143
Dec  3 13:10:34.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:10:34.144
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:34.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:34.167
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:10:34.172
Dec  3 13:10:34.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7" in namespace "projected-8758" to be "Succeeded or Failed"
Dec  3 13:10:34.192: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.415969ms
Dec  3 13:10:36.197: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014747217s
Dec  3 13:10:38.198: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015147041s
STEP: Saw pod success 12/03/22 13:10:38.198
Dec  3 13:10:38.198: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7" satisfied condition "Succeeded or Failed"
Dec  3 13:10:38.203: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 container client-container: <nil>
STEP: delete the pod 12/03/22 13:10:38.212
Dec  3 13:10:38.224: INFO: Waiting for pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 to disappear
Dec  3 13:10:38.227: INFO: Pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:10:38.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8758" for this suite. 12/03/22 13:10:38.232
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":229,"skipped":4318,"failed":0}
------------------------------
â€¢ [4.096 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:34.143
    Dec  3 13:10:34.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:10:34.144
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:34.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:34.167
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:10:34.172
    Dec  3 13:10:34.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7" in namespace "projected-8758" to be "Succeeded or Failed"
    Dec  3 13:10:34.192: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.415969ms
    Dec  3 13:10:36.197: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014747217s
    Dec  3 13:10:38.198: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015147041s
    STEP: Saw pod success 12/03/22 13:10:38.198
    Dec  3 13:10:38.198: INFO: Pod "downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:38.203: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:10:38.212
    Dec  3 13:10:38.224: INFO: Waiting for pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 to disappear
    Dec  3 13:10:38.227: INFO: Pod downwardapi-volume-da2449b3-6ceb-4139-b116-19f843b4bae7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:10:38.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8758" for this suite. 12/03/22 13:10:38.232
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:38.241
Dec  3 13:10:38.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:10:38.242
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:38.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:38.272
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-69458121-6458-4b37-823f-35f394db7c14 12/03/22 13:10:38.275
STEP: Creating a pod to test consume secrets 12/03/22 13:10:38.281
Dec  3 13:10:38.294: INFO: Waiting up to 5m0s for pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3" in namespace "secrets-2055" to be "Succeeded or Failed"
Dec  3 13:10:38.299: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.656558ms
Dec  3 13:10:40.304: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010045059s
Dec  3 13:10:42.303: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008879289s
STEP: Saw pod success 12/03/22 13:10:42.303
Dec  3 13:10:42.303: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3" satisfied condition "Succeeded or Failed"
Dec  3 13:10:42.308: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:10:42.316
Dec  3 13:10:42.328: INFO: Waiting for pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 to disappear
Dec  3 13:10:42.331: INFO: Pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:10:42.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2055" for this suite. 12/03/22 13:10:42.335
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":230,"skipped":4318,"failed":0}
------------------------------
â€¢ [4.104 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:38.241
    Dec  3 13:10:38.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:10:38.242
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:38.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:38.272
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-69458121-6458-4b37-823f-35f394db7c14 12/03/22 13:10:38.275
    STEP: Creating a pod to test consume secrets 12/03/22 13:10:38.281
    Dec  3 13:10:38.294: INFO: Waiting up to 5m0s for pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3" in namespace "secrets-2055" to be "Succeeded or Failed"
    Dec  3 13:10:38.299: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.656558ms
    Dec  3 13:10:40.304: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010045059s
    Dec  3 13:10:42.303: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008879289s
    STEP: Saw pod success 12/03/22 13:10:42.303
    Dec  3 13:10:42.303: INFO: Pod "pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:42.308: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:10:42.316
    Dec  3 13:10:42.328: INFO: Waiting for pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 to disappear
    Dec  3 13:10:42.331: INFO: Pod pod-secrets-de37f83a-accb-4c7d-8072-9411ffe876f3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:10:42.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2055" for this suite. 12/03/22 13:10:42.335
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:42.348
Dec  3 13:10:42.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:10:42.353
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:42.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:42.386
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:10:42.394
Dec  3 13:10:42.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b" in namespace "downward-api-2760" to be "Succeeded or Failed"
Dec  3 13:10:42.413: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.325322ms
Dec  3 13:10:44.419: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014596641s
Dec  3 13:10:46.417: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01244975s
STEP: Saw pod success 12/03/22 13:10:46.417
Dec  3 13:10:46.417: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b" satisfied condition "Succeeded or Failed"
Dec  3 13:10:46.422: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b container client-container: <nil>
STEP: delete the pod 12/03/22 13:10:46.43
Dec  3 13:10:46.444: INFO: Waiting for pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b to disappear
Dec  3 13:10:46.448: INFO: Pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:10:46.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2760" for this suite. 12/03/22 13:10:46.453
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":231,"skipped":4329,"failed":0}
------------------------------
â€¢ [4.116 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:42.348
    Dec  3 13:10:42.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:10:42.353
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:42.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:42.386
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:10:42.394
    Dec  3 13:10:42.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b" in namespace "downward-api-2760" to be "Succeeded or Failed"
    Dec  3 13:10:42.413: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.325322ms
    Dec  3 13:10:44.419: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014596641s
    Dec  3 13:10:46.417: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01244975s
    STEP: Saw pod success 12/03/22 13:10:46.417
    Dec  3 13:10:46.417: INFO: Pod "downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:46.422: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b container client-container: <nil>
    STEP: delete the pod 12/03/22 13:10:46.43
    Dec  3 13:10:46.444: INFO: Waiting for pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b to disappear
    Dec  3 13:10:46.448: INFO: Pod downwardapi-volume-8c9f6b9e-693d-4762-ac72-dfd7d20d405b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:10:46.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2760" for this suite. 12/03/22 13:10:46.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:46.467
Dec  3 13:10:46.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:10:46.468
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:46.488
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:46.491
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 12/03/22 13:10:46.495
Dec  3 13:10:46.507: INFO: Waiting up to 5m0s for pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4" in namespace "emptydir-5307" to be "Succeeded or Failed"
Dec  3 13:10:46.511: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.683108ms
Dec  3 13:10:48.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009017851s
Dec  3 13:10:50.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008773528s
STEP: Saw pod success 12/03/22 13:10:50.516
Dec  3 13:10:50.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4" satisfied condition "Succeeded or Failed"
Dec  3 13:10:50.519: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 container test-container: <nil>
STEP: delete the pod 12/03/22 13:10:50.527
Dec  3 13:10:50.545: INFO: Waiting for pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 to disappear
Dec  3 13:10:50.552: INFO: Pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:10:50.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5307" for this suite. 12/03/22 13:10:50.556
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":232,"skipped":4336,"failed":0}
------------------------------
â€¢ [4.097 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:46.467
    Dec  3 13:10:46.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:10:46.468
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:46.488
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:46.491
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/03/22 13:10:46.495
    Dec  3 13:10:46.507: INFO: Waiting up to 5m0s for pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4" in namespace "emptydir-5307" to be "Succeeded or Failed"
    Dec  3 13:10:46.511: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.683108ms
    Dec  3 13:10:48.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009017851s
    Dec  3 13:10:50.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008773528s
    STEP: Saw pod success 12/03/22 13:10:50.516
    Dec  3 13:10:50.516: INFO: Pod "pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4" satisfied condition "Succeeded or Failed"
    Dec  3 13:10:50.519: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:10:50.527
    Dec  3 13:10:50.545: INFO: Waiting for pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 to disappear
    Dec  3 13:10:50.552: INFO: Pod pod-c0d8f69b-5ea9-462c-be49-8d5b046dd2f4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:10:50.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5307" for this suite. 12/03/22 13:10:50.556
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:50.567
Dec  3 13:10:50.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename proxy 12/03/22 13:10:50.568
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:50.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:50.601
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Dec  3 13:10:50.604: INFO: Creating pod...
Dec  3 13:10:50.615: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2439" to be "running"
Dec  3 13:10:50.620: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291267ms
Dec  3 13:10:52.624: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.008828667s
Dec  3 13:10:52.624: INFO: Pod "agnhost" satisfied condition "running"
Dec  3 13:10:52.624: INFO: Creating service...
Dec  3 13:10:52.643: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=DELETE
Dec  3 13:10:52.656: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec  3 13:10:52.656: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=OPTIONS
Dec  3 13:10:52.663: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec  3 13:10:52.663: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=PATCH
Dec  3 13:10:52.669: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec  3 13:10:52.669: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=POST
Dec  3 13:10:52.676: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec  3 13:10:52.676: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=PUT
Dec  3 13:10:52.681: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec  3 13:10:52.681: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=DELETE
Dec  3 13:10:52.688: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec  3 13:10:52.688: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=OPTIONS
Dec  3 13:10:52.696: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec  3 13:10:52.697: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=PATCH
Dec  3 13:10:52.706: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec  3 13:10:52.706: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=POST
Dec  3 13:10:52.713: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec  3 13:10:52.714: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=PUT
Dec  3 13:10:52.721: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec  3 13:10:52.721: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=GET
Dec  3 13:10:52.727: INFO: http.Client request:GET StatusCode:301
Dec  3 13:10:52.727: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=GET
Dec  3 13:10:52.737: INFO: http.Client request:GET StatusCode:301
Dec  3 13:10:52.737: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=HEAD
Dec  3 13:10:52.744: INFO: http.Client request:HEAD StatusCode:301
Dec  3 13:10:52.744: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=HEAD
Dec  3 13:10:52.751: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec  3 13:10:52.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2439" for this suite. 12/03/22 13:10:52.758
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":233,"skipped":4359,"failed":0}
------------------------------
â€¢ [2.202 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:50.567
    Dec  3 13:10:50.567: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename proxy 12/03/22 13:10:50.568
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:50.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:50.601
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Dec  3 13:10:50.604: INFO: Creating pod...
    Dec  3 13:10:50.615: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2439" to be "running"
    Dec  3 13:10:50.620: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291267ms
    Dec  3 13:10:52.624: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.008828667s
    Dec  3 13:10:52.624: INFO: Pod "agnhost" satisfied condition "running"
    Dec  3 13:10:52.624: INFO: Creating service...
    Dec  3 13:10:52.643: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=DELETE
    Dec  3 13:10:52.656: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec  3 13:10:52.656: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=OPTIONS
    Dec  3 13:10:52.663: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec  3 13:10:52.663: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=PATCH
    Dec  3 13:10:52.669: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec  3 13:10:52.669: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=POST
    Dec  3 13:10:52.676: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec  3 13:10:52.676: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=PUT
    Dec  3 13:10:52.681: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec  3 13:10:52.681: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=DELETE
    Dec  3 13:10:52.688: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec  3 13:10:52.688: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Dec  3 13:10:52.696: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec  3 13:10:52.697: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=PATCH
    Dec  3 13:10:52.706: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec  3 13:10:52.706: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=POST
    Dec  3 13:10:52.713: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec  3 13:10:52.714: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=PUT
    Dec  3 13:10:52.721: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec  3 13:10:52.721: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=GET
    Dec  3 13:10:52.727: INFO: http.Client request:GET StatusCode:301
    Dec  3 13:10:52.727: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=GET
    Dec  3 13:10:52.737: INFO: http.Client request:GET StatusCode:301
    Dec  3 13:10:52.737: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/pods/agnhost/proxy?method=HEAD
    Dec  3 13:10:52.744: INFO: http.Client request:HEAD StatusCode:301
    Dec  3 13:10:52.744: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2439/services/e2e-proxy-test-service/proxy?method=HEAD
    Dec  3 13:10:52.751: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec  3 13:10:52.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2439" for this suite. 12/03/22 13:10:52.758
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:52.77
Dec  3 13:10:52.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename runtimeclass 12/03/22 13:10:52.771
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:52.797
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:52.81
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec  3 13:10:52.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2138" for this suite. 12/03/22 13:10:52.835
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":234,"skipped":4366,"failed":0}
------------------------------
â€¢ [0.073 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:52.77
    Dec  3 13:10:52.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename runtimeclass 12/03/22 13:10:52.771
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:52.797
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:52.81
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec  3 13:10:52.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2138" for this suite. 12/03/22 13:10:52.835
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:52.843
Dec  3 13:10:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename disruption 12/03/22 13:10:52.844
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:52.864
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:52.868
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 12/03/22 13:10:52.876
STEP: Waiting for all pods to be running 12/03/22 13:10:54.909
Dec  3 13:10:54.915: INFO: running pods: 0 < 3
Dec  3 13:10:56.921: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec  3 13:10:58.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3628" for this suite. 12/03/22 13:10:58.927
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":235,"skipped":4368,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.092 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:52.843
    Dec  3 13:10:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename disruption 12/03/22 13:10:52.844
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:52.864
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:52.868
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 12/03/22 13:10:52.876
    STEP: Waiting for all pods to be running 12/03/22 13:10:54.909
    Dec  3 13:10:54.915: INFO: running pods: 0 < 3
    Dec  3 13:10:56.921: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec  3 13:10:58.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3628" for this suite. 12/03/22 13:10:58.927
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:10:58.937
Dec  3 13:10:58.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:10:58.938
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:58.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:58.965
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-ece5bcd3-4418-4dc1-8c05-0d9f0ed9c7ee 12/03/22 13:10:58.971
STEP: Creating configMap with name cm-test-opt-upd-8c823da8-747d-4e84-ae75-8b30071a444f 12/03/22 13:10:58.977
STEP: Creating the pod 12/03/22 13:10:58.981
Dec  3 13:10:58.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0" in namespace "projected-2152" to be "running and ready"
Dec  3 13:10:58.997: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.757087ms
Dec  3 13:10:58.997: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:11:01.004: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011416329s
Dec  3 13:11:01.004: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:11:03.002: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.009127782s
Dec  3 13:11:03.002: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Running (Ready = true)
Dec  3 13:11:03.002: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-ece5bcd3-4418-4dc1-8c05-0d9f0ed9c7ee 12/03/22 13:11:03.033
STEP: Updating configmap cm-test-opt-upd-8c823da8-747d-4e84-ae75-8b30071a444f 12/03/22 13:11:03.043
STEP: Creating configMap with name cm-test-opt-create-ebff77f9-c644-49cf-a9c1-6f45165b4ab2 12/03/22 13:11:03.047
STEP: waiting to observe update in volume 12/03/22 13:11:03.053
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:12:27.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2152" for this suite. 12/03/22 13:12:27.511
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":236,"skipped":4391,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.587 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:10:58.937
    Dec  3 13:10:58.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:10:58.938
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:10:58.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:10:58.965
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-ece5bcd3-4418-4dc1-8c05-0d9f0ed9c7ee 12/03/22 13:10:58.971
    STEP: Creating configMap with name cm-test-opt-upd-8c823da8-747d-4e84-ae75-8b30071a444f 12/03/22 13:10:58.977
    STEP: Creating the pod 12/03/22 13:10:58.981
    Dec  3 13:10:58.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0" in namespace "projected-2152" to be "running and ready"
    Dec  3 13:10:58.997: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.757087ms
    Dec  3 13:10:58.997: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:11:01.004: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011416329s
    Dec  3 13:11:01.004: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:11:03.002: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.009127782s
    Dec  3 13:11:03.002: INFO: The phase of Pod pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0 is Running (Ready = true)
    Dec  3 13:11:03.002: INFO: Pod "pod-projected-configmaps-227fa3ba-4b67-4fd8-9d6d-dd658b2150d0" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-ece5bcd3-4418-4dc1-8c05-0d9f0ed9c7ee 12/03/22 13:11:03.033
    STEP: Updating configmap cm-test-opt-upd-8c823da8-747d-4e84-ae75-8b30071a444f 12/03/22 13:11:03.043
    STEP: Creating configMap with name cm-test-opt-create-ebff77f9-c644-49cf-a9c1-6f45165b4ab2 12/03/22 13:11:03.047
    STEP: waiting to observe update in volume 12/03/22 13:11:03.053
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:12:27.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2152" for this suite. 12/03/22 13:12:27.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:12:27.525
Dec  3 13:12:27.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 13:12:27.526
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:27.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:27.556
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6785 12/03/22 13:12:27.559
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6785 12/03/22 13:12:27.573
Dec  3 13:12:27.590: INFO: Found 0 stateful pods, waiting for 1
Dec  3 13:12:37.601: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 12/03/22 13:12:37.611
STEP: updating a scale subresource 12/03/22 13:12:37.614
STEP: verifying the statefulset Spec.Replicas was modified 12/03/22 13:12:37.621
STEP: Patch a scale subresource 12/03/22 13:12:37.626
STEP: verifying the statefulset Spec.Replicas was modified 12/03/22 13:12:37.636
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 13:12:37.642: INFO: Deleting all statefulset in ns statefulset-6785
Dec  3 13:12:37.647: INFO: Scaling statefulset ss to 0
Dec  3 13:12:47.668: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:12:47.673: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 13:12:47.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6785" for this suite. 12/03/22 13:12:47.693
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":237,"skipped":4398,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.177 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:12:27.525
    Dec  3 13:12:27.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 13:12:27.526
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:27.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:27.556
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6785 12/03/22 13:12:27.559
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6785 12/03/22 13:12:27.573
    Dec  3 13:12:27.590: INFO: Found 0 stateful pods, waiting for 1
    Dec  3 13:12:37.601: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 12/03/22 13:12:37.611
    STEP: updating a scale subresource 12/03/22 13:12:37.614
    STEP: verifying the statefulset Spec.Replicas was modified 12/03/22 13:12:37.621
    STEP: Patch a scale subresource 12/03/22 13:12:37.626
    STEP: verifying the statefulset Spec.Replicas was modified 12/03/22 13:12:37.636
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 13:12:37.642: INFO: Deleting all statefulset in ns statefulset-6785
    Dec  3 13:12:37.647: INFO: Scaling statefulset ss to 0
    Dec  3 13:12:47.668: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:12:47.673: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 13:12:47.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6785" for this suite. 12/03/22 13:12:47.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:12:47.704
Dec  3 13:12:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-webhook 12/03/22 13:12:47.706
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:47.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:47.736
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/03/22 13:12:47.741
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/03/22 13:12:47.99
STEP: Deploying the custom resource conversion webhook pod 12/03/22 13:12:48
STEP: Wait for the deployment to be ready 12/03/22 13:12:48.018
Dec  3 13:12:48.029: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 12/03/22 13:12:50.044
STEP: Verifying the service has paired with the endpoint 12/03/22 13:12:50.063
Dec  3 13:12:51.064: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Dec  3 13:12:51.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Creating a v1 custom resource 12/03/22 13:12:53.736
STEP: Create a v2 custom resource 12/03/22 13:12:53.759
STEP: List CRs in v1 12/03/22 13:12:53.812
STEP: List CRs in v2 12/03/22 13:12:53.818
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:12:54.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6032" for this suite. 12/03/22 13:12:54.344
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":238,"skipped":4408,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.700 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:12:47.704
    Dec  3 13:12:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-webhook 12/03/22 13:12:47.706
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:47.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:47.736
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/03/22 13:12:47.741
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/03/22 13:12:47.99
    STEP: Deploying the custom resource conversion webhook pod 12/03/22 13:12:48
    STEP: Wait for the deployment to be ready 12/03/22 13:12:48.018
    Dec  3 13:12:48.029: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 12/03/22 13:12:50.044
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:12:50.063
    Dec  3 13:12:51.064: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Dec  3 13:12:51.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Creating a v1 custom resource 12/03/22 13:12:53.736
    STEP: Create a v2 custom resource 12/03/22 13:12:53.759
    STEP: List CRs in v1 12/03/22 13:12:53.812
    STEP: List CRs in v2 12/03/22 13:12:53.818
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:12:54.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6032" for this suite. 12/03/22 13:12:54.344
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:12:54.405
Dec  3 13:12:54.406: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:12:54.406
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:54.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:54.441
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-3173 12/03/22 13:12:54.444
STEP: creating service affinity-nodeport in namespace services-3173 12/03/22 13:12:54.444
STEP: creating replication controller affinity-nodeport in namespace services-3173 12/03/22 13:12:54.464
I1203 13:12:54.473138      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-3173, replica count: 3
I1203 13:12:57.523768      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:13:00.523949      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:13:00.536: INFO: Creating new exec pod
Dec  3 13:13:00.544: INFO: Waiting up to 5m0s for pod "execpod-affinityn2dcp" in namespace "services-3173" to be "running"
Dec  3 13:13:00.555: INFO: Pod "execpod-affinityn2dcp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065539ms
Dec  3 13:13:02.560: INFO: Pod "execpod-affinityn2dcp": Phase="Running", Reason="", readiness=true. Elapsed: 2.01555582s
Dec  3 13:13:02.560: INFO: Pod "execpod-affinityn2dcp" satisfied condition "running"
Dec  3 13:13:03.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Dec  3 13:13:03.759: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Dec  3 13:13:03.759: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:03.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.241 80'
Dec  3 13:13:03.941: INFO: stderr: "+ + ncecho -v -t hostName\n -w 2 10.152.183.241 80\nConnection to 10.152.183.241 80 port [tcp/http] succeeded!\n"
Dec  3 13:13:03.941: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:03.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 31049'
Dec  3 13:13:04.157: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 172.31.4.162 31049\nConnection to 172.31.4.162 31049 port [tcp/*] succeeded!\n"
Dec  3 13:13:04.157: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:04.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31049'
Dec  3 13:13:04.376: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 172.31.38.234 31049\nConnection to 172.31.38.234 31049 port [tcp/*] succeeded!\n"
Dec  3 13:13:04.376: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:04.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:31049/ ; done'
Dec  3 13:13:04.635: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n"
Dec  3 13:13:04.636: INFO: stdout: "\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz"
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
Dec  3 13:13:04.636: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-3173, will wait for the garbage collector to delete the pods 12/03/22 13:13:04.652
Dec  3 13:13:04.718: INFO: Deleting ReplicationController affinity-nodeport took: 9.651984ms
Dec  3 13:13:04.819: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.392923ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:13:06.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3173" for this suite. 12/03/22 13:13:06.947
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":239,"skipped":4428,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.551 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:12:54.405
    Dec  3 13:12:54.406: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:12:54.406
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:12:54.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:12:54.441
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-3173 12/03/22 13:12:54.444
    STEP: creating service affinity-nodeport in namespace services-3173 12/03/22 13:12:54.444
    STEP: creating replication controller affinity-nodeport in namespace services-3173 12/03/22 13:12:54.464
    I1203 13:12:54.473138      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-3173, replica count: 3
    I1203 13:12:57.523768      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:13:00.523949      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:13:00.536: INFO: Creating new exec pod
    Dec  3 13:13:00.544: INFO: Waiting up to 5m0s for pod "execpod-affinityn2dcp" in namespace "services-3173" to be "running"
    Dec  3 13:13:00.555: INFO: Pod "execpod-affinityn2dcp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065539ms
    Dec  3 13:13:02.560: INFO: Pod "execpod-affinityn2dcp": Phase="Running", Reason="", readiness=true. Elapsed: 2.01555582s
    Dec  3 13:13:02.560: INFO: Pod "execpod-affinityn2dcp" satisfied condition "running"
    Dec  3 13:13:03.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Dec  3 13:13:03.759: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Dec  3 13:13:03.759: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:03.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.241 80'
    Dec  3 13:13:03.941: INFO: stderr: "+ + ncecho -v -t hostName\n -w 2 10.152.183.241 80\nConnection to 10.152.183.241 80 port [tcp/http] succeeded!\n"
    Dec  3 13:13:03.941: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:03.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 31049'
    Dec  3 13:13:04.157: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 172.31.4.162 31049\nConnection to 172.31.4.162 31049 port [tcp/*] succeeded!\n"
    Dec  3 13:13:04.157: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:04.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31049'
    Dec  3 13:13:04.376: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 172.31.38.234 31049\nConnection to 172.31.38.234 31049 port [tcp/*] succeeded!\n"
    Dec  3 13:13:04.376: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:04.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3173 exec execpod-affinityn2dcp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:31049/ ; done'
    Dec  3 13:13:04.635: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:31049/\n"
    Dec  3 13:13:04.636: INFO: stdout: "\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz\naffinity-nodeport-mg4nz"
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Received response from host: affinity-nodeport-mg4nz
    Dec  3 13:13:04.636: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-3173, will wait for the garbage collector to delete the pods 12/03/22 13:13:04.652
    Dec  3 13:13:04.718: INFO: Deleting ReplicationController affinity-nodeport took: 9.651984ms
    Dec  3 13:13:04.819: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.392923ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:13:06.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3173" for this suite. 12/03/22 13:13:06.947
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:06.957
Dec  3 13:13:06.957: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:13:06.958
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:06.979
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:06.982
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-cac0558e-aa91-4f00-bdbf-fed3c7c4646e 12/03/22 13:13:06.986
STEP: Creating a pod to test consume secrets 12/03/22 13:13:06.991
Dec  3 13:13:07.006: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc" in namespace "projected-8406" to be "Succeeded or Failed"
Dec  3 13:13:07.009: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.415696ms
Dec  3 13:13:09.016: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010364269s
Dec  3 13:13:11.014: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008561905s
STEP: Saw pod success 12/03/22 13:13:11.015
Dec  3 13:13:11.015: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc" satisfied condition "Succeeded or Failed"
Dec  3 13:13:11.021: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc container projected-secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:13:11.031
Dec  3 13:13:11.043: INFO: Waiting for pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc to disappear
Dec  3 13:13:11.046: INFO: Pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 13:13:11.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8406" for this suite. 12/03/22 13:13:11.051
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":240,"skipped":4452,"failed":0}
------------------------------
â€¢ [4.102 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:06.957
    Dec  3 13:13:06.957: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:13:06.958
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:06.979
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:06.982
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-cac0558e-aa91-4f00-bdbf-fed3c7c4646e 12/03/22 13:13:06.986
    STEP: Creating a pod to test consume secrets 12/03/22 13:13:06.991
    Dec  3 13:13:07.006: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc" in namespace "projected-8406" to be "Succeeded or Failed"
    Dec  3 13:13:07.009: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.415696ms
    Dec  3 13:13:09.016: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010364269s
    Dec  3 13:13:11.014: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008561905s
    STEP: Saw pod success 12/03/22 13:13:11.015
    Dec  3 13:13:11.015: INFO: Pod "pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc" satisfied condition "Succeeded or Failed"
    Dec  3 13:13:11.021: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:13:11.031
    Dec  3 13:13:11.043: INFO: Waiting for pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc to disappear
    Dec  3 13:13:11.046: INFO: Pod pod-projected-secrets-c12949cd-719c-49ab-92b5-339bfcc1c8bc no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 13:13:11.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8406" for this suite. 12/03/22 13:13:11.051
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:11.061
Dec  3 13:13:11.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:13:11.062
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:11.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:11.132
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 12/03/22 13:13:11.135
Dec  3 13:13:11.148: INFO: Waiting up to 5m0s for pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754" in namespace "downward-api-5697" to be "Succeeded or Failed"
Dec  3 13:13:11.152: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Pending", Reason="", readiness=false. Elapsed: 4.323979ms
Dec  3 13:13:13.157: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00929851s
Dec  3 13:13:15.160: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012119842s
STEP: Saw pod success 12/03/22 13:13:15.16
Dec  3 13:13:15.160: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754" satisfied condition "Succeeded or Failed"
Dec  3 13:13:15.166: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 container dapi-container: <nil>
STEP: delete the pod 12/03/22 13:13:15.177
Dec  3 13:13:15.194: INFO: Waiting for pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 to disappear
Dec  3 13:13:15.199: INFO: Pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec  3 13:13:15.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5697" for this suite. 12/03/22 13:13:15.204
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":241,"skipped":4455,"failed":0}
------------------------------
â€¢ [4.154 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:11.061
    Dec  3 13:13:11.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:13:11.062
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:11.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:11.132
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 12/03/22 13:13:11.135
    Dec  3 13:13:11.148: INFO: Waiting up to 5m0s for pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754" in namespace "downward-api-5697" to be "Succeeded or Failed"
    Dec  3 13:13:11.152: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Pending", Reason="", readiness=false. Elapsed: 4.323979ms
    Dec  3 13:13:13.157: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00929851s
    Dec  3 13:13:15.160: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012119842s
    STEP: Saw pod success 12/03/22 13:13:15.16
    Dec  3 13:13:15.160: INFO: Pod "downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754" satisfied condition "Succeeded or Failed"
    Dec  3 13:13:15.166: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 13:13:15.177
    Dec  3 13:13:15.194: INFO: Waiting for pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 to disappear
    Dec  3 13:13:15.199: INFO: Pod downward-api-3e8ba880-8454-47cd-bed6-5edd50e38754 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec  3 13:13:15.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5697" for this suite. 12/03/22 13:13:15.204
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:15.216
Dec  3 13:13:15.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename gc 12/03/22 13:13:15.217
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:15.258
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:15.262
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 12/03/22 13:13:15.272
STEP: delete the rc 12/03/22 13:13:20.286
STEP: wait for the rc to be deleted 12/03/22 13:13:20.296
Dec  3 13:13:21.309: INFO: 80 pods remaining
Dec  3 13:13:21.309: INFO: 80 pods has nil DeletionTimestamp
Dec  3 13:13:21.309: INFO: 
Dec  3 13:13:22.307: INFO: 71 pods remaining
Dec  3 13:13:22.307: INFO: 71 pods has nil DeletionTimestamp
Dec  3 13:13:22.307: INFO: 
Dec  3 13:13:23.310: INFO: 60 pods remaining
Dec  3 13:13:23.310: INFO: 60 pods has nil DeletionTimestamp
Dec  3 13:13:23.310: INFO: 
Dec  3 13:13:24.306: INFO: 40 pods remaining
Dec  3 13:13:24.306: INFO: 40 pods has nil DeletionTimestamp
Dec  3 13:13:24.306: INFO: 
Dec  3 13:13:25.313: INFO: 32 pods remaining
Dec  3 13:13:25.313: INFO: 32 pods has nil DeletionTimestamp
Dec  3 13:13:25.313: INFO: 
Dec  3 13:13:26.304: INFO: 19 pods remaining
Dec  3 13:13:26.304: INFO: 19 pods has nil DeletionTimestamp
Dec  3 13:13:26.304: INFO: 
STEP: Gathering metrics 12/03/22 13:13:27.306
W1203 13:13:27.309788      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec  3 13:13:27.309: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec  3 13:13:27.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4595" for this suite. 12/03/22 13:13:27.313
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":242,"skipped":4470,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.105 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:15.216
    Dec  3 13:13:15.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename gc 12/03/22 13:13:15.217
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:15.258
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:15.262
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 12/03/22 13:13:15.272
    STEP: delete the rc 12/03/22 13:13:20.286
    STEP: wait for the rc to be deleted 12/03/22 13:13:20.296
    Dec  3 13:13:21.309: INFO: 80 pods remaining
    Dec  3 13:13:21.309: INFO: 80 pods has nil DeletionTimestamp
    Dec  3 13:13:21.309: INFO: 
    Dec  3 13:13:22.307: INFO: 71 pods remaining
    Dec  3 13:13:22.307: INFO: 71 pods has nil DeletionTimestamp
    Dec  3 13:13:22.307: INFO: 
    Dec  3 13:13:23.310: INFO: 60 pods remaining
    Dec  3 13:13:23.310: INFO: 60 pods has nil DeletionTimestamp
    Dec  3 13:13:23.310: INFO: 
    Dec  3 13:13:24.306: INFO: 40 pods remaining
    Dec  3 13:13:24.306: INFO: 40 pods has nil DeletionTimestamp
    Dec  3 13:13:24.306: INFO: 
    Dec  3 13:13:25.313: INFO: 32 pods remaining
    Dec  3 13:13:25.313: INFO: 32 pods has nil DeletionTimestamp
    Dec  3 13:13:25.313: INFO: 
    Dec  3 13:13:26.304: INFO: 19 pods remaining
    Dec  3 13:13:26.304: INFO: 19 pods has nil DeletionTimestamp
    Dec  3 13:13:26.304: INFO: 
    STEP: Gathering metrics 12/03/22 13:13:27.306
    W1203 13:13:27.309788      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec  3 13:13:27.309: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec  3 13:13:27.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4595" for this suite. 12/03/22 13:13:27.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:27.322
Dec  3 13:13:27.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:13:27.323
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:27.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:27.344
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-2409 12/03/22 13:13:27.348
STEP: creating service affinity-clusterip-transition in namespace services-2409 12/03/22 13:13:27.348
STEP: creating replication controller affinity-clusterip-transition in namespace services-2409 12/03/22 13:13:27.362
I1203 13:13:27.371805      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2409, replica count: 3
I1203 13:13:30.423506      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:13:33.424403      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:13:36.425099      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:13:39.426165      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 13:13:42.426976      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:13:42.438: INFO: Creating new exec pod
Dec  3 13:13:42.450: INFO: Waiting up to 5m0s for pod "execpod-affinityx6mdp" in namespace "services-2409" to be "running"
Dec  3 13:13:42.455: INFO: Pod "execpod-affinityx6mdp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.335881ms
Dec  3 13:13:44.461: INFO: Pod "execpod-affinityx6mdp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011415877s
Dec  3 13:13:44.461: INFO: Pod "execpod-affinityx6mdp" satisfied condition "running"
Dec  3 13:13:45.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Dec  3 13:13:45.656: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Dec  3 13:13:45.656: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:45.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
Dec  3 13:13:45.825: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
Dec  3 13:13:45.825: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:13:45.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
Dec  3 13:13:46.139: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
Dec  3 13:13:46.139: INFO: stdout: "\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj"
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
Dec  3 13:13:46.449: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
Dec  3 13:13:46.449: INFO: stdout: "\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj"
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
Dec  3 13:13:46.450: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2409, will wait for the garbage collector to delete the pods 12/03/22 13:13:46.463
Dec  3 13:13:46.528: INFO: Deleting ReplicationController affinity-clusterip-transition took: 8.946245ms
Dec  3 13:13:46.629: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.969686ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:13:48.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2409" for this suite. 12/03/22 13:13:48.455
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":243,"skipped":4495,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.141 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:27.322
    Dec  3 13:13:27.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:13:27.323
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:27.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:27.344
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-2409 12/03/22 13:13:27.348
    STEP: creating service affinity-clusterip-transition in namespace services-2409 12/03/22 13:13:27.348
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2409 12/03/22 13:13:27.362
    I1203 13:13:27.371805      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2409, replica count: 3
    I1203 13:13:30.423506      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:13:33.424403      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:13:36.425099      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:13:39.426165      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1203 13:13:42.426976      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:13:42.438: INFO: Creating new exec pod
    Dec  3 13:13:42.450: INFO: Waiting up to 5m0s for pod "execpod-affinityx6mdp" in namespace "services-2409" to be "running"
    Dec  3 13:13:42.455: INFO: Pod "execpod-affinityx6mdp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.335881ms
    Dec  3 13:13:44.461: INFO: Pod "execpod-affinityx6mdp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011415877s
    Dec  3 13:13:44.461: INFO: Pod "execpod-affinityx6mdp" satisfied condition "running"
    Dec  3 13:13:45.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Dec  3 13:13:45.656: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Dec  3 13:13:45.656: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:45.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
    Dec  3 13:13:45.825: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
    Dec  3 13:13:45.825: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:13:45.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
    Dec  3 13:13:46.139: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
    Dec  3 13:13:46.139: INFO: stdout: "\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-cg88q\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-7k695\naffinity-clusterip-transition-tktgj"
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-cg88q
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-7k695
    Dec  3 13:13:46.139: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-2409 exec execpod-affinityx6mdp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
    Dec  3 13:13:46.449: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
    Dec  3 13:13:46.449: INFO: stdout: "\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj\naffinity-clusterip-transition-tktgj"
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.449: INFO: Received response from host: affinity-clusterip-transition-tktgj
    Dec  3 13:13:46.450: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2409, will wait for the garbage collector to delete the pods 12/03/22 13:13:46.463
    Dec  3 13:13:46.528: INFO: Deleting ReplicationController affinity-clusterip-transition took: 8.946245ms
    Dec  3 13:13:46.629: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.969686ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:13:48.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2409" for this suite. 12/03/22 13:13:48.455
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:48.464
Dec  3 13:13:48.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:13:48.465
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:48.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:48.493
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:13:48.498
Dec  3 13:13:48.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052" in namespace "downward-api-2785" to be "Succeeded or Failed"
Dec  3 13:13:48.513: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801186ms
Dec  3 13:13:50.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010279509s
Dec  3 13:13:52.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00980334s
STEP: Saw pod success 12/03/22 13:13:52.518
Dec  3 13:13:52.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052" satisfied condition "Succeeded or Failed"
Dec  3 13:13:52.522: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 container client-container: <nil>
STEP: delete the pod 12/03/22 13:13:52.533
Dec  3 13:13:52.550: INFO: Waiting for pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 to disappear
Dec  3 13:13:52.555: INFO: Pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:13:52.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2785" for this suite. 12/03/22 13:13:52.559
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":244,"skipped":4504,"failed":0}
------------------------------
â€¢ [4.104 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:48.464
    Dec  3 13:13:48.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:13:48.465
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:48.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:48.493
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:13:48.498
    Dec  3 13:13:48.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052" in namespace "downward-api-2785" to be "Succeeded or Failed"
    Dec  3 13:13:48.513: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801186ms
    Dec  3 13:13:50.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010279509s
    Dec  3 13:13:52.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00980334s
    STEP: Saw pod success 12/03/22 13:13:52.518
    Dec  3 13:13:52.518: INFO: Pod "downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052" satisfied condition "Succeeded or Failed"
    Dec  3 13:13:52.522: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:13:52.533
    Dec  3 13:13:52.550: INFO: Waiting for pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 to disappear
    Dec  3 13:13:52.555: INFO: Pod downwardapi-volume-8f45e9d3-fccd-4309-b4d7-6ad3e49d2052 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:13:52.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2785" for this suite. 12/03/22 13:13:52.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:52.569
Dec  3 13:13:52.569: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:13:52.57
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:52.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:52.611
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Dec  3 13:13:52.635: INFO: Waiting up to 5m0s for pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86" in namespace "svcaccounts-4912" to be "running"
Dec  3 13:13:52.639: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.467487ms
Dec  3 13:13:54.643: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86": Phase="Running", Reason="", readiness=true. Elapsed: 2.007942463s
Dec  3 13:13:54.643: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86" satisfied condition "running"
STEP: reading a file in the container 12/03/22 13:13:54.643
Dec  3 13:13:54.644: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 12/03/22 13:13:54.814
Dec  3 13:13:54.814: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 12/03/22 13:13:54.974
Dec  3 13:13:54.975: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Dec  3 13:13:55.156: INFO: Got root ca configmap in namespace "svcaccounts-4912"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 13:13:55.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4912" for this suite. 12/03/22 13:13:55.164
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":245,"skipped":4510,"failed":0}
------------------------------
â€¢ [2.601 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:52.569
    Dec  3 13:13:52.569: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:13:52.57
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:52.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:52.611
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Dec  3 13:13:52.635: INFO: Waiting up to 5m0s for pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86" in namespace "svcaccounts-4912" to be "running"
    Dec  3 13:13:52.639: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.467487ms
    Dec  3 13:13:54.643: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86": Phase="Running", Reason="", readiness=true. Elapsed: 2.007942463s
    Dec  3 13:13:54.643: INFO: Pod "pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86" satisfied condition "running"
    STEP: reading a file in the container 12/03/22 13:13:54.643
    Dec  3 13:13:54.644: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 12/03/22 13:13:54.814
    Dec  3 13:13:54.814: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 12/03/22 13:13:54.974
    Dec  3 13:13:54.975: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4912 pod-service-account-ad2221cf-390e-461c-97d0-0ea2d4cd6e86 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Dec  3 13:13:55.156: INFO: Got root ca configmap in namespace "svcaccounts-4912"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 13:13:55.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4912" for this suite. 12/03/22 13:13:55.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:55.171
Dec  3 13:13:55.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:13:55.172
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:55.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:55.192
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-ebd8cbda-f15b-49ba-9f79-31517e5f3f08 12/03/22 13:13:55.194
STEP: Creating a pod to test consume configMaps 12/03/22 13:13:55.199
Dec  3 13:13:55.208: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b" in namespace "projected-7213" to be "Succeeded or Failed"
Dec  3 13:13:55.212: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.650194ms
Dec  3 13:13:57.216: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007774282s
Dec  3 13:13:59.217: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008405707s
STEP: Saw pod success 12/03/22 13:13:59.217
Dec  3 13:13:59.217: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b" satisfied condition "Succeeded or Failed"
Dec  3 13:13:59.221: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:13:59.23
Dec  3 13:13:59.243: INFO: Waiting for pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b to disappear
Dec  3 13:13:59.246: INFO: Pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:13:59.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7213" for this suite. 12/03/22 13:13:59.25
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":246,"skipped":4517,"failed":0}
------------------------------
â€¢ [4.087 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:55.171
    Dec  3 13:13:55.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:13:55.172
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:55.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:55.192
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-ebd8cbda-f15b-49ba-9f79-31517e5f3f08 12/03/22 13:13:55.194
    STEP: Creating a pod to test consume configMaps 12/03/22 13:13:55.199
    Dec  3 13:13:55.208: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b" in namespace "projected-7213" to be "Succeeded or Failed"
    Dec  3 13:13:55.212: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.650194ms
    Dec  3 13:13:57.216: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007774282s
    Dec  3 13:13:59.217: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008405707s
    STEP: Saw pod success 12/03/22 13:13:59.217
    Dec  3 13:13:59.217: INFO: Pod "pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b" satisfied condition "Succeeded or Failed"
    Dec  3 13:13:59.221: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:13:59.23
    Dec  3 13:13:59.243: INFO: Waiting for pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b to disappear
    Dec  3 13:13:59.246: INFO: Pod pod-projected-configmaps-ff0d9e34-40a6-4a29-9fbd-ed9de6085f0b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:13:59.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7213" for this suite. 12/03/22 13:13:59.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:13:59.264
Dec  3 13:13:59.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-runtime 12/03/22 13:13:59.265
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:59.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:59.297
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 12/03/22 13:13:59.3
STEP: wait for the container to reach Succeeded 12/03/22 13:13:59.311
STEP: get the container status 12/03/22 13:14:03.339
STEP: the container should be terminated 12/03/22 13:14:03.343
STEP: the termination message should be set 12/03/22 13:14:03.343
Dec  3 13:14:03.343: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 12/03/22 13:14:03.344
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec  3 13:14:03.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-175" for this suite. 12/03/22 13:14:03.366
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":247,"skipped":4564,"failed":0}
------------------------------
â€¢ [4.110 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:13:59.264
    Dec  3 13:13:59.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-runtime 12/03/22 13:13:59.265
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:13:59.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:13:59.297
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 12/03/22 13:13:59.3
    STEP: wait for the container to reach Succeeded 12/03/22 13:13:59.311
    STEP: get the container status 12/03/22 13:14:03.339
    STEP: the container should be terminated 12/03/22 13:14:03.343
    STEP: the termination message should be set 12/03/22 13:14:03.343
    Dec  3 13:14:03.343: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 12/03/22 13:14:03.344
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec  3 13:14:03.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-175" for this suite. 12/03/22 13:14:03.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:03.387
Dec  3 13:14:03.388: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-runtime 12/03/22 13:14:03.395
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:03.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:03.43
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 12/03/22 13:14:03.437
STEP: wait for the container to reach Succeeded 12/03/22 13:14:03.453
STEP: get the container status 12/03/22 13:14:07.485
STEP: the container should be terminated 12/03/22 13:14:07.49
STEP: the termination message should be set 12/03/22 13:14:07.49
Dec  3 13:14:07.490: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/03/22 13:14:07.49
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec  3 13:14:07.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6856" for this suite. 12/03/22 13:14:07.514
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":248,"skipped":4638,"failed":0}
------------------------------
â€¢ [4.132 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:03.387
    Dec  3 13:14:03.388: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-runtime 12/03/22 13:14:03.395
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:03.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:03.43
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 12/03/22 13:14:03.437
    STEP: wait for the container to reach Succeeded 12/03/22 13:14:03.453
    STEP: get the container status 12/03/22 13:14:07.485
    STEP: the container should be terminated 12/03/22 13:14:07.49
    STEP: the termination message should be set 12/03/22 13:14:07.49
    Dec  3 13:14:07.490: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/03/22 13:14:07.49
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec  3 13:14:07.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6856" for this suite. 12/03/22 13:14:07.514
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:07.521
Dec  3 13:14:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename events 12/03/22 13:14:07.522
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:07.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:07.55
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 12/03/22 13:14:07.554
Dec  3 13:14:07.559: INFO: created test-event-1
Dec  3 13:14:07.567: INFO: created test-event-2
Dec  3 13:14:07.576: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 12/03/22 13:14:07.576
STEP: delete collection of events 12/03/22 13:14:07.582
Dec  3 13:14:07.582: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/03/22 13:14:07.609
Dec  3 13:14:07.609: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec  3 13:14:07.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8974" for this suite. 12/03/22 13:14:07.616
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":249,"skipped":4649,"failed":0}
------------------------------
â€¢ [0.105 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:07.521
    Dec  3 13:14:07.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename events 12/03/22 13:14:07.522
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:07.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:07.55
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 12/03/22 13:14:07.554
    Dec  3 13:14:07.559: INFO: created test-event-1
    Dec  3 13:14:07.567: INFO: created test-event-2
    Dec  3 13:14:07.576: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 12/03/22 13:14:07.576
    STEP: delete collection of events 12/03/22 13:14:07.582
    Dec  3 13:14:07.582: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/03/22 13:14:07.609
    Dec  3 13:14:07.609: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec  3 13:14:07.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8974" for this suite. 12/03/22 13:14:07.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:07.628
Dec  3 13:14:07.629: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:14:07.629
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:07.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:07.658
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 12/03/22 13:14:07.663
Dec  3 13:14:07.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 create -f -'
Dec  3 13:14:08.600: INFO: stderr: ""
Dec  3 13:14:08.600: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 12/03/22 13:14:08.6
Dec  3 13:14:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 diff -f -'
Dec  3 13:14:09.706: INFO: rc: 1
Dec  3 13:14:09.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 delete -f -'
Dec  3 13:14:09.862: INFO: stderr: ""
Dec  3 13:14:09.862: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:14:09.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2189" for this suite. 12/03/22 13:14:09.871
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":250,"skipped":4672,"failed":0}
------------------------------
â€¢ [2.259 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:07.628
    Dec  3 13:14:07.629: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:14:07.629
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:07.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:07.658
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 12/03/22 13:14:07.663
    Dec  3 13:14:07.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 create -f -'
    Dec  3 13:14:08.600: INFO: stderr: ""
    Dec  3 13:14:08.600: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 12/03/22 13:14:08.6
    Dec  3 13:14:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 diff -f -'
    Dec  3 13:14:09.706: INFO: rc: 1
    Dec  3 13:14:09.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2189 delete -f -'
    Dec  3 13:14:09.862: INFO: stderr: ""
    Dec  3 13:14:09.862: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:14:09.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2189" for this suite. 12/03/22 13:14:09.871
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:09.888
Dec  3 13:14:09.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:14:09.889
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:09.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:09.926
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 12/03/22 13:14:09.928
STEP: fetching the ConfigMap 12/03/22 13:14:09.934
STEP: patching the ConfigMap 12/03/22 13:14:09.937
STEP: listing all ConfigMaps in all namespaces with a label selector 12/03/22 13:14:09.951
STEP: deleting the ConfigMap by collection with a label selector 12/03/22 13:14:09.958
STEP: listing all ConfigMaps in test namespace 12/03/22 13:14:09.968
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:14:09.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6192" for this suite. 12/03/22 13:14:09.984
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":251,"skipped":4684,"failed":0}
------------------------------
â€¢ [0.112 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:09.888
    Dec  3 13:14:09.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:14:09.889
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:09.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:09.926
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 12/03/22 13:14:09.928
    STEP: fetching the ConfigMap 12/03/22 13:14:09.934
    STEP: patching the ConfigMap 12/03/22 13:14:09.937
    STEP: listing all ConfigMaps in all namespaces with a label selector 12/03/22 13:14:09.951
    STEP: deleting the ConfigMap by collection with a label selector 12/03/22 13:14:09.958
    STEP: listing all ConfigMaps in test namespace 12/03/22 13:14:09.968
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:14:09.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6192" for this suite. 12/03/22 13:14:09.984
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:10.005
Dec  3 13:14:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:14:10.006
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:10.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:10.029
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-4f11a9e8-06b6-4bf6-91ed-e7b6196b4e14 12/03/22 13:14:10.041
STEP: Creating a pod to test consume secrets 12/03/22 13:14:10.057
Dec  3 13:14:10.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042" in namespace "projected-6430" to be "Succeeded or Failed"
Dec  3 13:14:10.073: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164487ms
Dec  3 13:14:12.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01006487s
Dec  3 13:14:14.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009648466s
STEP: Saw pod success 12/03/22 13:14:14.079
Dec  3 13:14:14.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042" satisfied condition "Succeeded or Failed"
Dec  3 13:14:14.084: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:14:14.092
Dec  3 13:14:14.116: INFO: Waiting for pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 to disappear
Dec  3 13:14:14.122: INFO: Pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 13:14:14.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6430" for this suite. 12/03/22 13:14:14.127
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":252,"skipped":4745,"failed":0}
------------------------------
â€¢ [4.132 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:10.005
    Dec  3 13:14:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:14:10.006
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:10.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:10.029
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-4f11a9e8-06b6-4bf6-91ed-e7b6196b4e14 12/03/22 13:14:10.041
    STEP: Creating a pod to test consume secrets 12/03/22 13:14:10.057
    Dec  3 13:14:10.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042" in namespace "projected-6430" to be "Succeeded or Failed"
    Dec  3 13:14:10.073: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164487ms
    Dec  3 13:14:12.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01006487s
    Dec  3 13:14:14.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009648466s
    STEP: Saw pod success 12/03/22 13:14:14.079
    Dec  3 13:14:14.079: INFO: Pod "pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042" satisfied condition "Succeeded or Failed"
    Dec  3 13:14:14.084: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:14:14.092
    Dec  3 13:14:14.116: INFO: Waiting for pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 to disappear
    Dec  3 13:14:14.122: INFO: Pod pod-projected-secrets-a62308e7-489d-4dd5-94ed-ad88258d2042 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 13:14:14.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6430" for this suite. 12/03/22 13:14:14.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:14.139
Dec  3 13:14:14.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename discovery 12/03/22 13:14:14.14
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.175
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 12/03/22 13:14:14.191
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Dec  3 13:14:14.577: INFO: Checking APIGroup: apiregistration.k8s.io
Dec  3 13:14:14.578: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Dec  3 13:14:14.578: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Dec  3 13:14:14.578: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Dec  3 13:14:14.578: INFO: Checking APIGroup: apps
Dec  3 13:14:14.579: INFO: PreferredVersion.GroupVersion: apps/v1
Dec  3 13:14:14.579: INFO: Versions found [{apps/v1 v1}]
Dec  3 13:14:14.579: INFO: apps/v1 matches apps/v1
Dec  3 13:14:14.579: INFO: Checking APIGroup: events.k8s.io
Dec  3 13:14:14.580: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Dec  3 13:14:14.580: INFO: Versions found [{events.k8s.io/v1 v1}]
Dec  3 13:14:14.580: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Dec  3 13:14:14.580: INFO: Checking APIGroup: authentication.k8s.io
Dec  3 13:14:14.582: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Dec  3 13:14:14.582: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Dec  3 13:14:14.582: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Dec  3 13:14:14.582: INFO: Checking APIGroup: authorization.k8s.io
Dec  3 13:14:14.584: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Dec  3 13:14:14.584: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Dec  3 13:14:14.584: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Dec  3 13:14:14.584: INFO: Checking APIGroup: autoscaling
Dec  3 13:14:14.585: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Dec  3 13:14:14.585: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Dec  3 13:14:14.585: INFO: autoscaling/v2 matches autoscaling/v2
Dec  3 13:14:14.585: INFO: Checking APIGroup: batch
Dec  3 13:14:14.587: INFO: PreferredVersion.GroupVersion: batch/v1
Dec  3 13:14:14.587: INFO: Versions found [{batch/v1 v1}]
Dec  3 13:14:14.587: INFO: batch/v1 matches batch/v1
Dec  3 13:14:14.587: INFO: Checking APIGroup: certificates.k8s.io
Dec  3 13:14:14.588: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Dec  3 13:14:14.588: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Dec  3 13:14:14.588: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Dec  3 13:14:14.588: INFO: Checking APIGroup: networking.k8s.io
Dec  3 13:14:14.589: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Dec  3 13:14:14.589: INFO: Versions found [{networking.k8s.io/v1 v1}]
Dec  3 13:14:14.589: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Dec  3 13:14:14.589: INFO: Checking APIGroup: policy
Dec  3 13:14:14.590: INFO: PreferredVersion.GroupVersion: policy/v1
Dec  3 13:14:14.590: INFO: Versions found [{policy/v1 v1}]
Dec  3 13:14:14.590: INFO: policy/v1 matches policy/v1
Dec  3 13:14:14.590: INFO: Checking APIGroup: rbac.authorization.k8s.io
Dec  3 13:14:14.591: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Dec  3 13:14:14.591: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Dec  3 13:14:14.591: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Dec  3 13:14:14.591: INFO: Checking APIGroup: storage.k8s.io
Dec  3 13:14:14.592: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Dec  3 13:14:14.592: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Dec  3 13:14:14.592: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Dec  3 13:14:14.592: INFO: Checking APIGroup: admissionregistration.k8s.io
Dec  3 13:14:14.594: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Dec  3 13:14:14.594: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Dec  3 13:14:14.594: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Dec  3 13:14:14.594: INFO: Checking APIGroup: apiextensions.k8s.io
Dec  3 13:14:14.595: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Dec  3 13:14:14.595: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Dec  3 13:14:14.595: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Dec  3 13:14:14.595: INFO: Checking APIGroup: scheduling.k8s.io
Dec  3 13:14:14.596: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Dec  3 13:14:14.596: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Dec  3 13:14:14.596: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Dec  3 13:14:14.596: INFO: Checking APIGroup: coordination.k8s.io
Dec  3 13:14:14.599: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Dec  3 13:14:14.599: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Dec  3 13:14:14.599: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Dec  3 13:14:14.599: INFO: Checking APIGroup: node.k8s.io
Dec  3 13:14:14.599: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Dec  3 13:14:14.599: INFO: Versions found [{node.k8s.io/v1 v1}]
Dec  3 13:14:14.599: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Dec  3 13:14:14.599: INFO: Checking APIGroup: discovery.k8s.io
Dec  3 13:14:14.600: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Dec  3 13:14:14.600: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Dec  3 13:14:14.600: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Dec  3 13:14:14.600: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Dec  3 13:14:14.601: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Dec  3 13:14:14.601: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Dec  3 13:14:14.601: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Dec  3 13:14:14.601: INFO: Checking APIGroup: metrics.k8s.io
Dec  3 13:14:14.602: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Dec  3 13:14:14.602: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Dec  3 13:14:14.602: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Dec  3 13:14:14.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-7842" for this suite. 12/03/22 13:14:14.608
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":253,"skipped":4753,"failed":0}
------------------------------
â€¢ [0.477 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:14.139
    Dec  3 13:14:14.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename discovery 12/03/22 13:14:14.14
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.175
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 12/03/22 13:14:14.191
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Dec  3 13:14:14.577: INFO: Checking APIGroup: apiregistration.k8s.io
    Dec  3 13:14:14.578: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Dec  3 13:14:14.578: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Dec  3 13:14:14.578: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Dec  3 13:14:14.578: INFO: Checking APIGroup: apps
    Dec  3 13:14:14.579: INFO: PreferredVersion.GroupVersion: apps/v1
    Dec  3 13:14:14.579: INFO: Versions found [{apps/v1 v1}]
    Dec  3 13:14:14.579: INFO: apps/v1 matches apps/v1
    Dec  3 13:14:14.579: INFO: Checking APIGroup: events.k8s.io
    Dec  3 13:14:14.580: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Dec  3 13:14:14.580: INFO: Versions found [{events.k8s.io/v1 v1}]
    Dec  3 13:14:14.580: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Dec  3 13:14:14.580: INFO: Checking APIGroup: authentication.k8s.io
    Dec  3 13:14:14.582: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Dec  3 13:14:14.582: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Dec  3 13:14:14.582: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Dec  3 13:14:14.582: INFO: Checking APIGroup: authorization.k8s.io
    Dec  3 13:14:14.584: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Dec  3 13:14:14.584: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Dec  3 13:14:14.584: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Dec  3 13:14:14.584: INFO: Checking APIGroup: autoscaling
    Dec  3 13:14:14.585: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Dec  3 13:14:14.585: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Dec  3 13:14:14.585: INFO: autoscaling/v2 matches autoscaling/v2
    Dec  3 13:14:14.585: INFO: Checking APIGroup: batch
    Dec  3 13:14:14.587: INFO: PreferredVersion.GroupVersion: batch/v1
    Dec  3 13:14:14.587: INFO: Versions found [{batch/v1 v1}]
    Dec  3 13:14:14.587: INFO: batch/v1 matches batch/v1
    Dec  3 13:14:14.587: INFO: Checking APIGroup: certificates.k8s.io
    Dec  3 13:14:14.588: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Dec  3 13:14:14.588: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Dec  3 13:14:14.588: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Dec  3 13:14:14.588: INFO: Checking APIGroup: networking.k8s.io
    Dec  3 13:14:14.589: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Dec  3 13:14:14.589: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Dec  3 13:14:14.589: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Dec  3 13:14:14.589: INFO: Checking APIGroup: policy
    Dec  3 13:14:14.590: INFO: PreferredVersion.GroupVersion: policy/v1
    Dec  3 13:14:14.590: INFO: Versions found [{policy/v1 v1}]
    Dec  3 13:14:14.590: INFO: policy/v1 matches policy/v1
    Dec  3 13:14:14.590: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Dec  3 13:14:14.591: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Dec  3 13:14:14.591: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Dec  3 13:14:14.591: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Dec  3 13:14:14.591: INFO: Checking APIGroup: storage.k8s.io
    Dec  3 13:14:14.592: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Dec  3 13:14:14.592: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Dec  3 13:14:14.592: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Dec  3 13:14:14.592: INFO: Checking APIGroup: admissionregistration.k8s.io
    Dec  3 13:14:14.594: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Dec  3 13:14:14.594: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Dec  3 13:14:14.594: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Dec  3 13:14:14.594: INFO: Checking APIGroup: apiextensions.k8s.io
    Dec  3 13:14:14.595: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Dec  3 13:14:14.595: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Dec  3 13:14:14.595: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Dec  3 13:14:14.595: INFO: Checking APIGroup: scheduling.k8s.io
    Dec  3 13:14:14.596: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Dec  3 13:14:14.596: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Dec  3 13:14:14.596: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Dec  3 13:14:14.596: INFO: Checking APIGroup: coordination.k8s.io
    Dec  3 13:14:14.599: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Dec  3 13:14:14.599: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Dec  3 13:14:14.599: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Dec  3 13:14:14.599: INFO: Checking APIGroup: node.k8s.io
    Dec  3 13:14:14.599: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Dec  3 13:14:14.599: INFO: Versions found [{node.k8s.io/v1 v1}]
    Dec  3 13:14:14.599: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Dec  3 13:14:14.599: INFO: Checking APIGroup: discovery.k8s.io
    Dec  3 13:14:14.600: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Dec  3 13:14:14.600: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Dec  3 13:14:14.600: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Dec  3 13:14:14.600: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Dec  3 13:14:14.601: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Dec  3 13:14:14.601: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Dec  3 13:14:14.601: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Dec  3 13:14:14.601: INFO: Checking APIGroup: metrics.k8s.io
    Dec  3 13:14:14.602: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Dec  3 13:14:14.602: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Dec  3 13:14:14.602: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Dec  3 13:14:14.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-7842" for this suite. 12/03/22 13:14:14.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:14.617
Dec  3 13:14:14.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename tables 12/03/22 13:14:14.618
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.643
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Dec  3 13:14:14.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8200" for this suite. 12/03/22 13:14:14.663
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":254,"skipped":4761,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:14.617
    Dec  3 13:14:14.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename tables 12/03/22 13:14:14.618
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.643
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Dec  3 13:14:14.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-8200" for this suite. 12/03/22 13:14:14.663
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:14.675
Dec  3 13:14:14.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 13:14:14.676
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.704
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 12/03/22 13:14:14.711
Dec  3 13:14:14.727: INFO: Waiting up to 5m0s for pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22" in namespace "var-expansion-2067" to be "Succeeded or Failed"
Dec  3 13:14:14.737: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Pending", Reason="", readiness=false. Elapsed: 10.046328ms
Dec  3 13:14:16.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014285732s
Dec  3 13:14:18.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014326916s
STEP: Saw pod success 12/03/22 13:14:18.741
Dec  3 13:14:18.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22" satisfied condition "Succeeded or Failed"
Dec  3 13:14:18.746: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 container dapi-container: <nil>
STEP: delete the pod 12/03/22 13:14:18.754
Dec  3 13:14:18.768: INFO: Waiting for pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 to disappear
Dec  3 13:14:18.771: INFO: Pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 13:14:18.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2067" for this suite. 12/03/22 13:14:18.776
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":255,"skipped":4762,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:14.675
    Dec  3 13:14:14.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 13:14:14.676
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:14.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:14.704
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 12/03/22 13:14:14.711
    Dec  3 13:14:14.727: INFO: Waiting up to 5m0s for pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22" in namespace "var-expansion-2067" to be "Succeeded or Failed"
    Dec  3 13:14:14.737: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Pending", Reason="", readiness=false. Elapsed: 10.046328ms
    Dec  3 13:14:16.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014285732s
    Dec  3 13:14:18.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014326916s
    STEP: Saw pod success 12/03/22 13:14:18.741
    Dec  3 13:14:18.741: INFO: Pod "var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22" satisfied condition "Succeeded or Failed"
    Dec  3 13:14:18.746: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 13:14:18.754
    Dec  3 13:14:18.768: INFO: Waiting for pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 to disappear
    Dec  3 13:14:18.771: INFO: Pod var-expansion-3ff35a54-044a-4577-aac7-e0c14893ce22 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 13:14:18.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2067" for this suite. 12/03/22 13:14:18.776
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:18.785
Dec  3 13:14:18.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:14:18.786
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:18.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:18.819
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-7c45e4c1-9517-476c-abb7-0eb6a4d3f66b 12/03/22 13:14:18.822
STEP: Creating a pod to test consume configMaps 12/03/22 13:14:18.832
Dec  3 13:14:18.844: INFO: Waiting up to 5m0s for pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad" in namespace "configmap-137" to be "Succeeded or Failed"
Dec  3 13:14:18.851: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Pending", Reason="", readiness=false. Elapsed: 7.183543ms
Dec  3 13:14:20.855: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011124679s
Dec  3 13:14:22.857: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012758896s
STEP: Saw pod success 12/03/22 13:14:22.857
Dec  3 13:14:22.857: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad" satisfied condition "Succeeded or Failed"
Dec  3 13:14:22.860: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:14:22.869
Dec  3 13:14:22.884: INFO: Waiting for pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad to disappear
Dec  3 13:14:22.888: INFO: Pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:14:22.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-137" for this suite. 12/03/22 13:14:22.892
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":256,"skipped":4793,"failed":0}
------------------------------
â€¢ [4.116 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:18.785
    Dec  3 13:14:18.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:14:18.786
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:18.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:18.819
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-7c45e4c1-9517-476c-abb7-0eb6a4d3f66b 12/03/22 13:14:18.822
    STEP: Creating a pod to test consume configMaps 12/03/22 13:14:18.832
    Dec  3 13:14:18.844: INFO: Waiting up to 5m0s for pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad" in namespace "configmap-137" to be "Succeeded or Failed"
    Dec  3 13:14:18.851: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Pending", Reason="", readiness=false. Elapsed: 7.183543ms
    Dec  3 13:14:20.855: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011124679s
    Dec  3 13:14:22.857: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012758896s
    STEP: Saw pod success 12/03/22 13:14:22.857
    Dec  3 13:14:22.857: INFO: Pod "pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad" satisfied condition "Succeeded or Failed"
    Dec  3 13:14:22.860: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:14:22.869
    Dec  3 13:14:22.884: INFO: Waiting for pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad to disappear
    Dec  3 13:14:22.888: INFO: Pod pod-configmaps-1637df8d-1cfc-483c-ad6e-afca9850fdad no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:14:22.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-137" for this suite. 12/03/22 13:14:22.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:14:22.908
Dec  3 13:14:22.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption 12/03/22 13:14:22.909
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:22.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:22.935
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec  3 13:14:22.957: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 13:15:22.984: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:15:22.988
Dec  3 13:15:22.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption-path 12/03/22 13:15:22.989
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:23.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:23.063
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 12/03/22 13:15:23.068
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 13:15:23.068
Dec  3 13:15:23.087: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6899" to be "running"
Dec  3 13:15:23.091: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270225ms
Dec  3 13:15:25.098: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01045636s
Dec  3 13:15:25.098: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 13:15:25.101
Dec  3 13:15:25.113: INFO: found a healthy node: ip-172-31-38-234
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Dec  3 13:15:41.228: INFO: pods created so far: [1 1 1]
Dec  3 13:15:41.228: INFO: length of pods created so far: 3
Dec  3 13:15:45.240: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Dec  3 13:15:52.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6899" for this suite. 12/03/22 13:15:52.25
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:15:52.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8018" for this suite. 12/03/22 13:15:52.303
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":257,"skipped":4817,"failed":0}
------------------------------
â€¢ [SLOW TEST] [89.445 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:14:22.908
    Dec  3 13:14:22.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption 12/03/22 13:14:22.909
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:14:22.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:14:22.935
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec  3 13:14:22.957: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 13:15:22.984: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:15:22.988
    Dec  3 13:15:22.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption-path 12/03/22 13:15:22.989
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:23.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:23.063
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 12/03/22 13:15:23.068
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 13:15:23.068
    Dec  3 13:15:23.087: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6899" to be "running"
    Dec  3 13:15:23.091: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270225ms
    Dec  3 13:15:25.098: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01045636s
    Dec  3 13:15:25.098: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 13:15:25.101
    Dec  3 13:15:25.113: INFO: found a healthy node: ip-172-31-38-234
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Dec  3 13:15:41.228: INFO: pods created so far: [1 1 1]
    Dec  3 13:15:41.228: INFO: length of pods created so far: 3
    Dec  3 13:15:45.240: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Dec  3 13:15:52.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-6899" for this suite. 12/03/22 13:15:52.25
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:15:52.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8018" for this suite. 12/03/22 13:15:52.303
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:15:52.356
Dec  3 13:15:52.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:15:52.357
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:52.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:52.383
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:15:52.403
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:15:52.886
STEP: Deploying the webhook pod 12/03/22 13:15:52.896
STEP: Wait for the deployment to be ready 12/03/22 13:15:52.912
Dec  3 13:15:52.918: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 12/03/22 13:15:54.933
STEP: Verifying the service has paired with the endpoint 12/03/22 13:15:54.946
Dec  3 13:15:55.946: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 12/03/22 13:15:56.027
STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:15:56.1
STEP: Deleting the collection of validation webhooks 12/03/22 13:15:56.181
STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:15:56.236
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:15:56.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7896" for this suite. 12/03/22 13:15:56.253
STEP: Destroying namespace "webhook-7896-markers" for this suite. 12/03/22 13:15:56.263
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":258,"skipped":4817,"failed":0}
------------------------------
â€¢ [3.959 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:15:52.356
    Dec  3 13:15:52.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:15:52.357
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:52.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:52.383
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:15:52.403
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:15:52.886
    STEP: Deploying the webhook pod 12/03/22 13:15:52.896
    STEP: Wait for the deployment to be ready 12/03/22 13:15:52.912
    Dec  3 13:15:52.918: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 12/03/22 13:15:54.933
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:15:54.946
    Dec  3 13:15:55.946: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 12/03/22 13:15:56.027
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:15:56.1
    STEP: Deleting the collection of validation webhooks 12/03/22 13:15:56.181
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:15:56.236
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:15:56.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7896" for this suite. 12/03/22 13:15:56.253
    STEP: Destroying namespace "webhook-7896-markers" for this suite. 12/03/22 13:15:56.263
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:15:56.319
Dec  3 13:15:56.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:15:56.32
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:56.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:56.355
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 12/03/22 13:15:56.36
Dec  3 13:15:56.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1280 api-versions'
Dec  3 13:15:56.434: INFO: stderr: ""
Dec  3 13:15:56.434: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:15:56.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1280" for this suite. 12/03/22 13:15:56.439
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":259,"skipped":4817,"failed":0}
------------------------------
â€¢ [0.126 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:15:56.319
    Dec  3 13:15:56.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:15:56.32
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:56.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:56.355
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 12/03/22 13:15:56.36
    Dec  3 13:15:56.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1280 api-versions'
    Dec  3 13:15:56.434: INFO: stderr: ""
    Dec  3 13:15:56.434: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:15:56.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1280" for this suite. 12/03/22 13:15:56.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:15:56.448
Dec  3 13:15:56.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:15:56.448
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:56.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:56.474
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/03/22 13:15:56.478
Dec  3 13:15:56.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:15:59.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:16:10.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4686" for this suite. 12/03/22 13:16:10.573
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":260,"skipped":4850,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.133 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:15:56.448
    Dec  3 13:15:56.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:15:56.448
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:15:56.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:15:56.474
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/03/22 13:15:56.478
    Dec  3 13:15:56.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:15:59.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:16:10.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4686" for this suite. 12/03/22 13:16:10.573
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:10.582
Dec  3 13:16:10.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 13:16:10.583
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:10.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:10.608
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4440 12/03/22 13:16:10.611
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Dec  3 13:16:10.630: INFO: Found 0 stateful pods, waiting for 1
Dec  3 13:16:20.635: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 12/03/22 13:16:20.643
W1203 13:16:20.670790      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec  3 13:16:20.684: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:16:20.684: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 13:16:30.690: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:16:30.690: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 12/03/22 13:16:30.696
STEP: Delete all of the StatefulSets 12/03/22 13:16:30.703
STEP: Verify that StatefulSets have been deleted 12/03/22 13:16:30.711
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 13:16:30.742: INFO: Deleting all statefulset in ns statefulset-4440
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 13:16:30.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4440" for this suite. 12/03/22 13:16:30.781
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":261,"skipped":4871,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.217 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:10.582
    Dec  3 13:16:10.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 13:16:10.583
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:10.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:10.608
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4440 12/03/22 13:16:10.611
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Dec  3 13:16:10.630: INFO: Found 0 stateful pods, waiting for 1
    Dec  3 13:16:20.635: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 12/03/22 13:16:20.643
    W1203 13:16:20.670790      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec  3 13:16:20.684: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 13:16:20.684: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
    Dec  3 13:16:30.690: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 13:16:30.690: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 12/03/22 13:16:30.696
    STEP: Delete all of the StatefulSets 12/03/22 13:16:30.703
    STEP: Verify that StatefulSets have been deleted 12/03/22 13:16:30.711
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 13:16:30.742: INFO: Deleting all statefulset in ns statefulset-4440
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 13:16:30.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4440" for this suite. 12/03/22 13:16:30.781
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:30.8
Dec  3 13:16:30.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:16:30.801
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:30.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:30.898
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:16:30.904
Dec  3 13:16:30.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe" in namespace "downward-api-8927" to be "Succeeded or Failed"
Dec  3 13:16:30.922: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.858193ms
Dec  3 13:16:32.927: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009548583s
Dec  3 13:16:34.930: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011938938s
STEP: Saw pod success 12/03/22 13:16:34.93
Dec  3 13:16:34.930: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe" satisfied condition "Succeeded or Failed"
Dec  3 13:16:34.934: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe container client-container: <nil>
STEP: delete the pod 12/03/22 13:16:34.95
Dec  3 13:16:34.963: INFO: Waiting for pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe to disappear
Dec  3 13:16:34.970: INFO: Pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:16:34.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8927" for this suite. 12/03/22 13:16:34.974
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":262,"skipped":4871,"failed":0}
------------------------------
â€¢ [4.183 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:30.8
    Dec  3 13:16:30.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:16:30.801
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:30.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:30.898
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:16:30.904
    Dec  3 13:16:30.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe" in namespace "downward-api-8927" to be "Succeeded or Failed"
    Dec  3 13:16:30.922: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.858193ms
    Dec  3 13:16:32.927: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009548583s
    Dec  3 13:16:34.930: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011938938s
    STEP: Saw pod success 12/03/22 13:16:34.93
    Dec  3 13:16:34.930: INFO: Pod "downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe" satisfied condition "Succeeded or Failed"
    Dec  3 13:16:34.934: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe container client-container: <nil>
    STEP: delete the pod 12/03/22 13:16:34.95
    Dec  3 13:16:34.963: INFO: Waiting for pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe to disappear
    Dec  3 13:16:34.970: INFO: Pod downwardapi-volume-6a652e24-a9d0-47fc-a4ae-30d281d6dcfe no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:16:34.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8927" for this suite. 12/03/22 13:16:34.974
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:34.984
Dec  3 13:16:34.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replication-controller 12/03/22 13:16:34.985
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:35.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:35.016
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 12/03/22 13:16:35.025
STEP: waiting for RC to be added 12/03/22 13:16:35.033
STEP: waiting for available Replicas 12/03/22 13:16:35.034
STEP: patching ReplicationController 12/03/22 13:16:36.82
STEP: waiting for RC to be modified 12/03/22 13:16:36.839
STEP: patching ReplicationController status 12/03/22 13:16:36.839
STEP: waiting for RC to be modified 12/03/22 13:16:36.849
STEP: waiting for available Replicas 12/03/22 13:16:36.849
STEP: fetching ReplicationController status 12/03/22 13:16:36.855
STEP: patching ReplicationController scale 12/03/22 13:16:36.86
STEP: waiting for RC to be modified 12/03/22 13:16:36.868
STEP: waiting for ReplicationController's scale to be the max amount 12/03/22 13:16:36.868
STEP: fetching ReplicationController; ensuring that it's patched 12/03/22 13:16:38.456
STEP: updating ReplicationController status 12/03/22 13:16:38.46
STEP: waiting for RC to be modified 12/03/22 13:16:38.467
STEP: listing all ReplicationControllers 12/03/22 13:16:38.468
STEP: checking that ReplicationController has expected values 12/03/22 13:16:38.472
STEP: deleting ReplicationControllers by collection 12/03/22 13:16:38.472
STEP: waiting for ReplicationController to have a DELETED watchEvent 12/03/22 13:16:38.483
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec  3 13:16:38.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1948" for this suite. 12/03/22 13:16:38.548
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":263,"skipped":4878,"failed":0}
------------------------------
â€¢ [3.571 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:34.984
    Dec  3 13:16:34.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replication-controller 12/03/22 13:16:34.985
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:35.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:35.016
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 12/03/22 13:16:35.025
    STEP: waiting for RC to be added 12/03/22 13:16:35.033
    STEP: waiting for available Replicas 12/03/22 13:16:35.034
    STEP: patching ReplicationController 12/03/22 13:16:36.82
    STEP: waiting for RC to be modified 12/03/22 13:16:36.839
    STEP: patching ReplicationController status 12/03/22 13:16:36.839
    STEP: waiting for RC to be modified 12/03/22 13:16:36.849
    STEP: waiting for available Replicas 12/03/22 13:16:36.849
    STEP: fetching ReplicationController status 12/03/22 13:16:36.855
    STEP: patching ReplicationController scale 12/03/22 13:16:36.86
    STEP: waiting for RC to be modified 12/03/22 13:16:36.868
    STEP: waiting for ReplicationController's scale to be the max amount 12/03/22 13:16:36.868
    STEP: fetching ReplicationController; ensuring that it's patched 12/03/22 13:16:38.456
    STEP: updating ReplicationController status 12/03/22 13:16:38.46
    STEP: waiting for RC to be modified 12/03/22 13:16:38.467
    STEP: listing all ReplicationControllers 12/03/22 13:16:38.468
    STEP: checking that ReplicationController has expected values 12/03/22 13:16:38.472
    STEP: deleting ReplicationControllers by collection 12/03/22 13:16:38.472
    STEP: waiting for ReplicationController to have a DELETED watchEvent 12/03/22 13:16:38.483
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec  3 13:16:38.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1948" for this suite. 12/03/22 13:16:38.548
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:38.557
Dec  3 13:16:38.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:16:38.558
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.593
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 12/03/22 13:16:38.596
STEP: watching for the ServiceAccount to be added 12/03/22 13:16:38.607
STEP: patching the ServiceAccount 12/03/22 13:16:38.609
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/03/22 13:16:38.614
STEP: deleting the ServiceAccount 12/03/22 13:16:38.618
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 13:16:38.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9932" for this suite. 12/03/22 13:16:38.641
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":264,"skipped":4880,"failed":0}
------------------------------
â€¢ [0.091 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:38.557
    Dec  3 13:16:38.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:16:38.558
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.593
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 12/03/22 13:16:38.596
    STEP: watching for the ServiceAccount to be added 12/03/22 13:16:38.607
    STEP: patching the ServiceAccount 12/03/22 13:16:38.609
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/03/22 13:16:38.614
    STEP: deleting the ServiceAccount 12/03/22 13:16:38.618
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 13:16:38.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9932" for this suite. 12/03/22 13:16:38.641
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:38.651
Dec  3 13:16:38.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:16:38.652
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.676
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:16:38.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5237" for this suite. 12/03/22 13:16:38.732
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":265,"skipped":4912,"failed":0}
------------------------------
â€¢ [0.088 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:38.651
    Dec  3 13:16:38.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:16:38.652
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.676
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:16:38.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5237" for this suite. 12/03/22 13:16:38.732
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:38.743
Dec  3 13:16:38.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-pred 12/03/22 13:16:38.743
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.773
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec  3 13:16:38.777: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 13:16:38.786: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 13:16:38.789: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
Dec  3 13:16:38.794: INFO: nginx-ingress-controller-kubernetes-worker-5x9j7 from ingress-nginx-kubernetes-worker started at 2022-12-03 12:54:53 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.795: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 13:16:38.795: INFO: rc-test-q5zj5 from replication-controller-1948 started at 2022-12-03 13:16:35 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.795: INFO: 	Container rc-test ready: true, restart count 0
Dec  3 13:16:38.795: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 13:16:38.795: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 13:16:38.795: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 13:16:38.795: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
Dec  3 13:16:38.799: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.799: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  3 13:16:38.799: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 13:16:38.800: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container coredns ready: true, restart count 0
Dec  3 13:16:38.800: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec  3 13:16:38.800: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 13:16:38.800: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  3 13:16:38.800: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec  3 13:16:38.800: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 13:16:38.800: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 13:16:38.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 13:16:38.800: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  3 13:16:38.800: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
Dec  3 13:16:38.806: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  3 13:16:38.806: INFO: calico-kube-controllers-77cf5c5988-8l65n from kube-system started at 2022-12-03 12:43:54 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 13:16:38.806: INFO: rc-test-d74b8 from replication-controller-1948 started at 2022-12-03 13:16:36 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container rc-test ready: true, restart count 0
Dec  3 13:16:38.806: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 13:16:38.806: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container e2e ready: true, restart count 0
Dec  3 13:16:38.806: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 13:16:38.806: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
Dec  3 13:16:38.806: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 13:16:38.806: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 13:16:38.806
Dec  3 13:16:38.818: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1338" to be "running"
Dec  3 13:16:38.823: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764359ms
Dec  3 13:16:40.828: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.010554351s
Dec  3 13:16:40.828: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 13:16:40.833
STEP: Trying to apply a random label on the found node. 12/03/22 13:16:40.845
STEP: verifying the node has the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f 42 12/03/22 13:16:40.856
STEP: Trying to relaunch the pod, now with labels. 12/03/22 13:16:40.859
Dec  3 13:16:40.866: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1338" to be "not pending"
Dec  3 13:16:40.871: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706424ms
Dec  3 13:16:42.877: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.010328475s
Dec  3 13:16:42.877: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f off the node ip-172-31-38-234 12/03/22 13:16:42.881
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f 12/03/22 13:16:42.898
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:16:42.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1338" for this suite. 12/03/22 13:16:42.91
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":266,"skipped":4941,"failed":0}
------------------------------
â€¢ [4.190 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:38.743
    Dec  3 13:16:38.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-pred 12/03/22 13:16:38.743
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:38.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:38.773
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec  3 13:16:38.777: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec  3 13:16:38.786: INFO: Waiting for terminating namespaces to be deleted...
    Dec  3 13:16:38.789: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-38-234 before test
    Dec  3 13:16:38.794: INFO: nginx-ingress-controller-kubernetes-worker-5x9j7 from ingress-nginx-kubernetes-worker started at 2022-12-03 12:54:53 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.795: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 13:16:38.795: INFO: rc-test-q5zj5 from replication-controller-1948 started at 2022-12-03 13:16:35 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.795: INFO: 	Container rc-test ready: true, restart count 0
    Dec  3 13:16:38.795: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 13:16:38.795: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 13:16:38.795: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 13:16:38.795: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-4-162 before test
    Dec  3 13:16:38.799: INFO: default-http-backend-kubernetes-worker-6546b9855c-f44gm from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.799: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Dec  3 13:16:38.799: INFO: nginx-ingress-controller-kubernetes-worker-29vwl from ingress-nginx-kubernetes-worker started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: coredns-6bcf44f4cc-nlwz2 from kube-system started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container coredns ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: kube-state-metrics-74f5d549cc-njnx9 from kube-system started at 2022-12-03 11:48:06 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: metrics-server-v0.5.2-6b48dc6f97-scdrh from kube-system started at 2022-12-03 11:48:06 +0000 UTC (2 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container metrics-server ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: dashboard-metrics-scraper-85d45476c6-n9g62 from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: kubernetes-dashboard-7fb574cb-4xr9k from kubernetes-dashboard started at 2022-12-03 11:48:08 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-jf28n from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 13:16:38.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: 	Container systemd-logs ready: true, restart count 0
    Dec  3 13:16:38.800: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-76-203 before test
    Dec  3 13:16:38.806: INFO: nginx-ingress-controller-kubernetes-worker-c786f from ingress-nginx-kubernetes-worker started at 2022-12-03 11:50:50 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: calico-kube-controllers-77cf5c5988-8l65n from kube-system started at 2022-12-03 12:43:54 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: rc-test-d74b8 from replication-controller-1948 started at 2022-12-03 13:16:36 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container rc-test ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: sonobuoy from sonobuoy started at 2022-12-03 11:56:18 +0000 UTC (1 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: sonobuoy-e2e-job-642e753251e54e6e from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container e2e ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-g8lbn from sonobuoy started at 2022-12-03 11:56:20 +0000 UTC (2 container statuses recorded)
    Dec  3 13:16:38.806: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Dec  3 13:16:38.806: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/03/22 13:16:38.806
    Dec  3 13:16:38.818: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1338" to be "running"
    Dec  3 13:16:38.823: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764359ms
    Dec  3 13:16:40.828: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.010554351s
    Dec  3 13:16:40.828: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/03/22 13:16:40.833
    STEP: Trying to apply a random label on the found node. 12/03/22 13:16:40.845
    STEP: verifying the node has the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f 42 12/03/22 13:16:40.856
    STEP: Trying to relaunch the pod, now with labels. 12/03/22 13:16:40.859
    Dec  3 13:16:40.866: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1338" to be "not pending"
    Dec  3 13:16:40.871: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706424ms
    Dec  3 13:16:42.877: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.010328475s
    Dec  3 13:16:42.877: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f off the node ip-172-31-38-234 12/03/22 13:16:42.881
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-e7952665-cdd8-4ab4-ad14-0f535e99d54f 12/03/22 13:16:42.898
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:16:42.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1338" for this suite. 12/03/22 13:16:42.91
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:42.935
Dec  3 13:16:42.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:16:42.936
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:42.959
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:42.964
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:16:42.99
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:16:43.432
STEP: Deploying the webhook pod 12/03/22 13:16:43.443
STEP: Wait for the deployment to be ready 12/03/22 13:16:43.465
Dec  3 13:16:43.473: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:16:45.487
STEP: Verifying the service has paired with the endpoint 12/03/22 13:16:45.502
Dec  3 13:16:46.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/03/22 13:16:46.508
STEP: create a pod that should be updated by the webhook 12/03/22 13:16:46.524
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:16:46.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-515" for this suite. 12/03/22 13:16:46.565
STEP: Destroying namespace "webhook-515-markers" for this suite. 12/03/22 13:16:46.573
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":267,"skipped":4941,"failed":0}
------------------------------
â€¢ [3.723 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:42.935
    Dec  3 13:16:42.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:16:42.936
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:42.959
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:42.964
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:16:42.99
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:16:43.432
    STEP: Deploying the webhook pod 12/03/22 13:16:43.443
    STEP: Wait for the deployment to be ready 12/03/22 13:16:43.465
    Dec  3 13:16:43.473: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:16:45.487
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:16:45.502
    Dec  3 13:16:46.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/03/22 13:16:46.508
    STEP: create a pod that should be updated by the webhook 12/03/22 13:16:46.524
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:16:46.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-515" for this suite. 12/03/22 13:16:46.565
    STEP: Destroying namespace "webhook-515-markers" for this suite. 12/03/22 13:16:46.573
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:46.661
Dec  3 13:16:46.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename podtemplate 12/03/22 13:16:46.662
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:46.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:46.706
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec  3 13:16:46.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6564" for this suite. 12/03/22 13:16:46.76
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":268,"skipped":4963,"failed":0}
------------------------------
â€¢ [0.107 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:46.661
    Dec  3 13:16:46.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename podtemplate 12/03/22 13:16:46.662
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:46.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:46.706
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec  3 13:16:46.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6564" for this suite. 12/03/22 13:16:46.76
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:16:46.769
Dec  3 13:16:46.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 13:16:46.77
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:46.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:46.794
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-853 12/03/22 13:16:46.8
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 12/03/22 13:16:46.811
STEP: Creating stateful set ss in namespace statefulset-853 12/03/22 13:16:46.815
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-853 12/03/22 13:16:46.823
Dec  3 13:16:46.830: INFO: Found 0 stateful pods, waiting for 1
Dec  3 13:16:56.835: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/03/22 13:16:56.835
Dec  3 13:16:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 13:16:57.000: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 13:16:57.000: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 13:16:57.000: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 13:16:57.005: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 13:17:07.012: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:17:07.012: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:17:07.033: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999678s
Dec  3 13:17:08.038: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995448721s
Dec  3 13:17:09.045: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990877887s
Dec  3 13:17:10.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983321993s
Dec  3 13:17:11.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978968825s
Dec  3 13:17:12.059: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97516864s
Dec  3 13:17:13.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.969376561s
Dec  3 13:17:14.069: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964012327s
Dec  3 13:17:15.076: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959531444s
Dec  3 13:17:16.082: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.084161ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-853 12/03/22 13:17:17.082
Dec  3 13:17:17.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 13:17:17.259: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 13:17:17.259: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 13:17:17.259: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 13:17:17.264: INFO: Found 1 stateful pods, waiting for 3
Dec  3 13:17:27.270: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:17:27.270: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 13:17:27.270: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 12/03/22 13:17:27.27
STEP: Scale down will halt with unhealthy stateful pod 12/03/22 13:17:27.27
Dec  3 13:17:27.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 13:17:27.452: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 13:17:27.452: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 13:17:27.452: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 13:17:27.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 13:17:27.622: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 13:17:27.622: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 13:17:27.622: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 13:17:27.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 13:17:27.790: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 13:17:27.790: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 13:17:27.790: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 13:17:27.790: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:17:27.794: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  3 13:17:37.804: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:17:37.804: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:17:37.804: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 13:17:37.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999975s
Dec  3 13:17:38.824: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995599082s
Dec  3 13:17:39.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990412853s
Dec  3 13:17:40.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985719835s
Dec  3 13:17:41.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980467303s
Dec  3 13:17:42.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973662877s
Dec  3 13:17:43.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966712784s
Dec  3 13:17:44.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962063458s
Dec  3 13:17:45.863: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957227011s
Dec  3 13:17:46.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.706686ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-853 12/03/22 13:17:47.868
Dec  3 13:17:47.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 13:17:48.079: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 13:17:48.079: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 13:17:48.079: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 13:17:48.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 13:17:48.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 13:17:48.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 13:17:48.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 13:17:48.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 13:17:48.435: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 13:17:48.436: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 13:17:48.436: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 13:17:48.436: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 12/03/22 13:17:58.461
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 13:17:58.462: INFO: Deleting all statefulset in ns statefulset-853
Dec  3 13:17:58.466: INFO: Scaling statefulset ss to 0
Dec  3 13:17:58.478: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:17:58.482: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 13:17:58.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-853" for this suite. 12/03/22 13:17:58.498
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":269,"skipped":4963,"failed":0}
------------------------------
â€¢ [SLOW TEST] [71.737 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:16:46.769
    Dec  3 13:16:46.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 13:16:46.77
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:16:46.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:16:46.794
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-853 12/03/22 13:16:46.8
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 12/03/22 13:16:46.811
    STEP: Creating stateful set ss in namespace statefulset-853 12/03/22 13:16:46.815
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-853 12/03/22 13:16:46.823
    Dec  3 13:16:46.830: INFO: Found 0 stateful pods, waiting for 1
    Dec  3 13:16:56.835: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/03/22 13:16:56.835
    Dec  3 13:16:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 13:16:57.000: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 13:16:57.000: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 13:16:57.000: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 13:16:57.005: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec  3 13:17:07.012: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 13:17:07.012: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:17:07.033: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999678s
    Dec  3 13:17:08.038: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995448721s
    Dec  3 13:17:09.045: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990877887s
    Dec  3 13:17:10.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983321993s
    Dec  3 13:17:11.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978968825s
    Dec  3 13:17:12.059: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97516864s
    Dec  3 13:17:13.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.969376561s
    Dec  3 13:17:14.069: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964012327s
    Dec  3 13:17:15.076: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959531444s
    Dec  3 13:17:16.082: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.084161ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-853 12/03/22 13:17:17.082
    Dec  3 13:17:17.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 13:17:17.259: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 13:17:17.259: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 13:17:17.259: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 13:17:17.264: INFO: Found 1 stateful pods, waiting for 3
    Dec  3 13:17:27.270: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 13:17:27.270: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec  3 13:17:27.270: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 12/03/22 13:17:27.27
    STEP: Scale down will halt with unhealthy stateful pod 12/03/22 13:17:27.27
    Dec  3 13:17:27.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 13:17:27.452: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 13:17:27.452: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 13:17:27.452: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 13:17:27.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 13:17:27.622: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 13:17:27.622: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 13:17:27.622: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 13:17:27.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec  3 13:17:27.790: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec  3 13:17:27.790: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec  3 13:17:27.790: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec  3 13:17:27.790: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:17:27.794: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Dec  3 13:17:37.804: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 13:17:37.804: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 13:17:37.804: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec  3 13:17:37.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999975s
    Dec  3 13:17:38.824: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995599082s
    Dec  3 13:17:39.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990412853s
    Dec  3 13:17:40.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985719835s
    Dec  3 13:17:41.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980467303s
    Dec  3 13:17:42.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973662877s
    Dec  3 13:17:43.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966712784s
    Dec  3 13:17:44.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962063458s
    Dec  3 13:17:45.863: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957227011s
    Dec  3 13:17:46.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.706686ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-853 12/03/22 13:17:47.868
    Dec  3 13:17:47.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 13:17:48.079: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 13:17:48.079: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 13:17:48.079: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 13:17:48.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 13:17:48.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 13:17:48.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 13:17:48.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 13:17:48.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=statefulset-853 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec  3 13:17:48.435: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec  3 13:17:48.436: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec  3 13:17:48.436: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec  3 13:17:48.436: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 12/03/22 13:17:58.461
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 13:17:58.462: INFO: Deleting all statefulset in ns statefulset-853
    Dec  3 13:17:58.466: INFO: Scaling statefulset ss to 0
    Dec  3 13:17:58.478: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:17:58.482: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 13:17:58.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-853" for this suite. 12/03/22 13:17:58.498
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:17:58.508
Dec  3 13:17:58.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:17:58.509
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:17:58.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:17:58.541
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 12/03/22 13:17:58.545
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:17:58.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7930" for this suite. 12/03/22 13:17:58.554
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":270,"skipped":4970,"failed":0}
------------------------------
â€¢ [0.054 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:17:58.508
    Dec  3 13:17:58.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:17:58.509
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:17:58.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:17:58.541
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 12/03/22 13:17:58.545
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:17:58.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7930" for this suite. 12/03/22 13:17:58.554
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:17:58.564
Dec  3 13:17:58.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:17:58.565
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:17:58.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:17:58.594
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Dec  3 13:17:58.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 create -f -'
Dec  3 13:17:59.251: INFO: stderr: ""
Dec  3 13:17:59.251: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Dec  3 13:17:59.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 create -f -'
Dec  3 13:17:59.460: INFO: stderr: ""
Dec  3 13:17:59.460: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/03/22 13:17:59.46
Dec  3 13:18:00.464: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:18:00.464: INFO: Found 0 / 1
Dec  3 13:18:01.465: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:18:01.465: INFO: Found 1 / 1
Dec  3 13:18:01.465: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 13:18:01.468: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:18:01.468: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 13:18:01.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe pod agnhost-primary-fr694'
Dec  3 13:18:01.553: INFO: stderr: ""
Dec  3 13:18:01.553: INFO: stdout: "Name:             agnhost-primary-fr694\nNamespace:        kubectl-1995\nPriority:         0\nService Account:  default\nNode:             ip-172-31-38-234/172.31.38.234\nStart Time:       Sat, 03 Dec 2022 13:17:59 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.197.105\nIPs:\n  IP:           192.168.197.105\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://dc901d7ac46c2ade44c3d160c0af058c317cdeb3c2fc10000cb5b8d9950f3d3a\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 03 Dec 2022 13:18:00 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4hhkw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-4hhkw:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-1995/agnhost-primary-fr694 to ip-172-31-38-234\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Dec  3 13:18:01.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe rc agnhost-primary'
Dec  3 13:18:01.650: INFO: stderr: ""
Dec  3 13:18:01.650: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1995\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-fr694\n"
Dec  3 13:18:01.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe service agnhost-primary'
Dec  3 13:18:01.736: INFO: stderr: ""
Dec  3 13:18:01.736: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1995\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.179\nIPs:               10.152.183.179\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.197.105:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 13:18:01.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe node ip-172-31-38-234'
Dec  3 13:18:01.851: INFO: stderr: ""
Dec  3 13:18:01.852: INFO: stdout: "Name:               ip-172-31-38-234\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-38-234\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 03 Dec 2022 11:47:52 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-38-234\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 03 Dec 2022 13:17:59 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:48:40 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.38.234\n  Hostname:    ip-172-31-38-234\nCapacity:\n  cpu:                  2\n  ephemeral-storage:    16069568Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               8036332Ki\n  pods:                 110\nAllocatable:\n  cpu:                  2\n  ephemeral-storage:    14809713845\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7933932Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                      ec21180449e6dc41db0eab677abd7816\n  System UUID:                     ec211804-49e6-dc41-db0e-ab677abd7816\n  Boot ID:                         56a57b07-ba17-4194-b4c5-586b6d548b43\n  Kernel Version:                  5.15.0-1026-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-5x9j7           0 (0%)        0 (0%)      0 (0%)           0 (0%)         23m\n  kubectl-1995                     agnhost-primary-fr694                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q    0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  webhook-515                      webhook-to-be-mutated                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         75s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests  Limits\n  --------             --------  ------\n  cpu                  0 (0%)    0 (0%)\n  memory               0 (0%)    0 (0%)\n  ephemeral-storage    0 (0%)    0 (0%)\n  hugepages-1Gi        0 (0%)    0 (0%)\n  hugepages-2Mi        0 (0%)    0 (0%)\n  example.com/fakecpu  0         0\nEvents:                <none>\n"
Dec  3 13:18:01.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe namespace kubectl-1995'
Dec  3 13:18:01.946: INFO: stderr: ""
Dec  3 13:18:01.946: INFO: stdout: "Name:         kubectl-1995\nLabels:       e2e-framework=kubectl\n              e2e-run=50475f68-cfa2-4212-99a4-1120f9bc223d\n              kubernetes.io/metadata.name=kubectl-1995\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:18:01.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1995" for this suite. 12/03/22 13:18:01.952
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":271,"skipped":4986,"failed":0}
------------------------------
â€¢ [3.397 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:17:58.564
    Dec  3 13:17:58.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:17:58.565
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:17:58.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:17:58.594
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Dec  3 13:17:58.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 create -f -'
    Dec  3 13:17:59.251: INFO: stderr: ""
    Dec  3 13:17:59.251: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Dec  3 13:17:59.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 create -f -'
    Dec  3 13:17:59.460: INFO: stderr: ""
    Dec  3 13:17:59.460: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/03/22 13:17:59.46
    Dec  3 13:18:00.464: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:18:00.464: INFO: Found 0 / 1
    Dec  3 13:18:01.465: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:18:01.465: INFO: Found 1 / 1
    Dec  3 13:18:01.465: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec  3 13:18:01.468: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:18:01.468: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec  3 13:18:01.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe pod agnhost-primary-fr694'
    Dec  3 13:18:01.553: INFO: stderr: ""
    Dec  3 13:18:01.553: INFO: stdout: "Name:             agnhost-primary-fr694\nNamespace:        kubectl-1995\nPriority:         0\nService Account:  default\nNode:             ip-172-31-38-234/172.31.38.234\nStart Time:       Sat, 03 Dec 2022 13:17:59 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.197.105\nIPs:\n  IP:           192.168.197.105\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://dc901d7ac46c2ade44c3d160c0af058c317cdeb3c2fc10000cb5b8d9950f3d3a\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 03 Dec 2022 13:18:00 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4hhkw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-4hhkw:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-1995/agnhost-primary-fr694 to ip-172-31-38-234\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Dec  3 13:18:01.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe rc agnhost-primary'
    Dec  3 13:18:01.650: INFO: stderr: ""
    Dec  3 13:18:01.650: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1995\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-fr694\n"
    Dec  3 13:18:01.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe service agnhost-primary'
    Dec  3 13:18:01.736: INFO: stderr: ""
    Dec  3 13:18:01.736: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1995\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.179\nIPs:               10.152.183.179\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.197.105:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Dec  3 13:18:01.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe node ip-172-31-38-234'
    Dec  3 13:18:01.851: INFO: stderr: ""
    Dec  3 13:18:01.852: INFO: stdout: "Name:               ip-172-31-38-234\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-38-234\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 03 Dec 2022 11:47:52 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-38-234\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 03 Dec 2022 13:17:59 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:47:52 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 03 Dec 2022 13:15:34 +0000   Sat, 03 Dec 2022 11:48:40 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.38.234\n  Hostname:    ip-172-31-38-234\nCapacity:\n  cpu:                  2\n  ephemeral-storage:    16069568Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               8036332Ki\n  pods:                 110\nAllocatable:\n  cpu:                  2\n  ephemeral-storage:    14809713845\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               7933932Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                      ec21180449e6dc41db0eab677abd7816\n  System UUID:                     ec211804-49e6-dc41-db0e-ab677abd7816\n  Boot ID:                         56a57b07-ba17-4194-b4c5-586b6d548b43\n  Kernel Version:                  5.15.0-1026-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-5x9j7           0 (0%)        0 (0%)      0 (0%)           0 (0%)         23m\n  kubectl-1995                     agnhost-primary-fr694                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-92f6701692bf4f54-lms2q    0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  webhook-515                      webhook-to-be-mutated                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         75s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests  Limits\n  --------             --------  ------\n  cpu                  0 (0%)    0 (0%)\n  memory               0 (0%)    0 (0%)\n  ephemeral-storage    0 (0%)    0 (0%)\n  hugepages-1Gi        0 (0%)    0 (0%)\n  hugepages-2Mi        0 (0%)    0 (0%)\n  example.com/fakecpu  0         0\nEvents:                <none>\n"
    Dec  3 13:18:01.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1995 describe namespace kubectl-1995'
    Dec  3 13:18:01.946: INFO: stderr: ""
    Dec  3 13:18:01.946: INFO: stdout: "Name:         kubectl-1995\nLabels:       e2e-framework=kubectl\n              e2e-run=50475f68-cfa2-4212-99a4-1120f9bc223d\n              kubernetes.io/metadata.name=kubectl-1995\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:18:01.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1995" for this suite. 12/03/22 13:18:01.952
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:01.962
Dec  3 13:18:01.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:18:01.963
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:01.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:01.988
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-3443 12/03/22 13:18:01.992
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[] 12/03/22 13:18:02.006
Dec  3 13:18:02.010: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Dec  3 13:18:03.021: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3443 12/03/22 13:18:03.021
Dec  3 13:18:03.033: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3443" to be "running and ready"
Dec  3 13:18:03.036: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.349302ms
Dec  3 13:18:03.036: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:18:05.041: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008371235s
Dec  3 13:18:05.041: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec  3 13:18:05.041: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod1:[80]] 12/03/22 13:18:05.044
Dec  3 13:18:05.055: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 12/03/22 13:18:05.055
Dec  3 13:18:05.055: INFO: Creating new exec pod
Dec  3 13:18:05.065: INFO: Waiting up to 5m0s for pod "execpods6bbp" in namespace "services-3443" to be "running"
Dec  3 13:18:05.069: INFO: Pod "execpods6bbp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16869ms
Dec  3 13:18:07.076: INFO: Pod "execpods6bbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011092321s
Dec  3 13:18:07.076: INFO: Pod "execpods6bbp" satisfied condition "running"
Dec  3 13:18:08.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec  3 13:18:08.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:08.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:18:08.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
Dec  3 13:18:08.448: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:08.448: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-3443 12/03/22 13:18:08.448
Dec  3 13:18:08.454: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3443" to be "running and ready"
Dec  3 13:18:08.458: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.659509ms
Dec  3 13:18:08.458: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:18:10.464: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009922867s
Dec  3 13:18:10.465: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec  3 13:18:10.465: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod1:[80] pod2:[80]] 12/03/22 13:18:10.47
Dec  3 13:18:10.490: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 12/03/22 13:18:10.49
Dec  3 13:18:11.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec  3 13:18:11.643: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:11.643: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:18:11.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
Dec  3 13:18:11.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:11.779: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3443 12/03/22 13:18:11.779
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod2:[80]] 12/03/22 13:18:11.795
Dec  3 13:18:12.827: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 12/03/22 13:18:12.827
Dec  3 13:18:13.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec  3 13:18:13.980: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:13.980: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:18:13.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
Dec  3 13:18:14.166: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
Dec  3 13:18:14.166: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-3443 12/03/22 13:18:14.166
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[] 12/03/22 13:18:14.184
Dec  3 13:18:14.200: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:18:14.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3443" for this suite. 12/03/22 13:18:14.23
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":272,"skipped":4994,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.277 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:01.962
    Dec  3 13:18:01.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:18:01.963
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:01.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:01.988
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-3443 12/03/22 13:18:01.992
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[] 12/03/22 13:18:02.006
    Dec  3 13:18:02.010: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Dec  3 13:18:03.021: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-3443 12/03/22 13:18:03.021
    Dec  3 13:18:03.033: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3443" to be "running and ready"
    Dec  3 13:18:03.036: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.349302ms
    Dec  3 13:18:03.036: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:18:05.041: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008371235s
    Dec  3 13:18:05.041: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec  3 13:18:05.041: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod1:[80]] 12/03/22 13:18:05.044
    Dec  3 13:18:05.055: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 12/03/22 13:18:05.055
    Dec  3 13:18:05.055: INFO: Creating new exec pod
    Dec  3 13:18:05.065: INFO: Waiting up to 5m0s for pod "execpods6bbp" in namespace "services-3443" to be "running"
    Dec  3 13:18:05.069: INFO: Pod "execpods6bbp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16869ms
    Dec  3 13:18:07.076: INFO: Pod "execpods6bbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011092321s
    Dec  3 13:18:07.076: INFO: Pod "execpods6bbp" satisfied condition "running"
    Dec  3 13:18:08.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec  3 13:18:08.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:08.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:18:08.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
    Dec  3 13:18:08.448: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:08.448: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-3443 12/03/22 13:18:08.448
    Dec  3 13:18:08.454: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3443" to be "running and ready"
    Dec  3 13:18:08.458: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.659509ms
    Dec  3 13:18:08.458: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:18:10.464: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009922867s
    Dec  3 13:18:10.465: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec  3 13:18:10.465: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod1:[80] pod2:[80]] 12/03/22 13:18:10.47
    Dec  3 13:18:10.490: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 12/03/22 13:18:10.49
    Dec  3 13:18:11.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec  3 13:18:11.643: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:11.643: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:18:11.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
    Dec  3 13:18:11.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:11.779: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-3443 12/03/22 13:18:11.779
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[pod2:[80]] 12/03/22 13:18:11.795
    Dec  3 13:18:12.827: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 12/03/22 13:18:12.827
    Dec  3 13:18:13.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec  3 13:18:13.980: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:13.980: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:18:13.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3443 exec execpods6bbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.190 80'
    Dec  3 13:18:14.166: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.190 80\nConnection to 10.152.183.190 80 port [tcp/http] succeeded!\n"
    Dec  3 13:18:14.166: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-3443 12/03/22 13:18:14.166
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3443 to expose endpoints map[] 12/03/22 13:18:14.184
    Dec  3 13:18:14.200: INFO: successfully validated that service endpoint-test2 in namespace services-3443 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:18:14.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3443" for this suite. 12/03/22 13:18:14.23
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:14.24
Dec  3 13:18:14.240: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename server-version 12/03/22 13:18:14.241
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:14.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:14.276
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 12/03/22 13:18:14.28
STEP: Confirm major version 12/03/22 13:18:14.281
Dec  3 13:18:14.282: INFO: Major version: 1
STEP: Confirm minor version 12/03/22 13:18:14.282
Dec  3 13:18:14.282: INFO: cleanMinorVersion: 25
Dec  3 13:18:14.282: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Dec  3 13:18:14.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1153" for this suite. 12/03/22 13:18:14.286
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":273,"skipped":5045,"failed":0}
------------------------------
â€¢ [0.054 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:14.24
    Dec  3 13:18:14.240: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename server-version 12/03/22 13:18:14.241
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:14.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:14.276
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 12/03/22 13:18:14.28
    STEP: Confirm major version 12/03/22 13:18:14.281
    Dec  3 13:18:14.282: INFO: Major version: 1
    STEP: Confirm minor version 12/03/22 13:18:14.282
    Dec  3 13:18:14.282: INFO: cleanMinorVersion: 25
    Dec  3 13:18:14.282: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Dec  3 13:18:14.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1153" for this suite. 12/03/22 13:18:14.286
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:14.296
Dec  3 13:18:14.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:18:14.297
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:14.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:14.34
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/03/22 13:18:14.351
Dec  3 13:18:14.367: INFO: Waiting up to 5m0s for pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5" in namespace "emptydir-4515" to be "Succeeded or Failed"
Dec  3 13:18:14.372: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199174ms
Dec  3 13:18:16.378: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010789935s
Dec  3 13:18:18.377: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01026289s
STEP: Saw pod success 12/03/22 13:18:18.378
Dec  3 13:18:18.378: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5" satisfied condition "Succeeded or Failed"
Dec  3 13:18:18.382: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 container test-container: <nil>
STEP: delete the pod 12/03/22 13:18:18.397
Dec  3 13:18:18.409: INFO: Waiting for pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 to disappear
Dec  3 13:18:18.413: INFO: Pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:18:18.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4515" for this suite. 12/03/22 13:18:18.417
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":274,"skipped":5057,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:14.296
    Dec  3 13:18:14.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:18:14.297
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:14.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:14.34
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/03/22 13:18:14.351
    Dec  3 13:18:14.367: INFO: Waiting up to 5m0s for pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5" in namespace "emptydir-4515" to be "Succeeded or Failed"
    Dec  3 13:18:14.372: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199174ms
    Dec  3 13:18:16.378: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010789935s
    Dec  3 13:18:18.377: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01026289s
    STEP: Saw pod success 12/03/22 13:18:18.378
    Dec  3 13:18:18.378: INFO: Pod "pod-0e100d08-e681-4531-9b91-2aca08ee2ee5" satisfied condition "Succeeded or Failed"
    Dec  3 13:18:18.382: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:18:18.397
    Dec  3 13:18:18.409: INFO: Waiting for pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 to disappear
    Dec  3 13:18:18.413: INFO: Pod pod-0e100d08-e681-4531-9b91-2aca08ee2ee5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:18:18.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4515" for this suite. 12/03/22 13:18:18.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:18.43
Dec  3 13:18:18.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:18:18.431
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:18.455
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:18.458
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 12/03/22 13:18:18.462
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:18.468
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:18.468
STEP: creating a pod to probe DNS 12/03/22 13:18:18.468
STEP: submitting the pod to kubernetes 12/03/22 13:18:18.468
Dec  3 13:18:18.481: INFO: Waiting up to 15m0s for pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f" in namespace "dns-7635" to be "running"
Dec  3 13:18:18.485: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.965624ms
Dec  3 13:18:20.491: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01055636s
Dec  3 13:18:20.491: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:18:20.491
STEP: looking for the results for each expected name from probers 12/03/22 13:18:20.495
Dec  3 13:18:20.506: INFO: DNS probes using dns-test-2871d1ad-afed-4460-9f64-08f563110f4f succeeded

STEP: deleting the pod 12/03/22 13:18:20.506
STEP: changing the externalName to bar.example.com 12/03/22 13:18:20.52
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:20.53
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:20.53
STEP: creating a second pod to probe DNS 12/03/22 13:18:20.53
STEP: submitting the pod to kubernetes 12/03/22 13:18:20.53
Dec  3 13:18:20.538: INFO: Waiting up to 15m0s for pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c" in namespace "dns-7635" to be "running"
Dec  3 13:18:20.545: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.703267ms
Dec  3 13:18:22.549: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011545157s
Dec  3 13:18:22.550: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:18:22.55
STEP: looking for the results for each expected name from probers 12/03/22 13:18:22.553
Dec  3 13:18:22.559: INFO: File wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local from pod  dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 13:18:22.564: INFO: File jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local from pod  dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 13:18:22.564: INFO: Lookups using dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c failed for: [wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local]

Dec  3 13:18:27.577: INFO: DNS probes using dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c succeeded

STEP: deleting the pod 12/03/22 13:18:27.577
STEP: changing the service to type=ClusterIP 12/03/22 13:18:27.59
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:27.608
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
 12/03/22 13:18:27.608
STEP: creating a third pod to probe DNS 12/03/22 13:18:27.608
STEP: submitting the pod to kubernetes 12/03/22 13:18:27.619
Dec  3 13:18:27.631: INFO: Waiting up to 15m0s for pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4" in namespace "dns-7635" to be "running"
Dec  3 13:18:27.635: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03549ms
Dec  3 13:18:29.642: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.010441519s
Dec  3 13:18:29.642: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:18:29.642
STEP: looking for the results for each expected name from probers 12/03/22 13:18:29.646
Dec  3 13:18:29.659: INFO: DNS probes using dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4 succeeded

STEP: deleting the pod 12/03/22 13:18:29.659
STEP: deleting the test externalName service 12/03/22 13:18:29.677
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:18:29.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7635" for this suite. 12/03/22 13:18:29.701
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":275,"skipped":5099,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.278 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:18.43
    Dec  3 13:18:18.431: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:18:18.431
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:18.455
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:18.458
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 12/03/22 13:18:18.462
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:18.468
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:18.468
    STEP: creating a pod to probe DNS 12/03/22 13:18:18.468
    STEP: submitting the pod to kubernetes 12/03/22 13:18:18.468
    Dec  3 13:18:18.481: INFO: Waiting up to 15m0s for pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f" in namespace "dns-7635" to be "running"
    Dec  3 13:18:18.485: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.965624ms
    Dec  3 13:18:20.491: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01055636s
    Dec  3 13:18:20.491: INFO: Pod "dns-test-2871d1ad-afed-4460-9f64-08f563110f4f" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:18:20.491
    STEP: looking for the results for each expected name from probers 12/03/22 13:18:20.495
    Dec  3 13:18:20.506: INFO: DNS probes using dns-test-2871d1ad-afed-4460-9f64-08f563110f4f succeeded

    STEP: deleting the pod 12/03/22 13:18:20.506
    STEP: changing the externalName to bar.example.com 12/03/22 13:18:20.52
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:20.53
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:20.53
    STEP: creating a second pod to probe DNS 12/03/22 13:18:20.53
    STEP: submitting the pod to kubernetes 12/03/22 13:18:20.53
    Dec  3 13:18:20.538: INFO: Waiting up to 15m0s for pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c" in namespace "dns-7635" to be "running"
    Dec  3 13:18:20.545: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.703267ms
    Dec  3 13:18:22.549: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011545157s
    Dec  3 13:18:22.550: INFO: Pod "dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:18:22.55
    STEP: looking for the results for each expected name from probers 12/03/22 13:18:22.553
    Dec  3 13:18:22.559: INFO: File wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local from pod  dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec  3 13:18:22.564: INFO: File jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local from pod  dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec  3 13:18:22.564: INFO: Lookups using dns-7635/dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c failed for: [wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local]

    Dec  3 13:18:27.577: INFO: DNS probes using dns-test-d97a0ead-b4ab-48b8-9810-66b7b9c69d8c succeeded

    STEP: deleting the pod 12/03/22 13:18:27.577
    STEP: changing the service to type=ClusterIP 12/03/22 13:18:27.59
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:27.608
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7635.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7635.svc.cluster.local; sleep 1; done
     12/03/22 13:18:27.608
    STEP: creating a third pod to probe DNS 12/03/22 13:18:27.608
    STEP: submitting the pod to kubernetes 12/03/22 13:18:27.619
    Dec  3 13:18:27.631: INFO: Waiting up to 15m0s for pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4" in namespace "dns-7635" to be "running"
    Dec  3 13:18:27.635: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03549ms
    Dec  3 13:18:29.642: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.010441519s
    Dec  3 13:18:29.642: INFO: Pod "dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:18:29.642
    STEP: looking for the results for each expected name from probers 12/03/22 13:18:29.646
    Dec  3 13:18:29.659: INFO: DNS probes using dns-test-2a212c2f-5715-4bde-ac5a-725c08b208f4 succeeded

    STEP: deleting the pod 12/03/22 13:18:29.659
    STEP: deleting the test externalName service 12/03/22 13:18:29.677
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:18:29.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7635" for this suite. 12/03/22 13:18:29.701
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:29.711
Dec  3 13:18:29.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename podtemplate 12/03/22 13:18:29.713
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:29.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:29.743
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 12/03/22 13:18:29.747
Dec  3 13:18:29.752: INFO: created test-podtemplate-1
Dec  3 13:18:29.758: INFO: created test-podtemplate-2
Dec  3 13:18:29.764: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 12/03/22 13:18:29.764
STEP: delete collection of pod templates 12/03/22 13:18:29.767
Dec  3 13:18:29.767: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 12/03/22 13:18:29.787
Dec  3 13:18:29.787: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec  3 13:18:29.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6362" for this suite. 12/03/22 13:18:29.8
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":276,"skipped":5108,"failed":0}
------------------------------
â€¢ [0.100 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:29.711
    Dec  3 13:18:29.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename podtemplate 12/03/22 13:18:29.713
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:29.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:29.743
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 12/03/22 13:18:29.747
    Dec  3 13:18:29.752: INFO: created test-podtemplate-1
    Dec  3 13:18:29.758: INFO: created test-podtemplate-2
    Dec  3 13:18:29.764: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 12/03/22 13:18:29.764
    STEP: delete collection of pod templates 12/03/22 13:18:29.767
    Dec  3 13:18:29.767: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 12/03/22 13:18:29.787
    Dec  3 13:18:29.787: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec  3 13:18:29.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6362" for this suite. 12/03/22 13:18:29.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:29.815
Dec  3 13:18:29.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:18:29.816
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:29.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:29.845
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/03/22 13:18:29.848
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/03/22 13:18:29.848
STEP: creating a pod to probe DNS 12/03/22 13:18:29.848
STEP: submitting the pod to kubernetes 12/03/22 13:18:29.849
Dec  3 13:18:29.858: INFO: Waiting up to 15m0s for pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da" in namespace "dns-6337" to be "running"
Dec  3 13:18:29.863: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.491947ms
Dec  3 13:18:31.869: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010398017s
Dec  3 13:18:33.868: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Running", Reason="", readiness=true. Elapsed: 4.009775529s
Dec  3 13:18:33.868: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:18:33.868
STEP: looking for the results for each expected name from probers 12/03/22 13:18:33.872
Dec  3 13:18:33.911: INFO: DNS probes using dns-6337/dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da succeeded

STEP: deleting the pod 12/03/22 13:18:33.911
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:18:33.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6337" for this suite. 12/03/22 13:18:33.932
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":277,"skipped":5130,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:29.815
    Dec  3 13:18:29.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:18:29.816
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:29.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:29.845
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/03/22 13:18:29.848
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/03/22 13:18:29.848
    STEP: creating a pod to probe DNS 12/03/22 13:18:29.848
    STEP: submitting the pod to kubernetes 12/03/22 13:18:29.849
    Dec  3 13:18:29.858: INFO: Waiting up to 15m0s for pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da" in namespace "dns-6337" to be "running"
    Dec  3 13:18:29.863: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.491947ms
    Dec  3 13:18:31.869: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010398017s
    Dec  3 13:18:33.868: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da": Phase="Running", Reason="", readiness=true. Elapsed: 4.009775529s
    Dec  3 13:18:33.868: INFO: Pod "dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:18:33.868
    STEP: looking for the results for each expected name from probers 12/03/22 13:18:33.872
    Dec  3 13:18:33.911: INFO: DNS probes using dns-6337/dns-test-376d8638-8e0d-4223-b2d4-77da16cac6da succeeded

    STEP: deleting the pod 12/03/22 13:18:33.911
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:18:33.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6337" for this suite. 12/03/22 13:18:33.932
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:33.95
Dec  3 13:18:33.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename prestop 12/03/22 13:18:33.953
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:33.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:33.984
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-477 12/03/22 13:18:33.994
STEP: Waiting for pods to come up. 12/03/22 13:18:34.004
Dec  3 13:18:34.004: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-477" to be "running"
Dec  3 13:18:34.009: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 5.138288ms
Dec  3 13:18:36.016: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.012103539s
Dec  3 13:18:36.016: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-477 12/03/22 13:18:36.022
Dec  3 13:18:36.032: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-477" to be "running"
Dec  3 13:18:36.038: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.407861ms
Dec  3 13:18:38.043: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011447076s
Dec  3 13:18:40.047: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.015497768s
Dec  3 13:18:40.047: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 12/03/22 13:18:40.047
Dec  3 13:18:45.065: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 12/03/22 13:18:45.065
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Dec  3 13:18:45.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-477" for this suite. 12/03/22 13:18:45.082
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":278,"skipped":5180,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.144 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:33.95
    Dec  3 13:18:33.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename prestop 12/03/22 13:18:33.953
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:33.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:33.984
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-477 12/03/22 13:18:33.994
    STEP: Waiting for pods to come up. 12/03/22 13:18:34.004
    Dec  3 13:18:34.004: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-477" to be "running"
    Dec  3 13:18:34.009: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 5.138288ms
    Dec  3 13:18:36.016: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.012103539s
    Dec  3 13:18:36.016: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-477 12/03/22 13:18:36.022
    Dec  3 13:18:36.032: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-477" to be "running"
    Dec  3 13:18:36.038: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.407861ms
    Dec  3 13:18:38.043: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011447076s
    Dec  3 13:18:40.047: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.015497768s
    Dec  3 13:18:40.047: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 12/03/22 13:18:40.047
    Dec  3 13:18:45.065: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 12/03/22 13:18:45.065
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Dec  3 13:18:45.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-477" for this suite. 12/03/22 13:18:45.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:45.095
Dec  3 13:18:45.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename runtimeclass 12/03/22 13:18:45.096
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:45.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:45.124
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Dec  3 13:18:45.147: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8062 to be scheduled
Dec  3 13:18:45.149: INFO: 1 pods are not scheduled: [runtimeclass-8062/test-runtimeclass-runtimeclass-8062-preconfigured-handler-nmnwk(13822487-a2d3-46e8-a3bc-950e34ba8f17)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec  3 13:18:47.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8062" for this suite. 12/03/22 13:18:47.173
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":279,"skipped":5195,"failed":0}
------------------------------
â€¢ [2.086 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:45.095
    Dec  3 13:18:45.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename runtimeclass 12/03/22 13:18:45.096
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:45.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:45.124
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Dec  3 13:18:45.147: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8062 to be scheduled
    Dec  3 13:18:45.149: INFO: 1 pods are not scheduled: [runtimeclass-8062/test-runtimeclass-runtimeclass-8062-preconfigured-handler-nmnwk(13822487-a2d3-46e8-a3bc-950e34ba8f17)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec  3 13:18:47.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8062" for this suite. 12/03/22 13:18:47.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:47.182
Dec  3 13:18:47.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename deployment 12/03/22 13:18:47.182
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:47.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:47.21
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Dec  3 13:18:47.213: INFO: Creating deployment "test-recreate-deployment"
Dec  3 13:18:47.219: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 13:18:47.227: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  3 13:18:49.236: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 13:18:49.241: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 13:18:49.253: INFO: Updating deployment test-recreate-deployment
Dec  3 13:18:49.253: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec  3 13:18:49.358: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3023  370c9368-f941-4592-bbf7-d894783cb014 36041 2 2022-12-03 13:18:47 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00447ffc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-03 13:18:49 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-03 13:18:49 +0000 UTC,LastTransitionTime:2022-12-03 13:18:47 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 13:18:49.362: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-3023  540d788c-9225-4a38-a839-e628d3180a50 36037 1 2022-12-03 13:18:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 370c9368-f941-4592-bbf7-d894783cb014 0xc0044c7630 0xc0044c7631}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"370c9368-f941-4592-bbf7-d894783cb014\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044c76c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 13:18:49.362: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 13:18:49.362: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-3023  3e793c62-e4f1-4a8a-88ee-a340c78659c2 36028 2 2022-12-03 13:18:47 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 370c9368-f941-4592-bbf7-d894783cb014 0xc0044c7517 0xc0044c7518}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"370c9368-f941-4592-bbf7-d894783cb014\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044c75c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 13:18:49.368: INFO: Pod "test-recreate-deployment-9d58999df-pqb44" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-pqb44 test-recreate-deployment-9d58999df- deployment-3023  2651910e-1044-4fcf-ae5d-8970b76c5317 36039 0 2022-12-03 13:18:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 540d788c-9225-4a38-a839-e628d3180a50 0xc0044c7b60 0xc0044c7b61}] [] [{kube-controller-manager Update v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"540d788c-9225-4a38-a839-e628d3180a50\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hjxd4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hjxd4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 13:18:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec  3 13:18:49.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3023" for this suite. 12/03/22 13:18:49.375
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":280,"skipped":5204,"failed":0}
------------------------------
â€¢ [2.210 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:47.182
    Dec  3 13:18:47.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename deployment 12/03/22 13:18:47.182
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:47.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:47.21
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Dec  3 13:18:47.213: INFO: Creating deployment "test-recreate-deployment"
    Dec  3 13:18:47.219: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Dec  3 13:18:47.227: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Dec  3 13:18:49.236: INFO: Waiting deployment "test-recreate-deployment" to complete
    Dec  3 13:18:49.241: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Dec  3 13:18:49.253: INFO: Updating deployment test-recreate-deployment
    Dec  3 13:18:49.253: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec  3 13:18:49.358: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-3023  370c9368-f941-4592-bbf7-d894783cb014 36041 2 2022-12-03 13:18:47 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00447ffc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-03 13:18:49 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-03 13:18:49 +0000 UTC,LastTransitionTime:2022-12-03 13:18:47 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Dec  3 13:18:49.362: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-3023  540d788c-9225-4a38-a839-e628d3180a50 36037 1 2022-12-03 13:18:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 370c9368-f941-4592-bbf7-d894783cb014 0xc0044c7630 0xc0044c7631}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"370c9368-f941-4592-bbf7-d894783cb014\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044c76c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 13:18:49.362: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Dec  3 13:18:49.362: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-3023  3e793c62-e4f1-4a8a-88ee-a340c78659c2 36028 2 2022-12-03 13:18:47 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 370c9368-f941-4592-bbf7-d894783cb014 0xc0044c7517 0xc0044c7518}] [] [{kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"370c9368-f941-4592-bbf7-d894783cb014\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044c75c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec  3 13:18:49.368: INFO: Pod "test-recreate-deployment-9d58999df-pqb44" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-pqb44 test-recreate-deployment-9d58999df- deployment-3023  2651910e-1044-4fcf-ae5d-8970b76c5317 36039 0 2022-12-03 13:18:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 540d788c-9225-4a38-a839-e628d3180a50 0xc0044c7b60 0xc0044c7b61}] [] [{kube-controller-manager Update v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"540d788c-9225-4a38-a839-e628d3180a50\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-03 13:18:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hjxd4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hjxd4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-38-234,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-03 13:18:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.38.234,PodIP:,StartTime:2022-12-03 13:18:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec  3 13:18:49.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3023" for this suite. 12/03/22 13:18:49.375
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:49.395
Dec  3 13:18:49.396: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:18:49.396
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:49.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:49.421
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:18:49.445
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:18:50.108
STEP: Deploying the webhook pod 12/03/22 13:18:50.123
STEP: Wait for the deployment to be ready 12/03/22 13:18:50.138
Dec  3 13:18:50.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:18:52.16
STEP: Verifying the service has paired with the endpoint 12/03/22 13:18:52.174
Dec  3 13:18:53.174: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Dec  3 13:18:53.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/03/22 13:18:53.689
STEP: Creating a custom resource that should be denied by the webhook 12/03/22 13:18:53.705
STEP: Creating a custom resource whose deletion would be denied by the webhook 12/03/22 13:18:55.742
STEP: Updating the custom resource with disallowed data should be denied 12/03/22 13:18:55.751
STEP: Deleting the custom resource should be denied 12/03/22 13:18:55.761
STEP: Remove the offending key and value from the custom resource data 12/03/22 13:18:55.768
STEP: Deleting the updated custom resource should be successful 12/03/22 13:18:55.779
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:18:56.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2558" for this suite. 12/03/22 13:18:56.318
STEP: Destroying namespace "webhook-2558-markers" for this suite. 12/03/22 13:18:56.327
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":281,"skipped":5223,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.104 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:49.395
    Dec  3 13:18:49.396: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:18:49.396
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:49.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:49.421
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:18:49.445
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:18:50.108
    STEP: Deploying the webhook pod 12/03/22 13:18:50.123
    STEP: Wait for the deployment to be ready 12/03/22 13:18:50.138
    Dec  3 13:18:50.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:18:52.16
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:18:52.174
    Dec  3 13:18:53.174: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Dec  3 13:18:53.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/03/22 13:18:53.689
    STEP: Creating a custom resource that should be denied by the webhook 12/03/22 13:18:53.705
    STEP: Creating a custom resource whose deletion would be denied by the webhook 12/03/22 13:18:55.742
    STEP: Updating the custom resource with disallowed data should be denied 12/03/22 13:18:55.751
    STEP: Deleting the custom resource should be denied 12/03/22 13:18:55.761
    STEP: Remove the offending key and value from the custom resource data 12/03/22 13:18:55.768
    STEP: Deleting the updated custom resource should be successful 12/03/22 13:18:55.779
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:18:56.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2558" for this suite. 12/03/22 13:18:56.318
    STEP: Destroying namespace "webhook-2558-markers" for this suite. 12/03/22 13:18:56.327
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:18:56.504
Dec  3 13:18:56.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:18:56.505
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:56.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:56.541
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 12/03/22 13:18:56.544
Dec  3 13:18:56.562: INFO: Waiting up to 5m0s for pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3" in namespace "downward-api-3129" to be "Succeeded or Failed"
Dec  3 13:18:56.568: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.795508ms
Dec  3 13:18:58.574: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012578109s
Dec  3 13:19:00.574: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012751023s
STEP: Saw pod success 12/03/22 13:19:00.574
Dec  3 13:19:00.575: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3" satisfied condition "Succeeded or Failed"
Dec  3 13:19:00.582: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 container dapi-container: <nil>
STEP: delete the pod 12/03/22 13:19:00.595
Dec  3 13:19:00.608: INFO: Waiting for pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 to disappear
Dec  3 13:19:00.611: INFO: Pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec  3 13:19:00.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3129" for this suite. 12/03/22 13:19:00.616
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":282,"skipped":5295,"failed":0}
------------------------------
â€¢ [4.118 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:18:56.504
    Dec  3 13:18:56.504: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:18:56.505
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:18:56.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:18:56.541
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 12/03/22 13:18:56.544
    Dec  3 13:18:56.562: INFO: Waiting up to 5m0s for pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3" in namespace "downward-api-3129" to be "Succeeded or Failed"
    Dec  3 13:18:56.568: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.795508ms
    Dec  3 13:18:58.574: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012578109s
    Dec  3 13:19:00.574: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012751023s
    STEP: Saw pod success 12/03/22 13:19:00.574
    Dec  3 13:19:00.575: INFO: Pod "downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:00.582: INFO: Trying to get logs from node ip-172-31-38-234 pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 13:19:00.595
    Dec  3 13:19:00.608: INFO: Waiting for pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 to disappear
    Dec  3 13:19:00.611: INFO: Pod downward-api-ad2641f0-cfed-4119-8ebd-1bce708b1fe3 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec  3 13:19:00.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3129" for this suite. 12/03/22 13:19:00.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:00.637
Dec  3 13:19:00.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context-test 12/03/22 13:19:00.639
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:00.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:00.671
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Dec  3 13:19:00.684: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d" in namespace "security-context-test-6316" to be "Succeeded or Failed"
Dec  3 13:19:00.687: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.452484ms
Dec  3 13:19:02.696: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012075371s
Dec  3 13:19:04.692: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008675815s
Dec  3 13:19:04.692: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 13:19:04.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6316" for this suite. 12/03/22 13:19:04.698
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":283,"skipped":5316,"failed":0}
------------------------------
â€¢ [4.069 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:00.637
    Dec  3 13:19:00.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context-test 12/03/22 13:19:00.639
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:00.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:00.671
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Dec  3 13:19:00.684: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d" in namespace "security-context-test-6316" to be "Succeeded or Failed"
    Dec  3 13:19:00.687: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.452484ms
    Dec  3 13:19:02.696: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012075371s
    Dec  3 13:19:04.692: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008675815s
    Dec  3 13:19:04.692: INFO: Pod "busybox-readonly-false-f92151dd-9687-440c-a024-c3a37cc8218d" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 13:19:04.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6316" for this suite. 12/03/22 13:19:04.698
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:04.708
Dec  3 13:19:04.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:19:04.71
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:04.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:04.735
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  12/03/22 13:19:04.74
Dec  3 13:19:04.752: INFO: Waiting up to 5m0s for pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4" in namespace "svcaccounts-3860" to be "Succeeded or Failed"
Dec  3 13:19:04.755: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.78399ms
Dec  3 13:19:06.760: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526001s
Dec  3 13:19:08.761: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009123882s
STEP: Saw pod success 12/03/22 13:19:08.761
Dec  3 13:19:08.761: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4" satisfied condition "Succeeded or Failed"
Dec  3 13:19:08.766: INFO: Trying to get logs from node ip-172-31-38-234 pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:19:08.774
Dec  3 13:19:08.785: INFO: Waiting for pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 to disappear
Dec  3 13:19:08.788: INFO: Pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 13:19:08.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3860" for this suite. 12/03/22 13:19:08.793
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":284,"skipped":5323,"failed":0}
------------------------------
â€¢ [4.093 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:04.708
    Dec  3 13:19:04.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:19:04.71
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:04.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:04.735
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  12/03/22 13:19:04.74
    Dec  3 13:19:04.752: INFO: Waiting up to 5m0s for pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4" in namespace "svcaccounts-3860" to be "Succeeded or Failed"
    Dec  3 13:19:04.755: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.78399ms
    Dec  3 13:19:06.760: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526001s
    Dec  3 13:19:08.761: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009123882s
    STEP: Saw pod success 12/03/22 13:19:08.761
    Dec  3 13:19:08.761: INFO: Pod "test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:08.766: INFO: Trying to get logs from node ip-172-31-38-234 pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:19:08.774
    Dec  3 13:19:08.785: INFO: Waiting for pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 to disappear
    Dec  3 13:19:08.788: INFO: Pod test-pod-c40209c9-642f-4d8b-82fe-a6876875f4d4 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 13:19:08.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3860" for this suite. 12/03/22 13:19:08.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:08.808
Dec  3 13:19:08.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:19:08.809
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:08.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:08.835
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:19:08.838
Dec  3 13:19:08.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d" in namespace "projected-1939" to be "Succeeded or Failed"
Dec  3 13:19:08.853: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.199078ms
Dec  3 13:19:10.858: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008885899s
Dec  3 13:19:12.860: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010531258s
STEP: Saw pod success 12/03/22 13:19:12.86
Dec  3 13:19:12.860: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d" satisfied condition "Succeeded or Failed"
Dec  3 13:19:12.867: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d container client-container: <nil>
STEP: delete the pod 12/03/22 13:19:12.877
Dec  3 13:19:12.893: INFO: Waiting for pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d to disappear
Dec  3 13:19:12.896: INFO: Pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:19:12.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1939" for this suite. 12/03/22 13:19:12.9
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":285,"skipped":5342,"failed":0}
------------------------------
â€¢ [4.101 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:08.808
    Dec  3 13:19:08.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:19:08.809
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:08.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:08.835
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:19:08.838
    Dec  3 13:19:08.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d" in namespace "projected-1939" to be "Succeeded or Failed"
    Dec  3 13:19:08.853: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.199078ms
    Dec  3 13:19:10.858: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008885899s
    Dec  3 13:19:12.860: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010531258s
    STEP: Saw pod success 12/03/22 13:19:12.86
    Dec  3 13:19:12.860: INFO: Pod "downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:12.867: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d container client-container: <nil>
    STEP: delete the pod 12/03/22 13:19:12.877
    Dec  3 13:19:12.893: INFO: Waiting for pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d to disappear
    Dec  3 13:19:12.896: INFO: Pod downwardapi-volume-b374fe88-7efc-4433-b776-f9f511f6a28d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:19:12.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1939" for this suite. 12/03/22 13:19:12.9
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:12.912
Dec  3 13:19:12.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:19:12.913
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:12.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:12.937
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-c11ae214-0727-4d9d-bc2d-38428ca3897a 12/03/22 13:19:12.941
STEP: Creating a pod to test consume configMaps 12/03/22 13:19:12.946
Dec  3 13:19:12.958: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd" in namespace "projected-8985" to be "Succeeded or Failed"
Dec  3 13:19:12.962: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000922ms
Dec  3 13:19:14.967: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008935927s
Dec  3 13:19:16.968: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010428603s
STEP: Saw pod success 12/03/22 13:19:16.968
Dec  3 13:19:16.968: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd" satisfied condition "Succeeded or Failed"
Dec  3 13:19:16.973: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:19:16.98
Dec  3 13:19:17.002: INFO: Waiting for pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd to disappear
Dec  3 13:19:17.006: INFO: Pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:19:17.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8985" for this suite. 12/03/22 13:19:17.009
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":286,"skipped":5346,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:12.912
    Dec  3 13:19:12.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:19:12.913
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:12.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:12.937
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-c11ae214-0727-4d9d-bc2d-38428ca3897a 12/03/22 13:19:12.941
    STEP: Creating a pod to test consume configMaps 12/03/22 13:19:12.946
    Dec  3 13:19:12.958: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd" in namespace "projected-8985" to be "Succeeded or Failed"
    Dec  3 13:19:12.962: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000922ms
    Dec  3 13:19:14.967: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008935927s
    Dec  3 13:19:16.968: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010428603s
    STEP: Saw pod success 12/03/22 13:19:16.968
    Dec  3 13:19:16.968: INFO: Pod "pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:16.973: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:19:16.98
    Dec  3 13:19:17.002: INFO: Waiting for pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd to disappear
    Dec  3 13:19:17.006: INFO: Pod pod-projected-configmaps-8b6ee458-6a9d-409c-bf3e-babf4b5d8fdd no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:19:17.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8985" for this suite. 12/03/22 13:19:17.009
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:17.021
Dec  3 13:19:17.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:19:17.022
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:17.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:17.063
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 12/03/22 13:19:17.066
Dec  3 13:19:17.077: INFO: Waiting up to 5m0s for pod "pod-70f79710-490b-4ed0-abbb-00730465e380" in namespace "emptydir-4184" to be "Succeeded or Failed"
Dec  3 13:19:17.082: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Pending", Reason="", readiness=false. Elapsed: 4.716455ms
Dec  3 13:19:19.087: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009459719s
Dec  3 13:19:21.088: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010611307s
STEP: Saw pod success 12/03/22 13:19:21.088
Dec  3 13:19:21.088: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380" satisfied condition "Succeeded or Failed"
Dec  3 13:19:21.093: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-70f79710-490b-4ed0-abbb-00730465e380 container test-container: <nil>
STEP: delete the pod 12/03/22 13:19:21.1
Dec  3 13:19:21.113: INFO: Waiting for pod pod-70f79710-490b-4ed0-abbb-00730465e380 to disappear
Dec  3 13:19:21.116: INFO: Pod pod-70f79710-490b-4ed0-abbb-00730465e380 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:19:21.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4184" for this suite. 12/03/22 13:19:21.12
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":287,"skipped":5407,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:17.021
    Dec  3 13:19:17.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:19:17.022
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:17.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:17.063
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 12/03/22 13:19:17.066
    Dec  3 13:19:17.077: INFO: Waiting up to 5m0s for pod "pod-70f79710-490b-4ed0-abbb-00730465e380" in namespace "emptydir-4184" to be "Succeeded or Failed"
    Dec  3 13:19:17.082: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Pending", Reason="", readiness=false. Elapsed: 4.716455ms
    Dec  3 13:19:19.087: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009459719s
    Dec  3 13:19:21.088: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010611307s
    STEP: Saw pod success 12/03/22 13:19:21.088
    Dec  3 13:19:21.088: INFO: Pod "pod-70f79710-490b-4ed0-abbb-00730465e380" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:21.093: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-70f79710-490b-4ed0-abbb-00730465e380 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:19:21.1
    Dec  3 13:19:21.113: INFO: Waiting for pod pod-70f79710-490b-4ed0-abbb-00730465e380 to disappear
    Dec  3 13:19:21.116: INFO: Pod pod-70f79710-490b-4ed0-abbb-00730465e380 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:19:21.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4184" for this suite. 12/03/22 13:19:21.12
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:21.128
Dec  3 13:19:21.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:19:21.129
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:21.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:21.153
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Dec  3 13:19:21.171: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3" in namespace "kubelet-test-3327" to be "running and ready"
Dec  3 13:19:21.174: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.263124ms
Dec  3 13:19:21.175: INFO: The phase of Pod busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:19:23.180: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3": Phase="Running", Reason="", readiness=true. Elapsed: 2.009271555s
Dec  3 13:19:23.181: INFO: The phase of Pod busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3 is Running (Ready = true)
Dec  3 13:19:23.181: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec  3 13:19:23.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3327" for this suite. 12/03/22 13:19:23.197
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":288,"skipped":5410,"failed":0}
------------------------------
â€¢ [2.077 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:21.128
    Dec  3 13:19:21.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:19:21.129
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:21.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:21.153
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Dec  3 13:19:21.171: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3" in namespace "kubelet-test-3327" to be "running and ready"
    Dec  3 13:19:21.174: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.263124ms
    Dec  3 13:19:21.175: INFO: The phase of Pod busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:19:23.180: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3": Phase="Running", Reason="", readiness=true. Elapsed: 2.009271555s
    Dec  3 13:19:23.181: INFO: The phase of Pod busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3 is Running (Ready = true)
    Dec  3 13:19:23.181: INFO: Pod "busybox-readonly-fs47b38c4e-1bb2-4ff3-bbf7-33705a7654d3" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec  3 13:19:23.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3327" for this suite. 12/03/22 13:19:23.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:23.206
Dec  3 13:19:23.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:19:23.207
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:23.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:23.23
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-8333/secret-test-1d30e3ed-0bb2-4c6f-8dd4-9bd97c4ef4ba 12/03/22 13:19:23.233
STEP: Creating a pod to test consume secrets 12/03/22 13:19:23.239
Dec  3 13:19:23.260: INFO: Waiting up to 5m0s for pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167" in namespace "secrets-8333" to be "Succeeded or Failed"
Dec  3 13:19:23.263: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885889ms
Dec  3 13:19:25.269: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009098231s
Dec  3 13:19:27.270: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010547807s
STEP: Saw pod success 12/03/22 13:19:27.27
Dec  3 13:19:27.271: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167" satisfied condition "Succeeded or Failed"
Dec  3 13:19:27.275: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 container env-test: <nil>
STEP: delete the pod 12/03/22 13:19:27.283
Dec  3 13:19:27.296: INFO: Waiting for pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 to disappear
Dec  3 13:19:27.305: INFO: Pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:19:27.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8333" for this suite. 12/03/22 13:19:27.312
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":289,"skipped":5427,"failed":0}
------------------------------
â€¢ [4.112 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:23.206
    Dec  3 13:19:23.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:19:23.207
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:23.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:23.23
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-8333/secret-test-1d30e3ed-0bb2-4c6f-8dd4-9bd97c4ef4ba 12/03/22 13:19:23.233
    STEP: Creating a pod to test consume secrets 12/03/22 13:19:23.239
    Dec  3 13:19:23.260: INFO: Waiting up to 5m0s for pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167" in namespace "secrets-8333" to be "Succeeded or Failed"
    Dec  3 13:19:23.263: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885889ms
    Dec  3 13:19:25.269: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009098231s
    Dec  3 13:19:27.270: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010547807s
    STEP: Saw pod success 12/03/22 13:19:27.27
    Dec  3 13:19:27.271: INFO: Pod "pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:27.275: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 container env-test: <nil>
    STEP: delete the pod 12/03/22 13:19:27.283
    Dec  3 13:19:27.296: INFO: Waiting for pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 to disappear
    Dec  3 13:19:27.305: INFO: Pod pod-configmaps-3b112df2-5048-4ac7-aaa9-fa2575698167 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:19:27.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8333" for this suite. 12/03/22 13:19:27.312
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:27.319
Dec  3 13:19:27.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:19:27.32
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:27.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:27.346
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 12/03/22 13:19:27.359
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_udp@PTR;check="$$(dig +tcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_tcp@PTR;sleep 1; done
 12/03/22 13:19:27.38
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_udp@PTR;check="$$(dig +tcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_tcp@PTR;sleep 1; done
 12/03/22 13:19:27.38
STEP: creating a pod to probe DNS 12/03/22 13:19:27.38
STEP: submitting the pod to kubernetes 12/03/22 13:19:27.38
Dec  3 13:19:27.411: INFO: Waiting up to 15m0s for pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50" in namespace "dns-3688" to be "running"
Dec  3 13:19:27.420: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50": Phase="Pending", Reason="", readiness=false. Elapsed: 9.012733ms
Dec  3 13:19:29.426: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50": Phase="Running", Reason="", readiness=true. Elapsed: 2.01467551s
Dec  3 13:19:29.426: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:19:29.426
STEP: looking for the results for each expected name from probers 12/03/22 13:19:29.433
Dec  3 13:19:29.439: INFO: Unable to read wheezy_udp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.446: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.452: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.459: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.488: INFO: Unable to read jessie_udp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.493: INFO: Unable to read jessie_tcp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.498: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.502: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
Dec  3 13:19:29.530: INFO: Lookups using dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50 failed for: [wheezy_udp@dns-test-service.dns-3688.svc.cluster.local wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local jessie_udp@dns-test-service.dns-3688.svc.cluster.local jessie_tcp@dns-test-service.dns-3688.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local]

Dec  3 13:19:34.615: INFO: DNS probes using dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50 succeeded

STEP: deleting the pod 12/03/22 13:19:34.615
STEP: deleting the test service 12/03/22 13:19:34.63
STEP: deleting the test headless service 12/03/22 13:19:34.662
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:19:34.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3688" for this suite. 12/03/22 13:19:34.694
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":290,"skipped":5437,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.383 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:27.319
    Dec  3 13:19:27.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:19:27.32
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:27.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:27.346
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 12/03/22 13:19:27.359
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_udp@PTR;check="$$(dig +tcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_tcp@PTR;sleep 1; done
     12/03/22 13:19:27.38
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3688.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3688.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3688.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_udp@PTR;check="$$(dig +tcp +noall +answer +search 36.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.36_tcp@PTR;sleep 1; done
     12/03/22 13:19:27.38
    STEP: creating a pod to probe DNS 12/03/22 13:19:27.38
    STEP: submitting the pod to kubernetes 12/03/22 13:19:27.38
    Dec  3 13:19:27.411: INFO: Waiting up to 15m0s for pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50" in namespace "dns-3688" to be "running"
    Dec  3 13:19:27.420: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50": Phase="Pending", Reason="", readiness=false. Elapsed: 9.012733ms
    Dec  3 13:19:29.426: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50": Phase="Running", Reason="", readiness=true. Elapsed: 2.01467551s
    Dec  3 13:19:29.426: INFO: Pod "dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:19:29.426
    STEP: looking for the results for each expected name from probers 12/03/22 13:19:29.433
    Dec  3 13:19:29.439: INFO: Unable to read wheezy_udp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.446: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.452: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.459: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.488: INFO: Unable to read jessie_udp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.493: INFO: Unable to read jessie_tcp@dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.498: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.502: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local from pod dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50: the server could not find the requested resource (get pods dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50)
    Dec  3 13:19:29.530: INFO: Lookups using dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50 failed for: [wheezy_udp@dns-test-service.dns-3688.svc.cluster.local wheezy_tcp@dns-test-service.dns-3688.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local jessie_udp@dns-test-service.dns-3688.svc.cluster.local jessie_tcp@dns-test-service.dns-3688.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3688.svc.cluster.local]

    Dec  3 13:19:34.615: INFO: DNS probes using dns-3688/dns-test-307ef0de-2b25-4a73-907f-dbacb7c4fc50 succeeded

    STEP: deleting the pod 12/03/22 13:19:34.615
    STEP: deleting the test service 12/03/22 13:19:34.63
    STEP: deleting the test headless service 12/03/22 13:19:34.662
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:19:34.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3688" for this suite. 12/03/22 13:19:34.694
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:34.704
Dec  3 13:19:34.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename podtemplate 12/03/22 13:19:34.705
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:34.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:34.755
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 12/03/22 13:19:34.76
STEP: Replace a pod template 12/03/22 13:19:34.772
Dec  3 13:19:34.784: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec  3 13:19:34.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5159" for this suite. 12/03/22 13:19:34.789
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":291,"skipped":5440,"failed":0}
------------------------------
â€¢ [0.097 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:34.704
    Dec  3 13:19:34.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename podtemplate 12/03/22 13:19:34.705
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:34.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:34.755
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 12/03/22 13:19:34.76
    STEP: Replace a pod template 12/03/22 13:19:34.772
    Dec  3 13:19:34.784: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec  3 13:19:34.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5159" for this suite. 12/03/22 13:19:34.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:34.802
Dec  3 13:19:34.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 13:19:34.803
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:34.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:34.825
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Dec  3 13:19:34.846: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 13:19:39.850: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/03/22 13:19:39.85
STEP: Scaling up "test-rs" replicaset  12/03/22 13:19:39.851
Dec  3 13:19:39.866: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 12/03/22 13:19:39.866
W1203 13:19:39.876841      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec  3 13:19:39.879: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
Dec  3 13:19:39.906: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
Dec  3 13:19:39.924: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
Dec  3 13:19:40.026: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
Dec  3 13:19:40.807: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 2, AvailableReplicas 2
Dec  3 13:19:41.016: INFO: observed Replicaset test-rs in namespace replicaset-5659 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 13:19:41.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5659" for this suite. 12/03/22 13:19:41.022
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":292,"skipped":5447,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.227 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:34.802
    Dec  3 13:19:34.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 13:19:34.803
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:34.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:34.825
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Dec  3 13:19:34.846: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec  3 13:19:39.850: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/03/22 13:19:39.85
    STEP: Scaling up "test-rs" replicaset  12/03/22 13:19:39.851
    Dec  3 13:19:39.866: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 12/03/22 13:19:39.866
    W1203 13:19:39.876841      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec  3 13:19:39.879: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
    Dec  3 13:19:39.906: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
    Dec  3 13:19:39.924: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
    Dec  3 13:19:40.026: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 1, AvailableReplicas 1
    Dec  3 13:19:40.807: INFO: observed ReplicaSet test-rs in namespace replicaset-5659 with ReadyReplicas 2, AvailableReplicas 2
    Dec  3 13:19:41.016: INFO: observed Replicaset test-rs in namespace replicaset-5659 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 13:19:41.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5659" for this suite. 12/03/22 13:19:41.022
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:41.033
Dec  3 13:19:41.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 13:19:41.034
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:41.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:41.057
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 12/03/22 13:19:41.06
STEP: submitting the pod to kubernetes 12/03/22 13:19:41.061
Dec  3 13:19:41.073: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" in namespace "pods-2582" to be "running and ready"
Dec  3 13:19:41.076: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Pending", Reason="", readiness=false. Elapsed: 3.56318ms
Dec  3 13:19:41.076: INFO: The phase of Pod pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:19:43.083: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.010254382s
Dec  3 13:19:43.083: INFO: The phase of Pod pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339 is Running (Ready = true)
Dec  3 13:19:43.083: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/03/22 13:19:43.087
STEP: updating the pod 12/03/22 13:19:43.09
Dec  3 13:19:43.606: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339"
Dec  3 13:19:43.606: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" in namespace "pods-2582" to be "terminated with reason DeadlineExceeded"
Dec  3 13:19:43.609: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.799195ms
Dec  3 13:19:45.615: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.008558029s
Dec  3 13:19:47.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=false. Elapsed: 4.008284674s
Dec  3 13:19:49.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.007731866s
Dec  3 13:19:49.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 13:19:49.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2582" for this suite. 12/03/22 13:19:49.618
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":293,"skipped":5495,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.593 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:41.033
    Dec  3 13:19:41.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 13:19:41.034
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:41.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:41.057
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 12/03/22 13:19:41.06
    STEP: submitting the pod to kubernetes 12/03/22 13:19:41.061
    Dec  3 13:19:41.073: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" in namespace "pods-2582" to be "running and ready"
    Dec  3 13:19:41.076: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Pending", Reason="", readiness=false. Elapsed: 3.56318ms
    Dec  3 13:19:41.076: INFO: The phase of Pod pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:19:43.083: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.010254382s
    Dec  3 13:19:43.083: INFO: The phase of Pod pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339 is Running (Ready = true)
    Dec  3 13:19:43.083: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/03/22 13:19:43.087
    STEP: updating the pod 12/03/22 13:19:43.09
    Dec  3 13:19:43.606: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339"
    Dec  3 13:19:43.606: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" in namespace "pods-2582" to be "terminated with reason DeadlineExceeded"
    Dec  3 13:19:43.609: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.799195ms
    Dec  3 13:19:45.615: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=true. Elapsed: 2.008558029s
    Dec  3 13:19:47.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Running", Reason="", readiness=false. Elapsed: 4.008284674s
    Dec  3 13:19:49.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.007731866s
    Dec  3 13:19:49.614: INFO: Pod "pod-update-activedeadlineseconds-1ffa1e74-e1d3-4c0c-b952-7d8615214339" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 13:19:49.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2582" for this suite. 12/03/22 13:19:49.618
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:49.626
Dec  3 13:19:49.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:19:49.627
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:49.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:49.656
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 13:19:49.663
Dec  3 13:19:49.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7967 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Dec  3 13:19:49.757: INFO: stderr: ""
Dec  3 13:19:49.757: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 12/03/22 13:19:49.757
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Dec  3 13:19:49.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7967 delete pods e2e-test-httpd-pod'
Dec  3 13:19:52.485: INFO: stderr: ""
Dec  3 13:19:52.485: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:19:52.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7967" for this suite. 12/03/22 13:19:52.489
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":294,"skipped":5496,"failed":0}
------------------------------
â€¢ [2.869 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:49.626
    Dec  3 13:19:49.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:19:49.627
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:49.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:49.656
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 13:19:49.663
    Dec  3 13:19:49.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7967 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Dec  3 13:19:49.757: INFO: stderr: ""
    Dec  3 13:19:49.757: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 12/03/22 13:19:49.757
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Dec  3 13:19:49.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-7967 delete pods e2e-test-httpd-pod'
    Dec  3 13:19:52.485: INFO: stderr: ""
    Dec  3 13:19:52.485: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:19:52.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7967" for this suite. 12/03/22 13:19:52.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:52.497
Dec  3 13:19:52.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:19:52.498
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:52.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:52.527
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 12/03/22 13:19:52.531
Dec  3 13:19:52.540: INFO: Waiting up to 5m0s for pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616" in namespace "emptydir-3790" to be "Succeeded or Failed"
Dec  3 13:19:52.547: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Pending", Reason="", readiness=false. Elapsed: 6.797542ms
Dec  3 13:19:54.552: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012501688s
Dec  3 13:19:56.553: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013221937s
STEP: Saw pod success 12/03/22 13:19:56.553
Dec  3 13:19:56.553: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616" satisfied condition "Succeeded or Failed"
Dec  3 13:19:56.566: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 container test-container: <nil>
STEP: delete the pod 12/03/22 13:19:56.577
Dec  3 13:19:56.591: INFO: Waiting for pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 to disappear
Dec  3 13:19:56.597: INFO: Pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:19:56.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3790" for this suite. 12/03/22 13:19:56.601
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":295,"skipped":5523,"failed":0}
------------------------------
â€¢ [4.111 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:52.497
    Dec  3 13:19:52.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:19:52.498
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:52.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:52.527
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/03/22 13:19:52.531
    Dec  3 13:19:52.540: INFO: Waiting up to 5m0s for pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616" in namespace "emptydir-3790" to be "Succeeded or Failed"
    Dec  3 13:19:52.547: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Pending", Reason="", readiness=false. Elapsed: 6.797542ms
    Dec  3 13:19:54.552: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012501688s
    Dec  3 13:19:56.553: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013221937s
    STEP: Saw pod success 12/03/22 13:19:56.553
    Dec  3 13:19:56.553: INFO: Pod "pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616" satisfied condition "Succeeded or Failed"
    Dec  3 13:19:56.566: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:19:56.577
    Dec  3 13:19:56.591: INFO: Waiting for pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 to disappear
    Dec  3 13:19:56.597: INFO: Pod pod-6c9b50b3-32cd-4ea0-8f23-e330fe098616 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:19:56.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3790" for this suite. 12/03/22 13:19:56.601
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:19:56.612
Dec  3 13:19:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 13:19:56.612
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:56.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:56.641
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Dec  3 13:19:56.677: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 12/03/22 13:19:56.683
Dec  3 13:19:56.687: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:19:56.687: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 12/03/22 13:19:56.687
Dec  3 13:19:56.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:19:56.715: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:19:57.719: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:19:57.719: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:19:58.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec  3 13:19:58.720: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 12/03/22 13:19:58.724
Dec  3 13:19:58.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec  3 13:19:58.745: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Dec  3 13:19:59.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:19:59.751: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/03/22 13:19:59.751
Dec  3 13:19:59.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:19:59.762: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:20:00.767: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:20:00.767: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:20:01.766: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:20:01.767: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
Dec  3 13:20:02.770: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec  3 13:20:02.770: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:20:02.783
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3003, will wait for the garbage collector to delete the pods 12/03/22 13:20:02.783
Dec  3 13:20:02.850: INFO: Deleting DaemonSet.extensions daemon-set took: 9.66388ms
Dec  3 13:20:02.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.513413ms
Dec  3 13:20:04.958: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:20:04.958: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 13:20:04.964: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36966"},"items":null}

Dec  3 13:20:04.971: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36966"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:20:05.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3003" for this suite. 12/03/22 13:20:05.028
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":296,"skipped":5561,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.433 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:19:56.612
    Dec  3 13:19:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 13:19:56.612
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:19:56.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:19:56.641
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Dec  3 13:19:56.677: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 12/03/22 13:19:56.683
    Dec  3 13:19:56.687: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:19:56.687: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 12/03/22 13:19:56.687
    Dec  3 13:19:56.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:19:56.715: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:19:57.719: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:19:57.719: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:19:58.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec  3 13:19:58.720: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 12/03/22 13:19:58.724
    Dec  3 13:19:58.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec  3 13:19:58.745: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Dec  3 13:19:59.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:19:59.751: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/03/22 13:19:59.751
    Dec  3 13:19:59.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:19:59.762: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:20:00.767: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:20:00.767: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:20:01.766: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:20:01.767: INFO: Node ip-172-31-76-203 is running 0 daemon pod, expected 1
    Dec  3 13:20:02.770: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec  3 13:20:02.770: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:20:02.783
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3003, will wait for the garbage collector to delete the pods 12/03/22 13:20:02.783
    Dec  3 13:20:02.850: INFO: Deleting DaemonSet.extensions daemon-set took: 9.66388ms
    Dec  3 13:20:02.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.513413ms
    Dec  3 13:20:04.958: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:20:04.958: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 13:20:04.964: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36966"},"items":null}

    Dec  3 13:20:04.971: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36966"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:20:05.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3003" for this suite. 12/03/22 13:20:05.028
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:20:05.046
Dec  3 13:20:05.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:20:05.047
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:05.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:05.086
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:20:05.089
Dec  3 13:20:05.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e" in namespace "projected-73" to be "Succeeded or Failed"
Dec  3 13:20:05.103: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.915324ms
Dec  3 13:20:07.108: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009297223s
Dec  3 13:20:09.107: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008549799s
STEP: Saw pod success 12/03/22 13:20:09.107
Dec  3 13:20:09.108: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e" satisfied condition "Succeeded or Failed"
Dec  3 13:20:09.111: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e container client-container: <nil>
STEP: delete the pod 12/03/22 13:20:09.119
Dec  3 13:20:09.135: INFO: Waiting for pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e to disappear
Dec  3 13:20:09.138: INFO: Pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:20:09.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-73" for this suite. 12/03/22 13:20:09.142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":297,"skipped":5562,"failed":0}
------------------------------
â€¢ [4.103 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:20:05.046
    Dec  3 13:20:05.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:20:05.047
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:05.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:05.086
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:20:05.089
    Dec  3 13:20:05.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e" in namespace "projected-73" to be "Succeeded or Failed"
    Dec  3 13:20:05.103: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.915324ms
    Dec  3 13:20:07.108: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009297223s
    Dec  3 13:20:09.107: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008549799s
    STEP: Saw pod success 12/03/22 13:20:09.107
    Dec  3 13:20:09.108: INFO: Pod "downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e" satisfied condition "Succeeded or Failed"
    Dec  3 13:20:09.111: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e container client-container: <nil>
    STEP: delete the pod 12/03/22 13:20:09.119
    Dec  3 13:20:09.135: INFO: Waiting for pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e to disappear
    Dec  3 13:20:09.138: INFO: Pod downwardapi-volume-4e126aa6-7d75-4e59-9590-be39a3ad692e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:20:09.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-73" for this suite. 12/03/22 13:20:09.142
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:20:09.149
Dec  3 13:20:09.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename resourcequota 12/03/22 13:20:09.151
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:09.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:09.183
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 12/03/22 13:20:26.192
STEP: Creating a ResourceQuota 12/03/22 13:20:31.196
STEP: Ensuring resource quota status is calculated 12/03/22 13:20:31.203
STEP: Creating a ConfigMap 12/03/22 13:20:33.209
STEP: Ensuring resource quota status captures configMap creation 12/03/22 13:20:33.222
STEP: Deleting a ConfigMap 12/03/22 13:20:35.227
STEP: Ensuring resource quota status released usage 12/03/22 13:20:35.239
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec  3 13:20:37.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1886" for this suite. 12/03/22 13:20:37.248
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":298,"skipped":5564,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.109 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:20:09.149
    Dec  3 13:20:09.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename resourcequota 12/03/22 13:20:09.151
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:09.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:09.183
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 12/03/22 13:20:26.192
    STEP: Creating a ResourceQuota 12/03/22 13:20:31.196
    STEP: Ensuring resource quota status is calculated 12/03/22 13:20:31.203
    STEP: Creating a ConfigMap 12/03/22 13:20:33.209
    STEP: Ensuring resource quota status captures configMap creation 12/03/22 13:20:33.222
    STEP: Deleting a ConfigMap 12/03/22 13:20:35.227
    STEP: Ensuring resource quota status released usage 12/03/22 13:20:35.239
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec  3 13:20:37.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1886" for this suite. 12/03/22 13:20:37.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:20:37.261
Dec  3 13:20:37.261: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replication-controller 12/03/22 13:20:37.262
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:37.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:37.294
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Dec  3 13:20:37.298: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/03/22 13:20:38.311
STEP: Checking rc "condition-test" has the desired failure condition set 12/03/22 13:20:38.318
STEP: Scaling down rc "condition-test" to satisfy pod quota 12/03/22 13:20:39.327
Dec  3 13:20:39.339: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 12/03/22 13:20:39.339
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec  3 13:20:40.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-762" for this suite. 12/03/22 13:20:40.352
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":299,"skipped":5579,"failed":0}
------------------------------
â€¢ [3.101 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:20:37.261
    Dec  3 13:20:37.261: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replication-controller 12/03/22 13:20:37.262
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:37.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:37.294
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Dec  3 13:20:37.298: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/03/22 13:20:38.311
    STEP: Checking rc "condition-test" has the desired failure condition set 12/03/22 13:20:38.318
    STEP: Scaling down rc "condition-test" to satisfy pod quota 12/03/22 13:20:39.327
    Dec  3 13:20:39.339: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 12/03/22 13:20:39.339
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec  3 13:20:40.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-762" for this suite. 12/03/22 13:20:40.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:20:40.363
Dec  3 13:20:40.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:20:40.364
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:40.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:40.387
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:20:40.391
Dec  3 13:20:40.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc" in namespace "downward-api-1122" to be "Succeeded or Failed"
Dec  3 13:20:40.403: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26303ms
Dec  3 13:20:42.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008900893s
Dec  3 13:20:44.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00874074s
STEP: Saw pod success 12/03/22 13:20:44.409
Dec  3 13:20:44.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc" satisfied condition "Succeeded or Failed"
Dec  3 13:20:44.412: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc container client-container: <nil>
STEP: delete the pod 12/03/22 13:20:44.421
Dec  3 13:20:44.437: INFO: Waiting for pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc to disappear
Dec  3 13:20:44.441: INFO: Pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:20:44.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1122" for this suite. 12/03/22 13:20:44.445
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":300,"skipped":5587,"failed":0}
------------------------------
â€¢ [4.089 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:20:40.363
    Dec  3 13:20:40.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:20:40.364
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:40.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:40.387
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:20:40.391
    Dec  3 13:20:40.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc" in namespace "downward-api-1122" to be "Succeeded or Failed"
    Dec  3 13:20:40.403: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26303ms
    Dec  3 13:20:42.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008900893s
    Dec  3 13:20:44.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00874074s
    STEP: Saw pod success 12/03/22 13:20:44.409
    Dec  3 13:20:44.409: INFO: Pod "downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc" satisfied condition "Succeeded or Failed"
    Dec  3 13:20:44.412: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc container client-container: <nil>
    STEP: delete the pod 12/03/22 13:20:44.421
    Dec  3 13:20:44.437: INFO: Waiting for pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc to disappear
    Dec  3 13:20:44.441: INFO: Pod downwardapi-volume-d7f3fbec-62af-439f-95f9-03927d1a2bbc no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:20:44.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1122" for this suite. 12/03/22 13:20:44.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:20:44.454
Dec  3 13:20:44.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:20:44.455
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:44.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:44.478
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:20:44.511
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:20:44.749
STEP: Deploying the webhook pod 12/03/22 13:20:44.759
STEP: Wait for the deployment to be ready 12/03/22 13:20:44.771
Dec  3 13:20:44.780: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:20:46.791
STEP: Verifying the service has paired with the endpoint 12/03/22 13:20:46.801
Dec  3 13:20:47.802: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/03/22 13:20:47.806
STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:47.806
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/03/22 13:20:47.824
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/03/22 13:20:48.843
STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:48.843
STEP: Having no error when timeout is longer than webhook latency 12/03/22 13:20:49.884
STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:49.884
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/03/22 13:20:54.931
STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:54.931
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:20:59.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-559" for this suite. 12/03/22 13:20:59.986
STEP: Destroying namespace "webhook-559-markers" for this suite. 12/03/22 13:20:59.994
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":301,"skipped":5593,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.604 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:20:44.454
    Dec  3 13:20:44.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:20:44.455
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:20:44.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:20:44.478
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:20:44.511
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:20:44.749
    STEP: Deploying the webhook pod 12/03/22 13:20:44.759
    STEP: Wait for the deployment to be ready 12/03/22 13:20:44.771
    Dec  3 13:20:44.780: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:20:46.791
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:20:46.801
    Dec  3 13:20:47.802: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/03/22 13:20:47.806
    STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:47.806
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/03/22 13:20:47.824
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/03/22 13:20:48.843
    STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:48.843
    STEP: Having no error when timeout is longer than webhook latency 12/03/22 13:20:49.884
    STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:49.884
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/03/22 13:20:54.931
    STEP: Registering slow webhook via the AdmissionRegistration API 12/03/22 13:20:54.931
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:20:59.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-559" for this suite. 12/03/22 13:20:59.986
    STEP: Destroying namespace "webhook-559-markers" for this suite. 12/03/22 13:20:59.994
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:00.06
Dec  3 13:21:00.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 13:21:00.061
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:00.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:00.147
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 12/03/22 13:21:00.149
STEP: Ensuring job reaches completions 12/03/22 13:21:00.156
STEP: Ensuring pods with index for job exist 12/03/22 13:21:12.161
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 13:21:12.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7104" for this suite. 12/03/22 13:21:12.169
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":302,"skipped":5615,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.115 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:00.06
    Dec  3 13:21:00.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 13:21:00.061
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:00.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:00.147
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 12/03/22 13:21:00.149
    STEP: Ensuring job reaches completions 12/03/22 13:21:00.156
    STEP: Ensuring pods with index for job exist 12/03/22 13:21:12.161
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 13:21:12.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7104" for this suite. 12/03/22 13:21:12.169
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:12.175
Dec  3 13:21:12.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 13:21:12.176
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:12.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:12.2
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 12/03/22 13:21:12.204
STEP: setting up watch 12/03/22 13:21:12.205
STEP: submitting the pod to kubernetes 12/03/22 13:21:12.31
STEP: verifying the pod is in kubernetes 12/03/22 13:21:12.322
STEP: verifying pod creation was observed 12/03/22 13:21:12.327
Dec  3 13:21:12.328: INFO: Waiting up to 5m0s for pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb" in namespace "pods-8189" to be "running"
Dec  3 13:21:12.332: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78063ms
Dec  3 13:21:14.338: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb": Phase="Running", Reason="", readiness=true. Elapsed: 2.010315881s
Dec  3 13:21:14.338: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb" satisfied condition "running"
STEP: deleting the pod gracefully 12/03/22 13:21:14.343
STEP: verifying pod deletion was observed 12/03/22 13:21:14.351
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 13:21:16.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8189" for this suite. 12/03/22 13:21:16.713
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":303,"skipped":5619,"failed":0}
------------------------------
â€¢ [4.548 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:12.175
    Dec  3 13:21:12.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 13:21:12.176
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:12.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:12.2
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 12/03/22 13:21:12.204
    STEP: setting up watch 12/03/22 13:21:12.205
    STEP: submitting the pod to kubernetes 12/03/22 13:21:12.31
    STEP: verifying the pod is in kubernetes 12/03/22 13:21:12.322
    STEP: verifying pod creation was observed 12/03/22 13:21:12.327
    Dec  3 13:21:12.328: INFO: Waiting up to 5m0s for pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb" in namespace "pods-8189" to be "running"
    Dec  3 13:21:12.332: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.78063ms
    Dec  3 13:21:14.338: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb": Phase="Running", Reason="", readiness=true. Elapsed: 2.010315881s
    Dec  3 13:21:14.338: INFO: Pod "pod-submit-remove-6f635b49-e706-4e5e-8cde-db5e7de98ecb" satisfied condition "running"
    STEP: deleting the pod gracefully 12/03/22 13:21:14.343
    STEP: verifying pod deletion was observed 12/03/22 13:21:14.351
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 13:21:16.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8189" for this suite. 12/03/22 13:21:16.713
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:16.725
Dec  3 13:21:16.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:21:16.726
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:16.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:16.754
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:21:16.777
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:21:17.404
STEP: Deploying the webhook pod 12/03/22 13:21:17.418
STEP: Wait for the deployment to be ready 12/03/22 13:21:17.431
Dec  3 13:21:17.441: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 12/03/22 13:21:19.456
STEP: Verifying the service has paired with the endpoint 12/03/22 13:21:19.48
Dec  3 13:21:20.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/03/22 13:21:20.485
STEP: create a configmap that should be updated by the webhook 12/03/22 13:21:20.506
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:21:20.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6787" for this suite. 12/03/22 13:21:20.604
STEP: Destroying namespace "webhook-6787-markers" for this suite. 12/03/22 13:21:20.612
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":304,"skipped":5621,"failed":0}
------------------------------
â€¢ [3.956 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:16.725
    Dec  3 13:21:16.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:21:16.726
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:16.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:16.754
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:21:16.777
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:21:17.404
    STEP: Deploying the webhook pod 12/03/22 13:21:17.418
    STEP: Wait for the deployment to be ready 12/03/22 13:21:17.431
    Dec  3 13:21:17.441: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 12/03/22 13:21:19.456
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:21:19.48
    Dec  3 13:21:20.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/03/22 13:21:20.485
    STEP: create a configmap that should be updated by the webhook 12/03/22 13:21:20.506
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:21:20.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6787" for this suite. 12/03/22 13:21:20.604
    STEP: Destroying namespace "webhook-6787-markers" for this suite. 12/03/22 13:21:20.612
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:20.682
Dec  3 13:21:20.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pod-network-test 12/03/22 13:21:20.683
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:20.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:20.724
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-5758 12/03/22 13:21:20.727
STEP: creating a selector 12/03/22 13:21:20.727
STEP: Creating the service pods in kubernetes 12/03/22 13:21:20.727
Dec  3 13:21:20.727: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec  3 13:21:20.769: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5758" to be "running and ready"
Dec  3 13:21:20.781: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.540546ms
Dec  3 13:21:20.781: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:21:22.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017602725s
Dec  3 13:21:22.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 13:21:24.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017048812s
Dec  3 13:21:24.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 13:21:26.787: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018128766s
Dec  3 13:21:26.787: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 13:21:28.788: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019195011s
Dec  3 13:21:28.788: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 13:21:30.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017578935s
Dec  3 13:21:30.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec  3 13:21:32.800: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.031189821s
Dec  3 13:21:32.800: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec  3 13:21:32.800: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec  3 13:21:32.804: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5758" to be "running and ready"
Dec  3 13:21:32.808: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.462682ms
Dec  3 13:21:32.808: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec  3 13:21:32.808: INFO: Pod "netserver-1" satisfied condition "running and ready"
Dec  3 13:21:32.812: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5758" to be "running and ready"
Dec  3 13:21:32.816: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.549812ms
Dec  3 13:21:32.816: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Dec  3 13:21:32.816: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 12/03/22 13:21:32.82
Dec  3 13:21:32.863: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5758" to be "running"
Dec  3 13:21:32.867: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.987455ms
Dec  3 13:21:34.871: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008706002s
Dec  3 13:21:34.871: INFO: Pod "test-container-pod" satisfied condition "running"
Dec  3 13:21:34.876: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Dec  3 13:21:34.876: INFO: Breadth first check of 192.168.197.125 on host 172.31.38.234...
Dec  3 13:21:34.881: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.197.125&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 13:21:34.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:21:34.882: INFO: ExecWithOptions: Clientset creation
Dec  3 13:21:34.882: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.197.125%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 13:21:34.964: INFO: Waiting for responses: map[]
Dec  3 13:21:34.964: INFO: reached 192.168.197.125 after 0/1 tries
Dec  3 13:21:34.964: INFO: Breadth first check of 192.168.197.50 on host 172.31.4.162...
Dec  3 13:21:34.970: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.197.50&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 13:21:34.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:21:34.970: INFO: ExecWithOptions: Clientset creation
Dec  3 13:21:34.971: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.197.50%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 13:21:35.061: INFO: Waiting for responses: map[]
Dec  3 13:21:35.061: INFO: reached 192.168.197.50 after 0/1 tries
Dec  3 13:21:35.061: INFO: Breadth first check of 192.168.71.249 on host 172.31.76.203...
Dec  3 13:21:35.065: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.71.249&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec  3 13:21:35.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:21:35.066: INFO: ExecWithOptions: Clientset creation
Dec  3 13:21:35.066: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.71.249%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec  3 13:21:35.150: INFO: Waiting for responses: map[]
Dec  3 13:21:35.150: INFO: reached 192.168.71.249 after 0/1 tries
Dec  3 13:21:35.150: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec  3 13:21:35.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5758" for this suite. 12/03/22 13:21:35.158
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":305,"skipped":5622,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.484 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:20.682
    Dec  3 13:21:20.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pod-network-test 12/03/22 13:21:20.683
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:20.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:20.724
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-5758 12/03/22 13:21:20.727
    STEP: creating a selector 12/03/22 13:21:20.727
    STEP: Creating the service pods in kubernetes 12/03/22 13:21:20.727
    Dec  3 13:21:20.727: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec  3 13:21:20.769: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5758" to be "running and ready"
    Dec  3 13:21:20.781: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.540546ms
    Dec  3 13:21:20.781: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:21:22.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017602725s
    Dec  3 13:21:22.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 13:21:24.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017048812s
    Dec  3 13:21:24.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 13:21:26.787: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018128766s
    Dec  3 13:21:26.787: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 13:21:28.788: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019195011s
    Dec  3 13:21:28.788: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 13:21:30.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017578935s
    Dec  3 13:21:30.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec  3 13:21:32.800: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.031189821s
    Dec  3 13:21:32.800: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec  3 13:21:32.800: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec  3 13:21:32.804: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5758" to be "running and ready"
    Dec  3 13:21:32.808: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.462682ms
    Dec  3 13:21:32.808: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec  3 13:21:32.808: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Dec  3 13:21:32.812: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5758" to be "running and ready"
    Dec  3 13:21:32.816: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.549812ms
    Dec  3 13:21:32.816: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Dec  3 13:21:32.816: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 12/03/22 13:21:32.82
    Dec  3 13:21:32.863: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5758" to be "running"
    Dec  3 13:21:32.867: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.987455ms
    Dec  3 13:21:34.871: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008706002s
    Dec  3 13:21:34.871: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec  3 13:21:34.876: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Dec  3 13:21:34.876: INFO: Breadth first check of 192.168.197.125 on host 172.31.38.234...
    Dec  3 13:21:34.881: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.197.125&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 13:21:34.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:21:34.882: INFO: ExecWithOptions: Clientset creation
    Dec  3 13:21:34.882: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.197.125%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 13:21:34.964: INFO: Waiting for responses: map[]
    Dec  3 13:21:34.964: INFO: reached 192.168.197.125 after 0/1 tries
    Dec  3 13:21:34.964: INFO: Breadth first check of 192.168.197.50 on host 172.31.4.162...
    Dec  3 13:21:34.970: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.197.50&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 13:21:34.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:21:34.970: INFO: ExecWithOptions: Clientset creation
    Dec  3 13:21:34.971: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.197.50%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 13:21:35.061: INFO: Waiting for responses: map[]
    Dec  3 13:21:35.061: INFO: reached 192.168.197.50 after 0/1 tries
    Dec  3 13:21:35.061: INFO: Breadth first check of 192.168.71.249 on host 172.31.76.203...
    Dec  3 13:21:35.065: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.197.101:9080/dial?request=hostname&protocol=udp&host=192.168.71.249&port=8081&tries=1'] Namespace:pod-network-test-5758 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec  3 13:21:35.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:21:35.066: INFO: ExecWithOptions: Clientset creation
    Dec  3 13:21:35.066: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5758/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.197.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.71.249%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec  3 13:21:35.150: INFO: Waiting for responses: map[]
    Dec  3 13:21:35.150: INFO: reached 192.168.71.249 after 0/1 tries
    Dec  3 13:21:35.150: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec  3 13:21:35.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5758" for this suite. 12/03/22 13:21:35.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:35.166
Dec  3 13:21:35.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename downward-api 12/03/22 13:21:35.168
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:35.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:35.245
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 12/03/22 13:21:35.288
Dec  3 13:21:35.300: INFO: Waiting up to 5m0s for pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a" in namespace "downward-api-5664" to be "running and ready"
Dec  3 13:21:35.305: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197927ms
Dec  3 13:21:35.305: INFO: The phase of Pod annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:21:37.310: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009822398s
Dec  3 13:21:37.310: INFO: The phase of Pod annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a is Running (Ready = true)
Dec  3 13:21:37.310: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a" satisfied condition "running and ready"
Dec  3 13:21:37.894: INFO: Successfully updated pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec  3 13:21:41.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5664" for this suite. 12/03/22 13:21:41.922
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":306,"skipped":5629,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.764 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:35.166
    Dec  3 13:21:35.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename downward-api 12/03/22 13:21:35.168
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:35.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:35.245
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 12/03/22 13:21:35.288
    Dec  3 13:21:35.300: INFO: Waiting up to 5m0s for pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a" in namespace "downward-api-5664" to be "running and ready"
    Dec  3 13:21:35.305: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197927ms
    Dec  3 13:21:35.305: INFO: The phase of Pod annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:21:37.310: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009822398s
    Dec  3 13:21:37.310: INFO: The phase of Pod annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a is Running (Ready = true)
    Dec  3 13:21:37.310: INFO: Pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a" satisfied condition "running and ready"
    Dec  3 13:21:37.894: INFO: Successfully updated pod "annotationupdate8e719060-dd0b-4538-9996-39c1a0fc6c9a"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec  3 13:21:41.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5664" for this suite. 12/03/22 13:21:41.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:41.932
Dec  3 13:21:41.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:21:41.933
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:41.979
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:41.984
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 12/03/22 13:21:41.992
STEP: waiting for available Endpoint 12/03/22 13:21:42.018
STEP: listing all Endpoints 12/03/22 13:21:42.02
STEP: updating the Endpoint 12/03/22 13:21:42.024
STEP: fetching the Endpoint 12/03/22 13:21:42.032
STEP: patching the Endpoint 12/03/22 13:21:42.036
STEP: fetching the Endpoint 12/03/22 13:21:42.047
STEP: deleting the Endpoint by Collection 12/03/22 13:21:42.051
STEP: waiting for Endpoint deletion 12/03/22 13:21:42.069
STEP: fetching the Endpoint 12/03/22 13:21:42.071
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:21:42.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1481" for this suite. 12/03/22 13:21:42.086
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":307,"skipped":5641,"failed":0}
------------------------------
â€¢ [0.169 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:41.932
    Dec  3 13:21:41.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:21:41.933
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:41.979
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:41.984
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 12/03/22 13:21:41.992
    STEP: waiting for available Endpoint 12/03/22 13:21:42.018
    STEP: listing all Endpoints 12/03/22 13:21:42.02
    STEP: updating the Endpoint 12/03/22 13:21:42.024
    STEP: fetching the Endpoint 12/03/22 13:21:42.032
    STEP: patching the Endpoint 12/03/22 13:21:42.036
    STEP: fetching the Endpoint 12/03/22 13:21:42.047
    STEP: deleting the Endpoint by Collection 12/03/22 13:21:42.051
    STEP: waiting for Endpoint deletion 12/03/22 13:21:42.069
    STEP: fetching the Endpoint 12/03/22 13:21:42.071
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:21:42.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1481" for this suite. 12/03/22 13:21:42.086
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:42.103
Dec  3 13:21:42.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:21:42.104
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:42.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:42.14
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Dec  3 13:21:42.146: INFO: Got root ca configmap in namespace "svcaccounts-5393"
Dec  3 13:21:42.173: INFO: Deleted root ca configmap in namespace "svcaccounts-5393"
STEP: waiting for a new root ca configmap created 12/03/22 13:21:42.674
Dec  3 13:21:42.680: INFO: Recreated root ca configmap in namespace "svcaccounts-5393"
Dec  3 13:21:42.687: INFO: Updated root ca configmap in namespace "svcaccounts-5393"
STEP: waiting for the root ca configmap reconciled 12/03/22 13:21:43.187
Dec  3 13:21:43.192: INFO: Reconciled root ca configmap in namespace "svcaccounts-5393"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec  3 13:21:43.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5393" for this suite. 12/03/22 13:21:43.197
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":308,"skipped":5653,"failed":0}
------------------------------
â€¢ [1.102 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:42.103
    Dec  3 13:21:42.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename svcaccounts 12/03/22 13:21:42.104
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:42.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:42.14
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Dec  3 13:21:42.146: INFO: Got root ca configmap in namespace "svcaccounts-5393"
    Dec  3 13:21:42.173: INFO: Deleted root ca configmap in namespace "svcaccounts-5393"
    STEP: waiting for a new root ca configmap created 12/03/22 13:21:42.674
    Dec  3 13:21:42.680: INFO: Recreated root ca configmap in namespace "svcaccounts-5393"
    Dec  3 13:21:42.687: INFO: Updated root ca configmap in namespace "svcaccounts-5393"
    STEP: waiting for the root ca configmap reconciled 12/03/22 13:21:43.187
    Dec  3 13:21:43.192: INFO: Reconciled root ca configmap in namespace "svcaccounts-5393"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec  3 13:21:43.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5393" for this suite. 12/03/22 13:21:43.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:43.212
Dec  3 13:21:43.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename endpointslice 12/03/22 13:21:43.216
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:43.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:43.246
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 12/03/22 13:21:43.249
STEP: getting /apis/discovery.k8s.io 12/03/22 13:21:43.251
STEP: getting /apis/discovery.k8s.iov1 12/03/22 13:21:43.252
STEP: creating 12/03/22 13:21:43.255
STEP: getting 12/03/22 13:21:43.302
STEP: listing 12/03/22 13:21:43.326
STEP: watching 12/03/22 13:21:43.331
Dec  3 13:21:43.331: INFO: starting watch
STEP: cluster-wide listing 12/03/22 13:21:43.333
STEP: cluster-wide watching 12/03/22 13:21:43.336
Dec  3 13:21:43.336: INFO: starting watch
STEP: patching 12/03/22 13:21:43.337
STEP: updating 12/03/22 13:21:43.36
Dec  3 13:21:43.370: INFO: waiting for watch events with expected annotations
Dec  3 13:21:43.370: INFO: saw patched and updated annotations
STEP: deleting 12/03/22 13:21:43.37
STEP: deleting a collection 12/03/22 13:21:43.406
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec  3 13:21:43.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1144" for this suite. 12/03/22 13:21:43.456
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":309,"skipped":5709,"failed":0}
------------------------------
â€¢ [0.252 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:43.212
    Dec  3 13:21:43.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename endpointslice 12/03/22 13:21:43.216
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:43.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:43.246
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 12/03/22 13:21:43.249
    STEP: getting /apis/discovery.k8s.io 12/03/22 13:21:43.251
    STEP: getting /apis/discovery.k8s.iov1 12/03/22 13:21:43.252
    STEP: creating 12/03/22 13:21:43.255
    STEP: getting 12/03/22 13:21:43.302
    STEP: listing 12/03/22 13:21:43.326
    STEP: watching 12/03/22 13:21:43.331
    Dec  3 13:21:43.331: INFO: starting watch
    STEP: cluster-wide listing 12/03/22 13:21:43.333
    STEP: cluster-wide watching 12/03/22 13:21:43.336
    Dec  3 13:21:43.336: INFO: starting watch
    STEP: patching 12/03/22 13:21:43.337
    STEP: updating 12/03/22 13:21:43.36
    Dec  3 13:21:43.370: INFO: waiting for watch events with expected annotations
    Dec  3 13:21:43.370: INFO: saw patched and updated annotations
    STEP: deleting 12/03/22 13:21:43.37
    STEP: deleting a collection 12/03/22 13:21:43.406
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec  3 13:21:43.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1144" for this suite. 12/03/22 13:21:43.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:21:43.466
Dec  3 13:21:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename statefulset 12/03/22 13:21:43.467
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:43.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:43.533
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1107 12/03/22 13:21:43.536
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-1107 12/03/22 13:21:43.549
Dec  3 13:21:43.594: INFO: Found 0 stateful pods, waiting for 1
Dec  3 13:21:53.600: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 12/03/22 13:21:53.608
STEP: Getting /status 12/03/22 13:21:53.615
Dec  3 13:21:53.621: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 12/03/22 13:21:53.621
Dec  3 13:21:53.632: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 12/03/22 13:21:53.632
Dec  3 13:21:53.634: INFO: Observed &StatefulSet event: ADDED
Dec  3 13:21:53.634: INFO: Found Statefulset ss in namespace statefulset-1107 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec  3 13:21:53.634: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 12/03/22 13:21:53.634
Dec  3 13:21:53.634: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec  3 13:21:53.644: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 12/03/22 13:21:53.644
Dec  3 13:21:53.646: INFO: Observed &StatefulSet event: ADDED
Dec  3 13:21:53.646: INFO: Observed Statefulset ss in namespace statefulset-1107 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec  3 13:21:53.647: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec  3 13:21:53.647: INFO: Deleting all statefulset in ns statefulset-1107
Dec  3 13:21:53.653: INFO: Scaling statefulset ss to 0
Dec  3 13:22:03.681: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 13:22:03.685: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec  3 13:22:03.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1107" for this suite. 12/03/22 13:22:03.705
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":310,"skipped":5718,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.246 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:21:43.466
    Dec  3 13:21:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename statefulset 12/03/22 13:21:43.467
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:21:43.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:21:43.533
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1107 12/03/22 13:21:43.536
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-1107 12/03/22 13:21:43.549
    Dec  3 13:21:43.594: INFO: Found 0 stateful pods, waiting for 1
    Dec  3 13:21:53.600: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 12/03/22 13:21:53.608
    STEP: Getting /status 12/03/22 13:21:53.615
    Dec  3 13:21:53.621: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 12/03/22 13:21:53.621
    Dec  3 13:21:53.632: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 12/03/22 13:21:53.632
    Dec  3 13:21:53.634: INFO: Observed &StatefulSet event: ADDED
    Dec  3 13:21:53.634: INFO: Found Statefulset ss in namespace statefulset-1107 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec  3 13:21:53.634: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 12/03/22 13:21:53.634
    Dec  3 13:21:53.634: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec  3 13:21:53.644: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 12/03/22 13:21:53.644
    Dec  3 13:21:53.646: INFO: Observed &StatefulSet event: ADDED
    Dec  3 13:21:53.646: INFO: Observed Statefulset ss in namespace statefulset-1107 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec  3 13:21:53.647: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec  3 13:21:53.647: INFO: Deleting all statefulset in ns statefulset-1107
    Dec  3 13:21:53.653: INFO: Scaling statefulset ss to 0
    Dec  3 13:22:03.681: INFO: Waiting for statefulset status.replicas updated to 0
    Dec  3 13:22:03.685: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec  3 13:22:03.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1107" for this suite. 12/03/22 13:22:03.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:03.712
Dec  3 13:22:03.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:22:03.713
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:03.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:03.751
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 12/03/22 13:22:03.755
Dec  3 13:22:03.766: INFO: Waiting up to 5m0s for pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128" in namespace "emptydir-5455" to be "Succeeded or Failed"
Dec  3 13:22:03.770: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 3.94449ms
Dec  3 13:22:05.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008982324s
Dec  3 13:22:07.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009629447s
Dec  3 13:22:09.774: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008506715s
STEP: Saw pod success 12/03/22 13:22:09.774
Dec  3 13:22:09.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128" satisfied condition "Succeeded or Failed"
Dec  3 13:22:09.779: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 container test-container: <nil>
STEP: delete the pod 12/03/22 13:22:09.788
Dec  3 13:22:09.800: INFO: Waiting for pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 to disappear
Dec  3 13:22:09.803: INFO: Pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:22:09.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5455" for this suite. 12/03/22 13:22:09.809
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":311,"skipped":5723,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.111 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:03.712
    Dec  3 13:22:03.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:22:03.713
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:03.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:03.751
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/03/22 13:22:03.755
    Dec  3 13:22:03.766: INFO: Waiting up to 5m0s for pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128" in namespace "emptydir-5455" to be "Succeeded or Failed"
    Dec  3 13:22:03.770: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 3.94449ms
    Dec  3 13:22:05.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008982324s
    Dec  3 13:22:07.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009629447s
    Dec  3 13:22:09.774: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008506715s
    STEP: Saw pod success 12/03/22 13:22:09.774
    Dec  3 13:22:09.775: INFO: Pod "pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128" satisfied condition "Succeeded or Failed"
    Dec  3 13:22:09.779: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:22:09.788
    Dec  3 13:22:09.800: INFO: Waiting for pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 to disappear
    Dec  3 13:22:09.803: INFO: Pod pod-0f477f84-1cb5-4df2-91ef-f46e1b6cb128 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:22:09.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5455" for this suite. 12/03/22 13:22:09.809
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:09.823
Dec  3 13:22:09.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:22:09.824
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:09.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:09.85
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-ee8f2b8f-2d1c-4541-b184-5c9eb9a54095 12/03/22 13:22:09.855
STEP: Creating a pod to test consume secrets 12/03/22 13:22:09.866
Dec  3 13:22:09.876: INFO: Waiting up to 5m0s for pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31" in namespace "secrets-2158" to be "Succeeded or Failed"
Dec  3 13:22:09.880: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.785234ms
Dec  3 13:22:11.885: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008759126s
Dec  3 13:22:13.886: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009704134s
STEP: Saw pod success 12/03/22 13:22:13.886
Dec  3 13:22:13.886: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31" satisfied condition "Succeeded or Failed"
Dec  3 13:22:13.889: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:22:13.903
Dec  3 13:22:13.914: INFO: Waiting for pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 to disappear
Dec  3 13:22:13.920: INFO: Pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:22:13.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2158" for this suite. 12/03/22 13:22:13.925
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":312,"skipped":5725,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:09.823
    Dec  3 13:22:09.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:22:09.824
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:09.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:09.85
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-ee8f2b8f-2d1c-4541-b184-5c9eb9a54095 12/03/22 13:22:09.855
    STEP: Creating a pod to test consume secrets 12/03/22 13:22:09.866
    Dec  3 13:22:09.876: INFO: Waiting up to 5m0s for pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31" in namespace "secrets-2158" to be "Succeeded or Failed"
    Dec  3 13:22:09.880: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.785234ms
    Dec  3 13:22:11.885: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008759126s
    Dec  3 13:22:13.886: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009704134s
    STEP: Saw pod success 12/03/22 13:22:13.886
    Dec  3 13:22:13.886: INFO: Pod "pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31" satisfied condition "Succeeded or Failed"
    Dec  3 13:22:13.889: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:22:13.903
    Dec  3 13:22:13.914: INFO: Waiting for pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 to disappear
    Dec  3 13:22:13.920: INFO: Pod pod-secrets-64cf10a2-2b9d-4094-b6dd-01700ce9aa31 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:22:13.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2158" for this suite. 12/03/22 13:22:13.925
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:13.938
Dec  3 13:22:13.938: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:22:13.939
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:13.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:13.973
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-909f55dd-28db-4dfb-941b-959394b96d29 12/03/22 13:22:13.98
STEP: Creating a pod to test consume configMaps 12/03/22 13:22:13.986
Dec  3 13:22:13.994: INFO: Waiting up to 5m0s for pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534" in namespace "configmap-8232" to be "Succeeded or Failed"
Dec  3 13:22:14.000: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Pending", Reason="", readiness=false. Elapsed: 6.352934ms
Dec  3 13:22:16.004: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009989905s
Dec  3 13:22:18.005: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010763312s
STEP: Saw pod success 12/03/22 13:22:18.005
Dec  3 13:22:18.005: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534" satisfied condition "Succeeded or Failed"
Dec  3 13:22:18.010: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:22:18.02
Dec  3 13:22:18.081: INFO: Waiting for pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 to disappear
Dec  3 13:22:18.086: INFO: Pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:22:18.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8232" for this suite. 12/03/22 13:22:18.091
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":313,"skipped":5800,"failed":0}
------------------------------
â€¢ [4.161 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:13.938
    Dec  3 13:22:13.938: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:22:13.939
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:13.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:13.973
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-909f55dd-28db-4dfb-941b-959394b96d29 12/03/22 13:22:13.98
    STEP: Creating a pod to test consume configMaps 12/03/22 13:22:13.986
    Dec  3 13:22:13.994: INFO: Waiting up to 5m0s for pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534" in namespace "configmap-8232" to be "Succeeded or Failed"
    Dec  3 13:22:14.000: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Pending", Reason="", readiness=false. Elapsed: 6.352934ms
    Dec  3 13:22:16.004: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009989905s
    Dec  3 13:22:18.005: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010763312s
    STEP: Saw pod success 12/03/22 13:22:18.005
    Dec  3 13:22:18.005: INFO: Pod "pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534" satisfied condition "Succeeded or Failed"
    Dec  3 13:22:18.010: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:22:18.02
    Dec  3 13:22:18.081: INFO: Waiting for pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 to disappear
    Dec  3 13:22:18.086: INFO: Pod pod-configmaps-42d10136-573f-45f1-84b5-291cdd49e534 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:22:18.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8232" for this suite. 12/03/22 13:22:18.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:18.102
Dec  3 13:22:18.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename dns 12/03/22 13:22:18.103
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:18.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:18.126
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 12/03/22 13:22:18.133
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 12/03/22 13:22:18.143
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 12/03/22 13:22:18.143
STEP: creating a pod to probe DNS 12/03/22 13:22:18.143
STEP: submitting the pod to kubernetes 12/03/22 13:22:18.143
Dec  3 13:22:18.159: INFO: Waiting up to 15m0s for pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47" in namespace "dns-4377" to be "running"
Dec  3 13:22:18.166: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47": Phase="Pending", Reason="", readiness=false. Elapsed: 6.702314ms
Dec  3 13:22:20.171: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47": Phase="Running", Reason="", readiness=true. Elapsed: 2.011707264s
Dec  3 13:22:20.171: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47" satisfied condition "running"
STEP: retrieving the pod 12/03/22 13:22:20.171
STEP: looking for the results for each expected name from probers 12/03/22 13:22:20.176
Dec  3 13:22:20.196: INFO: DNS probes using dns-4377/dns-test-4fbdc297-2b71-4e63-872c-78d317940b47 succeeded

STEP: deleting the pod 12/03/22 13:22:20.196
STEP: deleting the test headless service 12/03/22 13:22:20.208
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec  3 13:22:20.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4377" for this suite. 12/03/22 13:22:20.231
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":314,"skipped":5829,"failed":0}
------------------------------
â€¢ [2.138 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:18.102
    Dec  3 13:22:18.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename dns 12/03/22 13:22:18.103
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:18.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:18.126
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 12/03/22 13:22:18.133
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     12/03/22 13:22:18.143
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4377.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     12/03/22 13:22:18.143
    STEP: creating a pod to probe DNS 12/03/22 13:22:18.143
    STEP: submitting the pod to kubernetes 12/03/22 13:22:18.143
    Dec  3 13:22:18.159: INFO: Waiting up to 15m0s for pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47" in namespace "dns-4377" to be "running"
    Dec  3 13:22:18.166: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47": Phase="Pending", Reason="", readiness=false. Elapsed: 6.702314ms
    Dec  3 13:22:20.171: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47": Phase="Running", Reason="", readiness=true. Elapsed: 2.011707264s
    Dec  3 13:22:20.171: INFO: Pod "dns-test-4fbdc297-2b71-4e63-872c-78d317940b47" satisfied condition "running"
    STEP: retrieving the pod 12/03/22 13:22:20.171
    STEP: looking for the results for each expected name from probers 12/03/22 13:22:20.176
    Dec  3 13:22:20.196: INFO: DNS probes using dns-4377/dns-test-4fbdc297-2b71-4e63-872c-78d317940b47 succeeded

    STEP: deleting the pod 12/03/22 13:22:20.196
    STEP: deleting the test headless service 12/03/22 13:22:20.208
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec  3 13:22:20.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4377" for this suite. 12/03/22 13:22:20.231
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:20.241
Dec  3 13:22:20.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 13:22:20.242
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:20.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:20.264
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/03/22 13:22:20.27
Dec  3 13:22:20.279: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7709" to be "running and ready"
Dec  3 13:22:20.286: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.446723ms
Dec  3 13:22:20.286: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:22:22.291: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.011582202s
Dec  3 13:22:22.291: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Dec  3 13:22:22.291: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 12/03/22 13:22:22.296
STEP: Then the orphan pod is adopted 12/03/22 13:22:22.302
STEP: When the matched label of one of its pods change 12/03/22 13:22:23.31
Dec  3 13:22:23.337: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 12/03/22 13:22:23.352
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 13:22:23.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7709" for this suite. 12/03/22 13:22:23.738
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":315,"skipped":5834,"failed":0}
------------------------------
â€¢ [3.626 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:20.241
    Dec  3 13:22:20.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 13:22:20.242
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:20.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:20.264
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/03/22 13:22:20.27
    Dec  3 13:22:20.279: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7709" to be "running and ready"
    Dec  3 13:22:20.286: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.446723ms
    Dec  3 13:22:20.286: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:22:22.291: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.011582202s
    Dec  3 13:22:22.291: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Dec  3 13:22:22.291: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 12/03/22 13:22:22.296
    STEP: Then the orphan pod is adopted 12/03/22 13:22:22.302
    STEP: When the matched label of one of its pods change 12/03/22 13:22:23.31
    Dec  3 13:22:23.337: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/03/22 13:22:23.352
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 13:22:23.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7709" for this suite. 12/03/22 13:22:23.738
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:23.867
Dec  3 13:22:23.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename daemonsets 12/03/22 13:22:23.868
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:23.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:23.926
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 12/03/22 13:22:24.101
STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:22:24.106
Dec  3 13:22:24.109: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:24.110: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:24.204: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:22:24.204: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:22:25.237: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:25.237: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:25.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:22:25.241: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:22:26.209: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:26.209: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:26.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:22:26.214: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
Dec  3 13:22:27.238: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:27.238: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:27.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:22:27.242: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/03/22 13:22:27.245
Dec  3 13:22:27.272: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:27.272: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  3 13:22:27.341: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Dec  3 13:22:27.341: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 12/03/22 13:22:27.341
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:22:28.36
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1196, will wait for the garbage collector to delete the pods 12/03/22 13:22:28.36
Dec  3 13:22:28.473: INFO: Deleting DaemonSet.extensions daemon-set took: 57.825481ms
Dec  3 13:22:28.774: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.865436ms
Dec  3 13:22:30.714: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec  3 13:22:30.714: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec  3 13:22:30.723: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38323"},"items":null}

Dec  3 13:22:30.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38323"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:22:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1196" for this suite. 12/03/22 13:22:30.795
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":316,"skipped":5834,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.975 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:23.867
    Dec  3 13:22:23.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename daemonsets 12/03/22 13:22:23.868
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:23.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:23.926
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 12/03/22 13:22:24.101
    STEP: Check that daemon pods launch on every node of the cluster. 12/03/22 13:22:24.106
    Dec  3 13:22:24.109: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:24.110: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:24.204: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:22:24.204: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:22:25.237: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:25.237: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:25.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:22:25.241: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:22:26.209: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:26.209: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:26.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:22:26.214: INFO: Node ip-172-31-38-234 is running 0 daemon pod, expected 1
    Dec  3 13:22:27.238: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:27.238: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:27.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:22:27.242: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/03/22 13:22:27.245
    Dec  3 13:22:27.272: INFO: DaemonSet pods can't tolerate node ip-172-31-47-238 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:27.272: INFO: DaemonSet pods can't tolerate node ip-172-31-70-229 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Dec  3 13:22:27.341: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Dec  3 13:22:27.341: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 12/03/22 13:22:27.341
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/03/22 13:22:28.36
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1196, will wait for the garbage collector to delete the pods 12/03/22 13:22:28.36
    Dec  3 13:22:28.473: INFO: Deleting DaemonSet.extensions daemon-set took: 57.825481ms
    Dec  3 13:22:28.774: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.865436ms
    Dec  3 13:22:30.714: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec  3 13:22:30.714: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec  3 13:22:30.723: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38323"},"items":null}

    Dec  3 13:22:30.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38323"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:22:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1196" for this suite. 12/03/22 13:22:30.795
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:30.843
Dec  3 13:22:30.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:22:30.844
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:30.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:30.979
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/03/22 13:22:31.105
Dec  3 13:22:31.180: INFO: Waiting up to 5m0s for pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9" in namespace "emptydir-6637" to be "Succeeded or Failed"
Dec  3 13:22:31.184: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.291688ms
Dec  3 13:22:33.188: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007785262s
Dec  3 13:22:35.209: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028861781s
STEP: Saw pod success 12/03/22 13:22:35.209
Dec  3 13:22:35.209: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9" satisfied condition "Succeeded or Failed"
Dec  3 13:22:35.213: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 container test-container: <nil>
STEP: delete the pod 12/03/22 13:22:35.221
Dec  3 13:22:35.235: INFO: Waiting for pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 to disappear
Dec  3 13:22:35.363: INFO: Pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:22:35.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6637" for this suite. 12/03/22 13:22:35.37
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":317,"skipped":5835,"failed":0}
------------------------------
â€¢ [4.567 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:30.843
    Dec  3 13:22:30.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:22:30.844
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:30.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:30.979
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/03/22 13:22:31.105
    Dec  3 13:22:31.180: INFO: Waiting up to 5m0s for pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9" in namespace "emptydir-6637" to be "Succeeded or Failed"
    Dec  3 13:22:31.184: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.291688ms
    Dec  3 13:22:33.188: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007785262s
    Dec  3 13:22:35.209: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028861781s
    STEP: Saw pod success 12/03/22 13:22:35.209
    Dec  3 13:22:35.209: INFO: Pod "pod-4ea946aa-b855-4e29-a680-f12fda6e39d9" satisfied condition "Succeeded or Failed"
    Dec  3 13:22:35.213: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:22:35.221
    Dec  3 13:22:35.235: INFO: Waiting for pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 to disappear
    Dec  3 13:22:35.363: INFO: Pod pod-4ea946aa-b855-4e29-a680-f12fda6e39d9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:22:35.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6637" for this suite. 12/03/22 13:22:35.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:35.415
Dec  3 13:22:35.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:22:35.416
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:35.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:35.514
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:22:35.758
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:22:36.503
STEP: Deploying the webhook pod 12/03/22 13:22:36.513
STEP: Wait for the deployment to be ready 12/03/22 13:22:36.625
Dec  3 13:22:36.638: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec  3 13:22:38.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 13, 22, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/03/22 13:22:40.685
STEP: Verifying the service has paired with the endpoint 12/03/22 13:22:40.702
Dec  3 13:22:41.703: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Dec  3 13:22:41.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2127-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 13:22:42.223
STEP: Creating a custom resource that should be mutated by the webhook 12/03/22 13:22:42.24
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:22:44.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9253" for this suite. 12/03/22 13:22:44.846
STEP: Destroying namespace "webhook-9253-markers" for this suite. 12/03/22 13:22:44.853
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":318,"skipped":5873,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.490 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:35.415
    Dec  3 13:22:35.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:22:35.416
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:35.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:35.514
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:22:35.758
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:22:36.503
    STEP: Deploying the webhook pod 12/03/22 13:22:36.513
    STEP: Wait for the deployment to be ready 12/03/22 13:22:36.625
    Dec  3 13:22:36.638: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Dec  3 13:22:38.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 13, 22, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 22, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/03/22 13:22:40.685
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:22:40.702
    Dec  3 13:22:41.703: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Dec  3 13:22:41.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2127-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 13:22:42.223
    STEP: Creating a custom resource that should be mutated by the webhook 12/03/22 13:22:42.24
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:22:44.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9253" for this suite. 12/03/22 13:22:44.846
    STEP: Destroying namespace "webhook-9253-markers" for this suite. 12/03/22 13:22:44.853
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:22:44.909
Dec  3 13:22:44.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:22:44.911
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:44.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:44.943
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-3313 12/03/22 13:22:44.95
Dec  3 13:22:44.964: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3313" to be "running and ready"
Dec  3 13:22:44.969: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 5.327966ms
Dec  3 13:22:44.969: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:22:46.974: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.010359063s
Dec  3 13:22:46.974: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec  3 13:22:46.974: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec  3 13:22:46.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec  3 13:22:47.138: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec  3 13:22:47.138: INFO: stdout: "iptables"
Dec  3 13:22:47.138: INFO: proxyMode: iptables
Dec  3 13:22:47.155: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec  3 13:22:47.158: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-3313 12/03/22 13:22:47.158
STEP: creating replication controller affinity-nodeport-timeout in namespace services-3313 12/03/22 13:22:47.175
I1203 13:22:47.184052      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3313, replica count: 3
I1203 13:22:50.234906      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:22:50.246: INFO: Creating new exec pod
Dec  3 13:22:50.256: INFO: Waiting up to 5m0s for pod "execpod-affinity8mgbr" in namespace "services-3313" to be "running"
Dec  3 13:22:50.259: INFO: Pod "execpod-affinity8mgbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723419ms
Dec  3 13:22:52.265: INFO: Pod "execpod-affinity8mgbr": Phase="Running", Reason="", readiness=true. Elapsed: 2.008988032s
Dec  3 13:22:52.265: INFO: Pod "execpod-affinity8mgbr" satisfied condition "running"
Dec  3 13:22:53.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Dec  3 13:22:53.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Dec  3 13:22:53.425: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:22:53.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.197 80'
Dec  3 13:22:53.599: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.197 80\nConnection to 10.152.183.197 80 port [tcp/http] succeeded!\n"
Dec  3 13:22:53.599: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:22:53.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 30397'
Dec  3 13:22:53.775: INFO: stderr: "+ nc -v -t -w 2 172.31.38.234 30397\n+ echo hostName\nConnection to 172.31.38.234 30397 port [tcp/*] succeeded!\n"
Dec  3 13:22:53.775: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:22:53.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 30397'
Dec  3 13:22:53.985: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.4.162 30397\nConnection to 172.31.4.162 30397 port [tcp/*] succeeded!\n"
Dec  3 13:22:53.985: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec  3 13:22:53.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:30397/ ; done'
Dec  3 13:22:54.237: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
Dec  3 13:22:54.237: INFO: stdout: "\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb"
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
Dec  3 13:22:54.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.38.234:30397/'
Dec  3 13:22:54.391: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
Dec  3 13:22:54.391: INFO: stdout: "affinity-nodeport-timeout-mwjlb"
Dec  3 13:23:14.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.38.234:30397/'
Dec  3 13:23:14.613: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
Dec  3 13:23:14.613: INFO: stdout: "affinity-nodeport-timeout-9n7zc"
Dec  3 13:23:14.613: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3313, will wait for the garbage collector to delete the pods 12/03/22 13:23:14.628
Dec  3 13:23:14.696: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 10.931898ms
Dec  3 13:23:14.797: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.474864ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:23:17.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3313" for this suite. 12/03/22 13:23:17.131
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":319,"skipped":5879,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.231 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:22:44.909
    Dec  3 13:22:44.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:22:44.911
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:22:44.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:22:44.943
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-3313 12/03/22 13:22:44.95
    Dec  3 13:22:44.964: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3313" to be "running and ready"
    Dec  3 13:22:44.969: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 5.327966ms
    Dec  3 13:22:44.969: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:22:46.974: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.010359063s
    Dec  3 13:22:46.974: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec  3 13:22:46.974: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec  3 13:22:46.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec  3 13:22:47.138: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec  3 13:22:47.138: INFO: stdout: "iptables"
    Dec  3 13:22:47.138: INFO: proxyMode: iptables
    Dec  3 13:22:47.155: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec  3 13:22:47.158: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-3313 12/03/22 13:22:47.158
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-3313 12/03/22 13:22:47.175
    I1203 13:22:47.184052      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3313, replica count: 3
    I1203 13:22:50.234906      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:22:50.246: INFO: Creating new exec pod
    Dec  3 13:22:50.256: INFO: Waiting up to 5m0s for pod "execpod-affinity8mgbr" in namespace "services-3313" to be "running"
    Dec  3 13:22:50.259: INFO: Pod "execpod-affinity8mgbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723419ms
    Dec  3 13:22:52.265: INFO: Pod "execpod-affinity8mgbr": Phase="Running", Reason="", readiness=true. Elapsed: 2.008988032s
    Dec  3 13:22:52.265: INFO: Pod "execpod-affinity8mgbr" satisfied condition "running"
    Dec  3 13:22:53.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Dec  3 13:22:53.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Dec  3 13:22:53.425: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:22:53.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.197 80'
    Dec  3 13:22:53.599: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.197 80\nConnection to 10.152.183.197 80 port [tcp/http] succeeded!\n"
    Dec  3 13:22:53.599: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:22:53.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 30397'
    Dec  3 13:22:53.775: INFO: stderr: "+ nc -v -t -w 2 172.31.38.234 30397\n+ echo hostName\nConnection to 172.31.38.234 30397 port [tcp/*] succeeded!\n"
    Dec  3 13:22:53.775: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:22:53.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.162 30397'
    Dec  3 13:22:53.985: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.4.162 30397\nConnection to 172.31.4.162 30397 port [tcp/*] succeeded!\n"
    Dec  3 13:22:53.985: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec  3 13:22:53.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.234:30397/ ; done'
    Dec  3 13:22:54.237: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
    Dec  3 13:22:54.237: INFO: stdout: "\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb\naffinity-nodeport-timeout-mwjlb"
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Received response from host: affinity-nodeport-timeout-mwjlb
    Dec  3 13:22:54.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.38.234:30397/'
    Dec  3 13:22:54.391: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
    Dec  3 13:22:54.391: INFO: stdout: "affinity-nodeport-timeout-mwjlb"
    Dec  3 13:23:14.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-3313 exec execpod-affinity8mgbr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.38.234:30397/'
    Dec  3 13:23:14.613: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.38.234:30397/\n"
    Dec  3 13:23:14.613: INFO: stdout: "affinity-nodeport-timeout-9n7zc"
    Dec  3 13:23:14.613: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3313, will wait for the garbage collector to delete the pods 12/03/22 13:23:14.628
    Dec  3 13:23:14.696: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 10.931898ms
    Dec  3 13:23:14.797: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.474864ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:23:17.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3313" for this suite. 12/03/22 13:23:17.131
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:23:17.143
Dec  3 13:23:17.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename cronjob 12/03/22 13:23:17.144
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:23:17.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:23:17.175
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 12/03/22 13:23:17.178
STEP: Ensuring a job is scheduled 12/03/22 13:23:17.185
STEP: Ensuring exactly one is scheduled 12/03/22 13:24:01.192
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/03/22 13:24:01.196
STEP: Ensuring the job is replaced with a new one 12/03/22 13:24:01.2
STEP: Removing cronjob 12/03/22 13:25:01.207
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec  3 13:25:01.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-864" for this suite. 12/03/22 13:25:01.221
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":320,"skipped":5907,"failed":0}
------------------------------
â€¢ [SLOW TEST] [104.088 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:23:17.143
    Dec  3 13:23:17.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename cronjob 12/03/22 13:23:17.144
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:23:17.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:23:17.175
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 12/03/22 13:23:17.178
    STEP: Ensuring a job is scheduled 12/03/22 13:23:17.185
    STEP: Ensuring exactly one is scheduled 12/03/22 13:24:01.192
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/03/22 13:24:01.196
    STEP: Ensuring the job is replaced with a new one 12/03/22 13:24:01.2
    STEP: Removing cronjob 12/03/22 13:25:01.207
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec  3 13:25:01.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-864" for this suite. 12/03/22 13:25:01.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:01.232
Dec  3 13:25:01.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:25:01.233
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:01.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:01.268
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-53d2f131-76db-41da-b797-450f83071a81 12/03/22 13:25:01.272
STEP: Creating a pod to test consume secrets 12/03/22 13:25:01.277
Dec  3 13:25:01.291: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1" in namespace "projected-3317" to be "Succeeded or Failed"
Dec  3 13:25:01.295: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63441ms
Dec  3 13:25:03.300: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009363711s
Dec  3 13:25:05.300: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009276182s
STEP: Saw pod success 12/03/22 13:25:05.3
Dec  3 13:25:05.301: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1" satisfied condition "Succeeded or Failed"
Dec  3 13:25:05.304: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 container projected-secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:25:05.329
Dec  3 13:25:05.347: INFO: Waiting for pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 to disappear
Dec  3 13:25:05.353: INFO: Pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec  3 13:25:05.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3317" for this suite. 12/03/22 13:25:05.359
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":321,"skipped":5912,"failed":0}
------------------------------
â€¢ [4.135 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:01.232
    Dec  3 13:25:01.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:25:01.233
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:01.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:01.268
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-53d2f131-76db-41da-b797-450f83071a81 12/03/22 13:25:01.272
    STEP: Creating a pod to test consume secrets 12/03/22 13:25:01.277
    Dec  3 13:25:01.291: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1" in namespace "projected-3317" to be "Succeeded or Failed"
    Dec  3 13:25:01.295: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63441ms
    Dec  3 13:25:03.300: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009363711s
    Dec  3 13:25:05.300: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009276182s
    STEP: Saw pod success 12/03/22 13:25:05.3
    Dec  3 13:25:05.301: INFO: Pod "pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1" satisfied condition "Succeeded or Failed"
    Dec  3 13:25:05.304: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:25:05.329
    Dec  3 13:25:05.347: INFO: Waiting for pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 to disappear
    Dec  3 13:25:05.353: INFO: Pod pod-projected-secrets-daf63d67-6bdb-4e47-b5dc-2d3a7050b8a1 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec  3 13:25:05.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3317" for this suite. 12/03/22 13:25:05.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:05.369
Dec  3 13:25:05.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:25:05.37
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:05.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:05.4
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:25:05.422
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:25:05.796
STEP: Deploying the webhook pod 12/03/22 13:25:05.804
STEP: Wait for the deployment to be ready 12/03/22 13:25:05.819
Dec  3 13:25:05.828: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:25:07.842
STEP: Verifying the service has paired with the endpoint 12/03/22 13:25:07.854
Dec  3 13:25:08.855: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 12/03/22 13:25:08.862
STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.881
STEP: Updating a validating webhook configuration's rules to not include the create operation 12/03/22 13:25:08.895
STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.909
STEP: Patching a validating webhook configuration's rules to include the create operation 12/03/22 13:25:08.922
STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.933
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:25:08.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8412" for this suite. 12/03/22 13:25:08.949
STEP: Destroying namespace "webhook-8412-markers" for this suite. 12/03/22 13:25:08.957
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":322,"skipped":5918,"failed":0}
------------------------------
â€¢ [3.653 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:05.369
    Dec  3 13:25:05.370: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:25:05.37
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:05.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:05.4
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:25:05.422
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:25:05.796
    STEP: Deploying the webhook pod 12/03/22 13:25:05.804
    STEP: Wait for the deployment to be ready 12/03/22 13:25:05.819
    Dec  3 13:25:05.828: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:25:07.842
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:25:07.854
    Dec  3 13:25:08.855: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 12/03/22 13:25:08.862
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.881
    STEP: Updating a validating webhook configuration's rules to not include the create operation 12/03/22 13:25:08.895
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.909
    STEP: Patching a validating webhook configuration's rules to include the create operation 12/03/22 13:25:08.922
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/03/22 13:25:08.933
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:25:08.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8412" for this suite. 12/03/22 13:25:08.949
    STEP: Destroying namespace "webhook-8412-markers" for this suite. 12/03/22 13:25:08.957
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:09.025
Dec  3 13:25:09.025: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:25:09.026
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:09.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:09.059
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-7e595289-6a6c-4ff0-853b-ff0bf84eec4e 12/03/22 13:25:09.097
STEP: Creating a pod to test consume secrets 12/03/22 13:25:09.104
Dec  3 13:25:09.114: INFO: Waiting up to 5m0s for pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714" in namespace "secrets-8570" to be "Succeeded or Failed"
Dec  3 13:25:09.118: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192515ms
Dec  3 13:25:11.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Running", Reason="", readiness=true. Elapsed: 2.010008973s
Dec  3 13:25:13.123: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Running", Reason="", readiness=false. Elapsed: 4.009077906s
Dec  3 13:25:15.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010001578s
STEP: Saw pod success 12/03/22 13:25:15.124
Dec  3 13:25:15.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714" satisfied condition "Succeeded or Failed"
Dec  3 13:25:15.129: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:25:15.137
Dec  3 13:25:15.151: INFO: Waiting for pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 to disappear
Dec  3 13:25:15.155: INFO: Pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:25:15.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8570" for this suite. 12/03/22 13:25:15.16
STEP: Destroying namespace "secret-namespace-2872" for this suite. 12/03/22 13:25:15.167
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":323,"skipped":5945,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.152 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:09.025
    Dec  3 13:25:09.025: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:25:09.026
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:09.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:09.059
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-7e595289-6a6c-4ff0-853b-ff0bf84eec4e 12/03/22 13:25:09.097
    STEP: Creating a pod to test consume secrets 12/03/22 13:25:09.104
    Dec  3 13:25:09.114: INFO: Waiting up to 5m0s for pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714" in namespace "secrets-8570" to be "Succeeded or Failed"
    Dec  3 13:25:09.118: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192515ms
    Dec  3 13:25:11.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Running", Reason="", readiness=true. Elapsed: 2.010008973s
    Dec  3 13:25:13.123: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Running", Reason="", readiness=false. Elapsed: 4.009077906s
    Dec  3 13:25:15.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010001578s
    STEP: Saw pod success 12/03/22 13:25:15.124
    Dec  3 13:25:15.124: INFO: Pod "pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714" satisfied condition "Succeeded or Failed"
    Dec  3 13:25:15.129: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:25:15.137
    Dec  3 13:25:15.151: INFO: Waiting for pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 to disappear
    Dec  3 13:25:15.155: INFO: Pod pod-secrets-08775876-d1cc-4d5e-ae0c-7f5001f2d714 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:25:15.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8570" for this suite. 12/03/22 13:25:15.16
    STEP: Destroying namespace "secret-namespace-2872" for this suite. 12/03/22 13:25:15.167
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:15.177
Dec  3 13:25:15.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename watch 12/03/22 13:25:15.179
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:15.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:15.208
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 12/03/22 13:25:15.211
STEP: starting a background goroutine to produce watch events 12/03/22 13:25:15.215
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/03/22 13:25:15.215
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec  3 13:25:17.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2553" for this suite. 12/03/22 13:25:18.042
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":324,"skipped":5948,"failed":0}
------------------------------
â€¢ [2.917 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:15.177
    Dec  3 13:25:15.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename watch 12/03/22 13:25:15.179
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:15.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:15.208
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 12/03/22 13:25:15.211
    STEP: starting a background goroutine to produce watch events 12/03/22 13:25:15.215
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/03/22 13:25:15.215
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec  3 13:25:17.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2553" for this suite. 12/03/22 13:25:18.042
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:18.098
Dec  3 13:25:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 13:25:18.099
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:18.12
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:18.124
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 12/03/22 13:25:18.134
STEP: watching for Pod to be ready 12/03/22 13:25:18.145
Dec  3 13:25:18.148: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions []
Dec  3 13:25:18.160: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
Dec  3 13:25:18.179: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
Dec  3 13:25:19.314: INFO: Found Pod pod-test in namespace pods-9361 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 12/03/22 13:25:19.318
STEP: getting the Pod and ensuring that it's patched 12/03/22 13:25:19.331
STEP: replacing the Pod's status Ready condition to False 12/03/22 13:25:19.336
STEP: check the Pod again to ensure its Ready conditions are False 12/03/22 13:25:19.349
STEP: deleting the Pod via a Collection with a LabelSelector 12/03/22 13:25:19.349
STEP: watching for the Pod to be deleted 12/03/22 13:25:19.359
Dec  3 13:25:19.362: INFO: observed event type MODIFIED
Dec  3 13:25:20.019: INFO: observed event type MODIFIED
Dec  3 13:25:22.320: INFO: observed event type MODIFIED
Dec  3 13:25:22.338: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 13:25:22.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9361" for this suite. 12/03/22 13:25:22.352
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":325,"skipped":5984,"failed":0}
------------------------------
â€¢ [4.264 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:18.098
    Dec  3 13:25:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 13:25:18.099
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:18.12
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:18.124
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 12/03/22 13:25:18.134
    STEP: watching for Pod to be ready 12/03/22 13:25:18.145
    Dec  3 13:25:18.148: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Dec  3 13:25:18.160: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
    Dec  3 13:25:18.179: INFO: observed Pod pod-test in namespace pods-9361 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
    Dec  3 13:25:19.314: INFO: Found Pod pod-test in namespace pods-9361 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-03 13:25:18 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 12/03/22 13:25:19.318
    STEP: getting the Pod and ensuring that it's patched 12/03/22 13:25:19.331
    STEP: replacing the Pod's status Ready condition to False 12/03/22 13:25:19.336
    STEP: check the Pod again to ensure its Ready conditions are False 12/03/22 13:25:19.349
    STEP: deleting the Pod via a Collection with a LabelSelector 12/03/22 13:25:19.349
    STEP: watching for the Pod to be deleted 12/03/22 13:25:19.359
    Dec  3 13:25:19.362: INFO: observed event type MODIFIED
    Dec  3 13:25:20.019: INFO: observed event type MODIFIED
    Dec  3 13:25:22.320: INFO: observed event type MODIFIED
    Dec  3 13:25:22.338: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 13:25:22.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9361" for this suite. 12/03/22 13:25:22.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:22.364
Dec  3 13:25:22.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename services 12/03/22 13:25:22.37
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:22.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:22.402
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4703 12/03/22 13:25:22.408
STEP: changing the ExternalName service to type=NodePort 12/03/22 13:25:22.417
STEP: creating replication controller externalname-service in namespace services-4703 12/03/22 13:25:22.448
I1203 13:25:22.469541      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4703, replica count: 2
I1203 13:25:25.521181      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 13:25:25.521: INFO: Creating new exec pod
Dec  3 13:25:25.545: INFO: Waiting up to 5m0s for pod "execpoddmlxw" in namespace "services-4703" to be "running"
Dec  3 13:25:25.556: INFO: Pod "execpoddmlxw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.52703ms
Dec  3 13:25:27.593: INFO: Pod "execpoddmlxw": Phase="Running", Reason="", readiness=true. Elapsed: 2.047017467s
Dec  3 13:25:27.593: INFO: Pod "execpoddmlxw" satisfied condition "running"
Dec  3 13:25:28.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 13:25:28.791: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 13:25:28.791: INFO: stdout: ""
Dec  3 13:25:29.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec  3 13:25:30.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 13:25:30.041: INFO: stdout: "externalname-service-2x4zz"
Dec  3 13:25:30.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Dec  3 13:25:30.215: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Dec  3 13:25:30.215: INFO: stdout: ""
Dec  3 13:25:31.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Dec  3 13:25:31.374: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Dec  3 13:25:31.374: INFO: stdout: ""
Dec  3 13:25:32.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Dec  3 13:25:32.383: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Dec  3 13:25:32.383: INFO: stdout: "externalname-service-2x4zz"
Dec  3 13:25:32.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
Dec  3 13:25:32.531: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
Dec  3 13:25:32.531: INFO: stdout: ""
Dec  3 13:25:33.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
Dec  3 13:25:33.711: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
Dec  3 13:25:33.711: INFO: stdout: ""
Dec  3 13:25:34.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
Dec  3 13:25:34.716: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
Dec  3 13:25:34.716: INFO: stdout: "externalname-service-2x4zz"
Dec  3 13:25:34.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 31921'
Dec  3 13:25:34.903: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 172.31.76.203 31921\nConnection to 172.31.76.203 31921 port [tcp/*] succeeded!\n"
Dec  3 13:25:34.903: INFO: stdout: "externalname-service-2x4zz"
Dec  3 13:25:34.903: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec  3 13:25:34.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4703" for this suite. 12/03/22 13:25:34.94
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":326,"skipped":6009,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.584 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:22.364
    Dec  3 13:25:22.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename services 12/03/22 13:25:22.37
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:22.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:22.402
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4703 12/03/22 13:25:22.408
    STEP: changing the ExternalName service to type=NodePort 12/03/22 13:25:22.417
    STEP: creating replication controller externalname-service in namespace services-4703 12/03/22 13:25:22.448
    I1203 13:25:22.469541      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4703, replica count: 2
    I1203 13:25:25.521181      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec  3 13:25:25.521: INFO: Creating new exec pod
    Dec  3 13:25:25.545: INFO: Waiting up to 5m0s for pod "execpoddmlxw" in namespace "services-4703" to be "running"
    Dec  3 13:25:25.556: INFO: Pod "execpoddmlxw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.52703ms
    Dec  3 13:25:27.593: INFO: Pod "execpoddmlxw": Phase="Running", Reason="", readiness=true. Elapsed: 2.047017467s
    Dec  3 13:25:27.593: INFO: Pod "execpoddmlxw" satisfied condition "running"
    Dec  3 13:25:28.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 13:25:28.791: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 13:25:28.791: INFO: stdout: ""
    Dec  3 13:25:29.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec  3 13:25:30.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec  3 13:25:30.041: INFO: stdout: "externalname-service-2x4zz"
    Dec  3 13:25:30.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Dec  3 13:25:30.215: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Dec  3 13:25:30.215: INFO: stdout: ""
    Dec  3 13:25:31.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Dec  3 13:25:31.374: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Dec  3 13:25:31.374: INFO: stdout: ""
    Dec  3 13:25:32.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Dec  3 13:25:32.383: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Dec  3 13:25:32.383: INFO: stdout: "externalname-service-2x4zz"
    Dec  3 13:25:32.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
    Dec  3 13:25:32.531: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
    Dec  3 13:25:32.531: INFO: stdout: ""
    Dec  3 13:25:33.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
    Dec  3 13:25:33.711: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
    Dec  3 13:25:33.711: INFO: stdout: ""
    Dec  3 13:25:34.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.234 31921'
    Dec  3 13:25:34.716: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.234 31921\nConnection to 172.31.38.234 31921 port [tcp/*] succeeded!\n"
    Dec  3 13:25:34.716: INFO: stdout: "externalname-service-2x4zz"
    Dec  3 13:25:34.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=services-4703 exec execpoddmlxw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.76.203 31921'
    Dec  3 13:25:34.903: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 172.31.76.203 31921\nConnection to 172.31.76.203 31921 port [tcp/*] succeeded!\n"
    Dec  3 13:25:34.903: INFO: stdout: "externalname-service-2x4zz"
    Dec  3 13:25:34.903: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec  3 13:25:34.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4703" for this suite. 12/03/22 13:25:34.94
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:34.95
Dec  3 13:25:34.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 13:25:34.951
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:34.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:34.991
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 12/03/22 13:25:34.997
Dec  3 13:25:35.010: INFO: Waiting up to 5m0s for pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44" in namespace "var-expansion-4581" to be "Succeeded or Failed"
Dec  3 13:25:35.014: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216733ms
Dec  3 13:25:37.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010081752s
Dec  3 13:25:39.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009824011s
STEP: Saw pod success 12/03/22 13:25:39.02
Dec  3 13:25:39.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44" satisfied condition "Succeeded or Failed"
Dec  3 13:25:39.025: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 container dapi-container: <nil>
STEP: delete the pod 12/03/22 13:25:39.034
Dec  3 13:25:39.050: INFO: Waiting for pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 to disappear
Dec  3 13:25:39.054: INFO: Pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 13:25:39.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4581" for this suite. 12/03/22 13:25:39.058
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":327,"skipped":6043,"failed":0}
------------------------------
â€¢ [4.122 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:34.95
    Dec  3 13:25:34.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 13:25:34.951
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:34.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:34.991
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 12/03/22 13:25:34.997
    Dec  3 13:25:35.010: INFO: Waiting up to 5m0s for pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44" in namespace "var-expansion-4581" to be "Succeeded or Failed"
    Dec  3 13:25:35.014: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216733ms
    Dec  3 13:25:37.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010081752s
    Dec  3 13:25:39.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009824011s
    STEP: Saw pod success 12/03/22 13:25:39.02
    Dec  3 13:25:39.020: INFO: Pod "var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44" satisfied condition "Succeeded or Failed"
    Dec  3 13:25:39.025: INFO: Trying to get logs from node ip-172-31-38-234 pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 container dapi-container: <nil>
    STEP: delete the pod 12/03/22 13:25:39.034
    Dec  3 13:25:39.050: INFO: Waiting for pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 to disappear
    Dec  3 13:25:39.054: INFO: Pod var-expansion-a7c6da16-d109-4a2b-a750-5c69b16dfc44 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 13:25:39.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4581" for this suite. 12/03/22 13:25:39.058
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:39.074
Dec  3 13:25:39.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:25:39.075
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:39.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:39.103
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:25:39.108
Dec  3 13:25:39.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623" in namespace "projected-4987" to be "Succeeded or Failed"
Dec  3 13:25:39.126: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Pending", Reason="", readiness=false. Elapsed: 5.52952ms
Dec  3 13:25:41.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010619954s
Dec  3 13:25:43.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010950039s
STEP: Saw pod success 12/03/22 13:25:43.131
Dec  3 13:25:43.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623" satisfied condition "Succeeded or Failed"
Dec  3 13:25:43.135: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 container client-container: <nil>
STEP: delete the pod 12/03/22 13:25:43.142
Dec  3 13:25:43.158: INFO: Waiting for pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 to disappear
Dec  3 13:25:43.165: INFO: Pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:25:43.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4987" for this suite. 12/03/22 13:25:43.17
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":328,"skipped":6048,"failed":0}
------------------------------
â€¢ [4.104 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:39.074
    Dec  3 13:25:39.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:25:39.075
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:39.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:39.103
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:25:39.108
    Dec  3 13:25:39.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623" in namespace "projected-4987" to be "Succeeded or Failed"
    Dec  3 13:25:39.126: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Pending", Reason="", readiness=false. Elapsed: 5.52952ms
    Dec  3 13:25:41.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010619954s
    Dec  3 13:25:43.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010950039s
    STEP: Saw pod success 12/03/22 13:25:43.131
    Dec  3 13:25:43.131: INFO: Pod "downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623" satisfied condition "Succeeded or Failed"
    Dec  3 13:25:43.135: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:25:43.142
    Dec  3 13:25:43.158: INFO: Waiting for pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 to disappear
    Dec  3 13:25:43.165: INFO: Pod downwardapi-volume-eff0c5e0-5741-47e0-b9f7-cef9e2e1b623 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:25:43.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4987" for this suite. 12/03/22 13:25:43.17
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:43.201
Dec  3 13:25:43.202: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:25:43.203
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:43.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:43.226
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-6647e241-4a0e-4b45-8ca9-4c739a4c486e 12/03/22 13:25:43.23
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:25:43.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7286" for this suite. 12/03/22 13:25:43.235
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":329,"skipped":6131,"failed":0}
------------------------------
â€¢ [0.043 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:43.201
    Dec  3 13:25:43.202: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:25:43.203
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:43.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:43.226
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-6647e241-4a0e-4b45-8ca9-4c739a4c486e 12/03/22 13:25:43.23
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:25:43.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7286" for this suite. 12/03/22 13:25:43.235
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:43.245
Dec  3 13:25:43.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sysctl 12/03/22 13:25:43.246
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:43.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:43.271
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/03/22 13:25:43.273
STEP: Watching for error events or started pod 12/03/22 13:25:43.285
STEP: Waiting for pod completion 12/03/22 13:25:45.29
Dec  3 13:25:45.291: INFO: Waiting up to 3m0s for pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe" in namespace "sysctl-3034" to be "completed"
Dec  3 13:25:45.294: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.282946ms
Dec  3 13:25:47.298: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007610913s
Dec  3 13:25:47.298: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe" satisfied condition "completed"
STEP: Checking that the pod succeeded 12/03/22 13:25:47.302
STEP: Getting logs from the pod 12/03/22 13:25:47.303
STEP: Checking that the sysctl is actually updated 12/03/22 13:25:47.31
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec  3 13:25:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3034" for this suite. 12/03/22 13:25:47.314
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":330,"skipped":6131,"failed":0}
------------------------------
â€¢ [4.076 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:43.245
    Dec  3 13:25:43.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sysctl 12/03/22 13:25:43.246
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:43.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:43.271
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/03/22 13:25:43.273
    STEP: Watching for error events or started pod 12/03/22 13:25:43.285
    STEP: Waiting for pod completion 12/03/22 13:25:45.29
    Dec  3 13:25:45.291: INFO: Waiting up to 3m0s for pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe" in namespace "sysctl-3034" to be "completed"
    Dec  3 13:25:45.294: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.282946ms
    Dec  3 13:25:47.298: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007610913s
    Dec  3 13:25:47.298: INFO: Pod "sysctl-44a1bb24-c8d3-4668-a334-52269a88e7fe" satisfied condition "completed"
    STEP: Checking that the pod succeeded 12/03/22 13:25:47.302
    STEP: Getting logs from the pod 12/03/22 13:25:47.303
    STEP: Checking that the sysctl is actually updated 12/03/22 13:25:47.31
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec  3 13:25:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3034" for this suite. 12/03/22 13:25:47.314
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:47.321
Dec  3 13:25:47.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:25:47.322
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:47.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:47.357
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-20cc1d2f-0425-464b-8edf-0a9650efd0ca 12/03/22 13:25:47.365
STEP: Creating a pod to test consume configMaps 12/03/22 13:25:47.37
Dec  3 13:25:47.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f" in namespace "projected-1187" to be "Succeeded or Failed"
Dec  3 13:25:47.383: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235413ms
Dec  3 13:25:49.388: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008584226s
Dec  3 13:25:51.389: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010178737s
STEP: Saw pod success 12/03/22 13:25:51.389
Dec  3 13:25:51.389: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f" satisfied condition "Succeeded or Failed"
Dec  3 13:25:51.393: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f container projected-configmap-volume-test: <nil>
STEP: delete the pod 12/03/22 13:25:51.401
Dec  3 13:25:51.412: INFO: Waiting for pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f to disappear
Dec  3 13:25:51.417: INFO: Pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:25:51.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1187" for this suite. 12/03/22 13:25:51.423
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":331,"skipped":6136,"failed":0}
------------------------------
â€¢ [4.110 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:47.321
    Dec  3 13:25:47.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:25:47.322
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:47.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:47.357
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-20cc1d2f-0425-464b-8edf-0a9650efd0ca 12/03/22 13:25:47.365
    STEP: Creating a pod to test consume configMaps 12/03/22 13:25:47.37
    Dec  3 13:25:47.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f" in namespace "projected-1187" to be "Succeeded or Failed"
    Dec  3 13:25:47.383: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235413ms
    Dec  3 13:25:49.388: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008584226s
    Dec  3 13:25:51.389: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010178737s
    STEP: Saw pod success 12/03/22 13:25:51.389
    Dec  3 13:25:51.389: INFO: Pod "pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f" satisfied condition "Succeeded or Failed"
    Dec  3 13:25:51.393: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f container projected-configmap-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:25:51.401
    Dec  3 13:25:51.412: INFO: Waiting for pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f to disappear
    Dec  3 13:25:51.417: INFO: Pod pod-projected-configmaps-addbfe37-fff0-4a6e-b2e6-73d4dd32b50f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:25:51.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1187" for this suite. 12/03/22 13:25:51.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:25:51.433
Dec  3 13:25:51.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:25:51.434
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:51.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:51.469
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 12/03/22 13:25:51.474
Dec  3 13:25:51.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 create -f -'
Dec  3 13:25:52.432: INFO: stderr: ""
Dec  3 13:25:52.432: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:25:52.432
Dec  3 13:25:52.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 13:25:52.507: INFO: stderr: ""
Dec  3 13:25:52.507: INFO: stdout: "update-demo-nautilus-7952p update-demo-nautilus-nltr2 "
Dec  3 13:25:52.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:25:52.585: INFO: stderr: ""
Dec  3 13:25:52.585: INFO: stdout: ""
Dec  3 13:25:52.585: INFO: update-demo-nautilus-7952p is created but not running
Dec  3 13:25:57.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 13:25:57.654: INFO: stderr: ""
Dec  3 13:25:57.654: INFO: stdout: "update-demo-nautilus-7952p update-demo-nautilus-nltr2 "
Dec  3 13:25:57.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:25:57.723: INFO: stderr: ""
Dec  3 13:25:57.723: INFO: stdout: "true"
Dec  3 13:25:57.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 13:25:57.792: INFO: stderr: ""
Dec  3 13:25:57.792: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 13:25:57.792: INFO: validating pod update-demo-nautilus-7952p
Dec  3 13:25:57.799: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 13:25:57.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 13:25:57.799: INFO: update-demo-nautilus-7952p is verified up and running
Dec  3 13:25:57.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:25:57.869: INFO: stderr: ""
Dec  3 13:25:57.869: INFO: stdout: "true"
Dec  3 13:25:57.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 13:25:57.935: INFO: stderr: ""
Dec  3 13:25:57.935: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 13:25:57.935: INFO: validating pod update-demo-nautilus-nltr2
Dec  3 13:25:57.942: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 13:25:57.942: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 13:25:57.942: INFO: update-demo-nautilus-nltr2 is verified up and running
STEP: scaling down the replication controller 12/03/22 13:25:57.942
Dec  3 13:25:57.943: INFO: scanned /root for discovery docs: <nil>
Dec  3 13:25:57.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Dec  3 13:25:59.036: INFO: stderr: ""
Dec  3 13:25:59.036: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:25:59.036
Dec  3 13:25:59.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 13:25:59.102: INFO: stderr: ""
Dec  3 13:25:59.102: INFO: stdout: "update-demo-nautilus-nltr2 "
Dec  3 13:25:59.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:25:59.166: INFO: stderr: ""
Dec  3 13:25:59.166: INFO: stdout: "true"
Dec  3 13:25:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 13:25:59.233: INFO: stderr: ""
Dec  3 13:25:59.233: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 13:25:59.233: INFO: validating pod update-demo-nautilus-nltr2
Dec  3 13:25:59.237: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 13:25:59.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 13:25:59.237: INFO: update-demo-nautilus-nltr2 is verified up and running
STEP: scaling up the replication controller 12/03/22 13:25:59.237
Dec  3 13:25:59.239: INFO: scanned /root for discovery docs: <nil>
Dec  3 13:25:59.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Dec  3 13:26:00.345: INFO: stderr: ""
Dec  3 13:26:00.345: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:26:00.345
Dec  3 13:26:00.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 13:26:00.415: INFO: stderr: ""
Dec  3 13:26:00.415: INFO: stdout: "update-demo-nautilus-h94k8 update-demo-nautilus-nltr2 "
Dec  3 13:26:00.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:26:00.483: INFO: stderr: ""
Dec  3 13:26:00.483: INFO: stdout: ""
Dec  3 13:26:00.483: INFO: update-demo-nautilus-h94k8 is created but not running
Dec  3 13:26:05.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec  3 13:26:05.580: INFO: stderr: ""
Dec  3 13:26:05.580: INFO: stdout: "update-demo-nautilus-h94k8 update-demo-nautilus-nltr2 "
Dec  3 13:26:05.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:26:05.651: INFO: stderr: ""
Dec  3 13:26:05.651: INFO: stdout: "true"
Dec  3 13:26:05.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 13:26:05.719: INFO: stderr: ""
Dec  3 13:26:05.719: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 13:26:05.719: INFO: validating pod update-demo-nautilus-h94k8
Dec  3 13:26:05.724: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 13:26:05.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 13:26:05.724: INFO: update-demo-nautilus-h94k8 is verified up and running
Dec  3 13:26:05.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec  3 13:26:05.792: INFO: stderr: ""
Dec  3 13:26:05.792: INFO: stdout: "true"
Dec  3 13:26:05.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec  3 13:26:05.872: INFO: stderr: ""
Dec  3 13:26:05.872: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec  3 13:26:05.872: INFO: validating pod update-demo-nautilus-nltr2
Dec  3 13:26:05.877: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 13:26:05.877: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 13:26:05.877: INFO: update-demo-nautilus-nltr2 is verified up and running
STEP: using delete to clean up resources 12/03/22 13:26:05.877
Dec  3 13:26:05.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 delete --grace-period=0 --force -f -'
Dec  3 13:26:05.979: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 13:26:05.979: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 13:26:05.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get rc,svc -l name=update-demo --no-headers'
Dec  3 13:26:06.090: INFO: stderr: "No resources found in kubectl-1755 namespace.\n"
Dec  3 13:26:06.090: INFO: stdout: ""
Dec  3 13:26:06.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 13:26:06.193: INFO: stderr: ""
Dec  3 13:26:06.193: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:26:06.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1755" for this suite. 12/03/22 13:26:06.198
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":332,"skipped":6143,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.774 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:25:51.433
    Dec  3 13:25:51.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:25:51.434
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:25:51.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:25:51.469
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 12/03/22 13:25:51.474
    Dec  3 13:25:51.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 create -f -'
    Dec  3 13:25:52.432: INFO: stderr: ""
    Dec  3 13:25:52.432: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:25:52.432
    Dec  3 13:25:52.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 13:25:52.507: INFO: stderr: ""
    Dec  3 13:25:52.507: INFO: stdout: "update-demo-nautilus-7952p update-demo-nautilus-nltr2 "
    Dec  3 13:25:52.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:25:52.585: INFO: stderr: ""
    Dec  3 13:25:52.585: INFO: stdout: ""
    Dec  3 13:25:52.585: INFO: update-demo-nautilus-7952p is created but not running
    Dec  3 13:25:57.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 13:25:57.654: INFO: stderr: ""
    Dec  3 13:25:57.654: INFO: stdout: "update-demo-nautilus-7952p update-demo-nautilus-nltr2 "
    Dec  3 13:25:57.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:25:57.723: INFO: stderr: ""
    Dec  3 13:25:57.723: INFO: stdout: "true"
    Dec  3 13:25:57.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-7952p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 13:25:57.792: INFO: stderr: ""
    Dec  3 13:25:57.792: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 13:25:57.792: INFO: validating pod update-demo-nautilus-7952p
    Dec  3 13:25:57.799: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 13:25:57.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 13:25:57.799: INFO: update-demo-nautilus-7952p is verified up and running
    Dec  3 13:25:57.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:25:57.869: INFO: stderr: ""
    Dec  3 13:25:57.869: INFO: stdout: "true"
    Dec  3 13:25:57.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 13:25:57.935: INFO: stderr: ""
    Dec  3 13:25:57.935: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 13:25:57.935: INFO: validating pod update-demo-nautilus-nltr2
    Dec  3 13:25:57.942: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 13:25:57.942: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 13:25:57.942: INFO: update-demo-nautilus-nltr2 is verified up and running
    STEP: scaling down the replication controller 12/03/22 13:25:57.942
    Dec  3 13:25:57.943: INFO: scanned /root for discovery docs: <nil>
    Dec  3 13:25:57.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Dec  3 13:25:59.036: INFO: stderr: ""
    Dec  3 13:25:59.036: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:25:59.036
    Dec  3 13:25:59.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 13:25:59.102: INFO: stderr: ""
    Dec  3 13:25:59.102: INFO: stdout: "update-demo-nautilus-nltr2 "
    Dec  3 13:25:59.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:25:59.166: INFO: stderr: ""
    Dec  3 13:25:59.166: INFO: stdout: "true"
    Dec  3 13:25:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 13:25:59.233: INFO: stderr: ""
    Dec  3 13:25:59.233: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 13:25:59.233: INFO: validating pod update-demo-nautilus-nltr2
    Dec  3 13:25:59.237: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 13:25:59.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 13:25:59.237: INFO: update-demo-nautilus-nltr2 is verified up and running
    STEP: scaling up the replication controller 12/03/22 13:25:59.237
    Dec  3 13:25:59.239: INFO: scanned /root for discovery docs: <nil>
    Dec  3 13:25:59.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Dec  3 13:26:00.345: INFO: stderr: ""
    Dec  3 13:26:00.345: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/03/22 13:26:00.345
    Dec  3 13:26:00.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 13:26:00.415: INFO: stderr: ""
    Dec  3 13:26:00.415: INFO: stdout: "update-demo-nautilus-h94k8 update-demo-nautilus-nltr2 "
    Dec  3 13:26:00.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:26:00.483: INFO: stderr: ""
    Dec  3 13:26:00.483: INFO: stdout: ""
    Dec  3 13:26:00.483: INFO: update-demo-nautilus-h94k8 is created but not running
    Dec  3 13:26:05.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec  3 13:26:05.580: INFO: stderr: ""
    Dec  3 13:26:05.580: INFO: stdout: "update-demo-nautilus-h94k8 update-demo-nautilus-nltr2 "
    Dec  3 13:26:05.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:26:05.651: INFO: stderr: ""
    Dec  3 13:26:05.651: INFO: stdout: "true"
    Dec  3 13:26:05.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-h94k8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 13:26:05.719: INFO: stderr: ""
    Dec  3 13:26:05.719: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 13:26:05.719: INFO: validating pod update-demo-nautilus-h94k8
    Dec  3 13:26:05.724: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 13:26:05.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 13:26:05.724: INFO: update-demo-nautilus-h94k8 is verified up and running
    Dec  3 13:26:05.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec  3 13:26:05.792: INFO: stderr: ""
    Dec  3 13:26:05.792: INFO: stdout: "true"
    Dec  3 13:26:05.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods update-demo-nautilus-nltr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec  3 13:26:05.872: INFO: stderr: ""
    Dec  3 13:26:05.872: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec  3 13:26:05.872: INFO: validating pod update-demo-nautilus-nltr2
    Dec  3 13:26:05.877: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec  3 13:26:05.877: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec  3 13:26:05.877: INFO: update-demo-nautilus-nltr2 is verified up and running
    STEP: using delete to clean up resources 12/03/22 13:26:05.877
    Dec  3 13:26:05.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 delete --grace-period=0 --force -f -'
    Dec  3 13:26:05.979: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec  3 13:26:05.979: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec  3 13:26:05.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get rc,svc -l name=update-demo --no-headers'
    Dec  3 13:26:06.090: INFO: stderr: "No resources found in kubectl-1755 namespace.\n"
    Dec  3 13:26:06.090: INFO: stdout: ""
    Dec  3 13:26:06.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-1755 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec  3 13:26:06.193: INFO: stderr: ""
    Dec  3 13:26:06.193: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:26:06.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1755" for this suite. 12/03/22 13:26:06.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:06.207
Dec  3 13:26:06.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:26:06.207
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:06.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:06.234
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/03/22 13:26:06.237
Dec  3 13:26:06.247: INFO: Waiting up to 5m0s for pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e" in namespace "emptydir-8883" to be "Succeeded or Failed"
Dec  3 13:26:06.250: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.174865ms
Dec  3 13:26:08.255: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008177328s
Dec  3 13:26:10.259: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011690788s
STEP: Saw pod success 12/03/22 13:26:10.259
Dec  3 13:26:10.259: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e" satisfied condition "Succeeded or Failed"
Dec  3 13:26:10.265: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e container test-container: <nil>
STEP: delete the pod 12/03/22 13:26:10.275
Dec  3 13:26:10.290: INFO: Waiting for pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e to disappear
Dec  3 13:26:10.295: INFO: Pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:26:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8883" for this suite. 12/03/22 13:26:10.3
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":333,"skipped":6149,"failed":0}
------------------------------
â€¢ [4.104 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:06.207
    Dec  3 13:26:06.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:26:06.207
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:06.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:06.234
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/03/22 13:26:06.237
    Dec  3 13:26:06.247: INFO: Waiting up to 5m0s for pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e" in namespace "emptydir-8883" to be "Succeeded or Failed"
    Dec  3 13:26:06.250: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.174865ms
    Dec  3 13:26:08.255: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008177328s
    Dec  3 13:26:10.259: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011690788s
    STEP: Saw pod success 12/03/22 13:26:10.259
    Dec  3 13:26:10.259: INFO: Pod "pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e" satisfied condition "Succeeded or Failed"
    Dec  3 13:26:10.265: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e container test-container: <nil>
    STEP: delete the pod 12/03/22 13:26:10.275
    Dec  3 13:26:10.290: INFO: Waiting for pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e to disappear
    Dec  3 13:26:10.295: INFO: Pod pod-75e9387b-91f6-4ac0-b96f-99cf8603f43e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:26:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8883" for this suite. 12/03/22 13:26:10.3
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:10.311
Dec  3 13:26:10.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename configmap 12/03/22 13:26:10.312
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:10.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:10.349
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-874/configmap-test-d835fcab-4219-4205-aede-3fda535b93ea 12/03/22 13:26:10.358
STEP: Creating a pod to test consume configMaps 12/03/22 13:26:10.366
Dec  3 13:26:10.378: INFO: Waiting up to 5m0s for pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c" in namespace "configmap-874" to be "Succeeded or Failed"
Dec  3 13:26:10.382: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.646333ms
Dec  3 13:26:12.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008873995s
Dec  3 13:26:14.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008676326s
STEP: Saw pod success 12/03/22 13:26:14.387
Dec  3 13:26:14.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c" satisfied condition "Succeeded or Failed"
Dec  3 13:26:14.391: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c container env-test: <nil>
STEP: delete the pod 12/03/22 13:26:14.399
Dec  3 13:26:14.415: INFO: Waiting for pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c to disappear
Dec  3 13:26:14.421: INFO: Pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec  3 13:26:14.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-874" for this suite. 12/03/22 13:26:14.425
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":334,"skipped":6150,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:10.311
    Dec  3 13:26:10.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename configmap 12/03/22 13:26:10.312
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:10.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:10.349
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-874/configmap-test-d835fcab-4219-4205-aede-3fda535b93ea 12/03/22 13:26:10.358
    STEP: Creating a pod to test consume configMaps 12/03/22 13:26:10.366
    Dec  3 13:26:10.378: INFO: Waiting up to 5m0s for pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c" in namespace "configmap-874" to be "Succeeded or Failed"
    Dec  3 13:26:10.382: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.646333ms
    Dec  3 13:26:12.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008873995s
    Dec  3 13:26:14.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008676326s
    STEP: Saw pod success 12/03/22 13:26:14.387
    Dec  3 13:26:14.387: INFO: Pod "pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c" satisfied condition "Succeeded or Failed"
    Dec  3 13:26:14.391: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c container env-test: <nil>
    STEP: delete the pod 12/03/22 13:26:14.399
    Dec  3 13:26:14.415: INFO: Waiting for pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c to disappear
    Dec  3 13:26:14.421: INFO: Pod pod-configmaps-1037e00b-50e0-4f5c-a149-bba8c3e66d3c no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec  3 13:26:14.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-874" for this suite. 12/03/22 13:26:14.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:14.438
Dec  3 13:26:14.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir-wrapper 12/03/22 13:26:14.439
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:14.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:14.478
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Dec  3 13:26:14.516: INFO: Waiting up to 5m0s for pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284" in namespace "emptydir-wrapper-6340" to be "running and ready"
Dec  3 13:26:14.532: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284": Phase="Pending", Reason="", readiness=false. Elapsed: 15.831443ms
Dec  3 13:26:14.532: INFO: The phase of Pod pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284 is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:26:16.538: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284": Phase="Running", Reason="", readiness=true. Elapsed: 2.022210092s
Dec  3 13:26:16.538: INFO: The phase of Pod pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284 is Running (Ready = true)
Dec  3 13:26:16.538: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284" satisfied condition "running and ready"
STEP: Cleaning up the secret 12/03/22 13:26:16.542
STEP: Cleaning up the configmap 12/03/22 13:26:16.549
STEP: Cleaning up the pod 12/03/22 13:26:16.559
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec  3 13:26:16.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6340" for this suite. 12/03/22 13:26:16.579
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":335,"skipped":6158,"failed":0}
------------------------------
â€¢ [2.148 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:14.438
    Dec  3 13:26:14.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir-wrapper 12/03/22 13:26:14.439
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:14.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:14.478
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Dec  3 13:26:14.516: INFO: Waiting up to 5m0s for pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284" in namespace "emptydir-wrapper-6340" to be "running and ready"
    Dec  3 13:26:14.532: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284": Phase="Pending", Reason="", readiness=false. Elapsed: 15.831443ms
    Dec  3 13:26:14.532: INFO: The phase of Pod pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284 is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:26:16.538: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284": Phase="Running", Reason="", readiness=true. Elapsed: 2.022210092s
    Dec  3 13:26:16.538: INFO: The phase of Pod pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284 is Running (Ready = true)
    Dec  3 13:26:16.538: INFO: Pod "pod-secrets-5605874d-93b8-4bec-932f-17f9d3217284" satisfied condition "running and ready"
    STEP: Cleaning up the secret 12/03/22 13:26:16.542
    STEP: Cleaning up the configmap 12/03/22 13:26:16.549
    STEP: Cleaning up the pod 12/03/22 13:26:16.559
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:26:16.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-6340" for this suite. 12/03/22 13:26:16.579
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:16.589
Dec  3 13:26:16.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename subpath 12/03/22 13:26:16.59
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:16.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:16.618
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/03/22 13:26:16.622
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-9sr9 12/03/22 13:26:16.728
STEP: Creating a pod to test atomic-volume-subpath 12/03/22 13:26:16.728
Dec  3 13:26:16.740: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9sr9" in namespace "subpath-8016" to be "Succeeded or Failed"
Dec  3 13:26:16.747: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.59623ms
Dec  3 13:26:18.755: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 2.015136413s
Dec  3 13:26:20.753: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 4.012466922s
Dec  3 13:26:22.756: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 6.015959986s
Dec  3 13:26:24.752: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 8.012029244s
Dec  3 13:26:26.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011345916s
Dec  3 13:26:28.750: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 12.010381165s
Dec  3 13:26:30.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 14.011054861s
Dec  3 13:26:32.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 16.010623141s
Dec  3 13:26:34.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 18.011129036s
Dec  3 13:26:36.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 20.010462378s
Dec  3 13:26:38.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=false. Elapsed: 22.011268493s
Dec  3 13:26:40.753: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012732173s
STEP: Saw pod success 12/03/22 13:26:40.753
Dec  3 13:26:40.753: INFO: Pod "pod-subpath-test-projected-9sr9" satisfied condition "Succeeded or Failed"
Dec  3 13:26:40.757: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-projected-9sr9 container test-container-subpath-projected-9sr9: <nil>
STEP: delete the pod 12/03/22 13:26:40.765
Dec  3 13:26:40.778: INFO: Waiting for pod pod-subpath-test-projected-9sr9 to disappear
Dec  3 13:26:40.784: INFO: Pod pod-subpath-test-projected-9sr9 no longer exists
STEP: Deleting pod pod-subpath-test-projected-9sr9 12/03/22 13:26:40.784
Dec  3 13:26:40.784: INFO: Deleting pod "pod-subpath-test-projected-9sr9" in namespace "subpath-8016"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec  3 13:26:40.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8016" for this suite. 12/03/22 13:26:40.792
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":336,"skipped":6202,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.209 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:16.589
    Dec  3 13:26:16.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename subpath 12/03/22 13:26:16.59
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:16.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:16.618
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/03/22 13:26:16.622
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-9sr9 12/03/22 13:26:16.728
    STEP: Creating a pod to test atomic-volume-subpath 12/03/22 13:26:16.728
    Dec  3 13:26:16.740: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9sr9" in namespace "subpath-8016" to be "Succeeded or Failed"
    Dec  3 13:26:16.747: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.59623ms
    Dec  3 13:26:18.755: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 2.015136413s
    Dec  3 13:26:20.753: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 4.012466922s
    Dec  3 13:26:22.756: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 6.015959986s
    Dec  3 13:26:24.752: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 8.012029244s
    Dec  3 13:26:26.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011345916s
    Dec  3 13:26:28.750: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 12.010381165s
    Dec  3 13:26:30.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 14.011054861s
    Dec  3 13:26:32.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 16.010623141s
    Dec  3 13:26:34.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 18.011129036s
    Dec  3 13:26:36.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=true. Elapsed: 20.010462378s
    Dec  3 13:26:38.751: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Running", Reason="", readiness=false. Elapsed: 22.011268493s
    Dec  3 13:26:40.753: INFO: Pod "pod-subpath-test-projected-9sr9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012732173s
    STEP: Saw pod success 12/03/22 13:26:40.753
    Dec  3 13:26:40.753: INFO: Pod "pod-subpath-test-projected-9sr9" satisfied condition "Succeeded or Failed"
    Dec  3 13:26:40.757: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-subpath-test-projected-9sr9 container test-container-subpath-projected-9sr9: <nil>
    STEP: delete the pod 12/03/22 13:26:40.765
    Dec  3 13:26:40.778: INFO: Waiting for pod pod-subpath-test-projected-9sr9 to disappear
    Dec  3 13:26:40.784: INFO: Pod pod-subpath-test-projected-9sr9 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-9sr9 12/03/22 13:26:40.784
    Dec  3 13:26:40.784: INFO: Deleting pod "pod-subpath-test-projected-9sr9" in namespace "subpath-8016"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec  3 13:26:40.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8016" for this suite. 12/03/22 13:26:40.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:40.799
Dec  3 13:26:40.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename lease-test 12/03/22 13:26:40.8
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:40.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:40.833
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Dec  3 13:26:40.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-1606" for this suite. 12/03/22 13:26:40.905
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":337,"skipped":6219,"failed":0}
------------------------------
â€¢ [0.112 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:40.799
    Dec  3 13:26:40.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename lease-test 12/03/22 13:26:40.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:40.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:40.833
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Dec  3 13:26:40.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-1606" for this suite. 12/03/22 13:26:40.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:40.912
Dec  3 13:26:40.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename emptydir 12/03/22 13:26:40.913
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:40.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:40.935
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/03/22 13:26:40.943
Dec  3 13:26:40.958: INFO: Waiting up to 5m0s for pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25" in namespace "emptydir-9738" to be "Succeeded or Failed"
Dec  3 13:26:40.968: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.487861ms
Dec  3 13:26:42.974: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015539039s
Dec  3 13:26:44.976: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018133913s
STEP: Saw pod success 12/03/22 13:26:44.976
Dec  3 13:26:44.977: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25" satisfied condition "Succeeded or Failed"
Dec  3 13:26:44.980: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 container test-container: <nil>
STEP: delete the pod 12/03/22 13:26:44.988
Dec  3 13:26:45.006: INFO: Waiting for pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 to disappear
Dec  3 13:26:45.010: INFO: Pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec  3 13:26:45.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9738" for this suite. 12/03/22 13:26:45.014
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":338,"skipped":6239,"failed":0}
------------------------------
â€¢ [4.111 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:40.912
    Dec  3 13:26:40.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename emptydir 12/03/22 13:26:40.913
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:40.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:40.935
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/03/22 13:26:40.943
    Dec  3 13:26:40.958: INFO: Waiting up to 5m0s for pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25" in namespace "emptydir-9738" to be "Succeeded or Failed"
    Dec  3 13:26:40.968: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.487861ms
    Dec  3 13:26:42.974: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015539039s
    Dec  3 13:26:44.976: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018133913s
    STEP: Saw pod success 12/03/22 13:26:44.976
    Dec  3 13:26:44.977: INFO: Pod "pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25" satisfied condition "Succeeded or Failed"
    Dec  3 13:26:44.980: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 container test-container: <nil>
    STEP: delete the pod 12/03/22 13:26:44.988
    Dec  3 13:26:45.006: INFO: Waiting for pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 to disappear
    Dec  3 13:26:45.010: INFO: Pod pod-03f9d1b4-90bf-42c6-85ca-5ca3f9898e25 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec  3 13:26:45.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9738" for this suite. 12/03/22 13:26:45.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:45.027
Dec  3 13:26:45.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:26:45.028
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:45.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:45.052
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 12/03/22 13:26:45.055
Dec  3 13:26:45.064: INFO: Waiting up to 5m0s for pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe" in namespace "projected-5168" to be "running and ready"
Dec  3 13:26:45.076: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.765748ms
Dec  3 13:26:45.076: INFO: The phase of Pod annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:26:47.081: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.017491497s
Dec  3 13:26:47.082: INFO: The phase of Pod annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe is Running (Ready = true)
Dec  3 13:26:47.082: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe" satisfied condition "running and ready"
Dec  3 13:26:47.606: INFO: Successfully updated pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:26:49.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5168" for this suite. 12/03/22 13:26:49.625
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":339,"skipped":6288,"failed":0}
------------------------------
â€¢ [4.607 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:45.027
    Dec  3 13:26:45.027: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:26:45.028
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:45.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:45.052
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 12/03/22 13:26:45.055
    Dec  3 13:26:45.064: INFO: Waiting up to 5m0s for pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe" in namespace "projected-5168" to be "running and ready"
    Dec  3 13:26:45.076: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.765748ms
    Dec  3 13:26:45.076: INFO: The phase of Pod annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:26:47.081: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.017491497s
    Dec  3 13:26:47.082: INFO: The phase of Pod annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe is Running (Ready = true)
    Dec  3 13:26:47.082: INFO: Pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe" satisfied condition "running and ready"
    Dec  3 13:26:47.606: INFO: Successfully updated pod "annotationupdate41184127-8ca1-41d8-bbeb-ac57454c58fe"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:26:49.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5168" for this suite. 12/03/22 13:26:49.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:49.636
Dec  3 13:26:49.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename var-expansion 12/03/22 13:26:49.637
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:49.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:49.664
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Dec  3 13:26:49.677: INFO: Waiting up to 2m0s for pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" in namespace "var-expansion-4312" to be "container 0 failed with reason CreateContainerConfigError"
Dec  3 13:26:49.681: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626616ms
Dec  3 13:26:51.687: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010138006s
Dec  3 13:26:51.688: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec  3 13:26:51.688: INFO: Deleting pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" in namespace "var-expansion-4312"
Dec  3 13:26:51.696: INFO: Wait up to 5m0s for pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec  3 13:26:53.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4312" for this suite. 12/03/22 13:26:53.722
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":340,"skipped":6304,"failed":0}
------------------------------
â€¢ [4.095 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:49.636
    Dec  3 13:26:49.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename var-expansion 12/03/22 13:26:49.637
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:49.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:49.664
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Dec  3 13:26:49.677: INFO: Waiting up to 2m0s for pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" in namespace "var-expansion-4312" to be "container 0 failed with reason CreateContainerConfigError"
    Dec  3 13:26:49.681: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626616ms
    Dec  3 13:26:51.687: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010138006s
    Dec  3 13:26:51.688: INFO: Pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec  3 13:26:51.688: INFO: Deleting pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" in namespace "var-expansion-4312"
    Dec  3 13:26:51.696: INFO: Wait up to 5m0s for pod "var-expansion-b915e9b9-50f5-4f5c-86fd-c0b380062327" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec  3 13:26:53.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4312" for this suite. 12/03/22 13:26:53.722
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:26:53.733
Dec  3 13:26:53.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename endpointslice 12/03/22 13:26:53.735
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:53.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:53.756
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 12/03/22 13:26:58.834
STEP: referencing matching pods with named port 12/03/22 13:27:03.846
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/03/22 13:27:08.857
STEP: recreating EndpointSlices after they've been deleted 12/03/22 13:27:13.87
Dec  3 13:27:13.900: INFO: EndpointSlice for Service endpointslice-7076/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec  3 13:27:23.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7076" for this suite. 12/03/22 13:27:23.92
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":341,"skipped":6327,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.198 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:26:53.733
    Dec  3 13:26:53.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename endpointslice 12/03/22 13:26:53.735
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:26:53.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:26:53.756
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 12/03/22 13:26:58.834
    STEP: referencing matching pods with named port 12/03/22 13:27:03.846
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/03/22 13:27:08.857
    STEP: recreating EndpointSlices after they've been deleted 12/03/22 13:27:13.87
    Dec  3 13:27:13.900: INFO: EndpointSlice for Service endpointslice-7076/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec  3 13:27:23.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7076" for this suite. 12/03/22 13:27:23.92
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:23.932
Dec  3 13:27:23.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:27:23.933
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:23.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:23.959
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec  3 13:27:23.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3827" for this suite. 12/03/22 13:27:23.992
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":342,"skipped":6328,"failed":0}
------------------------------
â€¢ [0.072 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:23.932
    Dec  3 13:27:23.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubelet-test 12/03/22 13:27:23.933
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:23.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:23.959
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec  3 13:27:23.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3827" for this suite. 12/03/22 13:27:23.992
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:24.006
Dec  3 13:27:24.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:27:24.007
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:24.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:24.033
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-40f9f343-7c4f-4d38-90cc-638a956d44e6 12/03/22 13:27:24.037
STEP: Creating a pod to test consume secrets 12/03/22 13:27:24.042
Dec  3 13:27:24.054: INFO: Waiting up to 5m0s for pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f" in namespace "secrets-9564" to be "Succeeded or Failed"
Dec  3 13:27:24.059: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.407956ms
Dec  3 13:27:26.066: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012647988s
Dec  3 13:27:28.064: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00987441s
STEP: Saw pod success 12/03/22 13:27:28.064
Dec  3 13:27:28.064: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f" satisfied condition "Succeeded or Failed"
Dec  3 13:27:28.068: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:27:28.076
Dec  3 13:27:28.097: INFO: Waiting for pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f to disappear
Dec  3 13:27:28.101: INFO: Pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:27:28.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9564" for this suite. 12/03/22 13:27:28.104
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":343,"skipped":6337,"failed":0}
------------------------------
â€¢ [4.105 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:24.006
    Dec  3 13:27:24.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:27:24.007
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:24.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:24.033
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-40f9f343-7c4f-4d38-90cc-638a956d44e6 12/03/22 13:27:24.037
    STEP: Creating a pod to test consume secrets 12/03/22 13:27:24.042
    Dec  3 13:27:24.054: INFO: Waiting up to 5m0s for pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f" in namespace "secrets-9564" to be "Succeeded or Failed"
    Dec  3 13:27:24.059: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.407956ms
    Dec  3 13:27:26.066: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012647988s
    Dec  3 13:27:28.064: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00987441s
    STEP: Saw pod success 12/03/22 13:27:28.064
    Dec  3 13:27:28.064: INFO: Pod "pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f" satisfied condition "Succeeded or Failed"
    Dec  3 13:27:28.068: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:27:28.076
    Dec  3 13:27:28.097: INFO: Waiting for pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f to disappear
    Dec  3 13:27:28.101: INFO: Pod pod-secrets-9714381e-996e-472a-b1f9-f5c08643209f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:27:28.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9564" for this suite. 12/03/22 13:27:28.104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:28.111
Dec  3 13:27:28.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:27:28.112
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:28.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:28.144
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 12/03/22 13:27:28.152
STEP: listing secrets in all namespaces to ensure that there are more than zero 12/03/22 13:27:28.16
STEP: patching the secret 12/03/22 13:27:28.166
STEP: deleting the secret using a LabelSelector 12/03/22 13:27:28.175
STEP: listing secrets in all namespaces, searching for label name and value in patch 12/03/22 13:27:28.185
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:27:28.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7969" for this suite. 12/03/22 13:27:28.196
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":344,"skipped":6338,"failed":0}
------------------------------
â€¢ [0.091 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:28.111
    Dec  3 13:27:28.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:27:28.112
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:28.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:28.144
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 12/03/22 13:27:28.152
    STEP: listing secrets in all namespaces to ensure that there are more than zero 12/03/22 13:27:28.16
    STEP: patching the secret 12/03/22 13:27:28.166
    STEP: deleting the secret using a LabelSelector 12/03/22 13:27:28.175
    STEP: listing secrets in all namespaces, searching for label name and value in patch 12/03/22 13:27:28.185
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:27:28.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7969" for this suite. 12/03/22 13:27:28.196
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:28.204
Dec  3 13:27:28.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:27:28.205
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:28.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:28.236
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 13:27:28.239
Dec  3 13:27:28.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec  3 13:27:28.320: INFO: stderr: ""
Dec  3 13:27:28.320: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 12/03/22 13:27:28.32
STEP: verifying the pod e2e-test-httpd-pod was created 12/03/22 13:27:33.37
Dec  3 13:27:33.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 get pod e2e-test-httpd-pod -o json'
Dec  3 13:27:33.443: INFO: stderr: ""
Dec  3 13:27:33.444: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-12-03T13:27:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2449\",\n        \"resourceVersion\": \"40376\",\n        \"uid\": \"3eaea9d4-e87d-434b-bb07-bec68af23cbb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-cdnbp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-38-234\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-cdnbp\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://04ae971cd5725f03304ad5cd4ebd4e1a2df1a0a004b08df5383753340618cd98\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-03T13:27:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.38.234\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.197.113\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.197.113\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-03T13:27:28Z\"\n    }\n}\n"
STEP: replace the image in the pod 12/03/22 13:27:33.444
Dec  3 13:27:33.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 replace -f -'
Dec  3 13:27:33.667: INFO: stderr: ""
Dec  3 13:27:33.668: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/03/22 13:27:33.668
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Dec  3 13:27:33.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 delete pods e2e-test-httpd-pod'
Dec  3 13:27:35.761: INFO: stderr: ""
Dec  3 13:27:35.761: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:27:35.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2449" for this suite. 12/03/22 13:27:35.769
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":345,"skipped":6344,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.575 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:28.204
    Dec  3 13:27:28.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:27:28.205
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:28.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:28.236
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/03/22 13:27:28.239
    Dec  3 13:27:28.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec  3 13:27:28.320: INFO: stderr: ""
    Dec  3 13:27:28.320: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 12/03/22 13:27:28.32
    STEP: verifying the pod e2e-test-httpd-pod was created 12/03/22 13:27:33.37
    Dec  3 13:27:33.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 get pod e2e-test-httpd-pod -o json'
    Dec  3 13:27:33.443: INFO: stderr: ""
    Dec  3 13:27:33.444: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-12-03T13:27:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2449\",\n        \"resourceVersion\": \"40376\",\n        \"uid\": \"3eaea9d4-e87d-434b-bb07-bec68af23cbb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-cdnbp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-38-234\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-cdnbp\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-03T13:27:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://04ae971cd5725f03304ad5cd4ebd4e1a2df1a0a004b08df5383753340618cd98\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-03T13:27:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.38.234\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.197.113\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.197.113\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-03T13:27:28Z\"\n    }\n}\n"
    STEP: replace the image in the pod 12/03/22 13:27:33.444
    Dec  3 13:27:33.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 replace -f -'
    Dec  3 13:27:33.667: INFO: stderr: ""
    Dec  3 13:27:33.668: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/03/22 13:27:33.668
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Dec  3 13:27:33.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-2449 delete pods e2e-test-httpd-pod'
    Dec  3 13:27:35.761: INFO: stderr: ""
    Dec  3 13:27:35.761: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:27:35.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2449" for this suite. 12/03/22 13:27:35.769
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:35.78
Dec  3 13:27:35.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename container-runtime 12/03/22 13:27:35.781
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:35.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:35.812
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 12/03/22 13:27:35.821
STEP: wait for the container to reach Succeeded 12/03/22 13:27:35.834
STEP: get the container status 12/03/22 13:27:39.862
STEP: the container should be terminated 12/03/22 13:27:39.866
STEP: the termination message should be set 12/03/22 13:27:39.866
Dec  3 13:27:39.866: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 12/03/22 13:27:39.866
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec  3 13:27:39.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9362" for this suite. 12/03/22 13:27:39.886
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":346,"skipped":6347,"failed":0}
------------------------------
â€¢ [4.205 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:35.78
    Dec  3 13:27:35.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename container-runtime 12/03/22 13:27:35.781
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:35.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:35.812
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 12/03/22 13:27:35.821
    STEP: wait for the container to reach Succeeded 12/03/22 13:27:35.834
    STEP: get the container status 12/03/22 13:27:39.862
    STEP: the container should be terminated 12/03/22 13:27:39.866
    STEP: the termination message should be set 12/03/22 13:27:39.866
    Dec  3 13:27:39.866: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 12/03/22 13:27:39.866
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec  3 13:27:39.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9362" for this suite. 12/03/22 13:27:39.886
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:39.987
Dec  3 13:27:39.987: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replication-controller 12/03/22 13:27:39.987
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:40.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:40.01
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 12/03/22 13:27:40.014
Dec  3 13:27:40.023: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2948" to be "running and ready"
Dec  3 13:27:40.026: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2769ms
Dec  3 13:27:40.026: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:27:42.033: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.009837552s
Dec  3 13:27:42.033: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Dec  3 13:27:42.033: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 12/03/22 13:27:42.037
STEP: Then the orphan pod is adopted 12/03/22 13:27:42.045
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec  3 13:27:43.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2948" for this suite. 12/03/22 13:27:43.059
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":347,"skipped":6387,"failed":0}
------------------------------
â€¢ [3.080 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:39.987
    Dec  3 13:27:39.987: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replication-controller 12/03/22 13:27:39.987
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:40.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:40.01
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 12/03/22 13:27:40.014
    Dec  3 13:27:40.023: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2948" to be "running and ready"
    Dec  3 13:27:40.026: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2769ms
    Dec  3 13:27:40.026: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:27:42.033: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.009837552s
    Dec  3 13:27:42.033: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Dec  3 13:27:42.033: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 12/03/22 13:27:42.037
    STEP: Then the orphan pod is adopted 12/03/22 13:27:42.045
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec  3 13:27:43.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2948" for this suite. 12/03/22 13:27:43.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:43.067
Dec  3 13:27:43.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename job 12/03/22 13:27:43.068
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:43.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:43.1
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 12/03/22 13:27:43.106
STEP: Ensuring active pods == parallelism 12/03/22 13:27:43.114
STEP: Orphaning one of the Job's Pods 12/03/22 13:27:45.12
Dec  3 13:27:45.639: INFO: Successfully updated pod "adopt-release-2lw5g"
STEP: Checking that the Job readopts the Pod 12/03/22 13:27:45.639
Dec  3 13:27:45.639: INFO: Waiting up to 15m0s for pod "adopt-release-2lw5g" in namespace "job-9316" to be "adopted"
Dec  3 13:27:45.642: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 3.468235ms
Dec  3 13:27:47.648: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.00905078s
Dec  3 13:27:47.648: INFO: Pod "adopt-release-2lw5g" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 12/03/22 13:27:47.648
Dec  3 13:27:48.161: INFO: Successfully updated pod "adopt-release-2lw5g"
STEP: Checking that the Job releases the Pod 12/03/22 13:27:48.161
Dec  3 13:27:48.161: INFO: Waiting up to 15m0s for pod "adopt-release-2lw5g" in namespace "job-9316" to be "released"
Dec  3 13:27:48.166: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 4.698973ms
Dec  3 13:27:50.170: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.008651953s
Dec  3 13:27:50.170: INFO: Pod "adopt-release-2lw5g" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec  3 13:27:50.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9316" for this suite. 12/03/22 13:27:50.173
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":348,"skipped":6402,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.113 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:43.067
    Dec  3 13:27:43.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename job 12/03/22 13:27:43.068
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:43.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:43.1
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 12/03/22 13:27:43.106
    STEP: Ensuring active pods == parallelism 12/03/22 13:27:43.114
    STEP: Orphaning one of the Job's Pods 12/03/22 13:27:45.12
    Dec  3 13:27:45.639: INFO: Successfully updated pod "adopt-release-2lw5g"
    STEP: Checking that the Job readopts the Pod 12/03/22 13:27:45.639
    Dec  3 13:27:45.639: INFO: Waiting up to 15m0s for pod "adopt-release-2lw5g" in namespace "job-9316" to be "adopted"
    Dec  3 13:27:45.642: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 3.468235ms
    Dec  3 13:27:47.648: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.00905078s
    Dec  3 13:27:47.648: INFO: Pod "adopt-release-2lw5g" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 12/03/22 13:27:47.648
    Dec  3 13:27:48.161: INFO: Successfully updated pod "adopt-release-2lw5g"
    STEP: Checking that the Job releases the Pod 12/03/22 13:27:48.161
    Dec  3 13:27:48.161: INFO: Waiting up to 15m0s for pod "adopt-release-2lw5g" in namespace "job-9316" to be "released"
    Dec  3 13:27:48.166: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 4.698973ms
    Dec  3 13:27:50.170: INFO: Pod "adopt-release-2lw5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.008651953s
    Dec  3 13:27:50.170: INFO: Pod "adopt-release-2lw5g" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec  3 13:27:50.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9316" for this suite. 12/03/22 13:27:50.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:50.182
Dec  3 13:27:50.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context-test 12/03/22 13:27:50.183
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:50.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:50.209
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Dec  3 13:27:50.222: INFO: Waiting up to 5m0s for pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3" in namespace "security-context-test-2271" to be "Succeeded or Failed"
Dec  3 13:27:50.226: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.871978ms
Dec  3 13:27:52.231: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009634746s
Dec  3 13:27:54.232: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010512246s
Dec  3 13:27:56.230: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007927145s
Dec  3 13:27:56.230: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 13:27:56.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2271" for this suite. 12/03/22 13:27:56.234
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":349,"skipped":6434,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.059 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:50.182
    Dec  3 13:27:50.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context-test 12/03/22 13:27:50.183
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:50.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:50.209
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Dec  3 13:27:50.222: INFO: Waiting up to 5m0s for pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3" in namespace "security-context-test-2271" to be "Succeeded or Failed"
    Dec  3 13:27:50.226: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.871978ms
    Dec  3 13:27:52.231: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009634746s
    Dec  3 13:27:54.232: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010512246s
    Dec  3 13:27:56.230: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007927145s
    Dec  3 13:27:56.230: INFO: Pod "busybox-user-65534-89fcae06-5bc2-4ccf-95e7-47af98477ca3" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 13:27:56.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2271" for this suite. 12/03/22 13:27:56.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:27:56.242
Dec  3 13:27:56.243: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:27:56.243
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:56.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:56.272
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-10424afc-f76e-4914-9013-8a856dc32066 12/03/22 13:27:56.276
STEP: Creating a pod to test consume secrets 12/03/22 13:27:56.281
Dec  3 13:27:56.295: INFO: Waiting up to 5m0s for pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7" in namespace "secrets-7305" to be "Succeeded or Failed"
Dec  3 13:27:56.299: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023015ms
Dec  3 13:27:58.305: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009764162s
Dec  3 13:28:00.305: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Running", Reason="", readiness=false. Elapsed: 4.009230401s
Dec  3 13:28:02.307: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011369264s
STEP: Saw pod success 12/03/22 13:28:02.307
Dec  3 13:28:02.307: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7" satisfied condition "Succeeded or Failed"
Dec  3 13:28:02.310: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 container secret-volume-test: <nil>
STEP: delete the pod 12/03/22 13:28:02.317
Dec  3 13:28:02.343: INFO: Waiting for pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 to disappear
Dec  3 13:28:02.348: INFO: Pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:28:02.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7305" for this suite. 12/03/22 13:28:02.353
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":350,"skipped":6443,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.118 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:27:56.242
    Dec  3 13:27:56.243: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:27:56.243
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:27:56.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:27:56.272
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-10424afc-f76e-4914-9013-8a856dc32066 12/03/22 13:27:56.276
    STEP: Creating a pod to test consume secrets 12/03/22 13:27:56.281
    Dec  3 13:27:56.295: INFO: Waiting up to 5m0s for pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7" in namespace "secrets-7305" to be "Succeeded or Failed"
    Dec  3 13:27:56.299: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023015ms
    Dec  3 13:27:58.305: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009764162s
    Dec  3 13:28:00.305: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Running", Reason="", readiness=false. Elapsed: 4.009230401s
    Dec  3 13:28:02.307: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011369264s
    STEP: Saw pod success 12/03/22 13:28:02.307
    Dec  3 13:28:02.307: INFO: Pod "pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7" satisfied condition "Succeeded or Failed"
    Dec  3 13:28:02.310: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 container secret-volume-test: <nil>
    STEP: delete the pod 12/03/22 13:28:02.317
    Dec  3 13:28:02.343: INFO: Waiting for pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 to disappear
    Dec  3 13:28:02.348: INFO: Pod pod-secrets-1a69bb11-0dc4-43f6-8db5-4f631070feb7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:28:02.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7305" for this suite. 12/03/22 13:28:02.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:02.363
Dec  3 13:28:02.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename replicaset 12/03/22 13:28:02.364
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:02.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:02.388
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 12/03/22 13:28:02.39
STEP: Verify that the required pods have come up 12/03/22 13:28:02.399
Dec  3 13:28:02.402: INFO: Pod name sample-pod: Found 0 pods out of 3
Dec  3 13:28:07.407: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 12/03/22 13:28:07.407
Dec  3 13:28:07.411: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 12/03/22 13:28:07.411
STEP: DeleteCollection of the ReplicaSets 12/03/22 13:28:07.415
STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/03/22 13:28:07.424
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec  3 13:28:07.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9088" for this suite. 12/03/22 13:28:07.432
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":351,"skipped":6460,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.076 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:02.363
    Dec  3 13:28:02.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename replicaset 12/03/22 13:28:02.364
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:02.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:02.388
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 12/03/22 13:28:02.39
    STEP: Verify that the required pods have come up 12/03/22 13:28:02.399
    Dec  3 13:28:02.402: INFO: Pod name sample-pod: Found 0 pods out of 3
    Dec  3 13:28:07.407: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 12/03/22 13:28:07.407
    Dec  3 13:28:07.411: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 12/03/22 13:28:07.411
    STEP: DeleteCollection of the ReplicaSets 12/03/22 13:28:07.415
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/03/22 13:28:07.424
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec  3 13:28:07.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9088" for this suite. 12/03/22 13:28:07.432
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:07.44
Dec  3 13:28:07.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename secrets 12/03/22 13:28:07.441
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:07.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:07.465
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-8cf3a7ab-6045-4472-9736-455dece4adfb 12/03/22 13:28:07.472
STEP: Creating a pod to test consume secrets 12/03/22 13:28:07.482
Dec  3 13:28:07.490: INFO: Waiting up to 5m0s for pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae" in namespace "secrets-821" to be "Succeeded or Failed"
Dec  3 13:28:07.494: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.953953ms
Dec  3 13:28:09.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009166287s
Dec  3 13:28:11.500: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010119701s
Dec  3 13:28:13.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009595603s
STEP: Saw pod success 12/03/22 13:28:13.499
Dec  3 13:28:13.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae" satisfied condition "Succeeded or Failed"
Dec  3 13:28:13.503: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae container secret-env-test: <nil>
STEP: delete the pod 12/03/22 13:28:13.51
Dec  3 13:28:13.521: INFO: Waiting for pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae to disappear
Dec  3 13:28:13.526: INFO: Pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec  3 13:28:13.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-821" for this suite. 12/03/22 13:28:13.53
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":352,"skipped":6465,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.097 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:07.44
    Dec  3 13:28:07.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename secrets 12/03/22 13:28:07.441
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:07.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:07.465
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-8cf3a7ab-6045-4472-9736-455dece4adfb 12/03/22 13:28:07.472
    STEP: Creating a pod to test consume secrets 12/03/22 13:28:07.482
    Dec  3 13:28:07.490: INFO: Waiting up to 5m0s for pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae" in namespace "secrets-821" to be "Succeeded or Failed"
    Dec  3 13:28:07.494: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.953953ms
    Dec  3 13:28:09.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009166287s
    Dec  3 13:28:11.500: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010119701s
    Dec  3 13:28:13.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009595603s
    STEP: Saw pod success 12/03/22 13:28:13.499
    Dec  3 13:28:13.499: INFO: Pod "pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae" satisfied condition "Succeeded or Failed"
    Dec  3 13:28:13.503: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae container secret-env-test: <nil>
    STEP: delete the pod 12/03/22 13:28:13.51
    Dec  3 13:28:13.521: INFO: Waiting for pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae to disappear
    Dec  3 13:28:13.526: INFO: Pod pod-secrets-fa68cb51-6c94-473e-be4b-20c352b02fae no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec  3 13:28:13.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-821" for this suite. 12/03/22 13:28:13.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:13.541
Dec  3 13:28:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:28:13.543
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:13.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:13.564
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:28:13.582
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:28:13.921
STEP: Deploying the webhook pod 12/03/22 13:28:13.93
STEP: Wait for the deployment to be ready 12/03/22 13:28:13.946
Dec  3 13:28:13.954: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 13:28:15.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 13, 28, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/03/22 13:28:17.972
STEP: Verifying the service has paired with the endpoint 12/03/22 13:28:17.984
Dec  3 13:28:18.984: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Dec  3 13:28:18.989: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6253-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 13:28:19.51
Dec  3 13:28:19.533: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version 12/03/22 13:28:19.644
STEP: Patching Custom Resource Definition to set v2 as storage 12/03/22 13:28:21.711
STEP: Patching the custom resource while v2 is storage version 12/03/22 13:28:21.744
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:28:22.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6125" for this suite. 12/03/22 13:28:22.336
STEP: Destroying namespace "webhook-6125-markers" for this suite. 12/03/22 13:28:22.343
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":353,"skipped":6512,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.912 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:13.541
    Dec  3 13:28:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:28:13.543
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:13.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:13.564
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:28:13.582
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:28:13.921
    STEP: Deploying the webhook pod 12/03/22 13:28:13.93
    STEP: Wait for the deployment to be ready 12/03/22 13:28:13.946
    Dec  3 13:28:13.954: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Dec  3 13:28:15.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 3, 13, 28, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 3, 13, 28, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/03/22 13:28:17.972
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:28:17.984
    Dec  3 13:28:18.984: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Dec  3 13:28:18.989: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6253-crds.webhook.example.com via the AdmissionRegistration API 12/03/22 13:28:19.51
    Dec  3 13:28:19.533: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource while v1 is storage version 12/03/22 13:28:19.644
    STEP: Patching Custom Resource Definition to set v2 as storage 12/03/22 13:28:21.711
    STEP: Patching the custom resource while v2 is storage version 12/03/22 13:28:21.744
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:28:22.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6125" for this suite. 12/03/22 13:28:22.336
    STEP: Destroying namespace "webhook-6125-markers" for this suite. 12/03/22 13:28:22.343
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:22.456
Dec  3 13:28:22.457: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:28:22.458
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:22.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:22.525
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 12/03/22 13:28:22.529
Dec  3 13:28:22.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9" in namespace "projected-4850" to be "Succeeded or Failed"
Dec  3 13:28:22.558: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.693289ms
Dec  3 13:28:24.563: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011954641s
Dec  3 13:28:26.563: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012592591s
STEP: Saw pod success 12/03/22 13:28:26.563
Dec  3 13:28:26.564: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9" satisfied condition "Succeeded or Failed"
Dec  3 13:28:26.567: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 container client-container: <nil>
STEP: delete the pod 12/03/22 13:28:26.575
Dec  3 13:28:26.639: INFO: Waiting for pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 to disappear
Dec  3 13:28:26.642: INFO: Pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec  3 13:28:26.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4850" for this suite. 12/03/22 13:28:26.648
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":354,"skipped":6545,"failed":0}
------------------------------
â€¢ [4.220 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:22.456
    Dec  3 13:28:22.457: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:28:22.458
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:22.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:22.525
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 12/03/22 13:28:22.529
    Dec  3 13:28:22.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9" in namespace "projected-4850" to be "Succeeded or Failed"
    Dec  3 13:28:22.558: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.693289ms
    Dec  3 13:28:24.563: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011954641s
    Dec  3 13:28:26.563: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012592591s
    STEP: Saw pod success 12/03/22 13:28:26.563
    Dec  3 13:28:26.564: INFO: Pod "downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9" satisfied condition "Succeeded or Failed"
    Dec  3 13:28:26.567: INFO: Trying to get logs from node ip-172-31-38-234 pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 container client-container: <nil>
    STEP: delete the pod 12/03/22 13:28:26.575
    Dec  3 13:28:26.639: INFO: Waiting for pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 to disappear
    Dec  3 13:28:26.642: INFO: Pod downwardapi-volume-ca954929-101e-4a52-b49d-ece4180815c9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec  3 13:28:26.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4850" for this suite. 12/03/22 13:28:26.648
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:26.678
Dec  3 13:28:26.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename security-context 12/03/22 13:28:26.679
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:26.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:26.717
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/03/22 13:28:26.749
Dec  3 13:28:26.764: INFO: Waiting up to 5m0s for pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad" in namespace "security-context-6508" to be "Succeeded or Failed"
Dec  3 13:28:26.787: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 23.367595ms
Dec  3 13:28:28.792: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028578956s
Dec  3 13:28:30.795: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031464411s
Dec  3 13:28:32.793: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029432366s
STEP: Saw pod success 12/03/22 13:28:32.793
Dec  3 13:28:32.793: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad" satisfied condition "Succeeded or Failed"
Dec  3 13:28:32.797: INFO: Trying to get logs from node ip-172-31-38-234 pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad container test-container: <nil>
STEP: delete the pod 12/03/22 13:28:32.804
Dec  3 13:28:32.820: INFO: Waiting for pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad to disappear
Dec  3 13:28:32.823: INFO: Pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec  3 13:28:32.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-6508" for this suite. 12/03/22 13:28:32.827
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":355,"skipped":6549,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.158 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:26.678
    Dec  3 13:28:26.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename security-context 12/03/22 13:28:26.679
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:26.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:26.717
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/03/22 13:28:26.749
    Dec  3 13:28:26.764: INFO: Waiting up to 5m0s for pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad" in namespace "security-context-6508" to be "Succeeded or Failed"
    Dec  3 13:28:26.787: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 23.367595ms
    Dec  3 13:28:28.792: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028578956s
    Dec  3 13:28:30.795: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031464411s
    Dec  3 13:28:32.793: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029432366s
    STEP: Saw pod success 12/03/22 13:28:32.793
    Dec  3 13:28:32.793: INFO: Pod "security-context-91745fa0-8d18-4788-9f7b-6d58195108ad" satisfied condition "Succeeded or Failed"
    Dec  3 13:28:32.797: INFO: Trying to get logs from node ip-172-31-38-234 pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad container test-container: <nil>
    STEP: delete the pod 12/03/22 13:28:32.804
    Dec  3 13:28:32.820: INFO: Waiting for pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad to disappear
    Dec  3 13:28:32.823: INFO: Pod security-context-91745fa0-8d18-4788-9f7b-6d58195108ad no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec  3 13:28:32.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-6508" for this suite. 12/03/22 13:28:32.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:32.839
Dec  3 13:28:32.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename webhook 12/03/22 13:28:32.841
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:32.863
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:32.867
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/03/22 13:28:32.894
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:28:33.325
STEP: Deploying the webhook pod 12/03/22 13:28:33.333
STEP: Wait for the deployment to be ready 12/03/22 13:28:33.347
Dec  3 13:28:33.371: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/03/22 13:28:35.383
STEP: Verifying the service has paired with the endpoint 12/03/22 13:28:35.397
Dec  3 13:28:36.397: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/03/22 13:28:36.403
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/03/22 13:28:36.418
STEP: Creating a dummy validating-webhook-configuration object 12/03/22 13:28:36.434
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/03/22 13:28:36.445
STEP: Creating a dummy mutating-webhook-configuration object 12/03/22 13:28:36.452
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/03/22 13:28:36.463
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:28:36.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5582" for this suite. 12/03/22 13:28:36.49
STEP: Destroying namespace "webhook-5582-markers" for this suite. 12/03/22 13:28:36.497
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":356,"skipped":6579,"failed":0}
------------------------------
â€¢ [3.711 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:32.839
    Dec  3 13:28:32.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename webhook 12/03/22 13:28:32.841
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:32.863
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:32.867
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/03/22 13:28:32.894
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/03/22 13:28:33.325
    STEP: Deploying the webhook pod 12/03/22 13:28:33.333
    STEP: Wait for the deployment to be ready 12/03/22 13:28:33.347
    Dec  3 13:28:33.371: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/03/22 13:28:35.383
    STEP: Verifying the service has paired with the endpoint 12/03/22 13:28:35.397
    Dec  3 13:28:36.397: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/03/22 13:28:36.403
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/03/22 13:28:36.418
    STEP: Creating a dummy validating-webhook-configuration object 12/03/22 13:28:36.434
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/03/22 13:28:36.445
    STEP: Creating a dummy mutating-webhook-configuration object 12/03/22 13:28:36.452
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/03/22 13:28:36.463
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:28:36.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5582" for this suite. 12/03/22 13:28:36.49
    STEP: Destroying namespace "webhook-5582-markers" for this suite. 12/03/22 13:28:36.497
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:36.552
Dec  3 13:28:36.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename kubectl 12/03/22 13:28:36.553
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:36.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:36.58
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 12/03/22 13:28:36.583
Dec  3 13:28:36.583: INFO: namespace kubectl-3949
Dec  3 13:28:36.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 create -f -'
Dec  3 13:28:37.410: INFO: stderr: ""
Dec  3 13:28:37.411: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/03/22 13:28:37.411
Dec  3 13:28:38.415: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:28:38.415: INFO: Found 0 / 1
Dec  3 13:28:39.416: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:28:39.416: INFO: Found 1 / 1
Dec  3 13:28:39.416: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 13:28:39.420: INFO: Selector matched 1 pods for map[app:agnhost]
Dec  3 13:28:39.420: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 13:28:39.420: INFO: wait on agnhost-primary startup in kubectl-3949 
Dec  3 13:28:39.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 logs agnhost-primary-ks2tb agnhost-primary'
Dec  3 13:28:39.517: INFO: stderr: ""
Dec  3 13:28:39.517: INFO: stdout: "Paused\n"
STEP: exposing RC 12/03/22 13:28:39.517
Dec  3 13:28:39.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Dec  3 13:28:39.623: INFO: stderr: ""
Dec  3 13:28:39.623: INFO: stdout: "service/rm2 exposed\n"
Dec  3 13:28:39.631: INFO: Service rm2 in namespace kubectl-3949 found.
STEP: exposing service 12/03/22 13:28:41.639
Dec  3 13:28:41.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Dec  3 13:28:41.739: INFO: stderr: ""
Dec  3 13:28:41.739: INFO: stdout: "service/rm3 exposed\n"
Dec  3 13:28:41.745: INFO: Service rm3 in namespace kubectl-3949 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec  3 13:28:43.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3949" for this suite. 12/03/22 13:28:43.758
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":357,"skipped":6590,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.215 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:36.552
    Dec  3 13:28:36.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename kubectl 12/03/22 13:28:36.553
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:36.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:36.58
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 12/03/22 13:28:36.583
    Dec  3 13:28:36.583: INFO: namespace kubectl-3949
    Dec  3 13:28:36.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 create -f -'
    Dec  3 13:28:37.410: INFO: stderr: ""
    Dec  3 13:28:37.411: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/03/22 13:28:37.411
    Dec  3 13:28:38.415: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:28:38.415: INFO: Found 0 / 1
    Dec  3 13:28:39.416: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:28:39.416: INFO: Found 1 / 1
    Dec  3 13:28:39.416: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec  3 13:28:39.420: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec  3 13:28:39.420: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec  3 13:28:39.420: INFO: wait on agnhost-primary startup in kubectl-3949 
    Dec  3 13:28:39.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 logs agnhost-primary-ks2tb agnhost-primary'
    Dec  3 13:28:39.517: INFO: stderr: ""
    Dec  3 13:28:39.517: INFO: stdout: "Paused\n"
    STEP: exposing RC 12/03/22 13:28:39.517
    Dec  3 13:28:39.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Dec  3 13:28:39.623: INFO: stderr: ""
    Dec  3 13:28:39.623: INFO: stdout: "service/rm2 exposed\n"
    Dec  3 13:28:39.631: INFO: Service rm2 in namespace kubectl-3949 found.
    STEP: exposing service 12/03/22 13:28:41.639
    Dec  3 13:28:41.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3232811020 --namespace=kubectl-3949 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Dec  3 13:28:41.739: INFO: stderr: ""
    Dec  3 13:28:41.739: INFO: stdout: "service/rm3 exposed\n"
    Dec  3 13:28:41.745: INFO: Service rm3 in namespace kubectl-3949 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec  3 13:28:43.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3949" for this suite. 12/03/22 13:28:43.758
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:28:43.767
Dec  3 13:28:43.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-watch 12/03/22 13:28:43.768
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:43.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:43.796
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Dec  3 13:28:43.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Creating first CR  12/03/22 13:28:46.369
Dec  3 13:28:46.375: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:28:46Z]] name:name1 resourceVersion:41216 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 12/03/22 13:28:56.377
Dec  3 13:28:56.387: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:28:56Z]] name:name2 resourceVersion:41265 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 12/03/22 13:29:06.39
Dec  3 13:29:06.398: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:06Z]] name:name1 resourceVersion:41285 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 12/03/22 13:29:16.399
Dec  3 13:29:16.408: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:16Z]] name:name2 resourceVersion:41304 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 12/03/22 13:29:26.409
Dec  3 13:29:26.417: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:06Z]] name:name1 resourceVersion:41323 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 12/03/22 13:29:36.418
Dec  3 13:29:36.427: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:16Z]] name:name2 resourceVersion:41343 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:29:46.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-820" for this suite. 12/03/22 13:29:46.948
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":358,"skipped":6596,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.194 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:28:43.767
    Dec  3 13:28:43.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-watch 12/03/22 13:28:43.768
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:28:43.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:28:43.796
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Dec  3 13:28:43.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Creating first CR  12/03/22 13:28:46.369
    Dec  3 13:28:46.375: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:28:46Z]] name:name1 resourceVersion:41216 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 12/03/22 13:28:56.377
    Dec  3 13:28:56.387: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:28:56Z]] name:name2 resourceVersion:41265 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 12/03/22 13:29:06.39
    Dec  3 13:29:06.398: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:06Z]] name:name1 resourceVersion:41285 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 12/03/22 13:29:16.399
    Dec  3 13:29:16.408: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:16Z]] name:name2 resourceVersion:41304 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 12/03/22 13:29:26.409
    Dec  3 13:29:26.417: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:46Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:06Z]] name:name1 resourceVersion:41323 uid:4b0d581f-f7d9-4b17-9aa0-906397021bbd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 12/03/22 13:29:36.418
    Dec  3 13:29:36.427: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-03T13:28:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-03T13:29:16Z]] name:name2 resourceVersion:41343 uid:ee0a5881-6e5f-493f-b3ef-7ea5778b47f0] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:29:46.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-820" for this suite. 12/03/22 13:29:46.948
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:29:46.962
Dec  3 13:29:46.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:29:46.963
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:29:46.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:29:46.985
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/03/22 13:29:46.989
Dec  3 13:29:46.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
Dec  3 13:29:49.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec  3 13:29:59.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6994" for this suite. 12/03/22 13:29:59.475
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":359,"skipped":6600,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.523 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:29:46.962
    Dec  3 13:29:46.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename crd-publish-openapi 12/03/22 13:29:46.963
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:29:46.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:29:46.985
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/03/22 13:29:46.989
    Dec  3 13:29:46.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    Dec  3 13:29:49.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec  3 13:29:59.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6994" for this suite. 12/03/22 13:29:59.475
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:29:59.487
Dec  3 13:29:59.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename sched-preemption 12/03/22 13:29:59.488
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:29:59.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:29:59.51
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec  3 13:29:59.541: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 13:30:59.569: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 12/03/22 13:30:59.573
Dec  3 13:30:59.604: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec  3 13:30:59.621: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec  3 13:30:59.648: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec  3 13:30:59.659: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Dec  3 13:30:59.683: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Dec  3 13:30:59.695: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/03/22 13:30:59.695
Dec  3 13:30:59.695: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:30:59.699: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.476952ms
Dec  3 13:31:01.705: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010107024s
Dec  3 13:31:03.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010779468s
Dec  3 13:31:05.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.010849004s
Dec  3 13:31:05.706: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec  3 13:31:05.706: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:31:05.711: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.88719ms
Dec  3 13:31:05.711: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 13:31:05.711: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:31:05.715: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884018ms
Dec  3 13:31:07.722: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011175924s
Dec  3 13:31:09.722: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.010848131s
Dec  3 13:31:09.722: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 13:31:09.722: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:31:09.727: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.692869ms
Dec  3 13:31:09.727: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 13:31:09.727: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:31:09.733: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.809845ms
Dec  3 13:31:09.733: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Dec  3 13:31:09.733: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
Dec  3 13:31:09.737: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.623961ms
Dec  3 13:31:09.737: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 12/03/22 13:31:09.737
Dec  3 13:31:09.753: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Dec  3 13:31:09.758: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.718456ms
Dec  3 13:31:11.764: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010068336s
Dec  3 13:31:13.764: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010558573s
Dec  3 13:31:13.764: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec  3 13:31:13.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1438" for this suite. 12/03/22 13:31:13.826
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":360,"skipped":6643,"failed":0}
------------------------------
â€¢ [SLOW TEST] [74.406 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:29:59.487
    Dec  3 13:29:59.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename sched-preemption 12/03/22 13:29:59.488
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:29:59.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:29:59.51
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec  3 13:29:59.541: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec  3 13:30:59.569: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 12/03/22 13:30:59.573
    Dec  3 13:30:59.604: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec  3 13:30:59.621: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec  3 13:30:59.648: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec  3 13:30:59.659: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Dec  3 13:30:59.683: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Dec  3 13:30:59.695: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/03/22 13:30:59.695
    Dec  3 13:30:59.695: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:30:59.699: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.476952ms
    Dec  3 13:31:01.705: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010107024s
    Dec  3 13:31:03.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010779468s
    Dec  3 13:31:05.706: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.010849004s
    Dec  3 13:31:05.706: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec  3 13:31:05.706: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:31:05.711: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.88719ms
    Dec  3 13:31:05.711: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 13:31:05.711: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:31:05.715: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884018ms
    Dec  3 13:31:07.722: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011175924s
    Dec  3 13:31:09.722: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.010848131s
    Dec  3 13:31:09.722: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 13:31:09.722: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:31:09.727: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.692869ms
    Dec  3 13:31:09.727: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 13:31:09.727: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:31:09.733: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.809845ms
    Dec  3 13:31:09.733: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec  3 13:31:09.733: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1438" to be "running"
    Dec  3 13:31:09.737: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.623961ms
    Dec  3 13:31:09.737: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 12/03/22 13:31:09.737
    Dec  3 13:31:09.753: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Dec  3 13:31:09.758: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.718456ms
    Dec  3 13:31:11.764: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010068336s
    Dec  3 13:31:13.764: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010558573s
    Dec  3 13:31:13.764: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec  3 13:31:13.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1438" for this suite. 12/03/22 13:31:13.826
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:31:13.898
Dec  3 13:31:13.899: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename projected 12/03/22 13:31:13.899
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:31:13.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:31:13.95
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-4ab684a5-e989-48ac-aa8a-ca96b77eadfd 12/03/22 13:31:13.954
STEP: Creating a pod to test consume configMaps 12/03/22 13:31:13.962
Dec  3 13:31:13.981: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40" in namespace "projected-1852" to be "Succeeded or Failed"
Dec  3 13:31:13.989: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Pending", Reason="", readiness=false. Elapsed: 8.441449ms
Dec  3 13:31:15.996: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014921337s
Dec  3 13:31:17.995: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014631556s
STEP: Saw pod success 12/03/22 13:31:17.996
Dec  3 13:31:17.996: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40" satisfied condition "Succeeded or Failed"
Dec  3 13:31:18.002: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 container agnhost-container: <nil>
STEP: delete the pod 12/03/22 13:31:18.024
Dec  3 13:31:18.044: INFO: Waiting for pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 to disappear
Dec  3 13:31:18.049: INFO: Pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec  3 13:31:18.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1852" for this suite. 12/03/22 13:31:18.055
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":361,"skipped":6677,"failed":0}
------------------------------
â€¢ [4.172 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:31:13.898
    Dec  3 13:31:13.899: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename projected 12/03/22 13:31:13.899
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:31:13.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:31:13.95
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-4ab684a5-e989-48ac-aa8a-ca96b77eadfd 12/03/22 13:31:13.954
    STEP: Creating a pod to test consume configMaps 12/03/22 13:31:13.962
    Dec  3 13:31:13.981: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40" in namespace "projected-1852" to be "Succeeded or Failed"
    Dec  3 13:31:13.989: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Pending", Reason="", readiness=false. Elapsed: 8.441449ms
    Dec  3 13:31:15.996: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014921337s
    Dec  3 13:31:17.995: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014631556s
    STEP: Saw pod success 12/03/22 13:31:17.996
    Dec  3 13:31:17.996: INFO: Pod "pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40" satisfied condition "Succeeded or Failed"
    Dec  3 13:31:18.002: INFO: Trying to get logs from node ip-172-31-38-234 pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 container agnhost-container: <nil>
    STEP: delete the pod 12/03/22 13:31:18.024
    Dec  3 13:31:18.044: INFO: Waiting for pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 to disappear
    Dec  3 13:31:18.049: INFO: Pod pod-projected-configmaps-18acca4b-ffde-4d36-84d5-3127a9610b40 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec  3 13:31:18.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1852" for this suite. 12/03/22 13:31:18.055
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/03/22 13:31:18.072
Dec  3 13:31:18.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: Building a namespace api object, basename pods 12/03/22 13:31:18.073
STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:31:18.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:31:18.107
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Dec  3 13:31:18.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
STEP: creating the pod 12/03/22 13:31:18.112
STEP: submitting the pod to kubernetes 12/03/22 13:31:18.113
Dec  3 13:31:18.125: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a" in namespace "pods-47" to be "running and ready"
Dec  3 13:31:18.132: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12ms
Dec  3 13:31:18.132: INFO: The phase of Pod pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a is Pending, waiting for it to be Running (with Ready = true)
Dec  3 13:31:20.138: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013782736s
Dec  3 13:31:20.138: INFO: The phase of Pod pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a is Running (Ready = true)
Dec  3 13:31:20.138: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec  3 13:31:20.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-47" for this suite. 12/03/22 13:31:20.183
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":362,"skipped":6697,"failed":0}
------------------------------
â€¢ [2.121 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/03/22 13:31:18.072
    Dec  3 13:31:18.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: Building a namespace api object, basename pods 12/03/22 13:31:18.073
    STEP: Waiting for a default service account to be provisioned in namespace 12/03/22 13:31:18.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/03/22 13:31:18.107
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Dec  3 13:31:18.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3232811020
    STEP: creating the pod 12/03/22 13:31:18.112
    STEP: submitting the pod to kubernetes 12/03/22 13:31:18.113
    Dec  3 13:31:18.125: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a" in namespace "pods-47" to be "running and ready"
    Dec  3 13:31:18.132: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12ms
    Dec  3 13:31:18.132: INFO: The phase of Pod pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a is Pending, waiting for it to be Running (with Ready = true)
    Dec  3 13:31:20.138: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013782736s
    Dec  3 13:31:20.138: INFO: The phase of Pod pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a is Running (Ready = true)
    Dec  3 13:31:20.138: INFO: Pod "pod-logs-websocket-1949b702-4b0c-4e9e-8471-f8514303566a" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec  3 13:31:20.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-47" for this suite. 12/03/22 13:31:20.183
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Dec  3 13:31:20.197: INFO: Running AfterSuite actions on all nodes
Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Dec  3 13:31:20.198: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Dec  3 13:31:20.198: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Dec  3 13:31:20.198: INFO: Running AfterSuite actions on node 1
Dec  3 13:31:20.198: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.001 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec  3 13:31:20.197: INFO: Running AfterSuite actions on all nodes
    Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Dec  3 13:31:20.197: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Dec  3 13:31:20.198: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Dec  3 13:31:20.198: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec  3 13:31:20.198: INFO: Running AfterSuite actions on node 1
    Dec  3 13:31:20.198: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.096 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5685.683 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h34m46.088567179s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

